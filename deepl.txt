DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
深度学习
2017年4月9日DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
iiDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录
致谢 xvi
数学符号 xvii
第一章 前言 1
1.1本书面向的读者 . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.2深度学习的历史趋势 . . . . . . . . . . . . . . . . . . . . . . . 11
1.2.1 神经网络的众多名称和命运变迁 . . . . . . . . . . . 12
1.2.2 与日俱增的数据量 . . . . . . . . . . . . . . . . . . . 17
1.2.3 与日俱增的模型规模 . . . . . . . . . . . . . . . . . . 19
1.2.4 与日俱增的精度、复杂度和对现实世界的冲击 . . . . 22
第一部分 应用数学与机器学习基础 25
第二章 线性代数 27
2.1标量、向量、矩阵和张量 . . . . . . . . . . . . . . . . . . . . 27
2.2矩阵和向量相乘 . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.3单位矩阵和逆矩阵 . . . . . . . . . . . . . . . . . . . . . . . . 31
2.4线性相关和生成子空间 . . . . . . . . . . . . . . . . . . . . . . 32
2.5范数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.6特殊类型的矩阵和向量 . . . . . . . . . . . . . . . . . . . . . . 36
2.7特征分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
2.8奇异值分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.9 Moore-Penrose 伪逆 . . . . . . . . . . . . . . . . . . . . . . . 40
iiiDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
iv 目录
2.10迹运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.11行列式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
2.12实例：主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . 42
第三章 概率与信息论 47
3.1为什么要使用概率？ . . . . . . . . . . . . . . . . . . . . . . . 47
3.2随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3.3.1 离散型变量和概率质量函数 . . . . . . . . . . . . . . 50
3.3.2 连续型变量和概率密度函数 . . . . . . . . . . . . . . 51
3.4边缘概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.5条件概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.6条件概率的链式法则 . . . . . . . . . . . . . . . . . . . . . . . 53
3.7独立性和条件独立性 . . . . . . . . . . . . . . . . . . . . . . . 53
3.8期望、方差和协方差 . . . . . . . . . . . . . . . . . . . . . . . 54
3.9常用概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.9.1 Bernoulli 分布 . . . . . . . . . . . . . . . . . . . . . 56
3.9.2 Multinoulli 分布 . . . . . . . . . . . . . . . . . . . . 56
3.9.3 高斯分布 . . . . . . . . . . . . . . . . . . . . . . . . 57
3.9.4 指数分布和 Laplace分布 . . . . . . . . . . . . . . . 58
3.9.5 Dirac 分布和经验分布 . . . . . . . . . . . . . . . . . 59
3.9.6 分布的混合 . . . . . . . . . . . . . . . . . . . . . . . 59
3.10常用函数的有用性质 . . . . . . . . . . . . . . . . . . . . . . . 61
3.11贝叶斯规则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.12连续型变量的技术细节 . . . . . . . . . . . . . . . . . . . . . . 64
3.13信息论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.14结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 69
第四章 数值计算 72
4.1上溢和下溢 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
4.2病态条件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
4.3基于梯度的优化方法 . . . . . . . . . . . . . . . . . . . . . . . 74
4.3.1 梯度之上： Jacobian 和Hessian矩阵 . . . . . . . . . 77DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 v
4.4约束优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
4.5实例：线性最小二乘 . . . . . . . . . . . . . . . . . . . . . . . 85
第五章 机器学习基础 87
5.1学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
5.1.1 任务 T. . . . . . . . . . . . . . . . . . . . . . . . . 88
5.1.2 性能度量 P. . . . . . . . . . . . . . . . . . . . . . . 91
5.1.3 经验 E. . . . . . . . . . . . . . . . . . . . . . . . . 92
5.1.4 示例：线性回归 . . . . . . . . . . . . . . . . . . . . 94
5.2容量、过拟合和欠拟合 . . . . . . . . . . . . . . . . . . . . . . 97
5.2.1 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . 102
5.2.2 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . 104
5.3超参数和验证集 . . . . . . . . . . . . . . . . . . . . . . . . . . 105
5.3.1 交叉验证 . . . . . . . . . . . . . . . . . . . . . . . . 106
5.4估计、偏差和方差 . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4.1 点估计 . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4.2 偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
5.4.3 方差和标准差 . . . . . . . . . . . . . . . . . . . . . . 111
5.4.4 权衡偏差和方差以最小化均方误差 . . . . . . . . . . 113
5.4.5 一致性 . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.5最大似然估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.5.1 条件对数似然和均方误差 . . . . . . . . . . . . . . . 116
5.5.2 最大似然的性质 . . . . . . . . . . . . . . . . . . . . 117
5.6贝叶斯统计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.6.1 最大后验 (MAP)估计 . . . . . . . . . . . . . . . . . 121
5.7监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.7.1 概率监督学习 . . . . . . . . . . . . . . . . . . . . . . 122
5.7.2 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . 123
5.7.3 其他简单的监督学习算法 . . . . . . . . . . . . . . . 125
5.8无监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . 128
5.8.1 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . 128
5.8.2 k-均值聚类 . . . . . . . . . . . . . . . . . . . . . . . 131
5.9随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . 132DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
vi 目录
5.10构建机器学习算法 . . . . . . . . . . . . . . . . . . . . . . . . 133
5.11促使深度学习发展的挑战 . . . . . . . . . . . . . . . . . . . . 134
5.11.1 维数灾难 . . . . . . . . . . . . . . . . . . . . . . . . 135
5.11.2 局部不变性和平滑正则化 . . . . . . . . . . . . . . . 135
5.11.3 流形学习 . . . . . . . . . . . . . . . . . . . . . . . . 139
第二部分 深层网络：现代实践 143
第六章 深度前馈网络 145
6.1实例：学习 XOR . . . . . . . . . . . . . . . . . . . . . . . . . 148
6.2基于梯度的学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 152
6.2.1 代价函数 . . . . . . . . . . . . . . . . . . . . . . . . 153
6.2.1.1 使用最大似然学习条件分布 . . . . . . . . . . . . . 154
6.2.1.2 学习条件统计量 . . . . . . . . . . . . . . . . . . . . 155
6.2.2 输出单元 . . . . . . . . . . . . . . . . . . . . . . . . 156
6.2.2.1 用于高斯输出分布的线性单元 . . . . . . . . . . . . 156
6.2.2.2 用于 Bernoulli 输出分布的 sigmoid单元 . . . . . . 157
6.2.2.3 用于 Multinoulli 输出分布的 softmax 单元 . . . . . 159
6.2.2.4 其他的输出类型 . . . . . . . . . . . . . . . . . . . . 161
6.3隐藏单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
6.3.1 整流线性单元及其扩展 . . . . . . . . . . . . . . . . . 166
6.3.2 logistic sigmoid 与双曲正切函数 . . . . . . . . . . . 168
6.3.3 其他隐藏单元 . . . . . . . . . . . . . . . . . . . . . . 168
6.4架构设计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
6.4.1 万能近似性质和深度 . . . . . . . . . . . . . . . . . . 170
6.4.2 其他架构上的考虑 . . . . . . . . . . . . . . . . . . . 173
6.5反向传播和其他的微分算法 . . . . . . . . . . . . . . . . . . . 175
6.5.1 计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . 176
6.5.2 微积分中的链式法则 . . . . . . . . . . . . . . . . . . 176
6.5.3 递归地使用链式法则来实现反向传播 . . . . . . . . . 178
6.5.4 全连接 MLP中的反向传播计算 . . . . . . . . . . . . 180
6.5.5 符号到符号的导数 . . . . . . . . . . . . . . . . . . . 181DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 vii
6.5.6 一般化的反向传播 . . . . . . . . . . . . . . . . . . . 183
6.5.7 实例：用于 MLP训练的反向传播 . . . . . . . . . . 187
6.5.8 复杂化 . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.5.9 深度学习界以外的微分 . . . . . . . . . . . . . . . . . 191
6.5.10 高阶微分 . . . . . . . . . . . . . . . . . . . . . . . . 192
6.6历史小记 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
第七章 深度学习中的正则化 196
7.1参数范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
7.1.1 L2参数正则化 . . . . . . . . . . . . . . . . . . . . . 198
7.1.2 L1参数正则化 . . . . . . . . . . . . . . . . . . . . . 201
7.2作为约束的范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . 203
7.3正则化和欠约束问题 . . . . . . . . . . . . . . . . . . . . . . . 205
7.4数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
7.5噪声鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
7.5.1 向输出目标注入噪声 . . . . . . . . . . . . . . . . . . 208
7.6半监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
7.7多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
7.8提前终止 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
7.9参数绑定和参数共享 . . . . . . . . . . . . . . . . . . . . . . . 216
7.9.1 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . 217
7.10稀疏表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
7.11 Bagging 和其他集成方法 . . . . . . . . . . . . . . . . . . . . . 219
7.12 Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
7.13对抗训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
7.14切面距离、正切传播和流形正切分类器 . . . . . . . . . . . . . 231
第八章 深度模型中的优化 234
8.1学习和纯优化有什么不同 . . . . . . . . . . . . . . . . . . . . 234
8.1.1 经验风险最小化 . . . . . . . . . . . . . . . . . . . . 235
8.1.2 代理损失函数和提前终止 . . . . . . . . . . . . . . . 236
8.1.3 批量算法和小批量算法 . . . . . . . . . . . . . . . . . 236DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
viii 目录
8.2神经网络优化中的挑战 . . . . . . . . . . . . . . . . . . . . . . 240
8.2.1 病态 . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
8.2.2 局部极小值 . . . . . . . . . . . . . . . . . . . . . . . 242
8.2.3 高原、鞍点和其他平坦区域 . . . . . . . . . . . . . . 243
8.2.4 悬崖和梯度爆炸 . . . . . . . . . . . . . . . . . . . . 245
8.2.5 长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . 246
8.2.6 非精确梯度 . . . . . . . . . . . . . . . . . . . . . . . 247
8.2.7 局部和全局结构间的弱对应 . . . . . . . . . . . . . . 247
8.2.8 优化的理论限制 . . . . . . . . . . . . . . . . . . . . 249
8.3基本算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
8.3.1 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . 250
8.3.2 动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
8.3.3 Nesterov 动量 . . . . . . . . . . . . . . . . . . . . . 255
8.4参数初始化策略 . . . . . . . . . . . . . . . . . . . . . . . . . . 255
8.5自适应学习率算法 . . . . . . . . . . . . . . . . . . . . . . . . 260
8.5.1 AdaGrad . . . . . . . . . . . . . . . . . . . . . . . . 260
8.5.2 RMSProp . . . . . . . . . . . . . . . . . . . . . . . . 261
8.5.3 Adam . . . . . . . . . . . . . . . . . . . . . . . . . . 261
8.5.4 选择正确的优化算法 . . . . . . . . . . . . . . . . . . 262
8.6二阶近似方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
8.6.1 牛顿法 . . . . . . . . . . . . . . . . . . . . . . . . . . 265
8.6.2 共轭梯度 . . . . . . . . . . . . . . . . . . . . . . . . 266
8.6.3 BFGS . . . . . . . . . . . . . . . . . . . . . . . . . . 269
8.7优化策略和元算法 . . . . . . . . . . . . . . . . . . . . . . . . 270
8.7.1 批标准化 . . . . . . . . . . . . . . . . . . . . . . . . 270
8.7.2 坐标下降 . . . . . . . . . . . . . . . . . . . . . . . . 273
8.7.3 Polyak 平均 . . . . . . . . . . . . . . . . . . . . . . . 273
8.7.4 监督预训练 . . . . . . . . . . . . . . . . . . . . . . . 274
8.7.5 设计有助于优化的模型 . . . . . . . . . . . . . . . . . 276
8.7.6 延拓法和课程学习 . . . . . . . . . . . . . . . . . . . 277
第九章 卷积网络 280
9.1卷积运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 ix
9.2动机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
9.3池化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
9.4卷积与池化作为一种无限强的先验 . . . . . . . . . . . . . . . 294
9.5基本卷积函数的变体 . . . . . . . . . . . . . . . . . . . . . . . 295
9.6结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
9.7数据类型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
9.8高效的卷积算法 . . . . . . . . . . . . . . . . . . . . . . . . . . 308
9.9随机或无监督的特征 . . . . . . . . . . . . . . . . . . . . . . . 309
9.10卷积网络的神经科学基础 . . . . . . . . . . . . . . . . . . . . 310
9.11卷积网络与深度学习的历史 . . . . . . . . . . . . . . . . . . . 316
第十章 序列建模：循环和递归网络 318
10.1展开计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
10.2循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
10.2.1 导师驱动过程和输出循环网络 . . . . . . . . . . . . . 325
10.2.2 计算循环神经网络的梯度 . . . . . . . . . . . . . . . 327
10.2.3 作为有向图模型的循环网络 . . . . . . . . . . . . . . 329
10.2.4 基于上下文的 RNN序列建模 . . . . . . . . . . . . . 333
10.3双向 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
10.4基于编码 -解码的序列到序列架构 . . . . . . . . . . . . . . . . 337
10.5深度循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
10.6递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 340
10.7长期依赖的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . 342
10.8回声状态网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
10.9渗漏单元和其他多时间尺度的策略 . . . . . . . . . . . . . . . 346
10.9.1 时间维度的跳跃连接 . . . . . . . . . . . . . . . . . . 346
10.9.2 渗漏单元和一系列不同时间尺度 . . . . . . . . . . . 347
10.9.3 删除连接 . . . . . . . . . . . . . . . . . . . . . . . . 347
10.10长短期记忆和其他门控 RNN . . . . . . . . . . . . . . . . . . 348
10.10.1 LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . 348
10.10.2 其他门控 RNN . . . . . . . . . . . . . . . . . . . . . 350
10.11优化长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
10.11.1 截断梯度 . . . . . . . . . . . . . . . . . . . . . . . . 352DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
x 目录
10.11.2 引导信息流的正则化 . . . . . . . . . . . . . . . . . . 354
10.12外显记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
第十一章 实践方法论 358
11.1性能度量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
11.2默认的基准模型 . . . . . . . . . . . . . . . . . . . . . . . . . . 361
11.3决定是否收集更多数据 . . . . . . . . . . . . . . . . . . . . . . 362
11.4选择超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
11.4.1 手动调整超参数 . . . . . . . . . . . . . . . . . . . . 363
11.4.2 自动超参数优化算法 . . . . . . . . . . . . . . . . . . 366
11.4.3 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . 367
11.4.4 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . 368
11.4.5 基于模型的超参数优化 . . . . . . . . . . . . . . . . . 369
11.5调试策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
11.6示例：多位数字识别 . . . . . . . . . . . . . . . . . . . . . . . 373
第十二章 应用 376
12.1大规模深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 376
12.1.1 快速的 CPU实现 . . . . . . . . . . . . . . . . . . . 377
12.1.2 GPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . 377
12.1.3 大规模的分布式实现 . . . . . . . . . . . . . . . . . . 379
12.1.4 模型压缩 . . . . . . . . . . . . . . . . . . . . . . . . 380
12.1.5 动态结构 . . . . . . . . . . . . . . . . . . . . . . . . 381
12.1.6 深度网络的专用硬件实现 . . . . . . . . . . . . . . . 383
12.2计算机视觉 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
12.2.1 预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . 384
12.2.1.1 对比度归一化 . . . . . . . . . . . . . . . . . . . . . 385
12.2.2 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . 388
12.3语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
12.4自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . 391
12.4.1 n-gram . . . . . . . . . . . . . . . . . . . . . . . . . 391
12.4.2 神经语言模型 . . . . . . . . . . . . . . . . . . . . . . 393DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 xi
12.4.3 高维输出 . . . . . . . . . . . . . . . . . . . . . . . . 395
12.4.3.1 使用短列表 . . . . . . . . . . . . . . . . . . . . . . 395
12.4.3.2 分层 Softmax . . . . . . . . . . . . . . . . . . . . . 396
12.4.3.3 重要采样 . . . . . . . . . . . . . . . . . . . . . . . . 398
12.4.3.4 噪声对比估计和排名损失 . . . . . . . . . . . . . . . 400
12.4.4 结合 n-gram和神经语言模型 . . . . . . . . . . . . . 400
12.4.5 神经机器翻译 . . . . . . . . . . . . . . . . . . . . . . 401
12.4.5.1 使用注意力机制并对齐数据片段 . . . . . . . . . . . 402
12.4.6 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . 405
12.5其他应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
12.5.1 推荐系统 . . . . . . . . . . . . . . . . . . . . . . . . 406
12.5.1.1 探索与开发 . . . . . . . . . . . . . . . . . . . . . . 408
12.5.2 知识表示、推理和回答 . . . . . . . . . . . . . . . . . 409
12.5.2.1 知识、联系和回答 . . . . . . . . . . . . . . . . . . . 409
第三部分 深度学习研究 413
第十三章 线性因子模型 416
13.1概率 PCA和因子分析 . . . . . . . . . . . . . . . . . . . . . . 417
13.2独立成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
13.3慢特征分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
13.4稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422
13.5 PCA 的流形解释 . . . . . . . . . . . . . . . . . . . . . . . . . 425
第十四章 自编码器 428
14.1欠完备自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . 429
14.2正则自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
14.2.1 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . 430
14.2.2 去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . 432
14.2.3 惩罚导数作为正则 . . . . . . . . . . . . . . . . . . . 433
14.3表示能力、层的大小和深度 . . . . . . . . . . . . . . . . . . . 433
14.4随机编码器和解码器 . . . . . . . . . . . . . . . . . . . . . . . 434DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
xii 目录
14.5去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
14.5.1 得分估计 . . . . . . . . . . . . . . . . . . . . . . . . 436
14.5.2 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . 439
14.6使用自编码器学习流形 . . . . . . . . . . . . . . . . . . . . . . 439
14.7收缩自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
14.8预测稀疏分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . 446
14.9自编码器的应用 . . . . . . . . . . . . . . . . . . . . . . . . . . 447
第十五章 表示学习 448
15.1贪心逐层无监督预训练 . . . . . . . . . . . . . . . . . . . . . . 449
15.1.1 何时以及为何无监督预训练有效？ . . . . . . . . . . 451
15.2迁移学习和领域自适应 . . . . . . . . . . . . . . . . . . . . . . 456
15.3半监督解释因果关系 . . . . . . . . . . . . . . . . . . . . . . . 460
15.4分布式表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
15.5得益于深度的指数增益 . . . . . . . . . . . . . . . . . . . . . . 470
15.6提供发现潜在原因的线索 . . . . . . . . . . . . . . . . . . . . 471
第十六章 深度学习中的结构化概率模型 474
16.1非结构化建模的挑战 . . . . . . . . . . . . . . . . . . . . . . . 475
16.2使用图描述模型结构 . . . . . . . . . . . . . . . . . . . . . . . 478
16.2.1 有向模型 . . . . . . . . . . . . . . . . . . . . . . . . 479
16.2.2 无向模型 . . . . . . . . . . . . . . . . . . . . . . . . 481
16.2.3 配分函数 . . . . . . . . . . . . . . . . . . . . . . . . 483
16.2.4 基于能量的模型 . . . . . . . . . . . . . . . . . . . . 484
16.2.5 分离和 d-分离 . . . . . . . . . . . . . . . . . . . . . 486
16.2.6 在有向模型和无向模型中转换 . . . . . . . . . . . . . 489
16.2.7 因子图 . . . . . . . . . . . . . . . . . . . . . . . . . . 492
16.3从图模型中采样 . . . . . . . . . . . . . . . . . . . . . . . . . . 493
16.4结构化建模的优势 . . . . . . . . . . . . . . . . . . . . . . . . 494
16.5学习依赖关系 . . . . . . . . . . . . . . . . . . . . . . . . . . . 495
16.6推断和近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . 496
16.7结构化概率模型的深度学习方法 . . . . . . . . . . . . . . . . . 497
16.7.1 实例：受限玻尔兹曼机 . . . . . . . . . . . . . . . . . 498DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 xiii
第十七章 蒙特卡罗方法 501
17.1采样和蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . 501
17.1.1 为什么需要采样？ . . . . . . . . . . . . . . . . . . . 501
17.1.2 蒙特卡罗采样的基础 . . . . . . . . . . . . . . . . . . 502
17.2重要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 503
17.3马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . 505
17.4 Gibbs 采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
17.5不同的峰值之间的混合挑战 . . . . . . . . . . . . . . . . . . . 510
17.5.1 不同峰值之间通过回火来混合 . . . . . . . . . . . . . 512
17.5.2 深度也许会有助于混合 . . . . . . . . . . . . . . . . . 513
第十八章 直面配分函数 515
18.1对数似然梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . 515
18.2随机最大似然和对比散度 . . . . . . . . . . . . . . . . . . . . 517
18.3伪似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523
18.4得分匹配和比率匹配 . . . . . . . . . . . . . . . . . . . . . . . 525
18.5去噪得分匹配 . . . . . . . . . . . . . . . . . . . . . . . . . . . 527
18.6噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . 528
18.7估计配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . 530
18.7.1 退火重要采样 . . . . . . . . . . . . . . . . . . . . . . 532
18.7.2 桥式采样 . . . . . . . . . . . . . . . . . . . . . . . . 535
第十九章 近似推断 537
19.1把推断视作优化问题 . . . . . . . . . . . . . . . . . . . . . . . 538
19.2期望最大化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540
19.3最大后验推断和稀疏编码 . . . . . . . . . . . . . . . . . . . . 541
19.4变分推断和变分学习 . . . . . . . . . . . . . . . . . . . . . . . 543
19.4.1 离散型潜变量 . . . . . . . . . . . . . . . . . . . . . . 544
19.4.2 变分法 . . . . . . . . . . . . . . . . . . . . . . . . . . 550
19.4.3 连续型潜变量 . . . . . . . . . . . . . . . . . . . . . . 553
19.4.4 学习和推断之间的相互作用 . . . . . . . . . . . . . . 555
19.5学成近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . 555
19.5.1 醒眠算法 . . . . . . . . . . . . . . . . . . . . . . . . 556DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
xiv 目录
19.5.2 学成推断的其他形式 . . . . . . . . . . . . . . . . . . 556
第二十章 深度生成模型 558
20.1玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 558
20.2受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . 560
20.2.1 条件分布 . . . . . . . . . . . . . . . . . . . . . . . . 561
20.2.2 训练受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . 562
20.3深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 563
20.4深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . 565
20.4.1 有趣的性质 . . . . . . . . . . . . . . . . . . . . . . . 567
20.4.2 DBM 均匀场推断 . . . . . . . . . . . . . . . . . . . 568
20.4.3 DBM 的参数学习 . . . . . . . . . . . . . . . . . . . 570
20.4.4 逐层预训练 . . . . . . . . . . . . . . . . . . . . . . . 571
20.4.5 联合训练深度玻尔兹曼机 . . . . . . . . . . . . . . . 573
20.5实值数据上的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . 577
20.5.1 Gaussian-Bernoulli RBM . . . . . . . . . . . . . . . 577
20.5.2 条件协方差的无向模型 . . . . . . . . . . . . . . . . . 578
20.6卷积玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . 582
20.7用于结构化或序列输出的玻尔兹曼机 . . . . . . . . . . . . . . 584
20.8其他玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . 585
20.9通过随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . 586
20.9.1 通过离散随机操作的反向传播 . . . . . . . . . . . . . 587
20.10有向生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 590
20.10.1 sigmoid 信念网络 . . . . . . . . . . . . . . . . . . . . 590
20.10.2 可微生成器网络 . . . . . . . . . . . . . . . . . . . . 591
20.10.3 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . 593
20.10.4 生成式对抗网络 . . . . . . . . . . . . . . . . . . . . 596
20.10.5 生成矩匹配网络 . . . . . . . . . . . . . . . . . . . . 599
20.10.6 卷积生成网络 . . . . . . . . . . . . . . . . . . . . . . 600
20.10.7 自回归网络 . . . . . . . . . . . . . . . . . . . . . . . 601
20.10.8 线性自回归网络 . . . . . . . . . . . . . . . . . . . . 601
20.10.9 神经自回归网络 . . . . . . . . . . . . . . . . . . . . 602
20.10.10 NADE . . . . . . . . . . . . . . . . . . . . . . . . . . 603DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 xv
20.11从自编码器采样 . . . . . . . . . . . . . . . . . . . . . . . . . . 605
20.11.1 与任意去噪自编码器相关的马尔可夫链 . . . . . . . . 606
20.11.2 夹合与条件采样 . . . . . . . . . . . . . . . . . . . . 606
20.11.3 回退训练过程 . . . . . . . . . . . . . . . . . . . . . . 607
20.12生成随机网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . 608
20.12.1 判别性 GSN . . . . . . . . . . . . . . . . . . . . . . . 609
20.13其他生成方案 . . . . . . . . . . . . . . . . . . . . . . . . . . . 609
20.14评估生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 610
20.15结论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612
参考文献 614
术语 678DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
致谢
TODO
xviDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
数学符号
本节简要介绍本书所使用的数学符号。我们在第 二章至第四章中描述大多数数
学概念，如果你不熟悉任何相应的数学概念，可以参考对应的章节。
数和数组
a标量 (整数或实数 )
a向量
A矩阵
A张量
In n行n列的单位矩阵
I维度蕴含于上下文的 单位矩阵
e(i)标准基向量 [0; : : : ; 0;1;0; : : : ; 0]，其中索引 i处值
为1
diag(a)对角方阵，其中对角元素由 a给定
a标量随机变量
a向量随机变量
A矩阵随机变量
xviiDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
xviii 目录
集合和图
A 集合
R 实数集
f0;1g包含 0和1的集合
f0;1; : : : ; ng包含 0和n之间所有整数的集合
[a; b]包含 a和b的实数区间
(a; b]不包含 a但包含 b的实数区间
AnB差集，即其元素包含于 A但不包含于 B
G 图
PaG(xi)图G中 xi的父节点
索引
ai向量 a的第 i个元素，其中索引从 1开始
a i除了第 i个元素， a的所有元素
Ai;j矩阵 A的i; j元素
Ai;:矩阵 A的第 i行
A:;i矩阵 A的第 i列
Ai;j;k 3维张量 A的(i; j; k )元素
A:;:;i3维张量的 2维切片
ai随机向量 a的第 i个元素DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 xix
线性代数中的操作
A⊤矩阵 A的转置
A+A的Moore-Penrose 伪逆
A⊙B A和 B的逐元素乘积（ Hadamard 乘积）
det(A) A的行列式
微积分
dy
dxy关于 x的导数
@y
@xy关于 x的偏导
∇ xy y关于 x的梯度
∇ Xy y关于 X的矩阵导数
∇Xy y关于X求导后的张量
@f
@xf:Rn!Rm的Jacobian 矩阵 J2Rmn
∇2
xf(x)or H(f)(x)f在点 x处的Hessian矩阵
∫
f(x)dx x整个域上的定积分
∫
Sf(x)dx 集合S上关于 x的定积分DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
xx 目录
概率和信息论
a?b a和 b相互独立的随机变量
a?bjc 给定 c后条件独立
P(a) 离散变量上的概率分布
p(a) 连续变量（或变量类型未指定时）上的概率分布
aP 具有分布 P的随机变量 a
ExP[f(x)]orEf(x)f(x)关于 P(x)的期望
Var(f(x)) f(x)在分布 P(x)下的方差
Cov(f(x); g(x)) f(x)和g(x)在分布 P(x)下的协方差
H(x) 随机变量 x的香农熵
DKL(P∥Q) P和Q的KL散度
N(x;;)均值为协方差为 ，x上的高斯分布DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
目录 xxi
函数
f:A!B定义域为 A值域为 B的函数 f
f◦g f和g的组合
f(x;)由参数化，关于 x的函数（有时为简化表示，我
们忽略记为 f(x)）
logx x 的自然对数
(x) Logistic sigmoid,1
1 + exp( x)
(x) Softplus, log(1 + exp(x))
jjxjjp x的Lp范数
jjxjj x的L2范数
x+x的正数部分 ,即 max(0; x)
1condition 如果条件为真则为 1，否则为 0
有时候我们使用函数 f，它的参数是一个标量，但应用到一个向量、矩阵或张
量：f(x),f(X), orf(X)。这表示逐元素地将 f应用于数组。例如， C=(X)，则
对于所有合法的 i、j和k，Ci;j;k=(Xi;j;k)。
数据集和分布
pdata 数据生成分布
^ptrain 由训练集定义的经验分布
X训练样本的集合
x(i)数据集的第 i个样本（输入）
y(i)or y(i)监督学习 中与 x(i)关联的目标
X mn的矩阵，其中行 Xi;:为输入样本 x(i)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
xxii 目录DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第一章 前言
远在古希腊时期，发明家就梦想着创造能自主思考的机器。神话人物皮格马利
翁(Pygmalion) 、代达罗斯 (Daedalus) 和赫淮斯托斯 (Hephaestus) 可以被看作传说
中的发明家，而加拉蒂亚 (Galatea) 、塔洛斯 (Talos)和潘多拉 (Pandora) 则可以被
视为人造生命 (Ovid and Martin ,2004;Sparkes ,1996;Tandy ,1997)。
当人类第一次构思可编程计算机时，就已经在思考计算机能否变得智能（尽管
这距造出第一台计算机还有一百多年） (Lovelace ,1842)。如今， 人工智能 （artiﬁcial
intelligence ,AI）已经成为一个具有众多实际应用和活跃研究课题的领域，并且正在
蓬勃发展。我们期望通过智能软件自动地处理常规劳动、理解语音或图像、帮助医
学诊断和支持基础科学研究。
在人工智能 的早期，那些对人类智力来说非常困难、但对计算机来说相对简单
的问题得到迅速解决，比如，那些可以通过一系列形式化的数学规则来描述的问题。
人工智能 的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，
如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭借直觉轻
易地解决。
针对这些比较直观的问题，本书讨论一种解决方案。该方案可以让计算机从经
验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简
单的概念之间的关系来定义。让计算机从经验获取知识，可以避免由人类来给计算
机形式化地指定它需要的所有知识。层次化的概念让计算机构建较简单的概念来学
习复杂概念。如果绘制出这些概念如何建立在彼此之上的图，我们将得到一张 ‘‘深’’
（层次很多）的图。基于这个原因，我们称这种方法为 AI深度学习 （deep learning ） 。
AI许多早期的成功发生在相对朴素且形式化的环境中，而且不要求计算机具
备很多关于世界的知识。例如， IBM的深蓝（ Deep Blue ）国际象棋系统在 1997年
1DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2 第一章 前言
击败了世界冠军 Garry Kasparov( Hsu,2002)。显然国际象棋是一个非常简单的领域，
因为它仅含有 64个位置并只能以严格限制的方式移动 32个棋子。设计一种成功的
国际象棋策略是巨大的成就，但向计算机描述棋子及其允许的走法并不是挑战的困
难所在。国际象棋完全可以由一个非常简短的、完全形式化的规则列表来描述，并
可以容易地由程序员事先准备好。
讽刺的是，抽象和形式化的任务对人类而言是最困难的脑力任务之一，但对计
算机而言却属于最容易的。计算机早就能够打败人类最好的象棋选手，但直到最近
计算机才在识别对象或语音任务中达到人类平均水平。一个人的日常生活需要关于
世界的巨量知识。很多这方面的知识是主观的、直观的，因此很难通过形式化的方
式表达清楚。计算机需要获取同样的知识才能表现出智能。 人工智能 的一个关键挑
战就是如何将这些非形式化的知识传达给计算机。
一些人工智能 项目力求将关于世界的知识用形式化的语言进行硬编码 (hard-
code)。计算机可以使用逻辑推理规则来自动地理解这些形式化语言中的声明。这就
是众所周知的 人工智能 的知识库（knowledge base ）方法。然而，这些项目最终都没
有取得重大的成功。其中最著名的项目是 Cyc ( Lenat and Guha ,1989)。Cyc包括一
个推断引擎和一个使用 CycL语言描述的声明数据库。这些声明是由人类监督者输
入的。这是一个笨拙的过程。人们设法设计出足够复杂的形式化规则来精确地描述世
界。例如， Cyc不能理解一个关于名为 Fred的人在早上剃须的故事 (Linde ,1992)。
它的推理引擎检测到故事中的不一致性：它知道人没有电气零件，但由于 Fred正拿
着一个电动剃须刀，它认为实体 ‘‘正在剃须的 Fred” (“FredWhileShaving”) 含有电
气部件。因此它产生了这样的疑问—— Fred在刮胡子的时候是否仍然是一个人。
依靠硬编码的知识体系面对的困难表明， AI系统需要具备自己获取知识的能力，
即从原始数据中提取模式的能力。这种能力被称为 机器学习 （machine learning ） 。
引入机器学习 使计算机能够解决涉及现实世界知识的问题，并能作出看似主观的决
策。比如，一个被称为 逻辑回归 （logistic regression ）的简单 机器学习 算法可以决定
是否建议剖腹产 (Mor-Yosef et al. ,1990)。而同样是简单 机器学习 算法的朴素贝叶
斯（naive Bayes ）则可以区分垃圾电子邮件和合法电子邮件。
这些简单的 机器学习 算法的性能在很大程度上依赖于给定数据的 表示（repre-
sentation ） 。例如，当 逻辑回归 被用于判断产妇是否适合剖腹产时， AI系统不会直接
检查患者。相反，医生需要告诉系统几条相关的信息，诸如是否存在子宫疤痕。表
示患者的每条信息被称为一个特征。 逻辑回归 学习病人的这些特征如何与各种结果
相关联。然而，它丝毫不能影响该特征定义的方式。如果将病人的 MRI扫描作为 逻DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3
辑回归的输入，而不是医生正式的报告，它将无法作出有用的预测。 MRI扫描的单
一像素与分娩过程中并发症之间的相关性微乎其微。
在整个计算机科学乃至日常生活中，对 表示的依赖都是一个普遍现象。在计算
机科学中，如果数据集合被精巧地结构化并被智能地索引，那么诸如搜索之类的操
作的处理速度就可以成指数级地加快。人们可以很容易地在阿拉伯数字的 表示下进
行算术运算，但在罗马数字的 表示下运算会比较耗时。因此，毫不奇怪， 表示的选择
会对机器学习 算法的性能产生巨大的影响。图 1.1展示了一个简单的可视化例子。
xyCartesian coordinates
rµPolar coordinates
图1.1:不同表示的例子：假设我们想在散点图中画一条线来分隔两类数据。在左图，我们使用笛
卡尔坐标表示数据，这个任务是不可能的。右图中，我们用极坐标表示数据，可以用垂直线简单地
解决这个任务。 （与 David Warde-Farley 合作画出此图。 ）
许多人工智能 任务都可以通过以下方式解决：先提取一个合适的特征集，然后
将这些特征提供给简单的 机器学习 算法。例如，对于通过声音鉴别说话者的任务来
说，一个有用的特征是对其声道大小的估计。这个特征为判断说话者是男性、女性
还是儿童提供了有力线索。
然而，对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想
编写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车
轮的存在与否作为特征。不幸的是，我们难以准确地根据像素值来描述车轮看上去
像什么。虽然车轮具有简单的几何形状，但它的图像可能会因场景而异，如落在车
轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的
前景物体等等。
解决这个问题的途径之一是使用 机器学习 来发掘表示本身，而不仅仅把 表示映DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4 第一章 前言
射到输出。这种方法我们称之为 表示学习 （representation learning ） 。学习到的 表
示往往比手动设计的 表示表现得更好。并且它们只需最少的人工干预，就能让 AI系
统迅速适应新的任务。 表示学习 算法只需几分钟就可以为简单的任务发现一个很好
的特征集，对于复杂任务则需要几小时到几个月。手动为一个复杂的任务设计特征
需要耗费大量的人工时间和精力；甚至需要花费整个社群研究人员几十年的时间。
表示学习 算法的典型例子是 自编码器 （autoencoder ） 。自编码器 由一个编码器
（encoder）函数和一个 解码器（decoder）函数组合而成。 编码器函数将输入数据转
换为一种不同的 表示，而解码器函数则将这个新的 表示转换到原来的形式。我们期
望当输入数据经过 编码器和解码器之后尽可能多地保留信息，同时希望新的 表示有
各种好的特性，这也是 自编码器 的训练目标。为了实现不同的特性，我们可以设计
不同形式的 自编码器 。
当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观
察数据的 变差因素 （factors of variation ） 。在此背景下， ‘‘因素’’这个词仅指代影响
的不同来源；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相
反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的
量。为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的
形式存在于人类的思维中。它们可以被看作数据的概念或者抽象，帮助我们了解这
些数据的丰富多样性。当分析语音记录时， 变差因素 包括说话者的年龄、性别、他们
的口音和他们正在说的词语。当分析汽车的图像时， 变差因素 包括汽车的位置、它
的颜色、太阳的角度和亮度。
在许多现实的 人工智能 应用中，困难主要源于多个 变差因素 同时影响着我们能
够观察到的每一个数据。比如，在一张包含红色汽车的图片中，其单个像素在夜间
可能会非常接近黑色。汽车轮廓的形状取决于视角。大多数应用需要我们 理清变差
因素并忽略我们不关心的因素。
显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话
口音这样的 变差因素 ，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这
几乎与获得原问题的 表示一样困难，因此，乍一看， 表示学习 似乎并不能帮助我们。
深度学习 （deep learning ）通过其他较简单的 表示来表达复杂 表示，解决了 表
示学习中的核心问题。
深度学习 让计算机通过较简单概念构建复杂的概念。图 1.2展示了深度学习 系统
如何通过组合较简单的概念（例如转角和轮廓，它们转而由边线定义）来表示图像DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5
Visible layer(input pixels)1st hidden layer(edges)
2nd hidden layer(corners andcontours)3rd hidden layer(object parts)CARPERSONANIMALOutput(object identity)
图1.2:深度学习模型的示意图。计算机难以理解原始感观输入数据的含义，如表示为像素值集合
的图像。将一组像素映射到对象标识的函数非常复杂。如果直接处理，学习或评估此映射似乎是
不可能的。深度学习将所需的复杂映射分解为一系列嵌套的简单映射（每个由模型的不同层描述）
来解决这一难题。输入展示在 可见层（visible layer ） ，这样命名的原因是因为它包含我们能观察
到的变量。然后是一系列从图像中提取越来越多抽象特征的 隐藏层（hidden layer ） 。因为它们的
值不在数据中给出，所以将这些层称为 ‘‘隐藏”;模型必须确定哪些概念有利于解释观察数据中的
关系。这里的图像是每个 隐藏单元 表示的特征的可视化。给定像素，第一层可以轻易地通过比较相
邻像素的亮度来识别边缘。有了第一 隐藏层描述的边缘，第二 隐藏层可以容易地搜索可识别为角
和扩展轮廓的边集合。给定第二 隐藏层中关于角和轮廓的图像描述，第三 隐藏层可以找到轮廓和
角的特定集合来检测特定对象的整个部分。最后，根据图像描述中包含的对象部分，可以识别图
像中存在的对象。经 Zeiler and Fergus (2014)许可转载此图。
中人的概念。 深度学习 模型的典型例子是前馈深度网络或 多层感知机 （multilayer
perceptron ,MLP） 。多层感知机 仅仅是一个将一组输入值映射到输出值的数学函数。
该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都
为输入提供了新的 表示。
学习数据的正确 表示的想法是解释 深度学习 的一个视角。另一个视角是深度促DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6 第一章 前言
使计算机学习一个多步骤的计算机程序。每一层 表示都可以被认为是并行执行另一
组指令之后计算机的存储器状态。更深的网络可以按顺序执行更多的指令。顺序指
令提供了极大的能力，因为后面的指令可以参考早期指令的结果。从这个角度上看，
在某层激活函数里，并非所有信息都蕴涵着解释输入的 变差因素 。表示还存储着状
态信息，用于帮助程序理解输入。这里的状态信息类似于传统计算机程序中的计数
器或指针。它与具体的输入内容无关，但有助于模型组织其处理过程。
目前主要有两种度量模型深度的方式。第一种方式是基于评估架构所需执行的
顺序指令的数目。假设我们将模型表示为给定输入后，计算对应输出的流程图，则
可以将这张流程图中的最长路径视为模型的深度。正如两个使用不同语言编写的等
价程序将具有不同的长度；相同的函数可以被绘制为具有不同深度的流程图，其深
度取决于我们可以用来作为一个步骤的函数。图 1.3说明了语言的选择如何给相同的
架构两个不同的衡量。
x1x1 
w1w1⇥x2x2w2w2⇥+ElementSet+⇥ xxwwElementSetLogisticRegressionLogisticRegression
图1.3:将输入映射到输出的计算图表的示意图，其中每个节点执行一个操作。深度是从输入到输
出的最长路径的长度，但这取决于可能的计算步骤的定义。这些图中所示的计算是 逻辑回归 模型的
输出， (wTx)，其中 是logistic sigmoid 函数。如果我们使用加法、乘法和 logistic sigmoid 作
为我们计算机语言的元素，那么这个模型深度为三。如果我们将 逻辑回归 视为元素本身，那么这
个模型深度为一。
另一种是在深度概率模型中使用的方法，它不是将计算图的深度视为模型深度，
而是将描述概念彼此如何关联的图的深度视为模型深度。在这种情况下，计算每个
概念表示的计算流程图的深度可能比概念本身的图更深。这是因为系统对较简单概
念的理解在给出更复杂概念的信息后可以进一步精细化。例如，一个 AI系统观察其
中一只眼睛在阴影中的脸部图像时，它最初可能只看到一只眼睛。但当检测到脸部DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7
的存在后，系统可以推断第二只眼睛也可能是存在的。在这种情况下，概念的图仅
包括两层（关于眼睛的层和关于脸的层） ，但如果我们细化每个概念的估计将需要额
外的 n次计算，即计算的图将包含 2n层。
由于并不总是清楚计算图的深度或概率模型图的深度哪一个是最有意义的，并
且由于不同的人选择不同的最小元素集来构建相应的图，因此就像计算机程序的长
度不存在单一的正确值一样，架构的深度也不存在单一的正确值。另外，也不存在
模型多么深才能被修饰为 ‘‘深’’的共识。但相比传统 机器学习 ，深度学习 研究的模型
涉及更多学到功能或学到概念的组合，这点毋庸置疑。
总之，这本书的主题—— 深度学习 是通向人工智能 的途径之一。具体来说，它
是机器学习 的一种，一种能够使计算机系统从经验和数据中得到提高的技术。我们
坚信机器学习 可以构建出在复杂实际环境下运行的 AI系统，并且是唯一切实可行的
方法。深度学习 是一种特定类型的 机器学习 ，具有强大的能力和灵活性，它将大千
世界表示为嵌套的层次概念体系（由较简单概念间的联系定义复杂概念、从一般抽
象概括到高级抽象表示） 。图 1.4说明了这些不同的 AI学科之间的关系。图 1.5展示
了每个学科如何工作的高层次原理。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8 第一章 前言
AIMachine learningRepresentation learningDeep learningExample:KnowledgebasesExample:LogisticregressionExample:ShallowautoencodersExample:MLPs
图1.4:维恩图展示了深度学习是一种表示学习，也是一种机器学习，可以用于许多（但不是全部）
AI方法。维恩图的每个部分包括一个 AI技术的示例。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9
InputHand-designed programOutput
InputHand-designed featuresMapping from featuresOutput
InputFeaturesMapping from featuresOutput
InputSimple featuresMapping from featuresOutput
Additional layers of more abstract features
Rule-basedsystemsClassicmachinelearningRepresentationlearningDeeplearning
图1.5:流程图展示了 AI系统的不同部分如何在不同的 AI学科中彼此相关。阴影框表示能从数
据中学习的组件。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10 第一章 前言
1.1本书面向的读者
这本书对各类读者都有一定用处，但我们主要是为两类受众对象而写的。其中
一类受众对象是学习 机器学习 的大学生（本科或研究生） ，包括那些已经开始职业
生涯的深度学习 和人工智能 研究者。另一类受众对象是没有 机器学习 或统计背景但
希望能快速地掌握这方面知识并在他们的产品或平台中使用 深度学习 的软件工程师。
深度学习 在许多软件领域都已被证明是有用的，包括计算机视觉、语音和音频处理、
自然语言处理、机器人技术、生物信息学和化学、电子游戏、搜索引擎、网络广告和
金融。
为了最好地服务各类读者，我们将本书组织为三个部分。第一部分介绍基本的
数学工具和 机器学习 的概念。第二部分介绍最成熟的 深度学习 算法，这些技术基本
上已经得到解决。第三部分讨论某些具有展望性的想法，它们被广泛地认为是 深度
学习未来的研究重点。
读者可以随意跳过不感兴趣或与自己背景不相关的部分。熟悉线性代数、概率
和基本机器学习 概念的读者可以跳过第一部分，例如，当读者只是想实现一个能工
作的系统则不需要阅读超出第二部分的内容。为了帮助读者选择章节，图 1.6展示了
这本书的高层组织结构的流程图。
我们假设所有读者都具备计算机科学背景。也假设读者熟悉编程，并且对计算
的性能问题、复杂性理论、入门级微积分和一些图论术语有基本的了解。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 11
1. IntroductionPart I: Applied Math and Machine Learning Basics2. Linear Algebra3. Probability and Information Theory4. Numerical Computation5. Machine Learning BasicsPart II: Deep Networks: Modern Practices6. Deep Feedforward Networks7. Regularization8. Optimization9.  CNNs10.  RNNs11. Practical Methodology12. ApplicationsPart III: Deep Learning Research13. Linear Factor Models14. Autoencoders15. Representation Learning16. Structured Probabilistic Models17. Monte Carlo Methods18. Partition Function19. Inference20. Deep Generative Models
图1.6:本书的高层组织。从一章到另一章的箭头表示前一章是理解后一章的必备内容。
1.2深度学习的历史趋势
通过历史背景了解 深度学习 是最简单的方式。这里我们仅指出 深度学习 的几个
关键趋势，而不是提供其详细的历史：DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12 第一章 前言
•深度学习 有着悠久而丰富的历史，但随着许多不同哲学观点的渐渐消逝，与之
对应的名称也渐渐尘封。
•随着可用的训练数据量不断增加， 深度学习 变得更加有用。
•随着时间的推移，针对 深度学习 的计算机软硬件基础设施都有所改善， 深度学
习模型的规模也随之增长。
•随着时间的推移， 深度学习 已经解决日益复杂的应用，并且精度不断提高。
1.2.1神经网络的众多名称和命运变迁
我们期待这本书的许多读者都听说过 深度学习 这一激动人心的新技术，并对一
本书提及一个新兴领域的 ‘‘历史’’而感到惊讶。事实上， 深度学习 的历史可以追溯到
20世纪 40年代。深度学习 看似是一个全新的领域，只不过因为在目前流行的前几
年它是相对冷门的，同时也因为它被赋予了许多不同的名称（其中大部分已经不再
使用） ，最近才成为众所周知的 “深度学习 ’’。这个领域已经更换了很多名称，它反映
了不同的研究人员和不同观点的影响。
全面地讲述 深度学习 的历史超出了本书的范围。然而，一些基本的背景对理解 深
度学习是有用的。一般来说，目前为止 深度学习 已经经历了三次发展浪潮： 20世纪
40年代到 60年代深度学习 的雏形出现在 控制论（cybernetics ）中， 20世纪 80年代
到90年代深度学习 表现为联结主义 （connectionism ） ，直到 2006年，才真正以 深
度学习之名复兴。图 1.7给出了定量的展示。
我们今天知道的一些最早的学习算法，是旨在模拟生物学习的计算模型，即大
脑怎样学习或为什么能学习的模型。其结果是 深度学习 以人工神经网络 （artiﬁcial
neural network ,ANN）之名而淡去。彼时， 深度学习 模型被认为是受生物大脑（无
论人类大脑或其他动物的大脑）所启发而设计出来的系统。尽管有些 机器学习 的神
经网络有时被用来理解大脑功能 (Hinton and Shallice ,1991)，但它们一般都没有被
设计成生物功能的真实模型。 深度学习 的神经观点受两个主要思想启发。一个想法
是大脑作为例子证明智能行为是可能的，因此，概念上，建立智能的直接途径是逆
向大脑背后的计算原理，并复制其功能。另一种看法是，理解大脑和人类智能背后
的原理也非常有趣，因此 机器学习 模型除了解决工程应用的能力，如果能让人类对
这些基本的科学问题有进一步的认识也将会很有用。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 13
1940 1950 1960 1970 1980 1990 2000
Year0.0000000.0000500.0001000.0001500.0002000.000250Frequency of Word or Phrasecybernetics
(connectionism + neural networks)
图1.7:根据 Google图书中短语 “控制论 ’’、“联结主义 ’’或“神经网络 ’’频率衡量的 人工神经网
络研究的历史浪潮（图中展示了三次浪潮的前两次，第三次最近才出现） 。第一次浪潮开始于
20世纪 40年代到 20世纪 60年代的控制论，随着生物学习理论的发展 (McCulloch and Pitts ,
1943;Hebb ,1949)和第一个模型的实现（如感知机 (Rosenblatt ,1958)），能实现单个神经元的
训练。第二次浪潮开始于 1980-1995 年间的联结主义 方法，可以使用反向传播 (Rumelhart et al. ,
1986a )训练具有一两个 隐藏层的神经网络。当前第三次浪潮，也就是深度学习，大约始于 2006年
(Hinton et al. ,2006a ;Bengio et al. ,2007a ;Ranzato et al. ,2007a )，并且现在在 2016年以书的形
式出现。另外两次浪潮类似地出现在书中的时间比相应的科学活动晚得多。
现代术语 “深度学习 ’’超越了目前 机器学习 模型的神经科学观点。它诉诸于学
习多层次组合 这一更普遍的原理，这一原理也可以应用于那些并非受神经科学启发
的机器学习 框架。
现代深度学习 的最早前身是从神经科学的角度出发的简单线性模型。这些模型
被设计为使用一组 n个输入 x1; : : : ; xn并将它们与一个输出 y相关联。这些模型希
望学习一组权重 w1; : : : ; wn，并计算它们的输出 f(x;w) = x1w1++xnwn。如
图1.7所示，这第一波 神经网络 研究浪潮被称为 控制论。
McCulloch-Pitts 神经元 (McCulloch and Pitts ,1943)是脑功能的早期模型。该
线性模型通过检验函数 f(x;w)的正负来识别两种不同类别的输入。显然，模型的
权重需要正确设置后才能使模型的输出对应于期望的类别。这些权重可以由操作人
员设定。在 20世纪 50年代，感知机 (Rosenblatt ,1956,1958)成为第一个能根据
每个类别的输入 样本来学习权重的模型。约在同一时期， 自适应线性单元 (adaptive
linear element, ADALINE) 简单地返回函数 f(x)本身的值来预测一个实数 (Widrow
and Hoﬀ ,1960)，并且它还可以学习从数据预测这些数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14 第一章 前言
这些简单的学习算法大大影响了 机器学习 的现代景象。用于调节 ADALINE 权
重的训练算法是被称为 随机梯度下降 （stochastic gradient descent ）的一种特例。稍
加改进后的 随机梯度下降 算法仍然是当今 深度学习 的主要训练算法。
基于感知机和 ADALINE 中使用的函数 f(x;w)的模型被称为 线性模型 （linear
model） 。尽管在许多情况下，这些模型以不同于原始模型的方式进行 训练，但仍是
目前最广泛使用的 机器学习 模型。
线性模型 有很多局限性。最著名的是，它们无法学习异或（ XOR）函数，即
f([0;1];w) = 1和f([1;0];w) = 1，但 f([1;1];w) = 0和f([0;0];w) = 0。观察到 线
性模型这个缺陷的批评者对受生物学启发的学习普遍地产生了抵触 (Minsky and
Papert ,1969)。这导致了 神经网络 热潮的第一次大衰退。
现在，神经科学被视为 深度学习 研究的一个重要灵感来源，但它已不再是该领
域的主要指导。
如今神经科学在 深度学习 研究中的作用被削弱，主要原因是我们根本没有足够
的关于大脑的信息来作为指导去使用它。要获得对被大脑实际使用算法的深刻理解，
我们需要有能力同时监测（至少是）数千相连神经元的活动。我们不能够做到这一
点，所以我们甚至连大脑最简单、最深入研究的部分都还远远没有理解 (Olshausen
and Field ,2005)。
神经科学已经给了我们依靠单一 深度学习 算法解决许多不同任务的理由。神经
学家们发现，如果将雪貂的大脑重新连接，使视觉信号传送到听觉区域，它们可以学
会用大脑的听觉处理区域去 ‘‘看” (Von Melchner et al. ,2000)。这暗示着大多数哺乳
动物的大脑能够使用单一的算法就可以解决其大脑可以解决的大部分不同任务。在
这个假设之前， 机器学习 研究是比较分散的，研究人员在不同的社群研究自然语言
处理、计算机视觉、运动规划和语音识别。如今，这些应用社群仍然是独立的，但是
对于深度学习 研究团体来说，同时研究许多或甚至所有这些应用领域是很常见的。
我们能够从神经科学得到一些粗略的指南。仅通过计算单元之间的相互作用而
变得智能的基本思想是受大脑启发的。新认知机 (Fukushima ,1980)受哺乳动物视
觉系统的结构启发，引入了一个处理图片的强大模型架构，它后来成为了现代卷积
网络的基础 (LeCun et al. ,1998b )（我们将会在第 9.10节看到） 。目前大多数 神经网
络是基于一个称为 整流线性单元 （rectiﬁed linear unit ）的神经单元模型。原始认
知机 (Fukushima ,1975)受我们关于大脑功能知识的启发，引入了一个更复杂的版
本。简化的现代版通过吸收来自不同观点的思想而形成， Nair and Hinton (2010b )DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 15
和Glorot et al. (2011a )援引神经科学作为影响， Jarrett et al. (2009a )援引更多面
向工程的影响。虽然神经科学是灵感的重要来源，但它不需要被视为刚性指导。我
们知道，真实的神经元计算着与现代 整流线性单元 非常不同的函数，但更接近真实
神经网络的系统并没有导致 机器学习 性能的提升。此外，虽然神经科学已经成功地
启发了一些 神经网络 架构，但我们对用于神经科学的生物学习还没有足够多的了解，
因此也就不能为训练这些架构用的 学习算法 提供太多的借鉴。
媒体报道经常强调 深度学习 与大脑的相似性。的确， 深度学习 研究者比其他 机
器学习领域（如核方法或贝叶斯统计）的研究者更可能地引用大脑作为影响，但是
大家不应该认为 深度学习 在尝试模拟大脑。现代 深度学习 从许多领域获取灵感，特
别是应用数学的基本内容如线性代数、概率论、信息论和数值优化。尽管一些 深度
学习的研究人员引用神经科学作为灵感的重要来源，然而其他学者完全不关心神经
科学。
值得注意的是，了解大脑是如何在算法层面上工作的尝试确实存在且发展良好。
这项尝试主要被称为 ‘‘计算神经科学 ’’，并且是独立于 深度学习 的领域。研究人员在
两个领域之间来回研究是很常见的。 深度学习 领域主要关注如何构建计算机系统，
从而成功解决需要智能才能解决的任务，而计算神经科学领域主要关注构建大脑如
何真实工作的比较精确的模型。
在20世纪 80年代，神经网络研究的第二次浪潮在很大程度上是伴随一个被称
为联结主义 （connectionism ）或并行分布处理 ( parallel distributed processing) 潮
流而出现的 (Rumelhart et al. ,1986d ;McClelland et al. ,1995)。联结主义 是在认知
科学的背景下出现的。认知科学是理解思维的跨学科途径，即它融合多个不同的分
析层次。在 20世纪 80年代初期，大多数认知科学家研究符号推理模型。尽管这很
流行，但符号模型很难解释大脑如何真正使用神经元实现推理功能。 联结主义 者开
始研究真正基于神经系统实现的认知模型 (Touretzky and Minton ,1985)，其中很
多复苏的想法可以追溯到心理学家 Donald Hebb 在20世纪 40年代的工作 (Hebb ,
1949)。
联结主义 的中心思想是，当网络将大量简单的计算单元连接在一起时可以实现
智能行为。这种见解同样适用于生物神经系统中的神经元，因为它和计算模型中 隐
藏单元起着类似的作用。
在上世纪 80年代的联结主义 期间形成的几个关键概念在今天的 深度学习 中仍然
是非常重要的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16 第一章 前言
其中一个概念是 分布式表示 （distributed representation ）(Hinton et al. ,1986)。
其思想是：系统的每一个输入都应该由多个特征 表示，并且每一个特征都应该参与
到多个可能输入的 表示。例如，假设我们有一个能够识别红色、绿色、或蓝色的汽
车、卡车和鸟类的视觉系统， 表示这些输入的其中一个方法是将九个可能的组合：红
卡车，红汽车，红鸟，绿卡车等等使用单独的神经元或 隐藏单元 激活。这需要九个
不同的神经元，并且每个神经必须独立地学习颜色和对象身份的概念。改善这种情
况的方法之一是使用 分布式表示 ，即用三个神经元描述颜色，三个神经元描述对象
身份。这仅仅需要 6个神经元而不是 9个，并且描述红色的神经元能够从汽车、卡
车和鸟类的图像中学习红色，而不仅仅是从一个特定类别的图像中学习。 分布式表
示的概念是本书的核心，我们将在第 十五章中更加详细地描述。
联结主义 潮流的另一个重要成就是反向传播在训练具有内部 表示的深度神经网
络中的成功使用以及反向传播算法的普及 (Rumelhart et al. ,1986c ;LeCun ,1987)。
这个算法虽然曾黯然失色不再流行，但截至写书之时，它仍是训练深度模型的主导
方法。
在20世纪 90年代，研究人员在使用 神经网络 进行序列建模的方面取得了重
要进展。 Hochreiter (1991b )和Bengio et al. (1994a )指出了对长序列进行建模的一
些根本性数学难题，这将在第 10.7节中描述。 Hochreiter and Schmidhuber (1997)
引入长短期记忆 （long short-term memory ,LSTM）网络来解决这些难题。如今，
LSTM在许多序列建模任务中广泛应用，包括 Google的许多自然语言处理任务。
神经网络 研究的第二次浪潮一直持续到上世纪 90年代中期。基于 神经网络 和其
他AI技术的创业公司开始寻求投资，其做法野心勃勃但不切实际。当 AI研究不能实
现这些不合理的期望时，投资者感到失望。同时， 机器学习 的其他领域取得了进步。
比如，核方法 (Boser et al. ,1992;Cortes and Vapnik ,1995;Schölkopf et al. ,1999)
和图模型 (Jordan ,1998)都在很多重要任务上实现了很好的效果。这两个因素导致
了神经网络 热潮的第二次衰退，并一直持续到 2007年。
在此期间， 神经网络 继续在某些任务上获得令人印象深刻的表现 (LeCun
et al. ,1998b ;Bengio et al. ,2001a )。加拿大高级研究所（ CIFAR）通过其神经计
算和自适应感知（ NCAP）研究计划帮助维持 神经网络 研究。该计划联合了分别
由Geoﬀrey Hinton 、Yoshua Bengio 和Yann LeCun 领导的多伦多大学、蒙特利尔大
学和纽约大学的 机器学习 研究小组。这个多学科的 CIFAR NCAP 研究计划还囊括
了神经科学家、人类和计算机视觉专家。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 17
在那个时候，人们普遍认为深度网络是难以训练的。现在我们知道， 20世纪 80
年代就存在的算法能工作得非常好，但是直到在 2006年前后都没有体现出来。这可
能仅仅由于其计算代价太高，而以当时可用的硬件难以进行足够的实验。
神经网络研究的第三次浪潮始于 2006年的突破。 Geoﬀrey Hinton 表明名为 深
度信念网络 的神经网络 可以使用一种称为贪婪逐层预训练的策略来有效地训练
(Hinton et al. ,2006a )，我们将在第 15.1节中更详细地描述。其他 CIFAR附属研究
小组很快表明，同样的策略可以被用来训练许多其他类型的深度网络 (Bengio and
LeCun ,2007a ;Ranzato et al. ,2007b )，并能系统地帮助提高在测试样例上的泛化能
力。神经网络 研究的这一次浪潮普及了 “深度学习 ’’这一术语的使用，强调研究者
现在有能力训练以前不可能训练的比较深的神经网络，并着力于深度的理论重要
性上 (Bengio and LeCun ,2007b ;Delalleau and Bengio ,2011;Pascanu et al. ,2014a ;
Montufar et al. ,2014)。此时，深度 神经网络 已经优于与之竞争的基于其他 机器学
习技术以及手工设计功能的 AI系统。在写这本书的时候，神经网络的第三次发展浪
潮仍在继续，尽管深度学习的研究重点在这一段时间内发生了巨大变化。第三次浪
潮已开始着眼于新的无监督学习技术和深度模型在小数据集的泛化能力，但目前更
多的兴趣点仍是比较传统的监督学习算法和深度模型充分利用大型标注数据集的能
力。
1.2.2与日俱增的数据量
人们可能想问，既然人工 神经网络 的第一个实验在 20世纪 50年代就完成了，
但为什么 深度学习 直到最近才被认为是关键技术。自 20世纪 90年代以来， 深度学
习就已经成功用于商业应用，但通常被视为是一种只有专家才可以使用的艺术而不
是一种技术，这种观点一直持续到最近。确实，要从一个 深度学习 算法获得良好的
性能需要一些技巧。幸运的是，随着训练数据的增加，所需的技巧正在减少。目前
在复杂的任务达到人类水平的学习算法，与 20世纪 80年代努力解决玩具问题 (toy
problem) 的学习算法几乎是一样的，尽管我们使用这些算法训练的模型经历了变革，
即简化了极深架构的训练。最重要的新进展是现在我们有了这些算法得以成功训练
所需的资源。图 1.8展示了基准数据集的大小如何随着时间的推移而显著增加。这
种趋势是由社会日益数字化驱动的。由于我们的活动越来越多发生在计算机上，我
们做什么也越来越多地被记录。由于我们的计算机越来越多地联网在一起，这些记
录变得更容易集中管理，并更容易将它们整理成适于 机器学习 应用的数据集。因为DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18 第一章 前言
统计估计的主要负担（观察少量数据以在新数据上泛化）已经减轻， ‘‘大数据 ’’时代
使机器学习 更加容易。截至 2016年，一个粗略的经验法则是，监督 深度学习 算法在
每类给定约 5000个标注样本情况下一般将达到可以接受的性能，当至少有 1000万
个标注样本的数据集用于训练时，它将达到或超过人类表现。此外，在更小的数据
集上获得成功是一个重要的研究领域，为此我们应特别侧重于如何通过无监督或半
监督学习充分利用大量的未标注样本。
1900 1950 1985 2000 2015
Year100101102103104105106107108109Dataset size (number examples)IrisMNISTPublic SVHN
ImageNet
CIFAR-10ImageNet10k
ILSVRC 2014Sports-1M
Rotated T vs. C T vs. G vs. FCriminalsCanadian Hansard
WMT
图1.8:与日俱增的数据量。 20世纪初，统计学家使用数百或数千的手动制作的度量来研究数据集
(Garson ,1900;Gosset ,1908;Anderson ,1935;Fisher ,1936)。20世纪 50年代到 80年代，受生物
启发的机器学习开拓者通常使用小的合成数据集，如低分辨率的字母位图，设计为在低计算成本下
表明神经网络能够学习特定功能 (Widrow and Hoﬀ ,1960;Rumelhart et al. ,1986b )。20世纪 80
年代和 90年代，机器学习变得更加统计，并开始利用包含成千上万个样本的更大数据集，如手写
扫描数字的 MNIST数据集（如图 1.9）所示 (LeCun et al. ,1998b )。在 21世纪初的第一个十年，
相同大小更复杂的数据集持续出现，如 CIFAR-10 数据集 (Krizhevsky and Hinton ,2009)。在这
十年结束和下五年，明显更大的数据集（包含数万到数千万的样例）完全改变了深度学习的可能
实现的事。这些数据集包括公共 Street View House Numbers 数据集 (Netzer et al. ,2011)、各种
版本的 ImageNet 数据集 (Deng et al. ,2009,2010a ;Russakovsky et al. ,2014a )以及 Sports-1M
数据集 (Karpathy et al. ,2014)。在图顶部，我们看到翻译句子的数据集通常远大于其他数据集，
如根据 Canadian Hansard 制作的 IBM数据集 (Brown et al. ,1990)和WMT 2014 英法数据集
(Schwenk ,2014)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 19
图1.9: MNIST 数据集的输入样例。 “NIST’’ 代表国家标准和技术研究所 (National Institute of
Standards and Technology) ，是最初收集这些数据的机构。 “M’’代表 ‘‘修改的 (Modiﬁed)’’ ，为更
容易地与机器学习算法一起使用，数据已经过预处理。 MNIST数据集包括手写数字的扫描和相关
标签（描述每个图像中包含 0-9中哪个数字） 。这个简单的分类问题是深度学习研究中最简单和最
广泛使用的测试之一。尽管现代技术很容易解决这个问题，它仍然很受欢迎。 Geoﬀrey Hinton 将
其描述为 ‘‘机器学习的 果蝇’’，这意味着机器学习研究人员可以在受控的实验室条件下研究他们的
算法，就像生物学家经常研究果蝇一样。
1.2.3与日俱增的模型规模
20世纪 80年代，神经网络 只能取得相对较小的成功，而现在 神经网络 非常成
功的另一个重要原因是我们现在拥有的计算资源可以运行更大的模型。 联结主义 的
主要见解之一是，当动物的许多神经元一起工作时会变得聪明。单独神经元或小集
合的神经元不是特别有用。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20 第一章 前言
生物神经元不是特别稠密地连接在一起。如图 1.10所示，几十年来，我们的 机
器学习模型中每个神经元的连接数量已经与哺乳动物的大脑在同一数量级上。
1950 1985 2000 2015
Year101102103104Connections per neuron12
34
567
89
10
Fruit yMouseCatHuman
图1.10:与日俱增的每神经元连接数。最初， 人工神经网络 中神经元之间的连接数受限于硬件能
力。而现在，神经元之间的连接数大多是出于设计考虑。一些 人工神经网络 中每个神经元的连接
数与猫一样多，并且对于其他神经网络来说，每个神经元的连接与较小哺乳动物（如小鼠）一
样多是非常普遍的。甚至人类大脑每个神经元的连接也没有过高的数量。生物神经网络规模来
自Wikipedia (2015)。
1.自适应线性单元 (Widrow and Hoﬀ ,1960)
2.神经认知机 (Fukushima ,1980)
3.GPU-加速卷积网络 (Chellapilla et al. ,2006)
4.深度玻尔兹曼机 (Salakhutdinov and Hinton ,2009a )
5.无监督卷积网络 (Jarrett et al. ,2009b )
6.GPU-加速多层感知机 (Ciresan et al. ,2010)
7.分布式自编码器 (Le et al. ,2012)
8.Multi-GPU 卷积网络 (Krizhevsky et al. ,2012a )
9.COTS HPC 无监督卷积网络 (Coates et al. ,2013)
10.GoogLeNet ( Szegedy et al. ,2014a )
如图 1.11所示，就神经元的总数目而言，直到最近 神经网络 都是惊人的小。自
从隐藏单元 引入以来，人工 神经网络 的规模大约每 2.4年扩大一倍。这种增长是由
更大内存、更快的计算机和更大的可用数据集驱动的。更大的网络能够在更复杂的
任务中实现更高的精度。这种趋势看起来将持续数十年。除非有能力迅速扩展的新
技术，否则至少要到 21世纪 50年代，人工 神经网络 将才能具备与人脑相同数量级
的神经元。生物神经元表示的功能可能比目前的人工神经元所表示的更复杂，因此DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 21
生物神经网络可能比图中描绘的甚至要更大。
1950 1985 2000 2015 2056
Year10 210 110010110210310410510610710810910101011Number of neurons (logarithmic scale)123
456
78
91011
121314
151617
181920
SpongeRoundwormLeechAntBeeFrogOctopusHuman
图1.11:与日俱增的神经网络规模。自从引入 隐藏单元 ，人工神经网络 的大小大约每 2.4年翻一
倍。生物神经网络规模来自 Wikipedia (2015)。
1.感知机 (Rosenblatt ,1958,1962)
2.自适应线性单元 (Widrow and Hoﬀ ,1960)
3.神经认知机 (Fukushima ,1980)
4.早期后向传播网络 (Rumelhart et al. ,1986b )
5.用于语音识别的 循环神经网络 (Robinson and Fallside ,1991)
6.用于语音识别的 多层感知机 (Bengio et al. ,1991)
7.均匀场 sigmoid 信念网络 (Saul et al. ,1996)
8.LeNet-5 ( LeCun et al. ,1998b )
9.回声状态网络 (Jaeger and Haas ,2004)
10.深度信念网络 (Hinton et al. ,2006a )
11.GPU-加速卷积网络 (Chellapilla et al. ,2006)
12.深度玻尔兹曼机 (Salakhutdinov and Hinton ,2009a )
13.GPU-加速深度信念网络 (Raina et al. ,2009a )
14.无监督卷积网络 (Jarrett et al. ,2009b )
15.GPU-加速多层感知机 (Ciresan et al. ,2010)
16.OMP-1 网络(Coates and Ng ,2011)
17.分布式自编码器 (Le et al. ,2012)
18.Multi-GPU 卷积网络 (Krizhevsky et al. ,2012a )
19.COTS HPC 无监督卷积网络 (Coates et al. ,2013)
20.GoogLeNet ( Szegedy et al. ,2014a )
现在看来，其神经元比一个水蛭还少的 神经网络 不能解决复杂的 人工智能 问题
是不足为奇的。即使现在的网络，从计算系统角度来看它可能相当大的，但实际上
它比相对原始的脊椎动物如青蛙的神经系统还要小。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
22 第一章 前言
由于更快的 CPU、通用 GPU的出现（在第 12.1.2节中讨论） 、更快的网络连接
和更好的分布式计算的软件基础设施，模型规模随着时间的推移不断增加是 深度学
习历史中最重要的趋势之一。人们普遍预计这种趋势将很好地持续到未来。
1.2.4与日俱增的精度、复杂度和对现实世界的冲击
20世纪 80年代以来， 深度学习 提供精确识别和预测的能力一直在提高。而且，
深度学习 持续成功地被应用于越来越广泛的实际问题中。
最早的深度模型被用来识别裁剪紧凑且非常小的图像中的单个对象 (Rumelhart
et al. ,1986d )。此后， 神经网络 可以处理的图像尺寸逐渐增加。现代对象识别网络能
处理丰富的高分辨率照片，并且不需要在被识别的对象附近进行裁剪 (Krizhevsky
et al. ,2012b )。类似地，最早的网络只能识别两种对象（或在某些情况下，单类对象
的存在与否） ，而这些现代网络通常能够识别至少 1000个不同类别的对象。对象识别
中最大的比赛是每年举行的 ImageNet 大型视觉识别挑战（ ILSVRC） 。深度学习 迅
速崛起的激动人心的一幕是卷积网络第一次大幅赢得这一挑战，它将最高水准的前
5错误率从 26.1%降到 15.3% ( Krizhevsky et al. ,2012b )，这意味着该卷积网络针对
每个图像的可能类别生成一个顺序列表，除了 15.3%的测试样本，其他测试样本的
正确类标都出现在此列表中的前 5项里。此后，深度卷积网络连续地赢得这些比赛，
截至写本书时， 深度学习 的最新结果将这个比赛中的前 5错误率降到了 3.6%，如
图1.12所示。
深度学习 也对语音识别产生了巨大影响。语音识别在 20世纪 90年代得到提
高后，直到约 2000年都停滞不前。 深度学习 的引入 (Dahl et al. ,2010;Deng et al. ,
2010b ;Seide et al. ,2011;Hinton et al. ,2012a )使得语音识别错误率陡然下降，有些
错误率甚至降低了一半。我们将在第 12.3节更详细地探讨这个历史。
深度网络在行人检测和图像分割中也取得了引人注目的成功 (Sermanet et al. ,
2013;Farabet et al. ,2013;Couprie et al. ,2013)，并且在交通标志分类上取得了超越
人类的表现 (Ciresan et al. ,2012)。
在深度网络的规模和精度有所提高的同时，它们可以解决的任务也日益复杂。
Goodfellow et al. (2014d )表明，神经网络 可以学习输出描述图像的整个字符序列，
而不是仅仅识别单个对象。此前，人们普遍认为，这种学习需要对序列中的单个元
素进行标注 (Gulcehre and Bengio ,2013)。循环神经网络 ，如之前提到的 LSTM序
列模型，现在用于对序列和其他序列之间的关系进行建模，而不是仅仅固定输入之DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
1.2深度学习的历史趋势 23
2010 2011 2012 2013 2014 2015
Year0:000:050:100:150:200:250:30ILSVRC classication error rate
图1.12:日益降低的错误率。由于深度网络达到了在 ImageNet 大规模视觉识别挑战中竞争所必
需的规模，它们每年都能赢得胜利，并且产生越来越低的错误率。数据来源于 Russakovsky et al.
(2014b )和Heet al. (2015)。
间的关系。这种序列到序列的学习似乎引领着另一个应用的颠覆性发展，即机器翻
译(Sutskever et al. ,2014;Bahdanau et al. ,2015)。
这种复杂性日益增加的趋势已将其推向逻辑结论，即神经图灵机 (Graves et al. ,
2014)的引入，它能学习读取存储单元和向存储单元写入任意内容。这样的 神经网
络可以从期望行为的 样本中学习简单的程序。例如，从杂乱和排好序的 样本中学习
对一系列数进行排序。这种自我编程技术正处于起步阶段，但原则上未来可以适用
于几乎所有的任务。
深度学习 的另一个最大的成就是其在 强化学习 （reinforcement learning ）领域
的扩展。在 强化学习 中，一个自主的智能体必须在没有人类操作者指导的情况下，通
过试错来学习执行任务。 DeepMind 表明，基于 深度学习 的强化学习 系统能够学会玩
Atari视频游戏，并在多种任务中可与人类匹敌 (Mnih et al. ,2015)。深度学习 也显
著改善了机器人 强化学习 的性能 (Finn et al. ,2015)。
许多深度学习 应用都是高利润的。现在 深度学习 被许多顶级的技术公司使用，包
括Google、Microsoft 、Facebook 、IBM、Baidu、Apple、Adobe、Netﬂix、NVIDIA
和NEC等。
深度学习 的进步也严重依赖于软件基础架构的进展。 软件库如 Theano ( Bergstra
et al. ,2010a ;Bastien et al. ,2012a )、PyLearn2 ( Goodfellow et al. ,2013e )、Torch ( Col-
lobert et al. ,2011b )、DistBelief ( Dean et al. ,2012)、Caﬀe ( Jia,2013)、MXNet ( ChenDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
24 第一章 前言
et al. ,2015)和TensorFlow ( Abadi et al. ,2015)都能支持重要的研究项目或商业产
品。
深度学习 也为其他科学做出了贡献。用于对象识别的现代卷积网络为神经科
学家们提供了可以研究的视觉处理模型 (DiCarlo ,2013)。深度学习 也为处理海量
数据以及在科学领域作出有效的预测提供了非常有用的工具。它已成功地用于预
测分子如何相互作用从而帮助制药公司设计新的药物 (Dahl et al. ,2014)，搜索亚
原子粒子 (Baldi et al. ,2014)，以及自动解析用于构建人脑三维图的显微镜图像
(Knowles-Barley et al. ,2014)等。我们期待 深度学习 未来能够出现在越来越多的科
学领域中。
总之，深度学习 是机器学习 的一种方法。在过去几十年的发展中，它大量借鉴
了我们关于人脑、统计学和应用数学的知识。近年来，得益于更强大的计算机、更
大的数据集和能够训练更深网络的技术， 深度学习 的普及性和实用性都有了极大的
发展。未来几年充满了进一步提高 深度学习 并将它带到新领域的挑战和机遇。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第一部分
应用数学与机器学习基础
25DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
26
本书这一部分将介绍理解 深度学习 所需的基本数学概念。我们从应用数学的一
般概念开始，这能使我们定义许多变量的函数，找到这些函数的最高和最低点，并
量化信念度。
接着，我们描述 机器学习 的基本目标，并描述如何实现这些目标。我们需要指
定代表某些信念的模型、设计衡量这些信念与现实对应程度的 代价函数 以及使用训
练算法最小化这个 代价函数 。
这个基本框架是广泛多样的 机器学习 算法的基础，其中也包括非深度的 机器学
习方法。在本书的后续部分，我们将在这个框架下开发 深度学习 算法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第二章 线性代数
线性代数作为数学的一个分支，广泛用于科学和工程中。然而，因为线性代数
主要是面向连续数学，而非离散数学，所以很多计算机科学家很少接触它。掌握好
线性代数对于理解和从事机器学习算法相关工作是很有必要的，尤其对于深度学习
算法而言。因此，在我们开始介绍深度学习之前，我们集中探讨一些必备的线性代
数知识。
如果你已经很熟悉线性代数，那么你可以轻松地跳过本章。如果你已经了解
这些概念，但是需要一份索引表来回顾一些重要公式，那么我们推荐 The Matrix
Cookbook (Petersen and Pedersen ,2006)。如果你没有接触过线性代数，那么本章将
告诉你本书所需的线性代数知识，不过我们仍然非常建议你参考其他专注于讲解线
性代数的文献，例如 Shilov (1977)。最后，本章跳过了很多重要但是对于理解深度
学习非必需的线性代数知识。
2.1标量、向量、矩阵和张量
学习线性代数，会涉及以下几类数学概念：
•标量（scalar） ：一个标量就是一个单独的数，它不同于线性代数中研究的其他
大部分对象（通常是多个数的数组） 。我们用斜体表示标量。标量通常被赋予小
写的变量名称。当我们介绍标量时，会明确它们是哪种类型的数。比如，在定
义实数标量时，我们可能会说 ‘‘令 s2R表示一条线的斜率 ’’；在定义自然数标
量时，我们可能会说 ‘‘令 n2N表示元素的数目 ’’。
•向量（vector） ：一个向量是一列数。这些数是有序排列的。通过次序中的 索
引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比
27DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
28 第二章 线性代数
如 x。向量中的元素可以通过带脚标的斜体表示。向量 x的第一个元素是 x1，
第二个元素是 x2，等等。我们也会注明存储在向量中的元素是什么类型的。如
果每个元素都属于 R，并且该向量有 n个元素，那么该向量属于实数集 R的
n次笛卡尔乘积构成的集合，记为 Rn。当我们需要明确表示向量中的元素时，
我们会将元素排列成一个方括号包围的纵列：
x=2
666664x1
x2
...
xn3
777775: (2.1)
我们可以把向量看作空间中的点，每个元素是不同坐标轴上的坐标。
有时我们需要 索引向量中的一些元素。在这种情况下，我们定义一个包含这些
元素索引的集合，然后将该集合写在脚标处。比如，指定 x1，x3和 x6，我们定
义集合 S=f1;3;6g，然后写作 xS。我们用符号－表示集合的补集中的 索引。
比如 x 1表示 x中除 x1外的所有元素， x S表示 x中除 x1，x3，x6外所有元
素构成的向量。
•矩阵（matrix） ：矩阵是一个二维数组，其中的每一个元素被两个 索引而非一个
所确定。我们通常会赋予矩阵粗体的大写变量名称，比如 A。如果一个实数矩
阵高度为 m，宽度为 n，那么我们说 A2Rmn。我们在表示矩阵中的元素时，
通常以不加粗的斜体形式使用其名称， 索引用逗号间隔。比如， A1;1表示 A左
上的元素， Am;n表示 A右下的元素。我们通过用 “:’’表示水平坐标，以表示
垂直坐标 i中的所有元素。比如， Ai;:表示 A中垂直坐标 i上的一横排元素。
这也被称为 A的第 i行（row） 。同样地， A:;i表示 A的第 i列（column） 。
当我们需要明确表示矩阵中的元素时，我们将它们写在用方括号包围起来的数
组中：[
A1;1A1;2
A2;1A2;2]
: (2.2)
有时我们需要矩阵值表达式的 索引，而不是单个元素。在这种情况下，我们在
表达式后面接下标，但不必将矩阵的变量名称小写化。比如， f(A)i;j表示函数
f作用在 A上输出的矩阵的第 i行第 j列元素。
•张量（tensor） ：在某些情况下，我们会讨论坐标超过两维的数组。一般地，一
个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。我们DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.2矩阵和向量相乘 29
使用字体 A来表示张量 “A’’。张量 A中坐标为 (i; j; k )的元素记作 Ai;j;k。
转置（transpose ）是矩阵的重要操作之一。矩阵的转置是以对角线为轴的镜像，
这条从左上角到右下角的对角线被称为 主对角线 （main diagonal ） 。图 2.1显示了这
个操作。我们将矩阵 A的转置表示为 A⊤，定义如下
(A⊤)i;j= Aj;i: (2.3)
向量可以看作是只有一列的矩阵。对应地，向量的转置可以看作是只有一行的
矩阵。有时，我们通过将向量元素作为行矩阵写在文本行中，然后使用转置操作将
其变为标准的列向量，来定义一个向量，比如 x= [ x1;x2;x3]⊤.
标量可以看作是只有一个元素的矩阵。因此，标量的转置等于它本身， a= a⊤。
A=24A1,1A1,2A2,1A2,2A3,1A3,235)A>=A1,1A2,1A3,1A1,2A2,2A3,2 
图2.1:矩阵的转置可以看成是以主对角线为轴的一个镜像。
只要矩阵的形状一样，我们可以把两个矩阵相加。两个矩阵相加是指对应位置
的元素相加，比如 C= A+B，其中 Ci;j= Ai;j+Bi;j。
标量和矩阵相乘，或是和矩阵相加时，我们只需将其与矩阵的每个元素相乘或
相加，比如 D= aB+c，其中 Di;j= aBi;j+c。
在深度学习中，我们也使用一些不那么常规的符号。我们允许矩阵和向量相
加，产生另一个矩阵： C= A+b，其中 Ci;j= Ai;j+bj。换言之，向量 b和矩阵
A的每一行相加。这个简写方法使我们无需在加法操作前定义一个将向量 b复制
到每一行而生成的矩阵。这种隐式地复制向量 b到很多位置的方式，被称为 广播
（broadcasting ） 。
2.2矩阵和向量相乘
矩阵乘法是矩阵运算中最重要的操作之一。两个矩阵 A和 B的矩阵乘积
（matrix product ）是第三个矩阵 C。为了使乘法定义良好，矩阵 A的列数必须和矩DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
30 第二章 线性代数
阵 B的行数相等。如果矩阵 A的形状是 mn，矩阵 B的形状是 np，那么矩阵
C的形状是 mp。我们可以通过将两个或多个矩阵并列放置以书写矩阵乘法，例如
C= AB: (2.4)
具体地，该乘法操作定义为
Ci;j=∑
kAi;kBk;j: (2.5)
需要注意的是，两个矩阵的标准乘积 不是指两个矩阵中对应元素的乘积。不过，
那样的矩阵操作确实是存在的，被称为 元素对应乘积 （element-wise product ）或
者Hadamard 乘积（Hadamard product ） ，记为 A⊙B。
两个相同维数的向量 x和 y的点积（dot product ）可看作是矩阵乘积 x⊤y。我
们可以把矩阵乘积 C= AB中计算 Ci;j的步骤看作是 A的第 i行和 B的第 j列之
间的点积。
矩阵乘积运算有许多有用的性质，从而使矩阵的数学分析更加方便。比如，矩
阵乘积服从分配律：
A(B+C) = AB+AC: (2.6)
矩阵乘积也服从结合律：
A(BC) = ( AB)C: (2.7)
不同于标量乘积，矩阵乘积 并不满足交换律（ AB = BA的情况并非总是满足） 。
然而，两个向量的 点积（dot product ）满足交换律：
x⊤y= y⊤x: (2.8)
矩阵乘积的转置有着简单的形式：
(AB)⊤= B⊤A⊤: (2.9)
利用向量乘积是标量，标量转置是自身的事实，我们可以证明式 (2.8)：
x⊤y=(
x⊤y)⊤= y⊤x: (2.10)
由于本书的重点不是线性代数，我们并不试图展示矩阵乘积的所有重要性质，
但读者应该知道矩阵乘积还有很多有用的性质。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.3单位矩阵和逆矩阵 31
现在我们已经知道了足够多的线性代数符号，可以表达下列线性方程组：
Ax= b (2.11)
其中 A2Rmn是一个已知矩阵， b2Rm是一个已知向量， x2Rn是一个我们要
求解的未知向量。向量 x的每一个元素 xi都是未知的。矩阵 A的每一行和 b中对
应的元素构成一个约束。我们可以把式 (2.11)重写为
A1;:x=b1 (2.12)
A2;:x=b2 (2.13)
 (2.14)
Am;:x=bm (2.15)
或者，更明确地，写作
A1;1x1+A1;2x2+ A1;nxn=b1 (2.16)
A2;1x1+A2;2x2+ A2;nxn=b2 (2.17)
 (2.18)
Am;1x1+Am;2x2+ Am;nxn=bm: (2.19)
矩阵向量乘积符号为这种形式的方程提供了更紧凑的表示。
2.3单位矩阵和逆矩阵
线性代数提供了被称为 矩阵逆（matrix inversion ）的强大工具。对于大多数矩
阵 A，我们都能通过 矩阵逆解析地求解式 (2.11)。
为了描述矩阵逆，我们首先需要定义 单位矩阵 （identity matrix ）的概念。任意
向量和单位矩阵相乘，都不会改变。我们将保持 n维向量不变的单位矩阵记作 In。
形式上， In2Rnn，
8x2Rn;Inx= x: (2.20)
单位矩阵的结构很简单：所有沿主对角线的元素都是 1，而所有其他位置的元素都是
0。如图 2.2所示的例子。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
32 第二章 线性代数
2
6641 0 0
0 1 0
0 0 13
775
图2.2:单位矩阵的一个样例：这是 I3。
矩阵 A的矩阵逆（matrix inversion ）记作 A 1，其定义的矩阵满足如下条件
A 1A= In: (2.21)
现在我们可以通过以下步骤求解式 (2.11)：
Ax= b (2.22)
A 1Ax= A 1b (2.23)
Inx= A 1b (2.24)
x= A 1b: (2.25)
当然，这取决于我们能否找到一个逆矩阵 A 1。在接下来的章节中，我们会讨
论逆矩阵 A 1存在的条件。
当逆矩阵 A 1存在时，有几种不同的算法都能找到它的闭解形式。理论上，相
同的逆矩阵可用于多次求解不同向量 b的方程。然而，逆矩阵 A 1主要是作为理论
工具使用的，并不会在大多数软件应用程序中实际使用。这是因为逆矩阵 A 1在数
字计算机上只能表现出有限的精度，有效使用向量 b的算法通常可以得到更精确的
x。
2.4线性相关和生成子空间
如果逆矩阵 A 1存在，那么式 (2.11)肯定对于每一个向量 b恰好存在一个解。
但是，对于方程组而言，对于向量 b的某些值，有可能不存在解，或者存在无限多
个解。存在多于一个解但是少于无限多个解的情况是不可能发生的；因为如果 x和
y都是某方程组的解，则
z=x+ (1 )y (2.26)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.4线性相关和生成子空间 33
（其中 取任意实数）也是该方程组的解。
为了分析方程有多少个解，我们可以将 A的列向量看作是从 原点（origin） （元
素都是零的向量）出发的不同方向，确定有多少种方法可以到达向量 b。在这个观点
下，向量 x中的每个元素表示我们应该沿着这些方向走多远，即 xi表示我们需要沿
着第 i个向量的方向走多远：
Ax=∑
ixiA:;i: (2.27)
一般而言，这种操作被称为 线性组合 （linear combination ） 。形式上，一组向量的线
性组合，是指每个向量乘以对应标量系数之后的和，即：
∑
iciv(i): (2.28)
一组向量的 生成子空间 （span）是原始向量线性组合后所能抵达的点的集合。
确定 Ax= b是否有解相当于确定向量 b是否在 A列向量的 生成子空间 中。这
个特殊的 生成子空间 被称为 A的列空间（column space ）或者 A的值域（range） 。
为了使方程 Ax= b对于任意向量 b2Rm都存在解，我们要求 A的列空间构
成整个 Rm。如果 Rm中的某个点不在 A的列空间中，那么该点对应的 b会使得
该方程没有解。矩阵 A的列空间是整个 Rm的要求，意味着 A至少有 m列，即
nm。否则， A列空间的维数会小于 m。例如，假设 A是一个 32的矩阵。目
标 b是3维的，但是 x只有 2维。所以无论如何修改 x的值，也只能描绘出 R3空
间中的二维平面。当且仅当向量 b在该二维平面中时，该方程有解。
不等式 nm仅是方程对每一点都有解的必要条件。这不是一个充分条件，因
为有些列向量可能是冗余的。假设有一个 R22中的矩阵，它的两个列向量是相同
的。那么它的列空间和它的一个列向量作为矩阵的列空间是一样的。换言之，虽然
该矩阵有 2列，但是它的列空间仍然只是一条线，不能涵盖整个 R2空间。
正式地说，这种冗余被称为 线性相关 （linear dependence ） 。如果一组向量中的
任意一个向量都不能表示成其他向量的线性组合，那么这组向量被称为 线性无关
（linearly independent ） 。如果某个向量是一组向量中某些向量的线性组合，那么我
们将这个向量加入到这组向量后不会增加这组向量的 生成子空间 。这意味着，如果
一个矩阵的 列空间涵盖整个 Rm，那么该矩阵必须包含至少一组 m个线性无关的向
量。这是式 (2.11)对于每一个向量 b的取值都有解的充分必要条件。值得注意的是，
这个条件是说该向量集恰好有 m个线性无关的列向量，而不是至少 m个。不存在DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
34 第二章 线性代数
一个 m维向量的集合具有多于 m个彼此线性不相关的列向量，但是一个有多于 m
个列向量的矩阵却有可能拥有不止一个大小为 m的线性无关向量集。
要想使矩阵可逆，我们还需要保证式 (2.11)对于每一个 b值至多有一个解。为
此，我们需要确保该矩阵至多有 m个列向量。否则，该方程会有不止一个解。
综上所述，这意味着该矩阵必须是一个 方阵（square） ，即 m=n，并且所有列
向量都是线性无关的。一个列向量线性相关的方阵被称为 奇异的（singular） 。
如果矩阵 A不是一个方阵或者是一个奇异的方阵，该方程仍然可能有解。但是
我们不能使用矩阵逆去求解。
目前为止，我们已经讨论了逆矩阵左乘。我们也可以定义逆矩阵右乘：
AA 1= I: (2.29)
对于方阵而言，它的左逆和右逆是相等的。
2.5范数
有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用被称为 范数
（norm）的函数衡量向量大小。形式上， Lp范数定义如下
∥x∥p=(∑
ijxijp)1
p
(2.30)
其中 p2R，p1。
范数（包括 Lp范数）是将向量映射到非负值的函数。直观上来说，向量 x的
范数衡量从原点到点 x的距离。更严格地说，范数是满足下列性质的任意函数：
•f(x) = 0) x= 0
•f(x+y)f(x) +f(y)（三角不等式 （triangle inequality ） ）
•82R,f(x) =jjf(x)
当p= 2时，L2范数被称为 欧几里得范数 （Euclidean norm ） 。它表示从原点
出发到向量 x确定的点的欧几里得距离。 L2范数在机器学习中出现地十分频繁，经DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.5范数 35
常简化表示为∥x∥，略去了下标 2。平方 L2范数也经常用来衡量向量的大小，可以
简单地通过 点积 x⊤x计算。
平方 L2范数在数学和计算上都比 L2范数本身更方便。例如，平方 L2范数对
x中每个元素的导数只取决于对应的元素，而 L2范数对每个元素的导数却和整个向
量相关。但是在很多情况下，平方 L2范数也可能不受欢迎，因为它在原点附近增长
得十分缓慢。在某些机器学习应用中，区分恰好是零的元素和非零但值很小的元素
是很重要的。在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的
数学形式的函数： L1范数。 L1范数可以简化如下：
∥x∥1=∑
ijxij: (2.31)
当机器学习问题中零和非零元素之间的差异非常重要时，通常会使用 L1范数。每当
x中某个元素从 0增加 ϵ，对应的 L1范数也会增加 ϵ。
有时候我们会统计向量中非零元素的个数来衡量向量的大小。有些作者将这种
函数称为 “L0范数’’，但是这个术语在数学意义上是不对的。向量的非零元素的数目
不是范数，因为对向量缩放 倍不会改变该向量非零元素的数目。因此， L1范数经
常作为表示非零元素数目的替代函数。
另外一个经常在机器学习中出现的范数是 L1范数，也被称为 最大范数 （max
norm） 。这个范数表示向量中具有最大幅值的元素的绝对值：
∥x∥1= max
ijxij: (2.32)
有时候我们可能也希望衡量矩阵的大小。在深度学习中，最常见的做法是使
用Frobenius 范数（Frobenius norm ） ，
∥A∥F=√∑
i;jA2
i;j; (2.33)
其类似于向量的 L2范数。
两个向量的 点积（dot product ）可以用范数来表示。具体地，
x⊤y=∥x∥2∥y∥2cos (2.34)
其中 表示 x和 y之间的夹角。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
36 第二章 线性代数
2.6特殊类型的矩阵和向量
有些特殊类型的矩阵和向量是特别有用的。
对角矩阵 （diagonal matrix ）只在主对角线上含有非零元素，其他位置都是零。
形式上，矩阵 D是对角矩阵，当且仅当对于所有的 i̸=j，Di;j= 0。我们已经看到
过一个对角矩阵：单位矩阵，对角元素全部是 1。我们用 diag(v)表示一个对角元素
由向量 v中元素给定的对角方阵。对角矩阵受到关注的部分原因是对角矩阵的乘法
计算很高效。计算乘法 diag(v)x，我们只需要将 x中的每个元素 xi放大 vi倍。换
言之， diag(v)x= v⊙x。计算对角方阵的逆矩阵也很高效。对角方阵的逆矩阵存在，
当且仅当对角元素都是非零值，在这种情况下， diag(v) 1=diag([1/v1; : : : ; 1/vn]⊤)。
在很多情况下，我们可以根据任意矩阵导出一些通用的机器学习算法；但通过将一
些矩阵限制为对角矩阵，我们可以得到计算代价较低的（并且简明扼要的）算法。
不是所有的对角矩阵都是方阵。长方形的矩阵也有可能是对角矩阵。非方阵的
对角矩阵没有逆矩阵，但我们仍然可以高效地计算它们的乘法。对于一个长方形对
角矩阵 D而言，乘法 Dx会涉及到 x中每个元素的缩放，如果 D是瘦长型矩阵，
那么在缩放后的末尾添加一些零；如果 D是胖宽型矩阵，那么在缩放后去掉最后一
些元素。
对称（symmetric ）矩阵是转置和自己相等的矩阵：
A= A⊤: (2.35)
当某些不依赖参数顺序的双参数函数生成元素时，对称矩阵经常会出现。例如，如
果 A是一个距离度量矩阵， Ai;j表示点 i到点 j的距离，那么 Ai;j= Aj;i，因为距
离函数是对称的。
单位向量 （unit vector ）是具有 单位范数 （unit norm ）的向量：
∥x∥2= 1: (2.36)
如果 x⊤y= 0，那么向量 x和向量 y互相正交（orthogonal ） 。如果两个向量都
有非零范数，那么这两个向量之间的夹角是 90度。在 Rn中，至多有 n个范数非
零向量互相正交。如果这些向量不仅互相正交，并且范数都为 1，那么我们称它们
是标准正交 （orthonormal ） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.7特征分解 37
正交矩阵 （orthogonal matrix ）是指行向量和列向量是分别标准正交的方阵：
A⊤A= AA⊤= I: (2.37)
这意味着
A 1= A⊤; (2.38)
所以正交矩阵受到关注是因为求逆计算代价小。我们需要注意正交矩阵的定义。反
直觉地，正交矩阵的行向量不仅是正交的，还是标准正交的。对于行向量或列向量
互相正交但不是标准正交的矩阵没有对应的专有术语。
2.7特征分解
许多数学对象可以通过将它们分解成多个组成部分，或者找到它们的一些属性
而更好地理解，这些属性是通用的，而不是由我们选择表示它们的方式产生的。
例如，整数可以分解为质因数。我们可以用十进制或二进制等不同方式表示整
数12，但是 12 = 233永远是对的。从这个表示中我们可以获得一些有用的信
息，比如 12不能被 5整除，或者 12的倍数可以被 3整除。
正如我们可以通过分解质因数来发现整数的一些内在性质，我们也可以通过分
解矩阵来发现矩阵表示成数组元素时不明显的函数性质。
特征分解 （eigendecomposition ）是使用最广的矩阵分解之一，即我们将矩阵分
解成一组特征向量和特征值。
方阵 A的特征向量 （eigenvector ）是指与 A相乘后相当于对该向量进行缩放
的非零向量 v：
Av=v: (2.39)
标量 被称为这个特征向量对应的 特征值（eigenvalue ） 。（类似地，我们也可以
定义左特征向量 （left eigenvector ）v⊤A=v⊤，但是通常我们更关注 右特征向量
（right eigenvector ） ） 。
如果 v是 A的特征向量，那么任何缩放后的向量 sv(s2R，s̸= 0)也是 A的
特征向量。此外， sv和 v有相同的特征值。基于这个原因，通常我们只考虑单位特
征向量。
假设矩阵 A有n个线性无关的特征向量 fv(1); : : : ; v(n)g，对应着特征值
f1; : : : ;  ng。我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
38 第二章 线性代数
V= [ v(1); : : : ; v(n)].类似地， 我们也可以将特征值连接成一个向量 = [1; : : : ;  n]⊤。
因此 A的特征分解 （eigendecomposition ）可以记作
A= Vdiag()V 1: (2.40)
我们已经看到了 构建具有特定特征值和特征向量的矩阵，能够使我们在目标方
向上延伸空间。然而，我们也常常希望将矩阵 分解（decompose ）成特征值和特征向
量。这样可以帮助我们分析矩阵的特定性质，就像质因数分解有助于我们理解整数。
不是每一个矩阵都可以分解成特征值和特征向量。在某些情况下，特征分解存
在，但是会涉及到复数，而非实数。幸运的是，在本书中我们通常只需要分解一类
有简单分解的矩阵。具体地，每个实对称矩阵都可以分解成实特征向量和实特征值：
A= QQ⊤: (2.41)
其中 Q是 A的特征向量组成的正交矩阵， 是对角矩阵。特征值 i;i对应的特征
向量是矩阵 Q的第 i列，记作 Q:;i。因为 Q是正交矩阵，我们可以将 A看作是沿
方向 v(i)延展 i倍的空间。如图 2.3所示的例子。
虽然任意一个实对称矩阵 A都有特征分解，但是特征分解可能并不唯一。如果
两个或多个特征向量拥有相同的特征值，那么在由这些特征向量产生的生成子空间
中，任意一组正交向量都是该特征值对应的特征向量。因此，我们可以等价地从这
些特征向量中构成 Q作为替代。按照惯例，我们通常按降序排列 的元素。在该
约定下，特征分解唯一当且仅当所有的特征值都是唯一的。
矩阵的特征分解给了我们很多关于矩阵的有用信息。矩阵是奇异的当且仅当含
有零特征值。实对称矩阵的特征分解也可以用于优化二次方程 f(x) = x⊤Ax，其中
限制∥x∥2= 1。当 x等于 A的某个特征向量时， f将返回对应的特征值。在限制条
件下，函数 f的最大值是最大特征值，最小值是最小特征值。
所有特征值都是正数的矩阵被称为 正定（positive deﬁnite ） ；所有特征值都是非
负数的矩阵被称为 半正定（positive semideﬁnite ） 。同样地，所有特征值都是负数的
矩阵被称为 负定（negative deﬁnite ） ；所有特征值都是非正数的矩阵被称为 半负定
（negative semideﬁnite ） 。半正定矩阵受到关注是因为它们保证 8x;x⊤Ax0。此外，
正定矩阵还保证 x⊤Ax= 0) x= 0。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.8奇异值分解 39
−3 −2 −1 0 1 2 3
x0−3−2−10123x1v(1)
v(2)Before multiplication
−3 −2 −1 0 1 2 3
x0
0−3−2−10123x0
1v(1)¸1v(1)
v(2)¸2v(2)After multiplicationEffect of eigenvectors and eigenvalues
图2.3:特征向量和特征值的作用效果。特征向量和特征值的作用效果的一个实例。在这里，矩阵
A有两个标准正交 的特征向量，对应特征值为 1的 v(1)以及对应特征值为 2的 v(2)。(左)我
们画出了所有的单位向量 u2R2的集合，构成一个单位圆。 (右)我们画出了所有的 Au点的集
合。通过观察 A拉伸单位圆的方式，我们可以看到它将 v(i)方向的空间拉伸了 i倍。
2.8奇异值分解
在第 2.7节，我们探讨了如何将矩阵分解成特征向量和特征值。还有另一种分解
矩阵的方法，被称为 奇异值分解 （singular value decomposition ,SVD） ，将矩阵分
解为奇异向量 （singular vector ）和奇异值（singular value ） 。通过奇异值分解 ，我
们会得到一些与 特征分解 相同类型的信息。然而， 奇异值分解 有更广泛的应用。每
个实数矩阵都有一个 奇异值分解 ，但不一定都有 特征分解 。例如，非方阵的矩阵没
有特征分解 ，这时我们只能使用 奇异值分解 。
回想一下，我们使用 特征分解 去分析矩阵 A时，得到特征向量构成的矩阵 V
和特征值构成的向量 ，我们可以重新将 A写作
A= Vdiag()V 1: (2.42)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
40 第二章 线性代数
奇异值分解 是类似的，只不过这回我们将矩阵 A分解成三个矩阵的乘积：
A= UDV⊤: (2.43)
假设 A是一个 mn的矩阵，那么 U是一个 mm的矩阵， D是一个 mn
的矩阵， V是一个 nn矩阵。
这些矩阵中的每一个经定义后都拥有特殊的结构。矩阵 U和 V都被定义为正
交矩阵，而矩阵 D被定义为对角矩阵。注意，矩阵 D不一定是方阵。
对角矩阵 D对角线上的元素被称为矩阵 A的奇异值（singular value ） 。矩阵
U的列向量被称为 左奇异向量 （left singular vector ） ，矩阵 V的列向量被称 右奇异
向量（right singular vector ） 。
事实上，我们可以用与 A相关的特征分解去解释 A的奇异值分解 。A的左奇
异向量（left singular vector ）是 AA⊤的特征向量。 A的右奇异向量 （right singular
vector）是 A⊤A的特征向量。 A的非零奇异值是 A⊤A特征值的平方根，同时也是
AA⊤特征值的平方根。
SVD最有用的一个性质可能是拓展矩阵求逆到非方矩阵上。我们将在下一节中
探讨。
2.9 Moore-Penrose 伪逆
对于非方矩阵而言，其逆矩阵没有定义。假设在下面的问题中，我们希望通过
矩阵 A的左逆 B来求解线性方程，
Ax= y (2.44)
等式两边左乘左逆 B后，我们得到
x= By: (2.45)
取决于问题的形式，我们可能无法设计一个唯一的映射将 A映射到 B。
如果矩阵 A的行数大于列数，那么上述方程可能没有解。如果矩阵 A的行数
小于列数，那么上述矩阵可能有多个解。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.10迹运算 41
Moore-Penrose 伪逆（Moore-Penrose pseudoinverse ）使我们在这类问题上
取得了一定的进展。矩阵 A的伪逆定义为：
A+= lim
a↘0(A⊤A+I) 1A⊤: (2.46)
计算伪逆的实际算法没有基于这个定义，而是使用下面的公式：
A+= VD+U⊤: (2.47)
其中，矩阵 U，D和 V是矩阵 A奇异值分解 后得到的矩阵。对角矩阵 D的伪逆
D+是其非零元素取倒数之后再转置得到的。
当矩阵 A的列数多于行数时，使用伪逆求解线性方程是众多可能解法中的一
种。特别地， x= A+y是方程所有可行解中欧几里得范数 ∥x∥2最小的一个。
当矩阵 A的行数多于列数时，可能没有解。在这种情况下，通过伪逆得到的 x
使得 Ax和 y的欧几里得距离∥Ax y∥2最小。
2.10迹运算
迹运算返回的是矩阵对角元素的和：
Tr(A) =∑
iAi;i: (2.48)
迹运算因为很多原因而有用。若不使用求和符号，有些矩阵运算很难描述，而通
过矩阵乘法和迹运算符号，可以清楚地表示。例如，迹运算提供了另一种描述矩
阵Frobenius 范数的方式：
∥A∥F=√
Tr(AA⊤): (2.49)
用迹运算表示表达式，我们可以使用很多有用的等式巧妙地处理表达式。例如，
迹运算在转置运算下是不变的：
Tr(A) =Tr(A⊤): (2.50)
多个矩阵相乘得到的方阵的迹，和将这些矩阵中的最后一个挪到最前面之后相
乘的迹是相同的。当然，我们需要考虑挪动之后矩阵乘积依然定义良好：
Tr(ABC ) =Tr(CAB ) =Tr(BCA ): (2.51)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
42 第二章 线性代数
或者更一般地，
Tr(n∏
i=1F(i)) =Tr(F(n)n 1∏
i=1F(i)): (2.52)
即使循环置换后矩阵乘积得到的矩阵形状变了，迹运算的结果依然不变。例如，假
设矩阵 A2Rmn，矩阵 B2Rnm，我们可以得到
Tr(AB) =Tr(BA) (2.53)
尽管 AB2Rmm和 BA2Rnn。
另一个有用的事实是标量在迹运算后仍然是它自己： a=Tr(a)。
2.11行列式
行列式，记作 det(A)，是一个将方阵 A映射到实数的函数。行列式等于矩阵特
征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小
了多少。如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的
体积。如果行列式是 1，那么这个转换保持空间体积不变。
2.12实例：主成分分析
主成分分析 （principal components analysis ,PCA）是一个简单的机器学习算
法，可以通过基础的线性代数知识推导。
假设在 Rn空间中我们有 m个点fx(1); : : : ; x(m)g，我们希望对这些点进行有损
压缩。有损压缩表示我们使用更少的内存，但损失一些精度去存储这些点。我们希
望损失的精度尽可能少。
一种编码这些点的方式是用低维表示。对于每个点 x(i)2Rn，会有一个对应的
编码向量 c(i)2Rl。如果 l比n小，那么我们便使用了更少的内存来存储原来的数
据。我们希望找到一个编码函数，根据输入返回编码， f(x) = c；我们也希望找到一
个解码函数，给定编码重构输入， xg(f(x))。
PCA由我们选择的解码函数而定。具体地，为了简化解码器，我们使用矩阵乘
法将编码映射回 Rn，即 g(c) = Dc，其中 D2Rnl是定义解码的矩阵。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.12实例：主成分分析 43
目前为止所描述的问题，可能会有多个解。因为如果我们按比例地缩小所有点
对应的编码向量 ci，那么我们只需按比例放大 D:;i，即可保持结果不变。为了使问
题有唯一解，我们限制 D中所有列向量都有 单位范数 。
计算这个解码器的最优编码可能是一个困难的问题。为了使编码问题简单一些，
PCA限制 D的列向量彼此正交（注意，除非 l=n，否则严格意义上 D不是一个
正交矩阵） 。
为了将这个基本想法变为我们能够实现的算法，首先我们需要明确如何根据每
一个输入 x得到一个最优编码 c。一种方法是最小化原始输入向量 x和重构向量
g(c)之间的距离。我们使用范数来衡量它们之间的距离。在 PCA算法中，我们使
用L2范数：
c= arg min
c∥x g(c)∥2: (2.54)
我们可以用平方 L2范数替代 L2范数，因为两者在相同的值 c上取得最小值。
这是因为 L2范数是非负的，并且平方运算在非负值上是单调递增的。
c= arg min
c∥x g(c)∥2
2: (2.55)
该最小化函数可以简化成
(x g(c))⊤(x g(c)) (2.56)
（式 (2.30)中L2范数的定义）
= x⊤x x⊤g(c) g(c)⊤x+g(c)⊤g(c) (2.57)
(分配律 )
= x⊤x 2x⊤g(c) +g(c)⊤g(c) (2.58)
(因为标量 g(c)⊤x的转置等于自己 )
因为第一项 x⊤x不依赖于 c，所以我们可以忽略它，得到如下的优化目标：
c= arg min
c 2x⊤g(c) +g(c)⊤g(c): (2.59)
更进一步，我们代入 g(c)的定义：
c= arg min
c 2x⊤Dc+c⊤D⊤Dc (2.60)
= arg min
c 2x⊤Dc+c⊤Ilc (2.61)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
44 第二章 线性代数
(矩阵 D的正交性和单位范数约束 )
= arg min
c 2x⊤Dc+c⊤c (2.62)
我们可以通过向量微积分来求解这个最优化问题（如果你不清楚怎么做，请参
考第 4.3节）
∇ c( 2x⊤Dc+c⊤c) = 0 (2.63)
 2D⊤x+ 2 c= 0 (2.64)
c= D⊤x: (2.65)
这使得算法很高效：最优编码 x只需要一个矩阵 -向量乘法操作。为了编码向量，
我们使用编码函数：
f(x) = D⊤x: (2.66)
进一步使用矩阵乘法，我们也可以定义 PCA重构操作：
r(x) =g(f(x)) = DD⊤x: (2.67)
接下来，我们需要挑选编码矩阵 D。要做到这一点，我们回顾最小化输入和重
构之间 L2距离的这个想法。因为我们用相同的矩阵 D对所有点进行解码，我们
不能再孤立地看待每个点。反之，我们必须最小化所有维数和所有点上的误差矩阵
的Frobenius 范数：
D= arg min
D√∑
i;j(
x(i)
j r(x(i))j)2
subject to D⊤D= Il: (2.68)
为了推导用于寻求 D的算法，我们首先考虑 l= 1的情况。在这种情况下， D
是一个单一向量 d。将式 (2.67)代入式 (2.68)，简化 D为 d，问题简化为
d= arg min
d∑
ix(i) dd⊤x(i)2
2subject to∥d∥2= 1: (2.69)
上述公式是直接代入得到的，但不是文体表述最舒服的方式。在上述公式中，我
们将标量 d⊤x(i)放在向量 d的右边。将该标量放在左边的写法更为传统。于是我们
通常写作如下：
d= arg min
d∑
ix(i) d⊤x(i)d2
2subject to∥d∥2= 1; (2.70)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
2.12实例：主成分分析 45
或者，考虑到标量的转置和自身相等，我们也可以写作：
d= arg min
d∑
ix(i) x(i)⊤dd2
2subject to∥d∥2= 1: (2.71)
读者应该对这些重排写法慢慢熟悉起来。
此时，使用单一矩阵来重述问题，比将问题写成求和形式更有帮助。这有助于
我们使用更紧凑的符号。将表示各点的向量堆叠成一个矩阵，记为 X2Rmn，其中
Xi;:= x(i)⊤。原问题可以重新表述为：
d= arg min
dX Xdd⊤2
Fsubject to d⊤d= 1: (2.72)
暂时不考虑约束，我们可以将 Frobenius 范数简化成下面的形式：
arg min
dX Xdd⊤2
F(2.73)
= arg min
dTr((
X Xdd⊤)⊤(
X Xdd⊤))
(2.74)
（式 (2.49)）
= arg min
dTr(
X⊤X X⊤Xdd⊤ dd⊤X⊤X+dd⊤X⊤Xdd⊤)
(2.75)
= arg min
dTr(X⊤X) Tr(X⊤Xdd⊤) Tr(dd⊤X⊤X) +Tr(dd⊤X⊤Xdd⊤)(2.76)
= arg min
d Tr(X⊤Xdd⊤) Tr(dd⊤X⊤X) +Tr(dd⊤X⊤Xdd⊤) (2.77)
（因为与 d无关的项不影响 arg min）
= arg min
d 2Tr(X⊤Xdd⊤) +Tr(dd⊤X⊤Xdd⊤) (2.78)
（因为循环改变迹运算中相乘矩阵的顺序不影响结果，如式 (2.52)所示）
= arg min
d 2Tr(X⊤Xdd⊤) +Tr(X⊤Xdd⊤dd⊤) (2.79)
（再次使用上述性质）
此时，我们再来考虑约束条件 :
arg min
d 2Tr(X⊤Xdd⊤) +Tr(X⊤Xdd⊤dd⊤)subject to d⊤d= 1 (2.80)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
46 第二章 线性代数
= arg min
d 2Tr(X⊤Xdd⊤) +Tr(X⊤Xdd⊤)subject to d⊤d= 1 (2.81)
(因为约束条件 )
= arg min
d Tr(X⊤Xdd⊤)subject to d⊤d= 1 (2.82)
= arg max
dTr(X⊤Xdd⊤)subject to d⊤d= 1 (2.83)
= arg max
dTr(d⊤X⊤Xd)subject to d⊤d= 1: (2.84)
这个优化问题可以通过特征分解来求解。具体地，最优的 d是 X⊤X最大特征
值对应的特征向量。
以上推导特定于 l= 1的情况，仅得到了第一个主成分。更一般地，当我们希望
得到主成分的基时，矩阵 D由前 l个最大的特征值对应的特征向量组成。这个结论
可以通过归纳法证明，我们建议将此证明作为练习。
线性代数是理解深度学习所必须掌握的基础数学学科之一。另一门在机器学习
中无处不在的重要数学学科是概率论，我们将在下章探讨。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第三章 概率与信息论
本章我们讨论概率论和信息论。
概率论是用于表示不确定性 声明的数学框架。它不仅提供了量化不确定性的方
法，也提供了用于导出新的不确定性 声明（statement ）的公理。在 人工智能 领域，
概率论主要有两种用途。首先，概率法则告诉我们 AI系统如何推理，据此我们设计
一些算法来计算或者估算由概率论导出的表达式。其次，我们可以用概率和统计从
理论上分析我们提出的 AI系统的行为。
概率论是众多科学学科和工程学科的基本工具。我们提供这一章，是为了确保
那些背景偏软件工程而较少接触概率论的读者也可以理解本书的内容。
概率论使我们能够提出不确定的 声明以及在不确定性存在的情况下进行推理，
而信息论使我们能够量化 概率分布 中的不确定性总量。
如果你已经对概率论和信息论很熟悉了，那么除了第 3.14节以外的整章内容，你
都可以跳过。而在第 3.14节中，我们会介绍用来描述机器学习中 结构化概率模型 的
图。即使你对这些主题没有任何的先验知识，本章对于完成深度学习的研究项目来
说也已经足够，尽管如此我们还是建议你能够参考一些额外的资料，例如 Jaynes
(2003)。
3.1为什么要使用概率？
计算机科学的许多分支处理的实体大部分都是完全确定且必然的。程序员通常
可以安全地假定 CPU将完美地执行每条机器指令。虽然硬件错误确实会发生，但它
们足够罕见，以致于大部分软件应用在设计时并不需要考虑这些因素的影响。鉴于
许多计算机科学家和软件工程师在一个相对干净和确定的环境中工作，机器学习对
47DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
48 第三章 概率与信息论
于概率论的大量使用是很令人吃惊的。
这是因为机器学习通常必须处理不确定量，有时也可能需要处理随机 (非确定性
的)量。不确定性和随机性可能来自多个方面。至少从 20世纪 80年代开始，研究
人员就对使用概率论来量化不确定性提出了令人信服的论据。这里给出的许多论据
都是根据 Pearl (1988)的工作总结或启发得到的。
几乎所有的活动都需要一些在不确定性存在的情况下进行推理的能力。事实上，
除了那些被定义为真的数学 声明，我们很难认定某个命题是千真万确的或者确保某
件事一定会发生。
不确定性有三种可能的来源：
1.被建模系统内在的随机性。例如，大多数 量子力学 的解释，都将 亚原子粒子的
动力学描述为概率的。我们还可以创建一些我们假设具有随机动态的理论情境，
例如一个假想的纸牌游戏，在这个游戏中我们假设纸牌被真正混洗成了随机顺
序。
2.不完全观测。即使是确定的系统，当我们不能观测到所有驱动系统行为的变量
时，该系统也会呈现随机性。例如，在 Monty Hall 问题中，一个游戏节目的参
与者被要求在三个门之间选择，并且会赢得放置在选中门后的奖品。其中两扇
门通向山羊，第三扇门通向一辆汽车。选手的每个选择所导致的结果是确定的，
但是站在选手的角度，结果是不确定的。
3.不完全建模。当我们使用一些必须舍弃某些观测信息的模型时，舍弃的信息会
导致模型的预测出现不确定性。例如，假设我们制作了一个机器人，它可以准
确地观察周围每一个对象的位置。在对这些对象将来的位置进行预测时，如果
机器人采用的是离散化的空间，那么离散化的方法将使得机器人无法确定对象
们的精确位置：因为每个对象都可能处于它被观测到的离散单元的任何一个角
落。
在很多情况下，使用一些简单而不确定的规则要比复杂而确定的规则更为实用，
即使真正的规则是确定的并且我们建模的系统可以足够精确地容纳复杂的规则。例
如，‘‘多数鸟儿都会飞 ’’这个简单的规则描述起来很简单很并且使用广泛，而正式的
规则—— ‘‘除了那些还没学会飞翔的幼鸟，因为生病或是受伤而失去了飞翔能力的
鸟，包括食火鸟 (cassowary) 、鸵鸟 (ostrich)、几维 (kiwi，一种新西兰产的无翼鸟 )DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.2随机变量 49
等不会飞的鸟类……以外，鸟儿会飞 ’’，很难应用、维护和沟通，即使经过这么多的
努力，这个规则还是很脆弱而且容易失效。
尽管我们的确需要一种用以对不确定性进行表示和推理的方法，但是概率论并
不能明显地提供我们在 人工智能 领域需要的所有工具。概率论最初的发展是为了分
析事件发生的频率。我们可以很容易地看出概率论，对于像在扑克牌游戏中抽出一
手特定的牌这种事件的研究中，是如何使用的。这类事件往往是可以重复的。当我
们说一个结果发生的概率为 p，这意味着如果我们反复实验 (例如，抽取一手牌 )无
限次，有 p的比例可能会导致这样的结果。这种推理似乎并不立即适用于那些不可
重复的命题。如果一个医生诊断了病人，并说该病人患流感的几率为 40%，这意味
着非常不同的事情——我们既不能让病人有无穷多的副本，也没有任何理由去相信
病人的不同副本在具有不同的潜在条件下表现出相同的症状。在医生诊断病人的例
子中，我们用概率来表示一种 信任度（degree of belief ） ，其中 1表示非常肯定病人
患有流感，而 0表示非常肯定病人没有流感。前面那种概率，直接与事件发生的频
率相联系，被称为 频率派概率 （frequentist probability ） ；而后者，涉及到确定性水
平，被称为 贝叶斯概率 （Bayesian probability ） 。
关于不确定性的常识推理，如果我们已经列出了若干条我们期望它具有的性质，
那么满足这些性质的唯一一种方法就是将 贝叶斯概率 和频率派概率 视为等同的。例
如，如果我们要在扑克牌游戏中根据玩家手上的牌计算她能够获胜的概率，我们使
用和医生情境完全相同的公式，就是我们依据病人的某些症状计算她是否患病的概
率。为什么一小组常识性假设蕴含了必须是相同的公理控制两种概率？更多的细节
参见 Ramsey (1926)。
概率可以被看作是用于处理不确定性的逻辑扩展。逻辑提供了一套形式化的规
则，可以在给定某些命题是真或假的假设下，判断另外一些命题是真的还是假的。概
率论提供了一套形式化的规则，可以在给定一些命题的 似然后，计算其他命题为真
的似然。
3.2随机变量
随机变量 （random variable ）是可以随机地取不同值的变量。我们通常用无格
式字体 (plain typeface) 中的小写字母来表示 随机变量 本身，而用手写体中的小写字
母来表示 随机变量 能够取到的值。例如， x1和x2都是随机变量 x可能的取值。对DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
50 第三章 概率与信息论
于向量值变量，我们会将 随机变量 写成 x，它的一个可能取值为 x。就其本身而言，
一个随机变量 只是对可能的状态的描述；它必须伴随着一个 概率分布 来指定每个状
态的可能性。
随机变量 可以是离散的或者连续的。离散 随机变量 拥有有限或者可数无限多的
状态。注意这些状态不一定非要是整数；它们也可能只是一些被命名的状态而没有
数值。连续 随机变量 伴随着实数值。
3.3概率分布
概率分布 （probability distribution ）用来描述 随机变量 或一簇随机变量 在每一
个可能取到的状态的可能性大小。我们描述 概率分布 的方式取决于 随机变量 是离散
的还是连续的。
3.3.1离散型变量和概率质量函数
离散型变量的 概率分布 可以用概率质量函数 （probability mass function ,PMF）
1来描述。我们通常用大写字母 P来表示概率质量函数 。通常每一个 随机变量 都会有
一个不同的 概率质量函数 ，并且读者必须根据 随机变量 来推断所使用的 PMF，而不
是根据函数的名称来推断；例如， P(x)通常和 P(y)不一样。
概率质量函数 将随机变量 能够取得的每个状态映射到 随机变量 取得该状态的概
率。 x=x的概率用 P(x)来表示，概率为 1表示 x=x是确定的，概率为 0表示
x=x是不可能发生的。有时为了使得 PMF的使用不相互混淆，我们会明确写出 随
机变量的名称： P(x=x)。有时我们会先定义一个 随机变量 ，然后用符号来说明
它遵循的分布： xP(x)。
概率质量函数 可以同时作用于多个 随机变量 。这种多个变量的 概率分布 被称
为联合概率分布 （joint probability distribution ） 。P(x=x;y=y)表示 x=x和
y=y同时发生的概率。我们也可以简写为 P(x; y)。
如果一个函数 P是随机变量 x的PMF，必须满足下面这几个条件：
•P的定义域必须是 x所有可能状态的集合。
1译者注：国内有些教材也将它翻译成概率分布律。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.3概率分布 51
•8x2x;0P(x)1:不可能发生的事件概率为 0，并且不存在比这概率更低
的状态。类似的，能够确保一定发生的事件概率为 1，而且不存在比这概率更
高的状态。
•∑
x2xP(x) = 1 :我们把这条性质称之为 归一化的 （normalized ） 。如果没有这
条性质，当我们计算很多事件其中之一发生的概率时可能会得到大于 1的概
率。
例如，考虑一个离散型 随机变量 x有k个不同的状态。我们可以假设 x是均匀
分布（uniform distribution ）的（也就是将它的每个状态视为等可能的） ，通过将它
的PMF设为
P(x=xi) =1
k(3.1)
对于所有的 i都成立。我们可以看出这满足上述成为 概率质量函数 的条件。因为 k
是一个正整数，所以1
k是正的。我们也可以看出
∑
iP(x=xi) =∑
i1
k=k
k= 1; (3.2)
因此分布也满足归一化条件。
3.3.2连续型变量和概率密度函数
当我们研究的对象是连续型 随机变量 时，我们用 概率密度函数 （probability
density function ,PDF）而不是 概率质量函数 来描述它的 概率分布 。如果一个函数 p
是概率密度函数 ，必须满足下面这几个条件：
•p的定义域必须是 x所有可能状态的集合。
•8x2x; p(x)0:注意，我们并不要求 p(x)1。
•∫
p(x)dx= 1:
概率密度函数 p(x)并没有直接对特定的状态给出概率，相对的，它给出了落在
面积为 x的无限小的区域内的概率为 p(x)x。
我们可以对 概率密度函数 求积分来获得点集的真实概率质量。特别地， x落在
集合S中的概率可以通过 p(x)对这个集合求积分来得到。在单变量的例子中， x落
在区间 [a; b]的概率是∫
[a;b]p(x)dx。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
52 第三章 概率与信息论
为了给出一个连续型 随机变量 的PDF的例子，我们可以考虑实数区间上的 均匀
分布。我们可以使用函数 u(x;a; b)，其中 a和b是区间的端点且满足 b > a。符号
“;’’表示 ‘‘以什么为参数 ’’；我们把 x作为函数的自变量， a和b作为定义函数的参
数。为了确保区间外没有概率，我们对所有的 x̸2[a; b]，令 u(x;a; b) = 0。在 [a; b]
内，有 u(x;a; b) =1
b a。我们可以看出任何一点都非负。另外，它的积分为 1。我们
通常用 xU(a; b)表示 x在[a; b]上是均匀分布 的。
3.4边缘概率
有时候，我们知道了一组变量的 联合概率分布 ，但想要了解其中一个子集的 概
率分布。这种定义在子集上的 概率分布 被称为边缘概率分布 （marginal probability
distribution ） 。
例如，假设有离散型 随机变量 x和 y，并且我们知道 P(x;y)。我们可以依据下
面的求和法则 （sum rule ）来计算 P(x)：
8x2x; P(x=x) =∑
yP(x=x;y=y): (3.3)
‘‘边缘概率 ’’的名称来源于手算边缘概率的计算过程。当 P(x;y)的每个值被写
在由每行表示不同的 x值，每列表示不同的 y值形成的网格中时，对网格中的每行
求和是很自然的事情，然后将求和的结果 P(x)写在每行右边的纸的边缘处。
对于连续型变量，我们需要用积分替代求和：
p(x) =∫
p(x; y)dy: (3.4)
3.5条件概率
在很多情况下，我们感兴趣的是某个事件，在给定其他事件发生时出现的
概率。这种概率叫做 条件概率 。我们将给定 x=x，y=y发生的条件概率 记为
P(y=yjx=x)。这个条件概率 可以通过下面的公式计算：
P(y=yjx=x) =P(y=y;x=x)
P(x=x): (3.5)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.6条件概率的链式法则 53
条件概率 只在 P(x=x)>0时有定义。我们不能计算给定在永远不会发生的事件上
的条件概率 。
这里需要注意的是，不要把 条件概率 和计算当采用某个动作后会发生什么相混
淆。假定某个人说德语，那么他是德国人的 条件概率 是非常高的，但是如果随机选
择的一个人会说德语，他的国籍不会因此而改变。计算一个行动的后果被称为 干预
查询（intervention query ） 。干预查询 属于因果模型 （causal modeling ）的范畴，我
们不会在本书中讨论。
3.6条件概率的链式法则
任何多维 随机变量 的联合概率分布 ，都可以分解成只有一个变量的 条件概率 相
乘的形式：
P(x(1); : : : ; x(n)) =P(x(1))n
i=2P(x(i)jx(1); : : : ; x(i 1)): (3.6)
这个规则被称为概率的 链式法则 （chain rule ）或者乘法法则 （product rule ） 。
它可以直接从式 (3.5)条件概率 的定义中得到。例如，使用两次定义可以得到
P(a;b;c) = P(ajb;c)P(b;c)
P(b;c) = P(bjc)P(c)
P(a;b;c) = P(ajb;c)P(bjc)P(c):
3.7独立性和条件独立性
两个随机变量 x和 y，如果它们的 概率分布 可以表示成两个因子的乘积形式，并
且一个因子只包含 x另一个因子只包含 y，我们就称这两个 随机变量 是相互独立的
（independent ） ：
8x2x; y2y; p(x=x;y=y) =p(x=x)p(y=y): (3.7)
如果关于 x和 y的条件概率 分布对于 z的每一个值都可以写成乘积的形式，
那么这两个 随机变量 x和 y在给定随机变量 z时是条件独立的 （conditionallyDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
54 第三章 概率与信息论
independent ） ：
8x2x; y2y; z2z; p(x=x;y=yjz=z) =p(x=xjz=z)p(y=yjz=z):
(3.8)
我们可以采用一种简化形式来表示独立性和条件独立性： x?y表示 x和 y相互
独立， x?yjz表示 x和 y在给定 z时条件独立。
3.8期望、方差和协方差
函数 f(x)关于某分布 P(x)的期望（expectation ）或者期望值（expected
value）是指，当 x由P产生， f作用于 x时，f(x)的平均值。对于离散型 随
机变量，这可以通过求和得到：
ExP[f(x)] =∑
xP(x)f(x); (3.9)
对于连续型 随机变量 可以通过求积分得到：
Exp[f(x)] =∫
p(x)f(x)dx: (3.10)
当概率分布 在上下文中指明时，我们可以只写出 期望作用的随机变量 的名称来进行
简化，例如 Ex[f(x)]。如果期望作用的随机变量 也很明确，我们可以完全不写脚标，
就像E[f(x)]。默认地，我们假设 E[]表示对方括号内的所有 随机变量 的值求平均。
类似的，当没有歧义时，我们还可以省略方括号。
期望是线性的，例如，
Ex[f(x) +g(x)] =Ex[f(x)] +Ex[g(x)]; (3.11)
其中 和不依赖于 x。
方差（variance）衡量的是当我们对 x依据它的 概率分布 进行采样时， 随机变
量 x的函数值会呈现多大的差异：
Var(f(x)) =E[
(f(x) E[f(x)])2]
: (3.12)
当方差很小时， f(x)的值形成的簇比较接近它们的 期望值。方差的平方根被称为 标
准差（standard deviation ） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.9常用概率分布 55
协方差（covariance ）在某种意义上给出了两个变量线性相关性的强度以及这些
变量的尺度：
Cov(f(x); g(y)) =E[(f(x) E[f(x)])(g(y) E[g(y)])]: (3.13)
协方差的绝对值如果很大则意味着变量值变化很大并且它们同时距离各自的均值很
远。如果 协方差是正的，那么两个变量都倾向于同时取得相对较大的值。如果 协方
差是负的，那么其中一个变量倾向于取得相对较大的值的同时，另一个变量倾向于
取得相对较小的值，反之亦然。其他的衡量指标如 相关系数 （correlation ）将每个变
量的贡献归一化，为了只衡量变量的相关性而不受各个变量尺度大小的影响。
协方差和相关性是有联系的，但实际上不同的概念。它们是有联系的，因为两
个变量如果相互独立那么它们的 协方差为零，如果两个变量的 协方差不为零那么它
们一定是相关的。然而，独立性又是和 协方差完全不同的性质。两个变量如果 协方
差为零，它们之间一定没有线性关系。独立性是比零 协方差的要求更强，因为独立性
还排除了非线性的关系。两个变量相互依赖但是具有零 协方差是可能的。例如，假
设我们首先从区间 [ 1;1]上的均匀分布 中采样出一个实数 x。然后我们对一个 随机
变量 s进行采样。 s以1
2的概率值为 1，否则为 -1。我们可以通过令 y=sx来生成
一个随机变量 y。显然， x和y不是相互独立的，因为 x完全决定了 y的尺度。然
而，Cov(x; y) = 0。
随机向量 x2Rn的协方差矩阵 （covariance matrix ）是一个 nn的矩阵，并
且满足
Cov(x)i;j=Cov(xi;xj): (3.14)
协方差矩阵 的对角元是方差：
Cov(xi;xi) =Var(xi): (3.15)
3.9常用概率分布
许多简单的 概率分布 在机器学习的众多领域中都是有用的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
56 第三章 概率与信息论
3.9.1 Bernoulli 分布
Bernoulli 分布（Bernoulli distribution ）是单个二值 随机变量 的分布。它由单
个参数 ϕ2[0;1]控制， ϕ给出了随机变量 等于 1的概率。它具有如下的一些性质：
P(x= 1) = ϕ (3.16)
P(x= 0) = 1 ϕ (3.17)
P(x=x) =ϕx(1 ϕ)1 x(3.18)
Ex[x] =ϕ (3.19)
Var x(x) =ϕ(1 ϕ) (3.20)
3.9.2 Multinoulli 分布
Multinoulli 分布（multinoulli distribution ）或者范畴分布 （categorical dis-
tribution ）是指在具有 k个不同状态的单个离散型 随机变量 上的分布，其中 k是一
个有限值。2Multinoulli 分布由向量 p2[0;1]k 1参数化，其中每一个分量 pi表示
第i个状态的概率。最后的第 k个状态的概率可以通过 1 1⊤p给出。注意我们必
须限制 1⊤p1。Multinoulli 分布经常用来表示对象分类的分布，所以我们很少假
设状态 1具有数值 1之类的。因此，我们通常不需要去计算 Multinoulli 分布的随机
变量的期望和方差。
Bernoulli 分布和Multinoulli 分布足够用来描述在它们领域内的任意分布。它们
能够描述这些分布，不是因为它们特别强大，而是因为它们的领域很简单；它们可
以对那些，能够将所有的状态进行枚举的离散型 随机变量 进行建模。当处理的是连
续型随机变量 时，会有不可数无限多的状态，所以任何通过少量参数描述的 概率分
布都必须在分布上加以严格的限制。
2“multinoulli’’ 这个术语是最近被 Gustavo Lacerdo 发明、被 Murphy (2012 )推广的。 Multinoulli 分布是多
项式分布 （multinomial distribution ）的一个特例。 多项式分布 是f0; : : : ; n gk中的向量的分布，用于表示当
对Multinoulli 分布采样 n次时 k个类中的每一个被访问的次数。很多文章使用 “多项式分布 ’’而实际上说的
是Multinoulli 分布，但是他们并没有说是对 n= 1的情况，这点需要注意。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.9常用概率分布 57
3.9.3高斯分布
实数上最常用的分布就是 正态分布 （normal distribution ） ，也称为 高斯分布
（Gaussian distribution ） ：
N(x;; 2) =√
1
22exp(
 1
22(x )2)
: (3.21)
图3.1画出了正态分布 的概率密度函数 。
 2:0 1:5 1:0 0:5 0:0 0:5 1:0 1:5 2:0
x0:000:050:100:150:200:250:300:350:40p(x)Maximum at x=
Inection points at
x=
图3.1:正态分布 。正态分布 N(x;; 2)呈现经典的 ‘‘钟形曲线 ’’的形状，其中中心峰的 x坐标
由给出，峰的宽度受 控制。在这个示例中，我们展示的是 标准正态分布 （standard normal
distribution ） ，其中 = 0; = 1。
正态分布 由两个参数控制， 2R和2(0;1)。参数 给出了中心峰值的坐
标，这也是分布的均值： E[x] =。分布的 标准差用表示，方差用2表示。
当我们要对 概率密度函数 求值时，我们需要对 平方并且取倒数。当我们需要
经常对不同参数下的 概率密度函数 求值时，一种更高效的参数化分布的方式是使用
参数 2(0;1)，来控制分布的 精度（precision ）(或方差的倒数 )：
N(x;;  1) =√

2exp(
 1
2(x )2)
: (3.22)
采用正态分布 在很多应用中都是一个明智的选择。当我们由于缺乏关于某个实
数上分布的先验知识而不知道该选择怎样的形式时， 正态分布 是默认的比较好的选
择，其中有两个原因。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
58 第三章 概率与信息论
第一，我们想要建模的很多分布的真实情况是比较接近 正态分布 的。中心极限
定理（central limit theorem ）说明很多独立 随机变量 的和近似服从 正态分布 。这意
味着在实际中，很多复杂系统都可以被成功地建模成 正态分布 的噪声，即使系统可
以被分解成一些更结构化的部分。
第二，在具有相同方差的所有可能的 概率分布 中，正态分布 在实数上具有最大
的不确定性。因此，我们可以认为 正态分布 是对模型加入的先验知识量最少的分布。
充分利用和证明这个想法需要更多的数学工具，我们推迟到第 19.4.2节进行讲解。
正态分布 可以推广到 Rn空间，这种情况下被称为 多维正态分布 （multivariate
normal distribution ） 。它的参数是一个正定对称矩阵 ：
N(x;;) =√
1
(2)ndet()exp(
 1
2(x )⊤ 1(x ))
: (3.23)
参数仍然表示分布的均值，只不过现在是向量值。参数 给出了分布的 协
方差矩阵 。和单变量的情况类似，当我们希望对很多不同参数下的 概率密度函数 多
次求值时， 协方差矩阵 并不是一个很高效的参数化分布的方式，因为对 概率密度函
数求值时需要对 求逆。我们可以使用一个 精度矩阵 （precision matrix ）进行替
代：
N(x;; 1) =√
det()
(2)nexp(
 1
2(x )⊤(x ))
: (3.24)
我们常常把 协方差矩阵 固定成一个对角阵。一个更简单的版本是 各向同性
（isotropic）高斯分布 ，它的协方差矩阵 是一个标量乘以单位阵。
3.9.4指数分布和 Laplace 分布
在深度学习中，我们经常会需要一个在 x= 0点处取得边界点 (sharp point) 的
分布。为了实现这一目的，我们可以使用 指数分布 （exponential distribution ） ：
p(x;) =1x0exp( x): (3.25)
指数分布使用 指示函数 (indicator function) 1x0来使得当 x取负值时的概率为零。
一个联系紧密的 概率分布 是Laplace 分布（Laplace distribution ） ，它允许我们
在任意一点 处设置概率质量的峰值
Laplace (x;; ) =1
2exp(
 jx j
)
: (3.26)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.9常用概率分布 59
3.9.5 Dirac 分布和经验分布
在一些情况下，我们希望概率分布中的所有质量都集中在一个点上。这可以通
过Dirac delta 函数（Dirac delta function ）(x)定义概率密度函数 来实现：
p(x) =(x ): (3.27)
Dirac delta 函数被定义成在除了 0以外的所有点的值都为 0，但是积分为 1。Dirac
delta函数不像普通函数一样对 x的每一个值都有一个实数值的输出，它是一种不同
类型的数学对象，被称为 广义函数 （generalized function ） ，广义函数 是依据积分性
质定义的数学对象。我们可以把 Dirac delta 函数想成一系列函数的极限点，这一系
列函数把除 0以外的所有点的概率密度越变越小。
通过把 p(x)定义成 函数左移 个单位，我们得到了一个在 x=处具有
无限窄也无限高的峰值的概率质量。
Dirac分布经常作为 经验分布 （empirical distribution ）的一个组成部分出现：
^p(x) =1
mm∑
i=1(x x(i)) (3.28)
经验分布 将概率密度1
m赋给 m个点 x(1); : : : ; x(m)中的每一个，这些点是给定的
数据集或者采样的集合。只有在定义连续型 随机变量 的经验分布时， Dirac delta 函
数才是必要的。对于离散型 随机变量 ，情况更加简单： 经验分布 可以被定义成一
个Multinoulli 分布，对于每一个可能的输入，其概率可以简单地设为在训练集上那
个输入值的 经验频率 （empirical frequency ） 。
当我们在训练集上训练模型时，我们可以认为从这个训练集上得到的 经验分
布指明了我们采样来源的分布。关于 经验分布 另外一种重要的观点是，它是训练数
据的似然最大的那个概率密度函数 (见第 5.5节)。
3.9.6分布的混合
通过组合一些简单的 概率分布 来定义新的 概率分布 也是很常见的。 一种通用的组
合方法是构造 混合分布 （mixture distribution ） 。混合分布由一些组件 (component)
分布构成。每次实验，样本是由哪个组件分布产生的取决于从一个 Multinoulli 分
布中采样的结果：
P(x) =∑
iP(c=i)P(xjc=i); (3.29)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
60 第三章 概率与信息论
这里 P(c)是对各组件的一个 Multinoulli 分布。
我们已经看过一个混合分布的例子了：实值变量的 经验分布 对于每一个训练实
例来说，就是以 Dirac分布为组件的混合分布。
混合模型是组合简单 概率分布 来生成更丰富的分布的一种简单策略。在第 十
六章中，我们更加详细地探讨从简单 概率分布 构建复杂模型的技术。
混合模型使我们能够一瞥以后会用到的一个非常重要的概念—— 潜变量
（latent variable ） 。潜变量是我们不能直接观测到的 随机变量 。混合模型的组件标
识变量 c就是其中一个例子。 潜变量在联合分布中可能和 x有关，在这种情况下，
P(x;c) =P(xjc)P(c)。潜变量的分布 P(c)以及关联 潜变量和观测变量的条件分布
P(xjc)，共同决定了分布 P(x)的形状，尽管描述 P(x)时可能并不需要 潜变量。潜
变量将在第 16.5节中深入讨论。
一个非常强大且常见的混合模型是 高斯混合模型 （Gaussian Mixture Model ） ，
它的组件 p(xjc=i)是高斯分布 。每个组件都有各自的参数，均值 (i)和协方差矩
阵(i)。有一些混合可以有更多的限制。例如， 协方差矩阵 可以通过 (i)=;8i的
形式在组件之间共享参数。和单个 高斯分布 一样，高斯混合模型 有时会限制每个组
件的协方差矩阵 为对角的或者各向同性的 (标量乘以单位矩阵） 。
除了均值和 协方差以外，高斯混合模型 的参数指明了给每个组件 i的先验概率
（prior probability ）i=P(c=i)。‘‘先验’’一词表明了在观测到 x之前传递给模
型关于 c的信念。作为对比， P(cjx)是后验概率 （posterior probability ） ，因为它
是在观测到 x之后进行计算的。 高斯混合模型 是概率密度的 万能近似器 （universal
approximator ） ，在这种意义下，任何平滑的概率密度都可以用具有足够多组件的 高
斯混合模型 以任意精度来逼近。
图3.2演示了某个 高斯混合模型 生成的样本。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.10常用函数的有用性质 61
x1x2
图3.2:来自高斯混合模型 的样本。在这个示例中，有三个组件。从左到右，第一个组件具有 各向
同性的协方差矩阵，这意味着它在每个方向上具有相同的方差。第二个组件具有对角的协方差矩
阵，这意味着它可以沿着每个轴的对齐方向单独控制方差。该示例中，沿着 x2轴的方差要比沿着
x1轴的方差大。第三个组件具有满秩的协方差矩阵，使它能够沿着任意基的方向单独地控制方差。
3.10常用函数的有用性质
某些函数在处理 概率分布 时经常会出现，尤其是深度学习的模型中用到的 概率
分布。
其中一个函数是 logistic sigmoid 函数：
(x) =1
1 + exp( x): (3.30)
logistic sigmoid 函数通常用来产生 Bernoulli 分布中的参数 ϕ，因为它的范围是
(0;1)，处在 ϕ的有效取值范围内。图 3.3给出了 sigmoid函数的图示。 sigmoid函数
在变量取绝对值非常大的正值或负值时会出现 饱和（saturate）现象，意味着函数会
变得很平，并且对输入的微小改变会变得不敏感。
另外一个经常遇到的函数是 softplus 函数（softplus function ）(Dugas et al. ,
2001a )：
(x) = log(1 + exp(x)): (3.31)
softplus函数可以用来产生 正态分布 的和参数，因为它的范围是 (0;1)。当处
理包含 sigmoid函数的表达式时它也经常出现。 softplus函数名来源于它是另外一个DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
62 第三章 概率与信息论
 10 5 0 5 10
x0:00:20:40:60:81:0(x)
图3.3:logistic sigmoid 函数。
函数的平滑（或 ‘‘软化’’）形式，这个函数是
x+= max(0; x): (3.32)
图3.4给出了 softplus函数的图示。
 10 5 0 5 10
x0246810(x)
图3.4:softplus 函数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.11贝叶斯规则 63
下面一些性质非常有用，你可能要记下来：
(x) =exp(x)
exp(x) + exp(0)(3.33)
d
dx(x) =(x)(1 (x)) (3.34)
1 (x) =( x) (3.35)
log(x) = ( x) (3.36)
d
dx(x) =(x) (3.37)
8x2(0;1);  1(x) = log(x
1 x)
(3.38)
8x >0;  1(x) = log(exp(x) 1) (3.39)
(x) =∫x
 1(y)dy (3.40)
(x) ( x) =x (3.41)
函数  1(x)在统计学中被称为 分对数（logit） ，但这个函数在机器学习中很少用到。
式(3.41)为函数名 “softplus’’ 提供了其他的正当理由。 softplus函数被设计成 正
部函数（positive part function ）的平滑版本，这个 正部函数 是指 x+= maxf0; xg。
与正部函数 相对的是 负部函数 （negative part function ）x = maxf0; xg。为了获
得类似负部函数 的一个平滑函数，我们可以使用 ( x)。就像 x可以用它的正部和
负部通过等式 x+ x =x恢复一样，我们也可以用同样的方式对 (x)和( x)
进行操作，就像式 (3.41)中那样。
3.11贝叶斯规则
我们经常会需要在已知 P(yjx)时计算 P(xjy)。幸运的是，如果还知道 P(x)，
我们可以用 贝叶斯规则 （Bayes’ rule ）来实现这一目的：
P(xjy) =P(x)P(yjx)
P(y): (3.42)
注意到 P(y)出现在上面的公式中，它通常使用 P(y) =∑
xP(yjx)P(x)来计算，
所以我们并不需要事先知道 P(y)的信息。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
64 第三章 概率与信息论
贝叶斯规则 可以从条件概率 的定义直接推导得出， 但我们最好记住这个公式的名
字，因为很多文献通过名字来引用这个公式。这个公式是以 Reverend Thomas Bayes
来命名的，他是第一个发现这个公式特例的人。这里介绍的一般形式由 Pierre-Simon
Laplace独立发现。
3.12连续型变量的技术细节
连续型随机变量 和概率密度函数 的深入理解需要用到数学分支 测度论（measure
theory）的相关内容来扩展概率论。 测度论超出了本书的范畴，但我们可以简要勾勒
一些测度论用来解决的问题。
在第 3.3.2节中，我们已经看到连续型向量值 随机变量 x落在某个集合 S中的
概率是通过 p(x)对集合 S积分得到的。对于集合 S的一些选择可能会引起悖论。例
如，构造两个集合 S1和S2使得 p(x2S1) +p(x2S2)>1并且S1\S2=∅是可能
的。这些集合通常是大量使用了实数的无限精度来构造的，例如通过构造分形形状
(fractal-shaped) 的集合或者是通过有理数相关集合的变换定义的集合。3测度论的
一个重要贡献就是提供了一些集合的特征使得我们在计算概率时不会遇到悖论。在
本书中，我们只对相对简单的集合进行积分，所以 测度论的这个方面不会成为一个
相关考虑。
对于我们的目的， 测度论更多的是用来描述那些适用于 Rn上的大多数点，却不
适用于一些边界情况的定理。 测度论提供了一种严格的方式来描述那些非常微小的
点集。这种集合被称为 “零测度（measure zero ）’’的。我们不会在本书中给出这个
概念的正式定义。然而，直观地理解这个概念是有用的，我们可以认为零测度集在
我们的度量空间中不占有任何的体积。例如，在 R2空间中，一条直线的测度为零，
而填充的多边形具有正的测度。类似的，一个单独的点的测度为零。可数多个零测
度集的并仍然是零测度的 (所以所有有理数构成的集合测度为零 )。
另外一个有用的 测度论中的术语是 “几乎处处 （almost everywhere ）’’。某个性
质如果是几乎处处都成立的，那么它在整个空间中除了一个测度为零的集合以外都
是成立的。因为这些例外只在空间中占有极其微小的量，它们在多数应用中都可以
被放心地忽略。概率论中的一些重要结果对于离散值成立但对于连续值只能是 ‘‘几
乎处处 ’’成立。
3Banach-Tarski 定理给出了这类集合的一个有趣的例子。译者注：我们这里把 “the set of rational numbers’’ 翻
译成 ‘‘有理数相关集合 ’’，理解为 ‘‘一些有理数组成的集合 ’’，如果直接用后面的翻译读起来会比较拗口。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.13信息论 65
连续型随机变量 的另一技术细节，涉及到处理那种相互之间有确定性函数关系
的连续型变量。假设我们有两个 随机变量 x和 y满足 y=g(x)，其中 g是可逆的、
连续可微的函数。可能有人会想 py(y) =px(g 1(y))。但实际上这并不对。
举一个简单的例子，假设我们有两个标量值 随机变量 x和 y，并且满足 y=x
2
以及 xU(0;1)。如果我们使用 py(y) =px(2y)，那么 py除了区间 [0;1
2]以外都为
0，并且在这个区间上的值为 1。这意味着
∫
py(y)dy=1
2; (3.43)
而这违背了概率密度的定义 (积分为 1)。这个常见错误之所以错是因为它没有考虑
到引入函数 g后造成的空间变形。回忆一下， x落在无穷小的体积为 x的区域内的
概率为 p(x)x。因为 g可能会扩展或者压缩空间，在 x空间内的包围着 x的无穷小
体积在 y空间中可能有不同的体积。
为了看出如何改正这个问题，我们回到标量值的情况。我们需要保持下面这个
性质：
jpy(g(x))dyj=jpx(x)dxj: (3.44)
求解上式，我们得到
py(y) =px(g 1(y))@x
@y(3.45)
或者等价地，
px(x) =py(g(x))@g(x)
@x: (3.46)
在高维空间中，微分运算扩展为 Jacobian 矩阵（Jacobian matrix ）的行列式——
矩阵的每个元素为 Ji;j=@xi
@yj。因此，对于实值向量 x和 y，
px(x) =py(g(x))det(@g(x)
@x): (3.47)
3.13信息论
信息论是应用数学的一个分支，主要研究的是对一个信号包含信息的多少进行
量化。它最初被发明是用来研究在一个含有噪声的信道上用离散的字母表来发送消
息，例如通过无线电传输来通信。在这种情况下，信息论告诉我们如何设计最优编
码，以及计算从一个特定的 概率分布 上采样得到、使用多种不同编码机制的消息的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
66 第三章 概率与信息论
期望长度。在机器学习中，我们也可以把信息论应用在连续型变量上，而信息论中
一些消息长度的解释不怎么使用。信息论是电子工程和计算机科学中许多领域的
基础。在本书中，我们主要使用信息论的一些关键思想来描述 概率分布 或者量化 概
率分布之间的相似性。有关信息论的更多细节，参见 Cover and Thomas (2006)或
者MacKay (2003)。
信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事
件发生，能提供更多的信息。消息说： ‘‘今天早上太阳升起 ’’信息量是如此之少以至
于没有必要发送，但一条消息说： ‘‘今天早上有日食 ’’信息量就很丰富。
我们想要通过这种基本想法来量化信息。特别地，
•非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件
应该没有信息量。
•较不可能发生的事件具有更高的信息量。
•独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，
应该是投掷一次硬币正面朝上的信息量的两倍。
为了满足上述三个性质，我们定义一个事件 x=x的自信息（self-information ）
为
I(x) = logP(x): (3.48)
在本书中，我们总是用 log来表示自然对数，其底数为 e。因此我们定义的 I(x)单
位是奈特（nats） 。一奈特是以1
e的概率观测到一个事件时获得的信息量。其他的材
料中使用底数为 2的对数，单位是 比特（bit）或者香农（shannons ） ；通过比特度
量的信息只是通过奈特度量信息的常数倍。
当 x是连续的，我们使用类似的关于信息的定义，但有些来源于离散形式的性
质就丢失了。例如，一个具有单位密度的事件信息量仍然为 0，但是不能保证它一定
发生。
自信息只处理单个的输出。我们可以用 香农熵（Shannon entropy ）来对整个 概
率分布中的不确定性总量进行量化：
H(x) =ExP[I(x)] = ExP[logP(x)]; (3.49)
也记作 H(P)。换言之，一个分布的 香农熵是指遵循这个分布的事件所产生的期望信
息总量。它给出了对依据 概率分布 P生成的符号进行编码所需的比特数在平均意义DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.13信息论 67
上的下界 (当对数底数不是 2时，单位将有所不同 )。那些接近确定性的分布 (输出几
乎可以确定 )具有较低的熵；那些接近 均匀分布 的概率分布 具有较高的熵。图 3.5给
出了一个说明。当 x是连续的， 香农熵被称为微分熵（diﬀerential entropy ） 。
0:0 0:2 0:4 0:6 0:8 1:0
p0:00:10:20:30:40:50:60:7Shannon entropy in nats
图3.5:二值随机变量的 香农熵。该图说明了更接近确定性的分布是如何具有较低的 香农熵，而更
接近均匀分布 的分布是如何具有较高的 香农熵。水平轴是 p，表示二值随机变量等于 1的概率。熵
由(p 1) log(1 p) plogp给出。当 p接近 0时，分布几乎是确定的，因为随机变量几乎总是
0。当 p接近 1时，分布也几乎是确定的，因为随机变量几乎总是 1。当 p= 0:5时，熵是最大的，
因为分布在两个结果（ 0和1）上是均匀的。
如果我们对于同一个 随机变量 x有两个单独的 概率分布 P(x)和Q(x)，我们可
以使用 KL散度（Kullback-Leibler (KL) divergence ）来衡量这两个分布的差异：
DKL(PjjQ) =ExP[
logP(x)
Q(x)]
=ExP[logP(x) logQ(x)]: (3.50)
在离散型变量的情况下， KL散度衡量的是，当我们使用一种被设计成能够使
得概率分布 Q产生的消息的长度最小的编码，发送包含由 概率分布 P产生的符号
的消息时，所需要的额外信息量 (如果我们使用底数为 2的对数时，信息量用比特衡
量，但在机器学习中，我们通常用奈特和自然对数。 )
KL散度有很多有用的性质，最重要的是它是非负的。 KL散度为0当且仅当
P和Q在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是 ‘‘几乎
处处’’相同的。因为 KL散度是非负的并且衡量的是两个分布之间的差异，它经常
被用作分布之间的某种距离。然而，它并不是真的距离因为它不是对称的：对于某
些P和Q，DKL(PjjQ)̸=DKL(QjjP)。这种非对称性意味着选择 DKL(PjjQ)还是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
68 第三章 概率与信息论
DKL(QjjP)影响很大。更多细节可以看图 3.6。
xProbability Densityq= argminqDKL(pkq)
p(x)
q(x)
xProbability Densityq= argminqDKL(qkp)
p(x)
q(x)
图3.6:KL散度是不对称的。假设我们有一个分布 p(x)，并且希望用另一个分布 q(x)来近似它。
我们可以选择最小化 DKL(pjjq)或最小化 DKL(qjjp)。为了说明每种选择的效果，我们令 p是两
个高斯分布 的混合，令 q为单个高斯分布 。选择使用 KL散度的哪个方向是取决于问题的。一些
应用需要这个近似分布 q在真实分布 p放置高概率的所有地方都放置高概率，而其他应用需要这
个近似分布 q在真实分布 p放置低概率的所有地方都很少放置高概率。 KL散度方向的选择反映
了对于每种应用，优先考虑哪一种选择。 (左)最小化 DKL(pjjq)的效果。在这种情况下，我们选
择一个 q使得它在 p具有高概率的地方具有高概率。当 p具有多个峰时， q选择将这些峰模糊到
一起，以便将高概率质量放到所有峰上。 (右)最小化 DKL(qjjp)的效果。在这种情况下，我们选
择一个 q使得它在 p具有低概率的地方具有低概率。当 p具有多个峰并且这些峰间隔很宽时，如
该图所示，最小化 KL散度会选择单个峰，以避免将概率质量放置在 p的多个峰之间的低概率区
域中。这里，我们说明当 q被选择成强调左边峰时的结果。我们也可以通过选择右边峰来得到 KL
散度相同的值。如果这些峰没有被足够强的低概率区域分离，那么 KL散度的这个方向仍然可能
选择模糊这些峰。
一个和 KL散度密切联系的量是 交叉熵（cross-entropy ）H(P; Q) =H(P) +
DKL(PjjQ)，它和 KL散度很像但是缺少左边一项：
H(P; Q) = ExPlogQ(x): (3.51)
针对 Q最小化交叉熵等价于最小化 KL散度，因为 Q并不参与被省略的那一项。
当我们计算这些量时，经常会遇到 0log0这个表达式。按照惯例，在信息论中，
我们将这个表达式处理为 limx!0xlogx= 0。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.14结构化概率模型 69
3.14结构化概率模型
机器学习的算法经常会涉及到在非常多的 随机变量 上的概率分布 。通常，这些 概
率分布涉及到的直接相互作用都是介于非常少的变量之间的。使用单个函数来描述
整个联合概率分布 是非常低效的 (无论是计算上还是统计上 )。
我们可以把 概率分布 分解成许多因子的乘积形式，而不是使用单一的函数来表
示概率分布 。例如，假设我们有三个 随机变量 a;b和 c，并且 a影响 b的取值， b影
响 c的取值，但是 a和 c在给定 b时是条件独立的。我们可以把全部三个变量的 概
率分布重新表示为两个变量的 概率分布 的连乘形式：
p(a;b;c) =p(a)p(bja)p(cjb): (3.52)
这种分解可以极大地减少用来描述一个分布的参数数量。每个因子使用的参数
数目是它的变量数目的指数倍。这意味着，如果我们能够找到一种使每个因子分布
具有更少变量的分解方法，我们就能极大地降低表示联合分布的成本。
我们可以用图来描述这种 分解。这里我们使用的是图论中的 ‘‘图’’的概念：由
一些可以通过边互相连接的顶点的集合构成。当我们用图来表示这种 概率分布 的分
解，我们把它称为 结构化概率模型 （structured probabilistic model ）或者图模型
（graphical model ） 。
有两种主要的 结构化概率模型 ：有向的和无向的。两种图模型都使用图 G，其中
图的每个节点对应着一个 随机变量 ，连接两个 随机变量 的边意味着 概率分布 可以表
示成这两个 随机变量 之间的直接作用。
有向（directed）模型使用带有有向边的图，它们用 条件概率 分布来表示 分解，
就像上面的例子。特别地，有向模型对于分布中的每一个 随机变量 xi都包含着一个
影响因子，这个组成 xi条件概率 的影响因子被称为 xi的父节点，记为 PaG(xi)：
p(x) =∏
ip(xijPaG(xi)): (3.53)
图3.7给出了一个有向图的例子以及它表示的 概率分布 的分解。
无向（undirected ）模型使用带有无向边的图，它们将 分解表示成一组函数；不
像有向模型那样，这些函数通常不是任何类型的 概率分布 。G中任何满足两两之
间有边连接的顶点的集合被称为团。无向模型中的每个团 C(i)都伴随着一个因子
ϕ(i)(C(i))。这些因子仅仅是函数，并不是 概率分布 。每个因子的输出都必须是非负DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
70 第三章 概率与信息论
aaccbb
eedd
图3.7:关于随机变量 a;b;c;d和 e的有向图模型。这幅图对应的概率分布可以分解为
p(a;b;c;d;e) =p(a)p(bja)p(cja;b)p(djb)p(ejc): (3.54)
该图模型使我们能够快速看出此分布的一些性质。例如， a和 c直接相互影响，但 a和 e只有通
过 c间接相互影响。
的，但是并没有像 概率分布 中那样要求因子的和或者积分为 1。
随机变量 的联合概率与所有这些因子的乘积 成比例（proportional ） ——意味着
因子的值越大则可能性越大。当然，不能保证这种乘积的求和为 1。所以我们需要除
以一个归一化常数 Z来得到归一化的 概率分布 ，归一化常数 Z被定义为 ϕ函数乘
积的所有状态的求和或积分。 概率分布 为：
p(x) =1
Z∏
iϕ(i)(
C(i))
: (3.55)
图3.8给出了一个无向图的例子以及它表示的 概率分布 的分解。
请记住，这些图模型表示的 分解仅仅是描述 概率分布 的一种语言。它们不是互
相排斥的 概率分布 族。有向或者无向不是 概率分布 的特性；它是 概率分布 的一种特
殊描述（description ）所具有的特性，而任何 概率分布 都可以用这两种方式进行描
述。
在本书第 一部分和第 二部分中，我们仅仅将 结构化概率模型 视作一门语言，来
描述不同的机器学习算法选择表示的直接的概率关系。在讨论研究课题之前，读者
不需要更深入地理解 结构化概率模型 。在第三部分的研究课题中，我们将更为详尽
地探讨结构化概率模型 。
本章复习了概率论中与深度学习最为相关的一些基本概念。我们还剩下一些基DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
3.14结构化概率模型 71
aaccbb
eedd
图3.8:关于随机变量 a;b;c;d和 e的无向图模型。这幅图对应的概率分布可以分解为
p(a;b;c;d;e) =1
Zϕ(1)(a;b;c)ϕ(2)(b;d)ϕ(3)(c;e): (3.56)
该图模型使我们能够快速看出此分布的一些性质。例如， a和 c直接相互影响，但 a和 e只有通
过 c间接相互影响。
本的数学工具需要讨论：数值方法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第四章 数值计算
机器学习 算法通常需要大量的数值计算。这通常是指通过迭代过程更新解的估
计值来解决数学问题的算法，而不是通过解析过程推导出公式来提供正确解的方法。
常见的操作包括优化（找到最小化或最大化函数值的参数）和线性方程组的求解。
对数字计算机来说实数无法在有限内存下精确表示，因此仅仅是计算涉及实数的函
数也是困难的。
4.1上溢和下溢
连续数学在数字计算机上的根本困难是，我们需要通过有限数量的位模式来表
示无限多的实数。这意味着我们在计算机中表示实数时，几乎总会引入一些近似误
差。在许多情况下，这仅仅是舍入误差。舍入误差会导致一些问题，特别是当许多
操作复合时，即使是理论上可行的算法，如果在设计时没有考虑最小化舍入误差的
累积，在实践时也可能会导致算法失效。
一种极具毁灭性的舍入误差是 下溢（underﬂow ） 。当接近零的数被四舍五入为
零时发生 下溢。许多函数在其参数为零而不是一个很小的正数时才会表现出质的不
同。例如，我们通常要避免被零除（一些软件环境将在这种情况下抛出异常，有些
会返回一个非数字 (not-a-number, NaN) 的占位符）或避免取零的对数（这通常被
视为 1，进一步的算术运算会使其变成非数字） 。
另一个极具破坏力的数值错误形式是 上溢（overﬂow） 。当大量级的数被近似为
1或 1时发生上溢。进一步的运算通常会导致这些无限值变为非数字。
必须对上溢和下溢进行数值稳定的一个例子是 softmax 函数（softmax func-
72DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.2病态条件 73
tion） 。softmax 函数经常用于预测与 Multinoulli 分布相关联的概率，定义为
softmax (x)i=exp(xi)∑n
j=1 exp(xj): (4.1)
考虑一下当所有 xi都等于某个常数 c时会发生什么。从理论分析上说，我们可以发
现所有的输出都应该为1
n。从数值计算上说，当 c量级很大时，这可能不会发生。如
果 c是很小的负数， exp(c)就会下溢。这意味着 softmax 函数的分母会变成 0，所以
最后的结果是未定义的。当 c是非常大的正数时， exp(c)的上溢再次导致整个表达
式未定义。这两个困难能通过计算 softmax (z)同时解决，其中 z= x max ixi。简
单的代数计算表明， softmax 解析上的函数值不会因为从输入向量减去或加上标量
而改变。减去 max ixi导致 exp的最大参数为 0，这排除了 上溢的可能性。同样地，
分母中至少有一个值为 1的项，这就排除了因分母 下溢而导致被零除的可能性。
还有一个小问题。分子中的 下溢仍可以导致整体表达式被计算为零。这意味着，
如果我们在计算 logsoftmax (x)时，先计算 softmax 再把结果传给 log函数，会错
误地得到 1。相反，我们必须实现一个单独的函数，并以数值稳定的方式计算
logsoftmax。我们可以使用相同的技巧来稳定 logsoftmax 函数。
在大多数情况下，我们没有明确地对本书描述的各种算法所涉及的数值考虑进
行详细说明。底层库的开发者在实现 深度学习 算法时应该牢记数值问题。本书的大
多数读者可以简单地依赖保证数值稳定的底层库。在某些情况下，我们有可能在实
现一个新的算法时自动保持数值稳定。 Theano ( Bergstra et al. ,2010a ;Bastien et al. ,
2012a )就是这样软件包的一个例子，它能自动检测并稳定 深度学习 中许多常见的数
值不稳定的表达式。
4.2病态条件
条件数表征函数相对于输入的微小变化而变化的快慢程度。输入被轻微扰动而
迅速改变的函数对于科学计算来说可能是有问题的，因为输入中的舍入误差可能导
致输出的巨大变化。
考虑函数 f(x) = A 1x。当 A2Rnn具有特征值分解时，其条件数为
max
i;ji
j: (4.2)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
74 第四章 数值计算
这是最大和最小特征值的模之比1。当该数很大时，矩阵求逆对输入的误差特别敏感。
这种敏感性是矩阵本身的固有特性，而不是矩阵求逆期间舍入误差的结果。即
使我们乘以完全正确的矩阵逆， 病态条件 的矩阵也会放大预先存在的误差。在实践
中，该错误将与求逆过程本身的数值误差进一步复合。
4.3基于梯度的优化方法
大多数深度学习 算法都涉及某种形式的优化。优化指的是改变 x以最小化或最
大化某个函数 f(x)的任务。我们通常以最小化 f(x)指代大多数最优化问题。最大
化可经由最小化算法最小化  f(x)来实现。
我们把要最小化或最大化的函数称为 目标函数 （objective function ）或准则
（criterion） 。当我们对其进行最小化时，我们也把它称为 代价函数 （cost function ） 、
损失函数 （loss function ）或误差函数 （error function ） 。虽然有些机器学习著作赋
予这些名称特殊的意义，但在这本书中我们交替使用这些术语。
我们通常使用一个上标 表示最小化或最大化函数的 x值。如我们记 x=
arg min f(x)。
我们假设读者已经熟悉微积分，这里简要回顾微积分概念如何与优化联系。
假设我们有一个函数 y=f(x)， 其中 x和 y是实数。 这个函数的 导数（derivative ）
记为 f′(x)或dy
dx。导数 f′(x)代表 f(x)在点 x处的斜率。换句话说，它表明如何缩
放输入的小变化才能在输出获得相应的变化： f(x+ϵ)f(x) +ϵf′(x)。
因此导数对于最小化一个函数很有用，因为它告诉我们如何更改 x来略微地改
善y。例如，我们知道对于足够小的 ϵ来说， f(x ϵsign(f′(x)))是比 f(x)小的。因
此我们可以将 x往导数的反方向移动一小步来减小 f(x)。这种技术被称为 梯度下降
（gradient descent ）(Cauchy ,1847)。图 4.1展示了一个例子。
当f′(x) = 0，导数无法提供往哪个方向移动的信息。 f′(x) = 0的点称为 临界
点（critical point ）或驻点（stationary point ） 。一个局部极小点 （local minimum ）
意味着这个点的 f(x)小于所有邻近点，因此不可能通过移动无穷小的步长来减小
f(x)。一个局部极大点 （local maximum ）意味着这个点的 f(x)大于所有邻近点，因
此不可能通过移动无穷小的步长来增大 f(x)。有些临界点既不是最小点也不是最大
1译者注：与通常的条件数定义有所不同。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.3基于梯度的优化方法 75
 2:0 1:5 1:0 0:5 0:0 0:5 1:0 1:5 2:0
x 2:0 1:5 1:0 0:50:00:51:01:52:0
Global minimum at x= 0.
Sincef0(x) = 0, gradient
descent halts here.
Forx<0, we havef0(x)<0,
so we can decrease fby
moving rightward.Forx>0, we havef0(x)>0,
so we can decrease fby
moving leftward.
f(x) =1
2x2
f0(x) =x
图4.1:梯度下降 。梯度下降 算法如何使用函数导数的示意图，即沿着函数的下坡方向（导数反方
向）直到最小。
点。这些点被称为 鞍点（saddle point ） 。见图 4.2给出的各种临界点的例子。
Minimum Maximum Saddle point
图4.2:临界点的类型。一维情况下，三种 临界点的示例。 临界点是斜率为零的点。这样的点可以
是局部极小点 （local minimum ） ，其值低于相邻点 ;局部极大点 （local maximum ） ，其值高于相
邻点;或鞍点，同时存在更高和更低的相邻点。
使f(x)取得绝对的最小值（相对所有其他值）的点是 全局最小点 （globalDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
76 第四章 数值计算
minimum ） 。函数可能只有一个 全局最小点 或存在多个 全局最小点 ，还可能存在不是
全局最优的 局部极小点 。在深度学习 的背景下，我们要优化的函数可能含有许多不
是最优的 局部极小点 ，或者还有很多处于非常平坦的区域内的 鞍点。尤其是当输入
是多维的时候，所有这些都将使优化变得困难。因此，我们通常寻找使 f非常小的
点，但这在任何形式意义下并不一定是最小。见图 4.3的例子。
xf(x)
Ideally, we would like
to arrive at the global
minimum, but this
might not be possible.This local minimum
performs nearly as well as
the global one,
so it is an acceptable
halting point.
This local minimum performs
poorly and should be avoided.
图4.3:近似最小化。当存在多个 局部极小点 或平坦区域时，优化算法可能无法找到 全局最小点 。
在深度学习的背景下，即使找到的解不是真正最小的，但只要它们对应于 代价函数 显著低的值，我
们通常就能接受这样的解。
我们经常最小化具有多维输入的函数： f:Rn!R。为了使 ‘‘最小化 ’’的概念有
意义，输出必须是一维的 (标量)。
针对具有多维输入的函数，我们需要用到 偏导数（partial derivative ）的概念。
偏导数@
@xif(x)衡量点 x处只有 xi增加时 f(x)如何变化。 梯度（gradient）是相
对一个向量求导的 导数:f的导数是包含所有 偏导数的向量，记为∇ xf(x)。梯度的第
i个元素是 f关于 xi的偏导数。在多维情况下， 临界点是梯度中所有元素都为零的
点。
在 u（单位向量）方向的 方向导数 （directional derivative ）是函数 f在 u方向
的斜率。换句话说， 方向导数 是函数 f(x+u)关于 的导数（在 = 0时取得） 。
使用链式法则 ，我们可以看到当 = 0时，@
@f(x+u) = u⊤∇ xf(x)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.3基于梯度的优化方法 77
为了最小化 f，我们希望找到使 f下降得最快的方向。计算 方向导数 ：
min
u;u⊤u=1u⊤∇ xf(x) (4.3)
= min
u;u⊤u=1∥u∥2∥∇ xf(x)∥2cos (4.4)
其中 是 u与梯度的夹角。将∥u∥2= 1代入，并忽略与 u无关的项，就能简化得
到 min
ucos。这在 u与梯度方向相反时取得最小。换句话说， 梯度向量指向上坡，
负梯度向量指向下坡。我们在负 梯度方向上移动可以减小 f。这被称为 最速下降法
(method of steepest descent) 或梯度下降 （gradient descent ） 。
最速下降建议新的点为
x′= x ϵ∇ xf(x) (4.5)
其中 ϵ为学习率（learning rate ） ，是一个确定步长大小的正标量。我们可以通过几
种不同的方式选择 ϵ。普遍的方式是选择一个小常数。有时我们通过计算，选择使 方
向导数消失的步长。还有一种方法是根据几个 ϵ计算 f(x ϵ∇ xf(x))，并选择其中
能产生最小 目标函数 值的 ϵ。这种策略被称为 线搜索。
最速下降在 梯度的每一个元素为零时收敛（或在实践中，很接近零时） 。在某些
情况下，我们也许能够避免运行该迭代算法，并通过解方程 ∇ xf(x) = 0直接跳到 临
界点。
虽然梯度下降 被限制在连续空间中的优化问题，但不断向更好的情况移动一小
步（即近似最佳的小移动）的一般概念可以推广到离散空间。递增带有离散参数
的目标函数 被称为爬山（hill climbing ）算法 (Russel and Norvig ,2003)。
4.3.1梯度之上： Jacobian 和Hessian 矩阵
有时我们需要计算输入和输出都为向量的函数的所有 偏导数。包含所有这样的
偏导数的矩阵被称为 Jacobian （Jacobian ）矩阵。具体来说，如果我们有一个函数：
f:Rm!Rn，f的Jacobian 矩阵 J2Rnm定义为 Ji;j=@
@xjf(x)i。
有时，我们也对 导数的导数感兴趣，即 二阶导数 （second derivative ） 。例如，有
一个函数 f:Rm!R，f的一阶导数(关于 xj)关于 xi的导数记为@2
@xi@xjf。在一维
情况下，我们可以将@2
@x2f为f′′(x)。二阶导数 告诉我们，一阶 导数将如何随着输入
的变化而改变。它表示只基于 梯度信息的梯度下降 步骤是否会产生如我们预期的那DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
78 第四章 数值计算
样大的改善，因此它是重要的。我们可以认为， 二阶导数 是对曲率的衡量。假设我
们有一个二次函数（虽然很多实践中的函数都不是二次的，但至少在局部可以很好
地用二次近似） 。如果这样的函数具有零 二阶导数 ，那就没有 曲率。也就是一条完全
平坦的线，仅用 梯度就可以预测它的值。我们使用沿负 梯度方向大小为 ϵ的下降步，
当该梯度是1时，代价函数 将下降 ϵ。如果二阶导数 是负的，函数曲线向下凹陷 (向
上凸出 )，因此代价函数 将下降的比 ϵ多。如果 二阶导数 是正的，函数曲线是向上凹
陷(向下凸出 )，因此代价函数 将下降的比 ϵ少。从图 4.4可以看出不同形式的 曲率如
何影响基于 梯度的预测值与真实的 代价函数 值的关系。
xf(x)Negative curvature
xf(x)No curvature
xf(x)Positive curvature
图4.4:二阶导数 确定函数的 曲率。这里我们展示具有各种 曲率的二次函数。虚线表示我们仅根据
梯度信息进行 梯度下降 后预期的 代价函数 值。对于负 曲率，代价函数 实际上比梯度预测下降得更
快。没有 曲率时，梯度正确预测下降值。对于正 曲率，函数比预期下降得更慢，并且最终会开始增
加，因此太大的步骤实际上可能会无意地增加函数值。
当我们的函数具有多维输入时， 二阶导数 也有很多。我们可以将这些导数合并
成一个矩阵，称为 Hessian （Hessian）矩阵。 Hessian矩阵 H(f)(x)定义为
H(f)(x)i;j=@2
@xi@xjf(x): (4.6)
Hessian等价于梯度的Jacobian 矩阵。
微分算子在任何二阶偏导连续的点处可交换，也就是它们的顺序可以互换：
@2
@xi@xjf(x) =@2
@xj@xif(x): (4.7)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.3基于梯度的优化方法 79
这意味着 Hi;j=Hj;i，因此 Hessian矩阵在这些点上是对称的。在 深度学习 背景下，
我们遇到的大多数函数的 Hessian几乎处处都是对称的。因为 Hessian矩阵是实对
称的，我们可以将其分解成一组实特征值和一组特征向量的正交基。在特定方向 d
上的二阶导数 可以写成 d⊤Hd。当 d是 H的一个特征向量时，这个方向的 二阶导
数就是对应的特征值。对于其他的方向 d，方向二阶导数 是所有特征值的加权平均，
权重在 0和1之间，且与 d夹角越小的特征向量的权重越大。最大特征值确定最
大二阶导数 ，最小特征值确定最小 二阶导数 。
我们可以通过（方向） 二阶导数 预期一个 梯度下降 步骤能表现得多好。我们在
当前点 x(0)处作函数 f(x)的近似二阶 泰勒级数：
f(x)f(x(0)) + ( x x(0))⊤g+1
2(x x(0))⊤H(x x(0)); (4.8)
其中 g是梯度， H是 x(0)点的 Hessian。如果我们使用 学习率 ϵ，那么新的点 x将
会是 x(0) ϵg。代入上述的近似，可得
f(x(0) ϵg)f(x(0)) ϵg⊤g+1
2ϵ2g⊤Hg: (4.9)
其中有 3项：函数的原始值、函数斜率导致的预期改善、函数 曲率导致的校正。当
最后一项太大时， 梯度下降 实际上是可能向上移动的。当 g⊤Hg为零或负时，近似
的泰勒级数表明增加 ϵ将永远使 f下降。在实践中， 泰勒级数不会在 ϵ大的时候也
保持准确，因此在这种情况下我们必须采取更启发式的选择。当 g⊤Hg为正时，通
过计算可得，使近似 泰勒级数下降最多的最优步长为
ϵ=g⊤g
g⊤Hg: (4.10)
最坏的情况下， g与 H最大特征值 max对应的特征向量对齐，则最优步长是1
max。
我们要最小化的函数能用二次函数很好地近似的情况下， Hessian的特征值决定了 学
习率的量级。
二阶导数 还可以被用于确定一个 临界点是否是局部极大点 、局部极小点 或鞍点。
回想一下，在 临界点处f′(x) = 0。而 f′′(x)>0意味着 f′(x)会随着我们移向右边
而增加，移向左边而减小，也就是 f′(x ϵ)<0和f′(x+ϵ)>0对足够小的 ϵ成立。
换句话说，当我们移向右边，斜率开始指向右边的上坡，当我们移向左边，斜率开
始指向左边的上坡。因此我们得出结论，当 f′(x) = 0且f′′(x)>0时， x是一个局
部极小点 。同样，当 f′(x) = 0且f′′(x)<0时， x是一个局部极大点 。这就是所谓DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
80 第四章 数值计算
的二阶导数测试 （second derivative test ） 。不幸的是，当 f′′(x) = 0时测试是不确
定的。在这种情况下， x可以是一个 鞍点或平坦区域的一部分。
在多维情况下，我们需要检测函数的所有 二阶导数 。利用 Hessian的特征值分
解，我们可以将 二阶导数测试 扩展到多维情况。在 临界点处（∇ xf(x) = 0） ，我们通
过检测 Hessian的特征值来判断该 临界点是一个局部极大点 、局部极小点 还是鞍点。
当Hessian是正定的（所有特征值都是正的） ，则该 临界点是局部极小点 。因为方
向二阶导数 在任意方向都是正的，参考单变量的 二阶导数测试 就能得出此结论。同
样的，当 Hessian是负定的（所有特征值都是负的） ，这个点就是 局部极大点 。在多
维情况下，实际上我们可以找到确定该点是否为 鞍点的积极迹象（某些情况下） 。如
果Hessian的特征值中至少一个是正的且至少一个是负的，那么 x是f某个横截面
的局部极大点 ，却是另一个横截面的 局部极小点 。见图 4.5中的例子。最后，多维 二
阶导数测试 可能像单变量版本那样是不确定的。当所有非零特征值是同号的且至少
有一个特征值是 0时，这个检测就是不确定的。这是因为单变量的 二阶导数测试 在
零特征值对应的横截面上是不确定的。
x1
−15015x2
−15015f(x1;x2)
−5000500
图4.5:既有正曲率又有负曲率的鞍点。示例中的函数是 f(x) =x2
1 x2
2。函数沿 x1轴向上弯
曲。x1轴是 Hessian 的一个特征向量，并且具有正特征值。函数沿 x2轴向下弯曲。该方向对应
于Hessian负特征值的特征向量。名称 “鞍点’’源自该处函数的鞍状形状。这是具有 鞍点函数的典
型示例。维度多于一个时， 鞍点不一定要具有 0特征值：仅需要同时具有正特征值和负特征值。我
们可以想象这样一个鞍点（具有正负特征值）在一个横截面内是 局部极大点 ，而在另一个横截面
内是局部极小点 。
多维情况下，单个点处每个方向上的 二阶导数 是不同。 Hessian的条件数衡量
这些二阶导数 的变化范围。当 Hessian的条件数很差时， 梯度下降 法也会表现得很DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.3基于梯度的优化方法 81
差。这是因为一个方向上的 导数增加得很快，而在另一个方向上增加得很慢。 梯度
下降不知道导数的这种变化，所以它不知道应该优先探索导数长期为负的方向。 病
态条件也导致很难选择合适的步长。步长必须足够小，以免冲过最小而向具有较强
正曲率的方向上升。这通常意味着步长太小，以致于在其他较小 曲率的方向上进展
不明显。见图 4.6的例子。
 30 20 10 010 20
x1 30 20 1001020x2
图4.6:梯度下降 无法利用包含在 Hessian 矩阵中的 曲率信息。这里我们使用 梯度下降 来最小
化Hessian 矩阵条件数为 5的二次函数 f(x)。这意味着最大 曲率方向具有比最小 曲率方向多五倍
的曲率。在这种情况下，最大 曲率在[1;1]⊤方向上，最小 曲率在[1; 1]⊤方向上。红线表示 梯度
下降的路径。这个非常细长的二次函数类似一个长峡谷。 梯度下降 把时间浪费于在峡谷壁反复下
降，因为它们是最陡峭的特征。由于步长有点大，有超过函数底部的趋势，因此需要在下一次迭代
时在对面的峡谷壁下降。与指向该方向的特征向量对应的 Hessian 的大的正特征值表示该方向上
的导数快速增加，因此基于 Hessian 的优化算法可以预测，在此情况下最陡峭方向实际上不是有
前途的搜索方向。
我们可以使用 Hessian矩阵的信息来指导搜索，以解决这个问题。其中最简单
的方法是 牛顿法（Newton’s method ） 。牛顿法基于一个二阶 泰勒展开来近似 x(0)附
近的 f(x)：
f(x)f(x(0)) + ( x x(0))⊤∇ xf(x(0)) +1
2(x x(0))⊤H(f)(x(0))(x x(0)):(4.11)
接着通过计算，我们可以得到这个函数的 临界点：
x= x(0) H(f)(x(0)) 1∇ xf(x(0)): (4.12)
当f是一个正定二次函数时， 牛顿法只要应用一次式 (4.12)就能直接跳到函数的最
小点。如果 f不是一个真正二次但能在局部近似为正定二次， 牛顿法则需要多次迭DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
82 第四章 数值计算
代应用式 (4.12)。迭代地更新近似函数和跳到近似函数的最小点可以比 梯度下降 更
快地到达临界点。这在接近 局部极小点 时是一个特别有用的性质，但是在 鞍点附近
是有害的。如式 (8.2.3)所讨论的，当附近的 临界点是最小点（ Hessian的所有特征值
都是正的）时 牛顿法才适用，而 梯度下降 不会被吸引到 鞍点(除非梯度指向鞍点)。
仅使用梯度信息的优化算法被称为 一阶优化算法 (ﬁrst-order optimization al-
gorithms) ，如梯度下降 。使用 Hessian 矩阵的优化算法被称为 二阶最优化算法
(second-order optimization algorithms)( Nocedal and Wright ,2006)，如牛顿法。
在本书大多数上下文中使用的优化算法适用于各种各样的函数，但几乎都没有
保证。因为在 深度学习 中使用的函数族是相当复杂的，所以 深度学习 算法往往缺乏
保证。在许多其他领域，优化的主要方法是为有限的函数族设计优化算法。
在深度学习 的背景下，限制函数满足 Lipschitz 连续（Lipschitz continuous ）或
其导数 Lipschitz 连续可以获得一些保证。 Lipschitz 连续函数的变化速度以 Lipschitz
常数（Lipschitz constant ）L为界：
8x;8y;jf(x) f(y)jL∥ x y∥2: (4.13)
这个属性允许我们量化我们的假设—— 梯度下降 等算法导致的输入的微小变化将使
输出只产生微小变化，因此是很有用的。 Lipschitz 连续性也是相当弱的约束，并
且深度学习 中很多优化问题经过相对较小的修改后就能变得 Lipschitz 连续。
最成功的特定优化领域或许是 凸优化（Convex optimization ） 。凸优化通过更强
的限制提供更多的保证。 凸优化算法只对凸函数适用，即 Hessian处处半正定的函
数。因为这些函数没有 鞍点而且其所有 局部极小点 必然是全局最小点 ，所以表现很
好。然而， 深度学习 中的大多数问题都难以表示成 凸优化的形式。 凸优化仅用作一
些深度学习 算法的子程序。 凸优化中的分析思路对证明 深度学习 算法的收敛性非常
有用，然而一般来说， 深度学习 背景下凸优化的重要性大大减少。有关 凸优化的详
细信息，详见 Boyd and Vandenberghe (2004)或Rockafellar (1997)。
4.4约束优化
有时候，在 x的所有可能值下最大化或最小化一个函数 f(x)不是我们所希望
的。相反，我们可能希望在 x的某些集合 S中找 f(x)的最大值或最小值。这被称
为约束优化 （constrained optimization ） 。在约束优化 术语中，集合 S内的点 x被称DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.4约束优化 83
为可行（feasible）点。
我们常常希望找到在某种意义上小的解。针对这种情况下的常见方法是强加一
个范数约束，如∥x∥1。
约束优化 的一个简单方法是将约束考虑在内后简单地对 梯度下降 进行修改。如
果我们使用一个小的恒定步长 ϵ，我们可以先取 梯度下降 的单步结果，然后将结果投
影回S。如果我们使用 线搜索，我们只能在步长为 ϵ范围内搜索 可行的新 x点，或者
我们可以将线上的每个点投影到约束区域。如果可能的话，在 梯度下降 或线搜索前
将梯度投影到可行域的切空间会更高效 (Rosen ,1960)。
一个更复杂的方法是设计一个不同的、无约束的优化问题，其解可以转化成原
始约束优化 问题的解。例如，我们要在 x2R2中最小化 f(x)，其中 x约束为具有单
位L2范数。我们可以关于 最小化 g() =f([cos;sin]⊤)，最后返回 [cos;sin]
作为原问题的解。这种方法需要创造性；优化问题之间的转换必须专门根据我们遇
到的每一种情况进行设计。
Karush–Kuhn–Tucker（KKT）方法2是针对约束优化 非常通用的解决方案。
为介绍 KKT方法，我们引入一个称为 广义 Lagrangian （generalized Lagrangian ）
或广义Lagrange 函数（generalized Lagrange function ）的新函数。
为了定义 Lagrangian ，我们先要通过等式和不等式的形式描述 S。我们希望通
过m个函数 g(i)和n个函数 h(j)描述S，那么 S可以表示为 S=fxj8i; g(i)(x) =
0and8j; h(j)(x)0g。其中涉及 g(i)的等式称为 等式约束 （equality constraint ） ，
涉及 h(j)的不等式称为 不等式约束 （inequality constraint ） 。
我们为每个约束引入新的变量 i和j，这些新变量被称为 KKT乘子。广义
Lagrangian 可以如下定义：
L(x;;) =f(x) +∑
iig(i)(x) +∑
jjh(j)(x): (4.14)
现在，我们可以通过优化无约束的 广义 Lagrangian 解决约束最小化问题。只要
存在至少一个 可行点且 f(x)不允许取1，那么
min
xmax
max
;0L(x;;) (4.15)
2KKT方法是 Lagrange 乘子法（只允许等式约束）的推广。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
84 第四章 数值计算
与如下函数有相同的最优 目标函数 值和最优点集 x
min
x2Sf(x): (4.16)
这是因为当约束满足时，
max
max
;0L(x;;) =f(x); (4.17)
而违反任意约束时，
max
max
;0L(x;;) =1: (4.18)
这些性质保证不可行点不会是最佳的，并且 可行点范围内的最优点不变。
要解决约束最大化问题，我们可以构造  f(x)的广义 Lagrange 函数，从而导
致以下优化问题：
min
xmax
max
;0 f(x) +∑
iig(i)(x) +∑
jjh(j)(x): (4.19)
我们也可将其转换为在外层最大化的问题：
max
xmin
min
;0f(x) +∑
iig(i)(x) ∑
jjh(j)(x): (4.20)
等式约束 对应项的符号并不重要；因为优化可以自由选择每个 i的符号，我们可以
随意将其定义为加法或减法。
不等式约束 特别有趣。如果 h(i)(x) = 0，我们就说说这个约束 h(i)(x)是活跃
(active)的。如果约束不是活跃的，则有该约束的问题的解与去掉该约束的问题的
解至少存在一个相同的局部解。一个不活跃约束有可能排除其他解。例如，整个区
域（代价相等的宽平区域）都是全局最优点的的凸问题可能因约束消去其中的某个
子区域，或在非凸问题的情况下，收敛时不活跃的约束可能排除了较好的局部 驻点。
然而，无论不活跃的约束是否被包括在内，收敛时找到的点仍然是一个 驻点。因为
一个不活跃的约束 h(i)必有负值，那么 min
xmax
max
;0L(x;;)中的 i= 0。因
此，我们可以观察到在该解中 ⊙h(x) = 0。换句话说，对于所有的 i，i0或
h(j)(x)0在收敛时必有一个是活跃的。为了获得关于这个想法的一些直观解释，
我们可以说这个解是由不等式强加的边界，我们必须通过对应的 KKT乘子影响 x
的解，或者不等式对解没有影响，我们则归零 KKT乘子。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
4.5实例：线性最小二乘 85
我们可以使用一组简单的性质来描述 约束优化 问题的最优点。这些性质称
为Karush–Kuhn–Tucker（KKT）条件 (Karush ,1939;Kuhn and Tucker ,1951)。
这些是确定一个点是最优点的必要条件，但不一定是充分条件。这些条件是：
•广义 Lagrangian 的梯度为零。
•所有关于 x和KKT乘子的约束都满足。
•不等式约束 显示的 ‘‘互补松弛性 ’’：⊙h(x) = 0。
有关 KKT方法的详细信息，请参阅 Nocedal and Wright (2006)。
4.5实例：线性最小二乘
假设我们希望找到最小化下式的 x值
f(x) =1
2∥Ax b∥2
2: (4.21)
存在专门的线性代数算法能够高效地解决这个问题；但是，我们也可以探索如何使
用基于梯度的优化来解决这个问题，这可以作为这些技术是如何工作的一个简单例
子。
首先，我们计算 梯度：
∇ xf(x) = A⊤(Ax b) = A⊤Ax A⊤b: (4.22)
然后，我们可以采用小的步长，并按照这个 梯度下降。见算法 4.1中的详细信息。
算法 4.1从任意点 x开始，使用 梯度下降 关于 x最小化 f(x) =1
2jjAx bjj2
2的算
法。
将步长 (ϵ)和容差 ()设为小的正数。
whilejjA⊤Ax A⊤bjj2> do
x x ϵ(
A⊤Ax A⊤b)
end while
我们也可以使用 牛顿法解决这个问题。因为在这个情况下，真实函数是二次的，
牛顿法所用的二次近似是精确的，该算法会在一步后收敛到 全局最小点 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
86 第四章 数值计算
现在假设我们希望最小化同样的函数，但受 x⊤x1的约束。要做到这一点，
我们引入 Lagrangian
L(x; ) =f(x) +(x⊤x 1): (4.23)
现在，我们解决以下问题
min
xmax
;0L(x; ): (4.24)
我们可以用 Moore-Penrose 伪逆： x= A+b找到无约束最小二乘问题的最小范
数解。如果这一点是 可行，那么这也是约束问题的解。否则，我们必须找到约束是活
跃的解。关于 x对Lagrangian 微分，我们得到方程
A⊤Ax A⊤b+ 2x= 0: (4.25)
这就告诉我们，该解的形式将会是
x= ( A⊤A+ 2I) 1A⊤b: (4.26)
的选择必须使结果服从约束。我们可以关于 进行梯度上升找到这个值。为了做
到这一点，观察
@
@L(x; ) = x⊤x 1: (4.27)
当 x的范数超过 1时，该导数是正的，所以为了跟随 导数上坡并相对 增
加Lagrangian ，我们需要增加 。因为 x⊤x的惩罚系数增加了，求解关于 x的
线性方程现在将得到具有较小范数的解。求解线性方程和调整 的过程将一直持续
到 x具有正确的范数并且关于 的导数是0。
本章总结了开发 机器学习 算法所需的数学基础。现在，我们已经准备好建立和
分析一些成熟的学习系统。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第五章 机器学习基础
深度学习 是机器学习 的一个特定分支。我们要想充分理解 深度学习 ，必须对 机器
学习的基本原理有深刻的理解。本章将探讨贯穿本书其余部分的一些 机器学习 重要
原理。我们建议新手读者或是希望更全面了解的读者参考一些更全面覆盖基础知识
的机器学习 参考书，例如 Murphy (2012)或者 Bishop (2006)。如果你已经熟知 机器
学习，可以跳过前面的部分，前往第 5.11节。第 5.11节涵盖了一些传统 机器学习 技
术观点，这些技术对 深度学习 的发展有着深远影响。
首先，我们将介绍学习算法的定义，并介绍一个简单的示例： 线性回归 算法。接
下来，我们会探讨拟合训练数据与寻找能够泛化到新数据的模式存在哪些不同的挑
战。大部分 机器学习 算法都有 超参数（必须在学习算法外设定） ；我们将探讨如何使
用额外的数据设置超参数。 机器学习 本质上属于应用统计学，更多地关注于如何用
计算机统计地估计复杂函数，不太关注为这些函数提供置信区间；因此我们会探讨
两种统计学的主要方法：频率派估计和 贝叶斯推断 。大部分 机器学习 算法可以分成 监
督学习和无监督学习 两类；我们将探讨不同的分类，并为每类提供一些简单的 机器
学习算法作为示例。大部分 深度学习 算法都是基于被称为 随机梯度下降 的算法求解
的。我们将介绍如何组合不同的算法部分，例如优化算法、 代价函数 、模型和 数据
集，来建立一个 机器学习 算法。最后在第 5.11节，我们会介绍一些限制传统 机器学
习泛化能力的因素。这些挑战促进了解决这些问题的 深度学习 算法的发展。
5.1学习算法
机器学习 算法是一种能够从数据中学习的算法。然而，我们所谓的 ‘‘学习’’是什
么意思呢？ Mitchell (1997)提供了一个简洁的定义： ‘‘对于某类任务 T和性能度量
P，一个计算机程序被认为可以从 经验 E中学习是指，通过 经验 E改进后，它在任
87DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
88 第五章 机器学习基础
务T上由性能度量 P衡量的性能有所提升。 ”经验 E，任务 T和性能度量 P的定
义范围非常宽广，在本书中我们并不会试图去解释这些定义的具体意义。相反，我
们会在接下来的章节中提供直观的解释和示例来介绍不同的任务、 性能度量 和经验，
这些将被用来构建 机器学习 算法。
5.1.1任务 T
机器学习 可以让我们解决一些人为设计和使用确定性程序很难解决的问题。从
科学和哲学的角度来看， 机器学习 受到关注是因为提高我们对 机器学习 的认识需要
提高我们对智能背后原理的理解。
从‘‘任务’’的相对正式的定义上说，学习过程本身不能算是任务。学习是我们所
谓的获取完成任务的能力。例如，我们的目标是使机器人能够行走，那么行走便是
任务。我们可以编程让机器人学会如何行走，或者可以人工编写特定的指令来指导
机器人如何行走。
通常机器学习 任务定义为 机器学习 系统应该如何处理 样本（example） 。样本是
指我们从某些希望 机器学习 系统处理的对象或事件中收集到的已经量化的 特征
（feature）的集合。我们通常会将 样本表示成一个向量 x2Rn，其中向量的每一个元
素xi是一个特征。例如，一张图片的 特征通常是指这张图片的像素值。
机器学习 可以解决很多类型的任务。一些非常常见的 机器学习 任务列举如下：
•分类：在这类任务中，计算机程序需要指定某些输入属于 k类中的哪一类。
为了完成这个任务，学习算法通常会返回一个函数 f:Rn!f1; : : : ; kg。当
y=f(x)时，模型将向量 x所代表的输入分类到数字码 y所代表的类别。还有
一些其他的分类问题，例如， f输出的是不同类别的概率分布。分类任务中有
一个任务是对象识别，其中输入是图片（通常由一组像素亮度值表示） ，输出
是表示图片物体的数字码。例如， Willow Garage PR2 机器人能像服务员一样
识别不同饮料，并送给点餐的顾客 (Goodfellow et al. ,2010)。目前，最好的对
象识别工作正是基于 深度学习 的(Krizhevsky et al. ,2012a ;Ioﬀe and Szegedy ,
2015)。对象识别同时也是计算机识别人脸的基本技术，可用于标记相片合辑中
的人脸 (Taigman et al. ,2014)，有助于计算机更自然地与用户交互。
•输入缺失分类 ：当输入向量的每个度量不被保证的时候，分类问题将会变得更
有挑战性。为了解决分类任务，学习算法只需要定义 一个从输入向量映射到输DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.1学习算法 89
出类别的函数。当一些输入可能丢失时，学习算法必须学习 一组函数，而不是
单个分类函数。每个函数对应着分类具有不同缺失输入子集的 x。这种情况在
医疗诊断中经常出现，因为很多类型的医学测试是昂贵的，对身体有害的。有
效地定义这样一个大集合函数的方法是学习所有相关变量的概率分布，然后通
过边缘化缺失变量来解决分类任务。使用 n个输入变量，我们现在可以获得每
个可能的缺失输入集合所需的所有 2n个不同的分类函数，但是计算机程序仅
需要学习一个描述联合概率分布的函数。参见 Goodfellow et al. (2013d )了解
以这种方式将深度概率模型应用于这类任务的示例。本节中描述的许多其他任
务也可以推广到缺失输入的情况 ;缺失输入分类只是 机器学习 能够解决的问题
的一个示例。
•回归：在这类任务中，计算机程序需要对给定输入预测数值。为了解决这个任
务，学习算法需要输出函数 f:Rn!R。除了返回结果的形式不一样外，这类
问题和分类问题是很像的。这类任务的一个示例是预测投保人的索赔金额（用
于设置保险费） ，或者预测证券未来的价格。这类预测也用在算法交易中。
•转录：这类任务中， 机器学习 系统观测一些相对非结构化表示的数据，并 转
录信息为离散的文本形式。例如，光学字符识别要求计算机程序根据文本图片
返回文字序列（ ASCII码或者 Unicode 码） 。谷歌街景以这种方式使用 深度学
习处理街道编号 (Goodfellow et al. ,2014d )。另一个例子是语音识别，计算机
程序输入一段音频波形，输出一序列音频记录中所说的字符或单词 ID的编码。
深度学习 是现代语音识别系统的重要组成部分，被各大公司广泛使用，包括微
软，IBM和谷歌 (Hinton et al. ,2012a )。
•机器翻译 ：在机器翻译任务中，输入是一种语言的符号序列，计算机程序必须
将其转化成另一种语言的符号序列。这通常适用于自然语言，如将英语译成
法语。最近， 深度学习 已经开始在这个任务上产生重要影响 (Sutskever et al. ,
2014;Bahdanau et al. ,2015)。
•结构化输出 ：结构化输出任务的输出是向量或者其他包含多个值的数据结构，
并且构成输出的这些不同元素间具有重要关系。这是一个很大的范畴，包括上
述转录任务和翻译任务在内的很多其他任务。例如语法分析——映射自然语言
句子到语法结构树，并标记树的节点为动词、名词、副词等等。参考 Collobert
(2011)将深度学习 应用到语法分析的示例。另一个例子是图像的像素级分割，
将每一个像素分配到特定类别。例如， 深度学习 可用于标注航拍照片中的道路DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
90 第五章 机器学习基础
位置 (Mnih and Hinton ,2010)。在这些标注型的任务中，输出的结构形式不
需要和输入尽可能相似。例如，在为图片添加描述的任务中，计算机程序观察
到一幅图，输出描述这幅图的自然语言句子 (Kiros et al. ,2014a ,b;Mao et al. ,
2014;Vinyals et al. ,2015b ;Donahue et al. ,2014;Karpathy and Li ,2015;Fang
et al. ,2015;Xuet al. ,2015)。这类任务被称为 结构化输出任务 是因为输出值之
间内部紧密相关。例如，为图片添加标题的程序输出的单词必须组合成一个通
顺的句子。
•异常检测 ：在这类任务中，计算机程序在一组事件或对象中筛选，并标记不正
常或非典型的个体。异常检测任务的一个示例是信用卡欺诈检测。通过对你的
购买习惯建模，信用卡公司可以检测到你的卡是否被滥用。如果窃贼窃取你的
信用卡或信用卡信息，窃贼采购物品的分布通常和你的不同。当该卡发生了不
正常的购买行为时，信用卡公司可以尽快冻结该卡以防欺诈。参考 Chandola
et al. (2009)了解欺诈检测方法。
•合成和采样 ：在这类任务中， 机器学习 程序生成一些和训练数据相似的新 样本。
通过机器学习 ，合成和采样可能在媒体应用中非常有用，可以避免艺术家大量
昂贵或者乏味费时的手动工作。例如，视频游戏可以自动生成大型物体或风景
的纹理，而不是让艺术家手动标记每个像素 (Luo et al. ,2013)。在某些情况下，
我们希望采样或合成过程可以根据给定的输入生成一些特定类型的输出。例如，
在语音合成任务中，我们提供书写的句子，要求程序输出这个句子语音的音频
波形。这是一类 结构化输出任务 ，但是多了每个输入并非只有一个正确输出的
条件，并且我们明确希望输出有很多变化，这可以使结果看上去更加自然和真
实。
•缺失值填补 ：在这类任务中， 机器学习 算法给定一个新 样本 x2Rn，x中某些
元素 xi缺失。算法必须填补这些缺失值。
•去噪：在这类任务中， 机器学习 算法的输入是， 干净样本 x2Rn经过未知损
坏过程后得到的 损坏样本 ~x2Rn。算法根据损坏后的 样本 ~x预测干净的 样本
x，或者更一般地预测条件概率分布 p(xj~x)。
•密度估计 或概率质量函数 估计：在密度估计问题中， 机器学习 算法学习函数
pmodel :Rn!R，其中 pmodel (x)可以解释成 样本采样空间的概率密度函数（如
果 x是连续的）或者 概率质量函数 （如果 x是离散的） 。要做好这样的任务DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.1学习算法 91
（当我们讨论 性能度量 P时，我们会明确定义任务是什么） ，算法需要学习观测
到的数据的结构。算法必须知道什么情况下 样本聚集出现，什么情况下不太可
能出现。以上描述的大多数任务都要求学习算法至少能隐式地捕获概率分布的
结构。密度估计可以让我们显式地捕获该分布。原则上，我们可以在该分布上
计算以便解决其他任务。例如，如果我们通过密度估计得到了概率分布 p(x)，
我们可以用该分布解决缺失值填补任务。如果 xi的值是缺失的，但是其他的变
量值 x i已知，那么我们可以得到条件概率分布 p(xijx i)。实际情况中，密
度估计并不能够解决所有这类问题，因为在很多情况下 p(x)是难以计算的。
当然，还有很多其他同类型或其他类型的任务。这里我们列举的任务类型只是
用来介绍 机器学习 可以做哪些任务，并非严格地定义 机器学习 任务分类。
5.1.2性能度量 P
为了评估 机器学习 算法的能力，我们必须设计其性能的定量度量。通常 性能度
量P是特定于系统执行的任务 T而言的。
对于诸如分类、缺失输入分类和 转录任务，我们通常度量模型的 准确率（accu-
racy） 。准确率是指该模型输出正确结果的 样本比率。我们也可以通过 错误率（error
rate）得到相同的信息。 错误率是指该模型输出错误结果的 样本比率。我们通常把 错
误率称为 0 1损失的期望。在一个特定的 样本上，如果结果是对的，那么 0 1损
失是0；否则是 1。但是对于密度估计这类任务而言，度量准确率，错误率或者其他
类型的 0 1损失是没有意义的。反之，我们必须使用不同的性能度量，使模型对每
个样本都输出一个连续数值的得分。最常用的方法是输出模型在一些 样本上概率对
数的平均值。
通常，我们会更加关注 机器学习 算法在未观测数据上的性能如何，因为这将决
定其在实际应用中的性能。因此，我们使用 测试集（test set）数据来评估系统性能，
将其与训练机器学习系统的训练集数据分开。
性能度量 的选择或许看上去简单且客观，但是选择一个与系统理想表现对应
的性能度量 通常是很难的。
在某些情况下，这是因为很难确定应该度量什么。例如，在执行 转录任务时，我
们是应该度量系统 转录整个序列的准确率，还是应该用一个更细粒度的指标，对序
列中正确的部分元素以正面评价？在执行回归任务时，我们应该更多地惩罚频繁犯DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
92 第五章 机器学习基础
一些中等错误的系统，还是较少犯错但是犯很大错误的系统？这些设计的选择取决
于应用。
还有一些情况，我们知道应该度量哪些数值，但是度量它们不太现实。这种情
况经常出现在密度估计中。很多最好的概率模型只能隐式地表示概率分布。在许多
这类模型中，计算空间中特定点的概率是不可行的。在这些情况下，我们必须设计
一个仍然对应于设计对象的替代标准，或者设计一个理想标准的良好近似。
5.1.3经验 E
根据学习过程中的不同 经验，机器学习 算法可以大致分类为 无监督（unsuper-
vised）算法和 监督（supervised ）算法。
本书中的大部分学习算法可以被理解为在整个 数据集（dataset）上获取 经验。
数据集是指很多 样本组成的集合，如第 5.1.1节所定义的。有时我们也将 样本称为数
据点（data point ） 。
Iris（鸢尾花卉） 数据集 (Fisher ,1936)是统计学家和 机器学习 研究者使用了很
久的数据集。它是 150个鸢尾花卉植物不同部分测量结果的集合。每个单独的植物
对应一个 样本。每个样本的特征是该植物不同部分的测量结果：萼片长度、萼片宽
度、花瓣长度和花瓣宽度。这个 数据集也记录了每个植物属于什么品种，其中共有
三个不同的品种。
无监督学习算法 （unsupervised learning algorithm ）训练含有很多 特征的数据
集，然后学习出这个 数据集上有用的结构性质。在 深度学习 中，我们通常要学习生
成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或 去噪。
还有一些其他类型的 无监督学习 任务，例如聚类，将 数据集分成相似 样本的集合。
监督学习算法 （supervised learning algorithm ）训练含有很多 特征的数据集，不
过数据集中的样本都有一个 标签（label）或目标（target） 。例如， Iris数据集注明
了每个鸢尾花卉 样本属于什么品种。 监督学习 算法通过研究 Iris数据集，学习如何
根据测量结果将 样本划分为三个不同品种。
大致说来， 无监督学习 涉及到观察随机向量 x的好几个 样本，试图显式或隐式
地学习出概率分布 p(x)，或者是该分布一些有意思的性质；而 监督学习 包含观察随
机向量 x及其相关联的值或向量 y，然后从 x预测 y，通常是估计 p(yjx)。术语监
督学习（supervised learning ）源自这样一个视角，教员或者老师提供 目标 y给机器DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.1学习算法 93
学习系统，指导其应该做什么。在 无监督学习 中，没有教员或者老师，算法必须学会
在没有指导的情况下理解数据。
无监督学习 和监督学习 不是严格定义的术语。它们之间界线通常是模糊的。很
多机器学习 技术可以用于这两个任务。例如，概率的链式法则表明对于向量 x2Rn，
联合分布可以分解成
p(x) =n∏
i=1p(xijx1; : : : ; xi 1): (5.1)
该分解意味着我们可以将其拆分成 n个监督学习 问题，来解决表面上的 无监督学习
p(x)。另外，我们求解 监督学习 问题 p(yjx)时，也可以使用传统的 无监督学习 策略
学习联合分布 p(x; y)，然后推断
p(yjx) =p(x; y)∑
y′p(x; y′): (5.2)
尽管无监督学习 和监督学习 并非完全没有交集的正式概念，它们确实有助于粗略分
类我们研究 机器学习 算法时遇到的问题。传统地，人们将回归、分类或者结构化输
出问题称为 监督学习 。支持其他任务的密度估计通常被称为 无监督学习 。
学习范式的其他变种也是有可能的。例如，半监督学习中，一些 样本有监督目
标，但其他 样本没有。在多实例学习中， 样本的整个集合被标记为含有或者不含有
该类的样本，但是集合中单独的样本是没有标记的。参考 Kotzias et al. (2015)了解
最近深度模型 进行多实例学习的示例。
有些机器学习 算法并不是训练于一个固定的 数据集上。例如， 强化学习 （rein-
forcement learning ）算法会和环境进行交互，所以学习系统和它的训练过程会有反
馈回路。这类算法超出了本书的范畴。请参考 Sutton and Barto (1998)或Bertsekas
and Tsitsiklis (1996)了解强化学习相关知识， Mnih and Kavukcuoglu (2013)介绍了
强化学习方向的 深度学习 方法。
大部分机器学习 算法简单地训练于一个 数据集上。数据集可以用很多不同方式
来表示。在所有的情况下， 数据集都是样本的集合，而 样本是特征的集合。
表示数据集的常用方法是 设计矩阵 （design matrix ） 。设计矩阵 的每一行包含
一个不同的 样本。每一列对应不同的 特征。例如， Iris数据集包含 150个样本，每
个样本有4个特征。这意味着我们可以将该 数据集表示为设计矩阵 X2R1504，其
中Xi;1表示第 i个植物的萼片长度， Xi;2表示第 i个植物的萼片宽度等等。我们在
本书中描述的大部分学习算法都是讲述它们是如何运行在 设计矩阵 数据集上的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
94 第五章 机器学习基础
当然，每一个 样本都能表示成向量，并且这些向量的大小相同，才能将一个 数
据集表示成设计矩阵 。这一点并非永远可能。例如，你有不同宽度和高度的照片的
集合，那么不同的照片将会包含不同数量的像素。因此不是所有的照片都可以表示
成相同长度的向量。第 9.7节和第十章将会介绍如何处理这些不同类型的异构数据。
在上述这类情况下，我们不会将 数据集表示成 m行的矩阵，而是表示成 m个元素
的结合：fx(1);x(2); : : : ; x(m)g。这种表示方式意味着 样本向量 x(i)和 x(j)可以有不
同的大小。
在监督学习 中，样本包含一个 标签或目标和一组特征。例如，我们希望使用学
习算法从照片中识别对象。我们需要明确哪些对象会出现在每张照片中。我们或许
会用数字编码表示，如 0表示人、 1表示车、 2表示猫等等。通常在处理包含观测 特
征的设计矩阵 X的数据集时，我们也会提供一个 标签向量 y，其中 yi表示样本 i
的标签。
当然，有时 标签可能不止一个数。例如，如果我们想要训练语音模型 转录整个
句子，那么每个句子 样本的标签是一个单词序列。
正如监督学习 和无监督学习 没有正式的定义， 数据集或者经验也没有严格的区
分。这里介绍的结构涵盖了大多数情况，但始终有可能为新的应用设计出新的结构。
5.1.4示例：线性回归
我们将机器学习 算法定义为，通过经验以提高计算机程序在某些任务上性能的
算法。这个定义有点抽象。为了使这个定义更具体点，我们展示一个简单的 机器学
习示例：线性回归 （linear regression ） 。当我们介绍更多有助于理解 机器学习 特性的
概念时，我们会反复回顾这个示例。
顾名思义， 线性回归 解决回归问题。换言之，我们的目标是建立一个系统，将向
量 x2Rn作为输入，预测标量 y2R作为输出。 线性回归 的输出是其输入的线性函
数。令 ^y表示模型预测 y应该取的值。我们定义输出为
^y= w⊤x; (5.3)
其中 w2Rn是参数（parameter ）向量。
参数是控制系统行为的值。在这种情况下， wi是系数，会和 特征 xi相乘之
后全部相加起来。我们可以将 w看作是一组决定每个 特征如何影响预测的 权重
（weight） 。如果特征 xi对应的权重 wi是正的，那么 特征的值增加，我们的预测值DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.1学习算法 95
^y也会增加。如果 特征 xi对应的权重 wi是负的，那么 特征的值增加，我们的预测
值^y会减少。如果 特征权重的大小很大，那么它对预测有很大的影响；如果 特征权
重的大小是零，那么它对预测没有影响。
因此，我们可以定义任务 T：通过输出 ^y= w⊤x从 x预测 y。接下来我们需要
定义性能度量 ——P。
假设我们有 m个输入样本组成的设计矩阵 ，我们不用它来训练模型，而是评
估模型性能如何。我们也有每个 样本对应的正确值 y组成的回归 目标向量。因为这
个数据集只是用来评估性能，我们称之为 测试集（test set） 。我们将输入的 设计矩
阵记作 X(test)，回归目标向量记作 y(test)。
度量模型性能的一种方法是计算模型在 测试集上的均方误差 （mean squared
error） 。如果 ^y(test)表示模型在 测试集上的预测值，那么 均方误差 表示为：
MSE test=1
m∑
i(^y(test) y(test))2
i: (5.4)
直观上，当 ^y(test)= y(test)时，我们会发现误差降为 0。我们也可以看到
MSE test=1
m^y(test) y(test)2
2; (5.5)
所以当预测值和 目标值之间的欧几里得距离增加时，误差也会增加。
为了构建一个 机器学习 算法，我们需要设计一个算法，通过观察训练集
(X(train );y(train ))获得经验，减少 MSE test以改进权重 w。一种直观方式（我们
将在后续的第 5.5.1节说明其合法性）是最小化训练集上的 均方误差 ，即 MSE train。
最小化 MSE train，我们可以简单地求解其导数为 0的情况：
∇ wMSE train= 0 (5.6)
)∇ w1
m^y(train ) y(train )2
2= 0 (5.7)
)1
m∇ wX(train )w y(train )2
2= 0 (5.8)
)∇ w(
X(train )w y(train ))⊤(
X(train )w y(train ))
= 0 (5.9)
)∇ w(
w⊤X(train )⊤X(train )w 2w⊤X(train )⊤y(train )+y(train )⊤y(train ))
= 0 (5.10)
)2X(train )⊤X(train )w 2X(train )⊤y(train )= 0 (5.11)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
96 第五章 机器学习基础
) w=(
X(train )⊤X(train )) 1
X(train )⊤y(train )(5.12)
通过式 (5.12)给出解的系统方程被称为 正规方程 （normal equation ）。计算
式(5.12)构成了一个简单的机器学习算法。图 5.1展示了线性回归 算法的使用示例。
 1:0 0:50:00:51:0
x1 3 2 10123yLinear regression example
0:5 1:0 1:5
w10:200:250:300:350:400:450:500:55MSE(train)Optimization of w
图5.1:一个线性回归 问题，其中训练集包括十个数据点，每个数据点包含一个特征。因为只有一
个特征，权重向量 w也只有一个要学习的参数 w1。(左)我们可以观察到 线性回归 学习 w1，从而
使得直线 y=w1x能够尽量接近穿过所有的训练点。 (右)标注的点表示由 正规方程 学习到的 w1
的值，我们发现它可以最小化训练集上的 均方误差 。
值得注意的是，术语 线性回归 （linear regression ）通常用来指稍微复杂一些，
附加额外参数（截距项 b）的模型。在这个模型中，
^y= w⊤x+b; (5.13)
因此从参数到预测的映射仍是一个线性函数，而从 特征到预测的映射是一个仿射函
数。如此扩展到仿射函数意味着模型预测的曲线仍然看起来像是一条直线，只是这
条直线没必要经过原点。除了通过添加偏置参数 b，我们还可以使用仅含权重的模
型，但是 x需要增加一项永远为 1的元素。对应于额外 1的权重起到了偏置参数的
作用。当我们在本书中提到仿射函数时，我们会经常使用术语 ‘‘线性’’。
截距项 b通常被称为仿射变换的 偏置（bias）参数。这个术语的命名源自该变
换的输出在没有任何输入时会偏移 b。它和统计偏差中指代统计估计算法的某个量的
期望估计偏离真实值的意思是不一样的。
线性回归 当然是一个极其简单且有局限的学习算法，但是它提供了一个说明学
习算法如何工作的例子。在接下来的小节中，我们将会介绍一些设计学习算法的基DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.2容量、过拟合和欠拟合 97
本原则，并说明如何使用这些原则来构建更复杂的学习算法。
5.2容量、过拟合和欠拟合
机器学习 的主要挑战是我们的算法必须能够在 先前未观测的新 输入上表现良好，
而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为 泛
化（generalization ） 。
通常情况下，当我们训练 机器学习 模型时，我们可以使用某个训练集，在训练
集上计算一些被称为 训练误差 （training error ）的度量误差，目标是降低训练误差。
目前为止，我们讨论的是一个简单的优化问题。 机器学习 和优化不同的地方在于，我
们也希望 泛化误差 （generalization error ） （也被称为 测试误差 （test error ） ）很低。
泛化误差被定义为新输入的误差期望。这里，期望的计算基于不同的可能输入，这
些输入采自于系统在现实中遇到的分布。
通常，我们度量模型在训练集中分出来的 测试集（test set）样本上的性能，来
评估机器学习 模型的泛化误差。
在我们的 线性回归 示例中，我们通过最小化 训练误差 来训练模型，
1
m(train )X(train )w y(train )2
2; (5.14)
但是我们真正关注的是 测试误差1
m(test)X(test)w y(test)2
2。
当我们只能观测到训练集时，我们如何才能影响 测试集的性能呢？ 统计学习理
论（statistical learning theory ）提供了一些答案。如果训练集和 测试集的数据是任
意收集的，那么我们能够做的确实很有限。如果我们可以对 训练集和测试集数据的
收集方式有些假设，那么我们能够对算法做些改进。
训练集和测试集数据通过 数据集上被称为 数据生成过程 （data generating pro-
cess）的概率分布生成。通常，我们会做一系列被统称为 独立同分布假设 （i.i.d.
assumption ）的假设。该假设是说，每个 数据集中的样本都是彼此 相互独立的 （in-
dependent ） ，并且训练集和测试集是同分布的 （identically distributed ） ，采样自相
同的分布。这个假设使我们能够在单个样本的概率分布描述数据生成过程。然后相
同的分布可以用来生成每一个训练 样本和每一个测试 样本。我们将这个共享的潜在
分布称为 数据生成分布 （data generating distribution ） ，记作 pdata。这个概率框架
和独立同分布假设允许我们从数学上研究 训练误差 和测试误差 之间的关系。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
98 第五章 机器学习基础
我们能观察到 训练误差 和测试误差 之间的直接联系是，随机模型 训练误差 的期
望和该模型 测试误差 的期望是一样的。假设我们有概率分布 p(x; y)，从中重复采样
生成训练集和测试集。对于某个固定的 w，训练集误差的期望恰好和 测试集误差的
期望一样，这是因为这两个期望的计算都使用了相同的数据集生成过程。这两种情
况的唯一区别是 数据集的名字不同。
当然，当我们使用 机器学习 算法时，我们不会提前固定参数，然后从 数据集中采
样。我们会在训练集上采样，然后挑选参数去降低训练集误差，然后再在 测试集上
采样。在这个过程中，测试误差期望会大于或等于训练误差期望。以下是决定 机器
学习算法效果是否好的因素：
1.降低训练误差。
2.缩小训练误差和测试误差的差距。
这两个因素对应 机器学习 的两个主要挑战： 欠拟合（underﬁtting ）和过拟合
（overﬁtting ） 。欠拟合是指模型不能在训练集上获得足够低的误差。而 过拟合是指训
练误差和和测试误差之间的差距太大。
通过调整模型的 容量（capacity） ，我们可以控制模型是否偏向于 过拟合或者欠
拟合。通俗地，模型的 容量是指其拟合各种函数的能力。 容量低的模型可能很难拟
合训练集。 容量高的模型可能会过拟合，因为记住了不适用于 测试集的训练集性质。
一种控制训练算法容量的方法是选择 假设空间 （hypothesis space ） ，即学习算
法可以选择为解决方案的函数集。例如， 线性回归 函数将关于其输入的所有线性函
数作为假设空间。广义 线性回归 的假设空间包括多项式函数，而非仅有线性函数。这
样做就增加了模型的容量。
一次多项式提供了我们已经熟悉的 线性回归 模型，其预测如下：
^y=b+wx: (5.15)
通过引入 x2作为线性回归 模型的另一个 特征，我们能够学习关于 x的二次函数模
型：
^y=b+w1x+w2x2: (5.16)
尽管该模型是 输入的二次函数，但输出仍是 参数的线性函数。因此我们仍然可以用 正
规方程得到模型的闭解。我们可以继续添加 x的更高幂作为额外 特征，例如下面的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.2容量、过拟合和欠拟合 99
9次多项式：
^y=b+9∑
i=1wixi: (5.17)
当机器学习 算法的容量适合于所执行任务的复杂度和所提供训练数据的数量时，
算法效果通常会最佳。 容量不足的模型不能解决复杂任务。 容量高的模型能够解决
复杂的任务，但是当其容量高于任务所需时，有可能会过拟合。
图5.2展示了这个原理的使用情况。我们比较了线性，二次和 9次预测器拟合真
实二次函数的效果。线性函数无法刻画真实函数的曲率，所以欠拟合。 9次函数能够
表示正确的函数，但是因为训练参数比训练 样本还多，所以它也能够表示无限多个
刚好穿越训练 样本点的很多其他函数。我们不太可能从这很多不同的解中选出一个
泛化良好的。在这个问题中，二次模型非常符合任务的真实结构，因此它可以很好
地泛化到新数据上。
x0yUnderfitting
x0yAppropriate capacity
x0yOverfitting
图5.2:我们用三个模型拟合了这个训练集的样本。训练数据是通过随机抽取 x然后用二次函数确
定性地生成 y来合成的。 (左)用一个线性函数拟合数据会导致 欠拟合——它无法捕捉数据中的 曲
率信息。 (中)用二次函数拟合数据在未观察到的点上 泛化得很好。这并不会导致明显的 欠拟合或
者过拟合。(右)一个 9阶的多项式拟合数据会导致 过拟合。在这里我们使用 Moore-Penrose 伪
逆来解这个欠定的 正规方程 。得出的解能够精确地穿过所有的训练点，但可惜我们无法提取有效
的结构信息。在两个数据点之间它有一个真实的函数所不包含的深谷。在数据的左侧，它也会急
剧增长，而在这一区域真实的函数却是下降的。
目前为止，我们探讨了通过改变输入 特征的数目和加入这些 特征对应的参数，改
变模型的容量。事实上，还有很多方法可以改变模型的容量。容量不仅取决于模型
的选择。模型规定了调整参数降低训练目标时，学习算法可以从哪些函数族中选择DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
100 第五章 机器学习基础
函数。这被称为模型的 表示容量 （representational capacity ） 。在很多情况下，从这
些函数中挑选出最优函数是非常困难的优化问题。实际中，学习算法不会真的找到
最优函数，而仅是找到一个可以大大降低训练误差的函数。额外的限制因素，比如
优化算法的不完美，意味着学习算法的 有效容量 （eﬀective capacity ）可能小于模型
族的表示容量 。
提高机器学习 模型泛化的现代思想可以追溯到早在托勒密时期的哲学家的思
想。许多早期的学者提出一个简约原则，现在广泛被称为 奥卡姆剃刀 （Occam’s
razor） （c. 1287-1387 ） 。该原则指出，在同样能够解释已知观测现象的假设中，我们
应该挑选 ‘‘最简单 ’’的那一个。这个想法是在 20世纪，由统计学习理论创始人形式
化并精确化的 (Vapnik and Chervonenkis ,1971;Vapnik ,1982;Blumer et al. ,1989;
Vapnik ,1995)。
统计学习理论提供了量化模型容量的不同方法。在这些中， 最有名的是 Vapnik-
Chervonenkis 维度（Vapnik-Chervonenkis dimension ,VC） 。VC维度量二元分类
器的容量。 VC维定义为该分类器能够分类的训练 样本的最大数目。假设存在 m个
不同 x点的训练集，分类器可以任意地标记该 m个不同的 x点，VC维被定义为 m
的最大可能值。
量化模型的容量使得统计学习理论可以进行量化预测。统计学习理论中最重要
的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量增长而增长，但
随着训练 样本增多而下降 (Vapnik and Chervonenkis ,1971;Vapnik ,1982;Blumer
et al. ,1989;Vapnik ,1995)。这些边界为 机器学习 算法可以有效解决问题提供了理论
验证，但是它们很少应用于实际中的 深度学习 算法。一部分原因是边界太松，另一
部分原因是很难确定 深度学习 算法的容量。由于有效容量受限于优化算法的能力，
确定深度学习 模型容量的问题特别困难。而且对于 深度学习 中的一般非凸优化问题，
我们只有很少的理论分析。
我们必须记住虽然更简单的函数更可能泛化（训练误差和测试误差的差距小） ，
但我们仍然需要选择一个充分复杂的假设以达到低的 训练误差 。通常，当模型容量
上升时，训练误差会下降，直到其渐近最小可能误差（假设误差度量有最小值） 。通
常，泛化误差 是一个关于模型容量的 U形曲线函数。如图 5.3所示。
为考虑容量任意高的极端情况，我们介绍 非参数（non-parametric ）模型的概
念。至此，我们只探讨过参数模型，例如 线性回归 。参数模型学习到的函数在观测新
数据前，参数是有限且固定的向量。非参数模型没有这些限制。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.2容量、过拟合和欠拟合 101
0 Optimal Capacity
CapacityErrorUndertting zone Overtting zone
Generalization gapTraining error
Generalization error
图5.3:容量和误差之间的典型关系。 训练误差 和测试误差 表现得非常不同。在图的左端， 训练误
差和泛化误差 都非常高。这是 欠拟合机制 （underﬁtting regime ） 。当我们增加 容量时，训练误差 减
小，但是 训练误差 和泛化误差 之间的间距却不断扩大。最终，这个间距的大小超过了 训练误差 的下
降，我们进入到了 过拟合机制 （overﬁtting regime ） ，其中容量过大，超过了 最佳容量 （optimal
capacity） 。
有时，非参数模型仅是一些不能实际实现的理论抽象（比如搜索所有可能概率
分布的算法） 。然而，我们也可以设计一些实用的非参数模型，使它们的复杂度和训
练集大小有关。这种算法的一个示例是 最近邻回归 （nearest neighbor regression ） 。
不像线性回归 有固定长度的向量作为权重， 最近邻回归 模型存储了训练集中所有的
X和 y。当需要为测试点 x分类时，模型会查询训练集中离该点最近的点，并返回
相关的回归 目标。换言之， ^y=yi其中 i= arg min∥Xi;: x∥2
2。该算法也可以扩展
成L2范数以外的距离度量，例如学成距离度量 (Goldberger et al. ,2005)。如果允许
该算法通过平均 Xi;:中所有邻近的向量对应的 yi来打破联系，那么该算法会在任意
回归数据集上达到最小可能的训练误差（如果存在两个相同的输入对应不同的输出，
那么训练误差可能会大于零） 。
最后，我们也可以将参数学习算法嵌入另一个增加参数数目的算法来创建非参
数学习算法。例如，我们可以想象这样一个算法，外层循环调整多项式的次数，内
层循环通过 线性回归 学习模型。
理想模型假设我们能够预先知道生成数据的真实概率分布。然而这样的模型仍
然会在很多问题上发生一些错误，因为分布中仍然会有一些 噪声。在监督学习 中，从
x到y的映射可能内在是随机的，或者 y可能是其他变量（包括 x在内）的确定性DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
102 第五章 机器学习基础
函数。从预先知道的真实分布 p(x; y)预测而出现的误差被称为 贝叶斯误差 （Bayes
error） 。
训练误差 和泛化误差 会随训练集的大小发生变化。泛化误差的期望从不会因训
练样本数目的增加而增加。对于非参数模型而言，更多的数据会得到更好的泛化能
力，直到达到最佳可能的泛化误差。任何模型容量小于最优容量的固定参数模型会
渐近到大于 贝叶斯误差 的误差值。如图 5.4所示。值得注意的是，具有最优容量的模
型仍然有可能在 训练误差 和泛化误差 之间存在很大的差距。在这种情况下，我们可
以通过收集更多的训练 样本来缩小差距。
5.2.1没有免费午餐定理
学习理论表明 机器学习 算法能够在有限个训练集 样本中很好地泛化。这似乎违
背一些基本的逻辑原则。归纳推理，或是从一组有限的 样本中推断一般的规则，在
逻辑上不是很有效。为了逻辑地推断一个规则去描述集合中的元素，我们必须具有
集合中每个元素的信息。
在一定程度上， 机器学习 仅通过概率法则就可以避免这个问题，而无需使用纯
逻辑推理整个确定性法则。 机器学习 保证找到一个在所关注的 大多数样本上可能正
确的规则。
可惜，即使这样也不能解决整个问题。 机器学习 的没有免费午餐定理 （no free
lunch theorem ）表明，在所有可能的数据生成分布上平均之后，每一个分类算法在
未事先观测的点上都有相同的错误率。换言之，在某种意义上，没有一个 机器学习 算
法总是比其他的要好。我们能够设想的最先进的算法和简单地将所有点归为同一类
的简单算法有着相同的平均性能（在所有可能的任务上） 。
幸运的是，这些结论仅在我们考虑 所有可能的数据生成分布时才成立。在真实
世界应用中，如果我们对遇到的概率分布进行假设的话，那么我们可以设计在这些
分布上效果良好的学习算法。
这意味着 机器学习 研究的目标不是找一个通用学习算法或是绝对最好的学习算
法。反之，我们的 目标是理解什么样的分布与人工智能获取经验的 ‘‘真实世界 ’’相
关，什么样的学习算法在我们关注的数据生成分布上效果最好。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.2容量、过拟合和欠拟合 103
100101102103104105
Number of training examples0.00.51.01.52.02.53.03.5Error (MSE)Bayes error
Train (quadratic)
Test (quadratic)
Test (optimal capacity)
Train (optimal capacity)
100101102103104105
Number of training examples05101520Optimal capacity (polynomial degree)
图5.4:训练集大小对 训练误差 ，测试误差 以及最佳容量 的影响。通过给一个 5阶多项式添加适当
大小的噪声，我们构造了一个合成的 回归问题，生成单个测试集，然后生成一些不同尺寸的训练
集。为了描述 95%置信区间的 误差条，对于每一个尺寸，我们生成了 40个不同的训练集。 (上)
两个不同的模型上训练集和测试集的 MSE，一个二次模型，另一个模型的阶数通过最小化 测试误
差来选择。两个模型都是用闭式解来拟合。对于二次模型来说，当训练集增加时 训练误差 也随之
增大。这是由于越大的数据集越难以拟合。同时， 测试误差 随之减小，因为关于训练数据的不正确
的假设越来越少。二次模型的容量并不足以解决这个问题，所以它的 测试误差 趋近于一个较高的
值。最佳容量 点处的测试误差 趋近于贝叶斯误差 。训练误差 可以低于 贝叶斯误差 ，因为训练算法有
能力记住训练集中特定的样本。当训练集趋向于无穷大时，任何固定容量的模型（在这里指的是
二次模型）的 训练误差 都至少增至 贝叶斯误差 。(下)当训练集大小增大时， 最佳容量 （在这里是
用最优多项式回归器的阶数衡量的）也会随之增大。 最佳容量 在达到足够捕捉模型复杂度之后就
不再增长了。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
104 第五章 机器学习基础
5.2.2正则化
没有免费午餐定理暗示我们必须在特定任务上设计性能良好的 机器学习 算法。
我们建立一组学习算法的偏好来达到这个要求。当这些偏好和我们希望算法解决的
学习问题相吻合时，性能会更好。
至此，我们具体讨论修改学习算法的方法只有，通过增加或减少学习算法可选
假设空间的函数来增加或减少模型的容量。我们列举的一个具体示例是 线性回归 增
加或减少多项式的次数。目前为止讨论的观点都是过度简化的。
算法的效果不仅很大程度上受影响于假设空间的函数数量，也取决于这些函数
的具体形式。我们已经讨论的学习算法（ 线性回归 ）具有包含其输入的线性函数集
的假设空间。对于输入和输出确实接近线性相关的问题，这些线性函数是很有用的。
对于完全非线性的问题它们不太有效。例如，我们用 线性回归 ，从x预测 sin(x)，效
果不会好。因此我们可以通过两种方式控制算法的性能，一是允许使用的函数种类，
二是这些函数的数量。
在假设空间中，相比于某一个学习算法，我们可能更偏好另一个学习算法。这
意味着两个函数都是符合条件的，但是我们更偏好其中一个。只有非偏好函数比偏
好函数在训练 数据集上效果明显好很多时，我们才会考虑非偏好函数。
例如，我们可以加入 权重衰减 （weight decay ）来修改 线性回归 的训练标准。带
权重衰减的 线性回归 最小化训练集上的 均方误差 和正则项的和 J(w)，其偏好于平方
L2范数较小的权重。具体如下：
J(w) =MSE train+w⊤w; (5.18)
其中 是提前挑选的值，控制我们偏好小范数权重的程度。当 = 0，我们没有任
何偏好。越大的 偏好范数越小的权重。最小化 J(w)可以看作是拟合训练数据和
偏好小权重范数之间的权衡。这会使得解决方案的斜率较小，或是将权重放在较少
的特征上。我们可以训练具有不同 值的高次多项式回归模型，来举例说明如何通
过权重衰减控制模型欠拟合或过拟合的趋势。如图 5.5所示。
更一般地， 正则化一个学习函数 f(x;)的模型，我们可以给 代价函数 添加被称
为正则化项 （regularizer ）的惩罚。在权重衰减的例子中， 正则化项 是Ω( w) = w⊤w。
在第七章，我们将看到很多其他可能的 正则化项 。
表示对函数的偏好是比增减假设空间的成员函数更一般的控制模型 容量的方法。
我们可以将去掉假设空间中的某个函数看作是对不赞成这个函数的无限偏好。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.3超参数和验证集 105
x0yUnderfitting
(Excessive ¸)
x0yAppropriate weight decay
(Medium ¸)
x0yOverfitting
(¸!0)
图5.5:我们使用高阶多项式回归模型来拟合图 5.2中训练样本。真实函数是二次的，但是在这里
我们只使用 9阶多项式。我们通过改变 权重衰减 的量来避免高阶模型的过拟合问题。 (左)当非
常大时，我们可以强迫模型学习到了一个没有斜率的函数。由于它只能表示一个常数函数，所以
会导致欠拟合。(中)取一个适当的 时，学习算法能够用一个正常的形状来恢复曲率。即使模型
能够用更复杂的形状来来表示函数， 权重衰减 鼓励用一个带有更小参数的更简单的模型来描述它。
(右)当权重衰减 趋近于 0（即使用 Moore-Penrose 伪逆来解这个带有最小 正则化的欠定问题）时，
这个 9阶多项式会导致严重的 过拟合，这和我们在图 5.2中看到的一样。
在我们权重衰减的示例中，通过在最小化的 目标中额外增加一项，我们明确地
表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示对不同解的偏
好。总而言之，这些不同的方法都被称为 正则化（regularization ） 。正则化是指我们
修改学习算法，使其降低泛化误差而非训练误差 。正则化是机器学习 领域的中心问
题之一，只有优化能够与其重要性相媲。
没有免费午餐定理 已经清楚地阐述了没有最优的学习算法，特别地，没有最优
的正则化形式。反之，我们必须挑选一个非常适合于我们所要解决的任务的正则形
式。深度学习 中普遍的（特别是本书中的）理念是大量任务（例如所有人类能做的
智能任务）也许都可以使用非常通用的 正则化形式来有效解决。
5.3超参数和验证集
大多数机器学习 算法都有超参数，可以设置来控制算法行为。超参数的值不是
通过学习算法本身学习出来的（尽管我们可以设计一个嵌套的学习过程，一个学习DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
106 第五章 机器学习基础
算法为另一个学习算法学出最优超参数） 。
在图 5.2所示的多项式回归示例中，有一个超参数：多项式的次数，作为 容量超
参数。控制 权重衰减 程度的 是另一个超参数。
有时一个选项被设为学习算法不用学习的超参数，是因为它太难优化了。更多
的情况是，该选项必须是超参数，因为它不适合在训练集上学习。这适用于控制模
型容量的所有超参数。如果在训练集上学习超参数，这些超参数总是趋向于最大可
能的模型容量，导致过拟合（参考图 5.3） 。例如，相比低次多项式和正的权重衰减
设定，更高次的多项式和权重衰减参数设定 = 0总能在训练集上更好地拟合。
为了解决这个问题，我们需要一个训练算法观测不到的 验证集（validation set ）
样本。
早先我们讨论过和训练数据相同分布的 样本组成的测试集，它可以用来估计学
习过程完成之后的 学习器的泛化误差。其重点在于测试 样本不能以任何形式参与到
模型的选择中，包括设定超参数。基于这个原因， 测试集中的样本不能用于验证集。
因此，我们总是从 训练数据中构建验证集。特别地，我们将训练数据分成两个不相
交的子集。其中一个用于学习参数。另一个作为验证集，用于估计训练中或训练后
的泛化误差，更新超参数。用于学习参数的数据子集通常仍被称为训练集，尽管这
会和整个训练过程用到的更大的 数据集相混。用于挑选超参数的数据子集被称为 验
证集（validation set ） 。通常， 80%的训练数据用于训练， 20%用于验证。由于验证
集是用来 ‘‘训练’’超参数的，尽管验证集的误差通常会比训练集误差小，验证集会低
估泛化误差。所有超参数优化完成之后，泛化误差可能会通过 测试集来估计。
在实际中，当相同的 测试集已在很多年中重复地用于评估不同算法的性能，并
且考虑学术界在该 测试集上的各种尝试，我们最后可能也会对 测试集有着乐观的估
计。基准会因之变得陈旧，而不能反映系统的真实性能。值得庆幸的是，学术界往往
会移到新的（通常会更巨大、更具挑战性）基准 数据集上。
5.3.1交叉验证
将数据集分成固定的训练集和固定的 测试集后，若测试集的误差很小，这将是
有问题的。一个小规模的 测试集意味着平均测试误差估计的统计不确定性，使得很
难判断算法 A是否比算法 B在给定的任务上做得更好。
当数据集有十万计或者更多的 样本时，这不会是一个严重的问题。当 数据集太DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.3超参数和验证集 107
小时，也有替代方法允许我们使用所有的 样本估计平均测试误差，代价是增加了计
算量。这些过程是基于在原始数据上随机采样或分离出的不同 数据集上重复训练和
测试的想法。最常见的是 k-折交叉验证过程，如算法 5.1所示，将 数据集分成 k个
不重合的子集。测试误差可以估计为 k次计算后的平均测试误差。在第 i次测试时，
数据的第 i个子集用于 测试集，其他的数据用于训练集。带来的一个问题是不存在
平均误差方差的无偏估计 (Bengio and Grandvalet ,2004)，但是我们通常会使用近
似来解决。
算法5.1k-折交叉验证算法。当给定数据集 D对于简单的训练 /测试或训练 /验证分
割而言太小难以产生泛化误差的准确估计时（因为在小的测试集上， L可能具有过
高的方差） ， k-折交叉验证算法可以用于估计学习算法 A的泛化误差。数据集 D包
含的元素是抽象的样本 z(i)（对于第 i个样本） ，在 监督学习 的情况代表（输入，目
标）对 z(i)= ( x(i); y(i))，或者无监督学习 的情况下仅用于输入 z(i)= x(i)。该算法
返回D中每个示例的误差向量 e，其均值是估计的泛化误差。单个样本上的误差可
用于计算平均值周围的置信区间（式 (5.47)） 。虽然这些置信区间在使用交叉验证之
后不能很好地证明，但是通常的做法是只有当算法 A误差的置信区间低于并且不与
算法 B的置信区间相交时，我们才声明算法 A比算法 B更好。
Deﬁne KFoldXV (D; A; L; k ):
Require: D为给定数据集，其中元素为 z(i)
Require: A为学习算法，可视为一个函数（使用数据集作为输入，输出一个学好的
函数）
Require: L为损失函数 ，可视为来自学好的函数 f，将样本 z(i)2D映射到 R中
标量的函数
Require: k为折数
将D分为 k个互斥子集 Di，它们的并集为 D
forifrom 1tokdo
fi=A(DnDi)
for z(j)inDido
ej=L(fi;z(j))
end for
end for
Return eDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
108 第五章 机器学习基础
5.4估计、偏差和方差
统计领域为我们提供了很多工具来实现 机器学习 目标，不仅可以解决训练集上
的任务，还可以泛化。基本的概念，例如参数估计、偏差和方差，对于正式地刻画泛
化、欠拟合和过拟合都非常有帮助。
5.4.1点估计
点估计试图为一些感兴趣的量提供单个 ‘‘最优’’预测。一般地，感兴趣的量可以
是单个参数，或是某些参数模型中的一个向量参数，例如第 5.1.4节线性回归 中的权
重，但是也有可能是整个函数。
为了区分参数估计和真实值，我们习惯将参数 的点估计表示为 ^。
令fx(1); : : : ; x(m)g是m个独立同分布（ i.i.d.）的数据点。 点估计（point esti-
mator）或统计量（statistics ）是这些数据的任意函数：
^m=g(x(1); : : : ; x(m)): (5.19)
这个定义不要求 g返回一个接近真实 的值，或者 g的值域恰好是 的允许取值
范围。点估计的定义非常宽泛，给了 估计量的设计者极大的灵活性。虽然几乎所有
的函数都可以称为 估计量，但是一个良好的 估计量的输出会接近生成训练数据的真
实参数。
现在，我们采取频率派在统计上的观点。换言之，我们假设真实参数 是固定
但未知的，而点估计 ^是数据的函数。由于数据是随机过程采样出来的，数据的任
何函数都是随机的。因此 ^是一个随机变量。
点估计也可以指输入和 目标变量之间关系的估计。我们将这种类型的点估计称
为函数估计。
函数估计 有时我们会关注函数估计（或函数近似） 。这时我们试图从输入向量 x预
测变量 y。我们假设有一个函数 f(x)表示 y和 x之间的近似关系。例如，我们可能
假设 y=f(x) +ϵ，其中ϵ是 y中未能从 x预测的一部分。在函数估计中，我们感
兴趣的是用模型估计去近似 f，或者估计 ^f。函数估计和估计参数 是一样的；函
数估计 ^f是函数空间中的一个点估计。 线性回归 示例（第 5.1.4节中讨论的）和多项DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.4估计、偏差和方差 109
式回归示例（第 5.2节中讨论的）都既可以被解释为估计参数 w，又可以被解释为估
计从 x到y的函数映射 ^f。
现在我们回顾点估计最常研究的性质，并探讨这些性质说明了估计的哪些特点。
5.4.2偏差
估计的偏差被定义为：
bias(^m) =E(^m) ; (5.20)
其中期望作用在所有数据（看作是从随机变量采样得到的）上， 是用于定义数
据生成分布的 的真实值。如果 bias(^m) = 0，那么估计量 ^m被称为是 无偏
（unbiased ） ，这意味着 E(^m) =。如果 limm!1bias(^m) = 0，那么估计量 ^m被
称为是渐近无偏 （asymptotically unbiased ） ，这意味着 limm!1E(^m) =。
示例：伯努利分布 考虑一组服从均值为 的伯努利分布的独立同分布的样本
fx(1); : : : ; x(m)g：
P(x(i);) =x(i)(1 )(1 x(i)): (5.21)
这个分布中参数 的常用估计量是训练样本的均值：
^m=1
mm∑
i=1x(i): (5.22)
判断这个 估计量是否有偏，我们将式 (5.22)代入式 (5.20)：
bias(^m) =E[^m]  (5.23)
=E[
1
mm∑
i=1x(i)]
  (5.24)
=1
mm∑
i=1E[
x(i)]
  (5.25)
=1
mm∑
i=11∑
x(i)=0(
x(i)x(i)(1 )(1 x(i)))
  (5.26)
=1
mm∑
i=1()  (5.27)
= = 0 (5.28)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
110 第五章 机器学习基础
因为 bias(^) = 0，我们称估计 ^是无偏的。
示例：均值的高斯分布估计 现在，考虑一组独立同分布的 样本fx(1); : : : ; x(m)g服
从高斯分布 p(x(i)) =N(x(i);; 2)，其中 i2f1; : : : ; mg。回顾高斯概率密度函数如
下：
p(x(i);; 2) =1p
22exp(
 1
2(x(i) )2
2)
: (5.29)
高斯均值参数的常用 估计量被称为样本均值 （sample mean ） ：
^m=1
mm∑
i=1x(i)(5.30)
判断样本均值 是否有偏，我们再次计算它的期望：
bias(^m) =E[^m]  (5.31)
=E[
1
mm∑
i=1x(i)]
  (5.32)
=(
1
mm∑
i=1E[
x(i)])
  (5.33)
=(
1
mm∑
i=1)
  (5.34)
= = 0 (5.35)
因此我们发现 样本均值 是高斯均值参数的无偏 估计量。
示例：高斯分布方差估计 本例中，我们比较高斯分布方差参数 2的两个不同估
计。我们探讨是否有一个是有偏的。
我们考虑的第一个方差估计被称为 样本方差 （sample variance ） ：
^2
m=1
mm∑
i=1(
x(i) ^m)2; (5.36)
其中 ^m是样本均值 。更形式地，我们对计算感兴趣
bias(^2
m) =E[^2
m] 2: (5.37)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.4估计、偏差和方差 111
我们首先估计项 E[^2
m]：
E[^2
m] =E[
1
mm∑
i=1(
x(i) ^m)2]
(5.38)
=m 1
m2(5.39)
回到式 (5.37)，我们可以得出 ^2
m的偏差是 2/m。因此样本方差 是有偏估计。
无偏样本方差 （unbiased sample variance ）估计
~2
m=1
m 1m∑
i=1(
x(i) ^m)2(5.40)
提供了另一种可选方法。正如名字所言，这个估计是无偏的。换言之，我们会发现
E[~2
m] =2：
E[~2
m] =E[
1
m 1m∑
i=1(
x(i) ^m)2]
(5.41)
=m
m 1E[^2
m] (5.42)
=m
m 1(m 1
m2)
(5.43)
=2: (5.44)
我们有两个 估计量：一个是有偏的，另一个是无偏的。尽管无偏估计显然是令
人满意的，但它并不总是 ‘‘最好’’的估计。我们将看到，经常会使用其他具有重要性
质的有偏估计。
5.4.3方差和标准差
我们有时会考虑 估计量的另一个性质是它作为数据样本的函数，期望的变化程
度是多少。正如我们可以计算 估计量的期望来决定它的偏差，我们也可以计算它的
方差。估计量的方差（variance）就是一个 方差
Var(^) (5.45)
其中随机变量是训练集。另外，方差的平方根被称为 标准差（standard error ） ，记作
SE(^)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
112 第五章 机器学习基础
估计量的方差或 标准差告诉我们，当独立地从潜在的数据生成过程中重采样数
据集时，如何期望估计的变化。正如我们希望估计的偏差较小，我们也希望其方差
较小。
当我们使用有限的样本计算任何统计量时，真实参数的估计都是不确定的，在
这个意义下，从相同的分布得到其他样本时，它们的统计量也会不一样。任何方差
估计量的期望程度是我们想量化的误差的来源。
均值的标准差被记作
SE(^m) =vuutVar[
1
mm∑
i=1x(i)]
=pm; (5.46)
其中 2是样本 x(i)的真实方差。 标准差通常被记作 。可惜，样本方差的平方根和
方差无偏估计的平方根都不是 标准差的无偏估计。这两种计算方法都倾向于低估真
实的标准差，但仍用于实际中。相较而言，方差无偏估计的平方根较少被低估。对于
较大的 m，这种近似非常合理。
均值的标准差在机器学习 实验中非常有用。我们通常用 测试集样本的误差均值
来估计泛化误差。 测试集中样本的数量决定了这个估计的精确度。中心极限定理告
诉我们均值会接近一个高斯分布，我们可以用 标准差计算出真实期望落在选定区间
的概率。例如，以均值 ^m为中心的 95%置信区间是
(^m 1:96SE(^m);^m+ 1:96SE(^m)); (5.47)
以上区间是基于均值 ^m和方差 SE(^m)2的高斯分布。在 机器学习 实验中，我们通
常说算法 A比算法 B好，是指算法 A的误差的 95%置信区间的上界小于算法 B
的误差的 95%置信区间的下界。
示例： 伯努利分布 我们再次考虑从伯努利分布（回顾 P(x(i);) =x(i)(1 )1 x(i)）
中独立同分布采样出来的一组 样本fx(1); : : : ; x(m)g。这次我们关注估计 ^m=DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.4估计、偏差和方差 113
1
m∑m
i=1x(i)的方差：
Var(
^m)
=Var(
1
mm∑
i=1x(i))
(5.48)
=1
m2m∑
i=1Var(
x(i))
(5.49)
=1
m2m∑
i=1(1 ) (5.50)
=1
m2m(1 ) (5.51)
=1
m(1 ) (5.52)
估计量方差的下降速率是关于 数据集样本数目 m的函数。这是常见估计量的普遍性
质，在探讨一致性（参考第 5.4.5节）时，我们会继续讨论。
5.4.4权衡偏差和方差以最小化均方误差
偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函数或参
数的误差期望。而方差度量着数据上任意特定采样可能导致的估计期望的偏差。
当我们可以在一个偏差更大的估计和一个方差更大的估计中进行选择时，会发
生什么呢？我们该如何选择？例如，想象我们希望近似图 5.2中的函数，我们只可以
选择一个偏差较大的估计或一个方差较大的估计，我们该如何选择呢？
判断这种权衡最常用的方法是交叉验证。经验上，交叉验证在真实世界的许多任
务中都非常成功。另外，我们也可以比较这些估计的 均方误差 （mean squared error ,
MSE） ：
MSE =E[(^m )2] (5.53)
=Bias(^m)2+Var(^m) (5.54)
MSE度量着估计和真实参数 之间平方误差的总体期望偏差。如式 (5.54)所示，
MSE估计包含了偏差和方差。理想的估计具有较小的 MSE或是在检查中会稍微约
束它们的偏差和方差。
偏差和方差的关系和 机器学习 容量、 欠拟合和过拟合的概念紧密相联。 用 MSE度
量泛化误差（偏差和方差对于泛化误差都是有意义的）时，增加容量会增加方差，降DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
114 第五章 机器学习基础
低偏差。如图 5.6所示，我们再次在关于容量的函数中，看到泛化误差的 U形曲线。
CapacityBiasGeneralizationerrorVarianceOptimalcapacityOverﬁtting zoneUnderﬁtting zone
图5.6:当容量增大（ x轴）时， 偏差（用点表示）随之减小，而方差（虚线）随之增大，使得 泛
化误差（加粗曲线）产生了另一种 U形。如果我们沿着轴改变 容量，会发现 最佳容量 ，当容量小
于最佳容量 会呈现欠拟合，大于时导致 过拟合。这种关系与第 5.2节以及图 5.3中讨论的 容量、欠
拟合和过拟合之间的关系类似。
5.4.5一致性
目前我们已经探讨了固定大小训练集下不同 估计量的性质。通常，我们也会关
注训练数据增多后 估计量的效果。特别地，我们希望当 数据集中数据点的数量 m增
加时，点估计会收敛到对应参数的真实值。更形式地，我们想要
plimm!1^m=: (5.55)
符号 plim表示依概率收敛，即对于任意的 ϵ >0，当 m!1时，有 P(j^m j>
ϵ)!0。式 (5.55)表示的条件被称为 一致性（consistency ） 。有时它是指弱一致性，
强一致性是指 几乎必然 （almost sure ）从 ^收敛到 。几乎必然收敛 （almost sure
convergence ）是指当 p(limm!1 x(m)= x) = 1时，随机变量序列 x(1)，x(2)，: : :收
敛到 x。
一致性保证了 估计量的偏差会随数据 样本数目的增多而减少。然而，反过来是
不正确的——渐近无偏并不意味着一致性。例如，考虑用包含 m个样本的 数据集
fx(1); : : : ; x(m)g估计正态分布N(x;; 2)的均值参数 。我们可以使用 数据集的第DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.5最大似然估计 115
一个样本 x(1)作为无偏估计量： ^=x(1)。在该情况下， E(^m) =，所以不管观测
到多少数据点，该 估计量都是无偏的。然而，这不是一个一致估计，因为它 不满足当
m!1时， ^m!。
5.5最大似然估计
之前，我们已经看过常用估计的定义，并分析了它们的性质。但是这些估计是
从哪里来的呢？我们希望有些准则可以让我们从不同模型中得到特定函数作为好的
估计，而不是猜测某些函数可能是好的估计，然后分析其偏差和方差。
最常用的准则是 最大似然估计 。
考虑一组含有 m个样本的数据集 X=fx(1); : : : ; x(m)g，独立地由未知的真实数
据生成分布 pdata(x)生成。
令pmodel (x;)是一族由确定在相同空间上的概率分布。换言之， pmodel (x;)
将任意输入 x映射到实数来估计真实概率 pdata(x)。
对的最大似然估计被定义为：
ML= arg max
pmodel (X;); (5.56)
= arg max
m∏
i=1pmodel (x(i);): (5.57)
多个概率的乘积会因很多原因不便于计算。例如，计算中很可能会出现数值
下溢。为了得到一个便于计算的等价优化问题，我们观察到似然对数不会改变其
arg max 但是将乘积转化成了便于计算的求和形式：
ML= arg max
m∑
i=1logpmodel (x(i);): (5.58)
因为当我们重新缩放 代价函数 时 arg max 不会改变，我们可以除以 m得到和训练数
据经验分布 ^pdata相关的期望作为准则：
ML= arg max
Ex^pdata logpmodel (x;): (5.59)
一种解释 最大似然估计 的观点是将它看作最小化训练集上的经验分布 ^pdata和模DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
116 第五章 机器学习基础
型分布之间的差异，两者之间的差异程度可以通过 KL散度度量。 KL散度被定义为
DKL(^pdata∥pmodel ) =Ex^pdata[log^pdata(x) logpmodel (x)]: (5.60)
左边一项仅涉及到数据生成过程，和模型无关。这意味着当我们训练模型最小化 KL
散度时，我们只需要最小化
 Ex^pdata[logpmodel (x)]; (5.61)
当然，这和式 (5.59)中最大化是相同的。
最小化 KL散度其实就是在最小化分布之间的 交叉熵。许多作者使用术语 “交
叉熵’’特定表示伯努利或 softmax 分布的负对数似然，但那是用词不当的。任何一
个由负对数似然组成的 损失都是定义在训练集上的经验分布和定义在模型上的概率
分布之间的 交叉熵。例如， 均方误差 是经验分布和高斯模型之间的 交叉熵。
我们可以将最大似然看作是使模型分布尽可能地和经验分布 ^pdata相匹配的尝
试。理想情况下，我们希望匹配真实的数据生成分布 pdata，但我们没法直接知道这
个分布。
虽然最优在最大化似然或是最小化 KL散度时是相同的，但目标函数值是不
一样的。在软件中，我们通常将两者都称为最小化 代价函数 。因此最大化似然变成
了最小化负对数似然（ NLL)，或者等价的是最小化交叉熵。将最大化似然看作最小
化KL散度的视角在这个情况下是有帮助的，因为已知 KL散度最小值是零。当 x
取实数时，负对数似然是负值。
5.5.1条件对数似然和均方误差
最大似然估计 很容易扩展到估计条件概率 P(yjx;)，从而给定 x预测 y。实
际上这是最常见的情况，因为这构成了大多数 监督学习 的基础。如果 X表示所有的
输入， Y表示我们观测到的 目标，那么条件 最大似然估计 是
ML= arg max
P(YjX;): (5.62)
如果假设 样本是独立同分布的，那么这可以分解成
ML= arg max
m∑
i=1logP(y(i)jx(i);): (5.63)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.5最大似然估计 117
示例：线性回归 作为最大似然 第5.1.4节介绍的 线性回归 ，可以被看作是最大似然
过程。之前，我们将 线性回归 作为学习从输入 x映射到输出 ^y的算法。从 x到^y的
映射选自最小化 均方误差 （我们或多或少介绍的一个标准） 。现在，我们以 最大似然
估计的角度重新审视 线性回归 。我们现在希望模型能够得到条件概率 p(yjx)，而不
只是得到一个单独的预测 ^y。想象有一个无限大的训练集，我们可能会观测到几个训
练样本有相同的输入 x但是不同的 y。现在学习算法的目标是拟合分布 p(yjx)到和
x相匹配的不同的 y。为了得到我们之前推导出的相同的 线性回归 算法，我们定义
p(yjx) =N(y; ^y(x;w); 2)。函数 ^y(x;w)预测高斯的均值。在这个例子中，我们假
设方差是用户固定的某个常量 2。这种函数形式 p(yjx)会使得最大似然估计 得出
和之前相同的学习算法。由于假设 样本是独立同分布的，条件对数似然（式 (5.63)）
如下
m∑
i=1logp(y(i)jx(i);) (5.64)
= mlog m
2log(2) m∑
i=1^y(i) y(i)2
22; (5.65)
其中 ^y(i)是线性回归 在第 i个输入 x(i)上的输出， m是训练样本的数目。对比于 均
方误差的对数似然，
MSE train=1
mm∑
i=1^y(i) y(i)2; (5.66)
我们立刻可以看出最大化关于 w的对数似然和最小化 均方误差 会得到相同的参数估
计 w。但是对于相同的最优 w，这两个准则有着不同的值。这验证了 MSE可以用
于最大似然估计 。正如我们将看到的， 最大似然估计 有几个理想的性质。
5.5.2最大似然的性质
最大似然估计 最吸引人的地方在于，它被证明当 样本数目 m!1时，就收敛
率而言是最好的渐近估计。
在合适的条件下， 最大似然估计 具有一致性（参考第 5.4.5节） ，意味着训练 样
本数目趋向于无穷大时，参数的 最大似然估计 会收敛到参数的真实值。这些条件是：
•真实分布 pdata必须在模型族 pmodel (;)中。否则，没有估计可以还原 pdata。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
118 第五章 机器学习基础
•真实分布 pdata必须刚好对应一个 值。否则， 最大似然估计 恢复出真实分布
pdata后，也不能决定数据生成过程使用哪个 。
除了最大似然估计 ，还有其他的归纳准则，其中许多共享一致估计的性质。然
而，一致估计的 统计效率 （statistic eﬃciency ）可能区别很大。某些一致估计可能会
在固定数目的样本上获得一个较低的泛化误差，或者等价地，可能只需要较少的 样
本就能达到一个固定程度的泛化误差。
统计效率通常用于 有参情况 （parametric case ）的研究中（例如 线性回归 ） 。有
参情况中我们的目标是估计参数值（假设有可能确定真实参数） ，而不是函数值。一
种度量我们和真实参数相差多少的方法是计算 均方误差 的期望，即计算 m个从数据
生成分布中出来的训练 样本上的估计参数和真实参数之间差值的平方。有参 均方误
差估计随着 m的增加而减少，当 m较大时， Cramér-Rao 下界 (Rao,1945;Cramér ,
1946)表明不存在 均方误差 低于最大似然估计 的一致估计。
因为这些原因（一致性和统计效率） ，最大似然通常是 机器学习 中的首选估计。
当样本数目小到会发生过拟合时， 正则化策略如权重衰减可用于获得训练数据有限
时方差较小的最大似然有偏版本。
5.6贝叶斯统计
至此我们已经讨论了 频率派统计 （frequentist statistics ）方法和基于估计单一
值的方法，然后基于该估计作所有的预测。另一种方法是在做预测时会考虑所有
可能的。后者属于 贝叶斯统计 （Bayesian statistics ）的范畴。
正如第 5.4.1节中讨论的，频率派的视角是真实参数 是未知的定值，而点估计
^是考虑数据集上函数（可以看作是随机的）的随机变量。
贝叶斯统计的视角完全不同。贝叶斯用概率反映知识状态的确定性程度。 数据
集能够被直接观测到，因此不是随机的。另一方面，真实参数 是未知或不确定的，
因此可以表示成随机变量。
在观察到数据前，我们将 的已知知识表示成 先验概率分布 （prior probability
distribution ） ，p()（有时简单地称为 ‘‘先验’’） 。一般而言， 机器学习 实践者会选择
一个相当宽泛的（即，高熵的）先验分布，反映在观测到任何数据前参数 的高度
不确定性。例如，我们可能会假设先验 在有限区间中均匀分布。许多先验偏好于DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.6贝叶斯统计 119
‘‘更简单 ’’的解（如小幅度的系数，或是接近常数的函数） 。
现在假设我们有一组数据样本 fx(1); : : : ; x(m)g。通过贝叶斯规则 结合数据似然
p(x(1); : : : ; x(m)j)和先验，我们可以恢复数据对我们关于 信念的影响：
p(jx(1); : : : ; x(m)) =p(x(1); : : : ; x(m)j)p()
p(x(1); : : : ; x(m))(5.67)
在贝叶斯估计常用的情景下，先验开始是相对均匀的分布或高熵的高斯分布，观测
数据通常会使后验的熵下降，并集中在参数的几个可能性很高的值。
相对于最大似然估计 ，贝叶斯估计有两个重要区别。第一，不像最大似然方法预
测时使用的点估计，贝叶斯方法使用 的全分布。例如，在观测到 m个样本后，
下一个数据 样本 x(m+1)的预测分布如下：
p(x(m+1)jx(1); : : : ; x(m)) =∫
p(x(m+1)j)p(jx(1); : : : ; x(m))d: (5.68)
这里，每个具有正概率密度的 的值有助于下一个 样本的预测，其中贡献由后验密
度本身加权。在观测到 数据集fx(1); : : : ; x(m)g之后，如果我们仍然非常不确定 的
值，那么这个不确定性会直接包含在我们所做的任何预测中。
在第 5.4节中，我们已经探讨频率派方法解决给定点估计 的不确定性的方法
是评估方差，估计的方差评估了观测数据重新从观测数据中采样后，估计可能如何
变化。对于如何处理估计不确定性的这个问题，贝叶斯派的答案是积分，这往往会
防止过拟合。当然，积分仅仅是概率法则的应用，使贝叶斯方法容易验证，而频率
派机器学习 基于相当特别的决定构建了一个估计，将 数据集里的所有信息归纳到一
个单独的点估计。
贝叶斯方法和最大似然方法的第二个最大区别是由贝叶斯先验分布造成的。先
验能够影响概率质量密度朝参数空间中偏好先验的区域偏移。实践中，先验通常表
现为偏好更简单或更光滑的模型。对贝叶斯方法的批判认为先验是人为主观判断影
响预测的来源。
当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练 样本数目很大
时，通常会有很大的计算 代价。
示例：贝叶斯 线性回归 我们使用贝叶斯估计方法学习 线性回归 的参数。在 线性回
归中，我们学习从输入向量 x2Rn预测标量 y2R的线性映射。该预测由向量DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
120 第五章 机器学习基础
w2Rn参数化：
^y= w⊤x: (5.69)
给定一组 m个训练样本 (X(train );y(train ))，我们可以表示整个训练集对 y的预测：
^y(train )= X(train )w: (5.70)
表示为 y(train )上的高斯条件分布，我们得到
p(y(train )jX(train );w) =N(y(train );X(train )w;I) (5.71)
/ exp(
 1
2(y(train ) X(train )w)⊤(y(train ) X(train )w))
;
(5.72)
其中，我们根据标准的 MSE公式假设 y上的高斯方差为 1。在下文中，为减少符号
负担，我们将 (X(train );y(train ))简单表示为 (X;y)。
为确定模型参数向量 w的后验分布，我们首先需要指定一个先验分布。先验应
该反映我们对这些参数取值的信念。虽然有时将我们的先验信念表示为模型的参数
很难或很不自然，但在实践中我们通常假设一个相当广泛的分布来表示 的高度不
确定性。实数值参数通常使用高斯作为先验分布：
p(w) =N(w;0;0)/ exp(
 1
2(w 0)⊤ 1
0(w 0))
; (5.73)
其中，0和0分别是先验分布的均值向量和协方差矩阵。1
确定好先验后，我们现在可以继续确定模型参数的 后验分布。
p(wjX;y)/p(yjX;w)p(w) (5.74)
/ exp(
 1
2(y Xw)⊤(y Xw))
exp(
 1
2(w 0)⊤ 1
0(w 0))
(5.75)
/ exp(1
2(
 2y⊤Xw+w⊤X⊤Xw+w⊤ 1
0w 2⊤
0 1
0w))
:(5.76)
现在我们定义 m= ( X⊤X+ 1
0) 1和m=m(X⊤y+ 1
00)。使用这些新的
1除非有理由使用协方差矩阵的特定结构，我们通常假设其为对角协方差矩阵 0=diag(0)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.6贝叶斯统计 121
变量，我们发现后验可改写为高斯分布：
p(wjX;y)/ exp(
 1
2(w m)⊤ 1
m(w m) +1
2⊤
m 1
mm)
(5.77)
/ exp(
 1
2(w m)⊤ 1
m(w m))
: (5.78)
所有不包括的参数向量 w的项都已经被删去了；它们意味着分布的积分必须归一这
个事实。式 (3.23)显示了如何标准化多元高斯分布。
检查此后验分布可以让我们获得 贝叶斯推断 效果的一些直觉。大多数情况下，
我们设置0= 0。如果我们设置 0=1
I，那么 m对 w的估计就和频率派带权重
衰减惩罚 w⊤w的线性回归 的估计是一样的。一个区别是若 设为 0则贝叶斯估
计是未定义的——我们不能将贝叶斯学习过程初始化为一个无限宽的 w先验。更重
要的区别是贝叶斯估计会给出一个协方差矩阵，表示 w所有不同值的可能范围，而
不仅是估计 m。
5.6.1最大后验 (MAP )估计
原则上，我们应该使用参数 的完整贝叶斯后验分布进行预测，但单点估计
常常也是需要的。希望使用点估计的一个常见原因是，对于大多数有意义的模型而
言，大多数涉及到贝叶斯后验的计算是非常棘手的，点估计提供了一个可行的近似
解。我们仍然可以让先验影响点估计的选择来利用贝叶斯方法的优点，而不是简单
地回到最大似然估计 。一种能够做到这一点的合理方式是选择 最大后验 （Maximum
A Posteriori ,MAP）点估计。 MAP估计选择后验概率最大的点（或在 是连续值
的更常见情况下，概率密度最大的点） ：
MAP = arg max
p(jx) = arg max
logp(xj) + logp(): (5.79)
我们可以认出上式右边的 logp(xj)对应着标准的对数似然项， logp()对应着先
验分布。
例如，考虑具有高斯先验权重 w的线性回归 模型。如果先验是 N(w;0;1
I2)，
那么式 (5.79)的对数先验项正比于熟悉的权重衰减惩罚 w⊤w，加上一个不依赖于
w也不会影响学习过程的项。因此，具有高斯先验权重的 MAP贝叶斯推断 对应着权
重衰减。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
122 第五章 机器学习基础
正如全贝叶斯推断 ，MAP贝叶斯推断 的优势是能够利用来自先验的信息，这些
信息无法从训练数据中获得。该附加信息有助于减少 最大后验 点估计的方差（相比
于ML估计） 。然而，这个优点的代价是增加了偏差。
许多正规化估计方法，例如权重衰减 正则化的最大似然学习，可以被解释为 贝
叶斯推断 的MAP近似。这个适应于 正则化时加到目标函数的附加项对应着 logp()。
并非所有的正则化惩罚都对应着 MAP贝叶斯推断 。例如，有些 正则化项 可能不是一
个概率分布的对数。还有些 正则化项 依赖于数据，当然也不会是一个先验概率分布。
MAP贝叶斯推断 提供了一个直观的方法来设计复杂但可解释的 正则化项 。例
如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一个单独的高斯
分布 (Nowlan and Hinton ,1992)。
5.7监督学习算法
回顾第 5.1.3节，粗略地说， 监督学习 算法是给定一组输入 x和输出 y的训练
集，学习如何关联输入和输出。在许多情况下，输出 y很难自动收集，必须由人来
提供 ‘‘监督’’，不过该术语仍然适用于训练集目标可以被自动收集的情况。
5.7.1概率监督学习
本书的大部分 监督学习 算法都是基于估计概率分布 p(yjx)的。我们可以使用 最
大似然估计 找到对于有参分布族 p(yjx;)最好的参数向量 。
我们已经看到， 线性回归 对应于分布族
p(yjx;) =N(y;⊤x;I): (5.80)
通过定义一族不同的概率分布，我们可以将 线性回归 扩展到分类情况中。如果我们
有两个类，类 0和类 1，那么我们只需要指定这两类之一的概率。类 1的概率决定
了类 0的概率，因为这两个值加起来必须等于 1。
我们用于 线性回归 的实数正态分布是用均值参数化的。我们提供这个均值的任
何值都是有效的。二元变量上的的分布稍微复杂些，因为它的均值必须始终在 0和
1之间。解决这个问题的一种方法是使用 logistic sigmoid 函数将线性函数的输出压DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.7监督学习算法 123
缩进区间 (0;1)。该值可以解释为概率：
p(y= 1jx;) =(⊤x): (5.81)
这个方法被称为 逻辑回归 （logistic regression ） ，这个名字有点奇怪，因为该模型用
于分类而非回归。
线性回归 中，我们能够通过求解正规方程以找到最佳权重。相比而言，逻辑回
归会更困难些。其最佳权重没有闭解。反之，我们必须最大化对数似然来搜索最优
解。我们可以通过 梯度下降 算法最小化负对数似然来搜索。
通过确定正确的输入和输出变量上的有参条件概率分布族，相同的策略基本上
可以用于任何 监督学习 问题。
5.7.2支持向量机
支持向量机 （support vector machine ,SVM）是监督学习 中最有影响力的方法
之一 (Boser et al. ,1992;Cortes and Vapnik ,1995)。类似于逻辑回归，这个模型也
是基于线性函数 w⊤x+b的。不同于逻辑回归的是，支持向量机不输出概率，只输
出类别。当 w⊤x+b为正时， 支持向量机 预测属于正类。类似地，当 w⊤x+b为负
时，支持向量机 预测属于负类。
支持向量机 的一个重要创新是 核技巧（kernel trick ） 。核技巧观察到许多 机器学
习算法都可以写成 样本间点积的形式。例如， 支持向量机 中的线性函数可以重写为
w⊤x+b=b+m∑
i=1ix⊤x(i); (5.82)
其中， x(i)是训练样本，是系数向量。学习算法重写为这种形式允许我们将 x替
换为特征函数 ϕ(x)的输出， 点积替换为被称为 核函数（kernel function ）的函数
k(x;x(i)) =ϕ(x)ϕ(x(i))。运算符表示类似于 ϕ(x)⊤ϕ(x(i))的点积。对于某些 特
征空间，我们可能不会书面地使用向量 内积。在某些无限维空间中，我们需要使用
其他类型的 内积，如基于积分而非加和的 内积。这种类型 内积的完整介绍超出了本
书的范围。
使用核估计替换 点积之后，我们可以使用如下函数进行预测
f(x) =b+∑
iik(x;x(i)): (5.83)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
124 第五章 机器学习基础
这个函数关于 x是非线性的，关于 ϕ(x)是线性的。和f(x)之间的关系也是线性
的。核函数完全等价于用 ϕ(x)预处理所有的输入，然后在新的转换空间学习线性模
型。
核技巧十分强大有两个原因。首先，它使我们能够使用保证有效收敛的凸优化
技术来学习非线性模型（关于 x的函数） 。这是可能的，因为我们可以认为 ϕ是固
定的，仅优化 ，即优化算法可以将决策函数视为不同空间中的线性函数。其二，核
函数 k的实现方法通常有比直接构建 ϕ(x)再算点积高效很多。
在某些情况下， ϕ(x)甚至可以是无限维的，对于普通的显式方法而言，这将是
无限的计算代价。在很多情况下，即使 ϕ(x)是难算的， k(x;x′)却会是一个关于 x
非线性的、易算的函数。举个无限维空间易算的核的例子，我们构建一个作用于非
负整数 x上的特征映射 ϕ(x)。假设这个映射返回一个由开头 x个1，随后是无限个
0的向量。我们可以写一个核函数 k(x; x(i)) = min(x; x(i))，完全等价于对应的无限
维点积。
最常用的核函数是 高斯核（Gaussian kernel ） ，
k(u;v) =N(u v;0; 2I); (5.84)
其中N(x;;)是标准正态密度。这个核也被称为 径向基函数 （radial basis func-
tion,RBF）核，因为其值沿 v中从 u向外辐射的方向减小。高斯核对应于无限维空
间中的点积，但是该空间的推导没有整数上最小核的示例那么直观。
我们可以认为高斯核在执行一种 模板匹配 (template matching) 。训练标签 y相
关的训练 样本 x变成了类别 y的模版。当测试点 x′到 x的欧几里得距离很小，对
应的高斯核响应很大时，表明 x′和模版 x非常相似。该模型进而会赋予相对应的训
练标签 y较大的权重。总的来说，预测将会组合很多这种通过训练样本相似度加权
的训练标签。
支持向量机 不是唯一可以使用 核技巧来增强的算法。许多其他的线性模型也
可以通过这种方式来增强。使用 核技巧的算法类别被称为 核机器（kernel machine ）
或核方法（kernel method ）(Williams and Rasmussen ,1996;Schölkopf et al. ,1999)。
核机器的一个主要缺点是计算决策函数的成本关于训练 样本的数目是线性的。
因为第 i个样本贡献 ik(x;x(i))到决策函数。 支持向量机 能够通过学习主要包含零
的向量，以缓和这个缺点。那么判断新 样本的类别仅需要计算非零 i对应的训
练样本的核函数。这些训练 样本被称为支持向量 （support vector ） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.7监督学习算法 125
当数据集很大时， 核机器的计算量也会很大。我们将会在第 5.9节回顾这个想
法。带通用核的核机器致力于泛化得更好。我们将在第 5.11节解释原因。现代 深
度学习的设计旨在克服核机器的这些限制。当前 深度学习 的复兴始于 Hinton et al.
(2006b )表明神经网络能够在 MNIST基准数据上胜过 RBF核的支持向量机 。
5.7.3其他简单的监督学习算法
我们已经简要介绍过另一个非概率 监督学习 算法，最近邻回归。更一般地， k-最
近邻是一类可用于分类或回归的技术。作为一个非参数学习算法， k-最近邻并不局
限于固定数目的参数。我们通常认为 k-最近邻算法没有任何参数，而是使用训练数
据的简单函数。事实上，它甚至也没有一个真正的训练阶段或学习过程。反之，在
测试阶段我们希望在新的测试输入 x上产生 y，我们需要在训练数据 X上找到 x的
k-最近邻。然后我们返回训练集上对应的 y值的平均值。这几乎适用于任何类型可
以确定 y值平均值的 监督学习 。在分类情况中，我们可以关于 one-hot编码向量 c
求平均，其中 cy= 1，其他的 i值取 ci= 0。然后，我们可以解释这些 one-hot编码
的均值为类别的概率分布。作为一个非参数学习算法， k-近邻能达到非常高的容量。
例如，假设我们有一个用 0-1误差度量性能的多分类任务。在此设定中，当训练 样
本数目趋向于无穷大时， 1-最近邻收敛到两倍贝叶斯误差。超出贝叶斯误差的原因
是它会随机从等距离的临近点中随机挑一个。而存在无限的训练数据时，所有测试
点 x周围距离为零的邻近点有无限多个。如果我们使用所有这些临近点投票的决策
方式，而不是随机挑选一个，那么该过程将会收敛到贝叶斯错误率。 k-最近邻的高容
量使其在训练 样本数目大时能够获取较高的精度。然而，它的计算成本很高，另外
在训练集较小时泛化能力很差。 k-最近邻的一个弱点是它不能学习出哪一个 特征比
其他更具识别力。例如，假设我们要处理一个的回归任务，其中 x2R100是从各向
同性的高斯分布中抽取的，但是只有一个变量 x1和结果相关。进一步假设该 特征直
接决定了输出，即在所有情况中 y=x1。最近邻回归 不能检测到这个简单模式。大
多数点 x的最近邻将取决于 x2到x100的大多数 特征，而不是单独取决于 特征 x1。
因此，小训练集上的输出将会非常随机。
决策树（decision tree ）及其变种是另一类将输入空间分成不同的区域，每个区
域有独立参数的算法 (Breiman et al. ,1984)。如图 5.7所示，决策树的每个节点都与
输入空间的一个区域相关联，并且内部节点继续将区域分成子节点下的子区域（通
常使用坐标轴拆分区域） 。空间由此细分成不重叠的区域，叶节点和输入区域之间形DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
126 第五章 机器学习基础
成一一对应的关系。每个叶结点将其输入区域的每个点映射到相同的输出。决策树
通常有特定的训练算法，超出了本书的范围。如果允许学习任意大小的决策树，那
么它可以被视作非参数算法。然而实践中通常有大小限制，作为 正则化项 将其转变
成有参模型。由于决策树通常使用坐标轴相关的拆分，并且每个子节点关联到常数
输出，因此有时解决一些对于逻辑回归很简单的问题很费力。例如，假设有一个二
分类问题，当 x2> x 1时分为正类，则决策树的分界不是坐标轴对齐的。因此，决策
树将需要许多节点近似决策边界，坐标轴对齐使其算法步骤不断地来回穿梭于真正
的决策函数。
正如我们已经看到的，最近邻预测和决策树都有很多的局限性。尽管如此，在
计算资源受限制时，它们都是很有用的学习算法。通过思考复杂算法和 k-最近邻或
决策树之间的相似性和差异，我们可以建立对更复杂学习算法的直觉。
读者可以参考 Murphy (2012);Bishop (2006);Hastie et al. (2001)或其他机器
学习教科书了解更多的传统 监督学习 算法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.7监督学习算法 127
0101
11101
011
1111111011010010001110111111010010001001111111
11
图5.7:描述一个 决策树如何工作的示意图。 (上)树中每个节点都选择将输入样本送到左子节点
(0)或者右子节点 (1)。内部的节点用圆圈表示，叶节点用方块表示。每一个节点可以用一个二值的
字符串识别并对应树中的位置，这个字符串是通过给起父亲节点的字符串添加一个位元来实现的
（0表示选择左或者上， 1表示选择右或者下） 。 (下)这个树将空间分为区域。这个二维平面说明 决
策树可以分割 R2。这个平面中画出了树的节点，每个内部点穿过分割线并用来给样本分类，叶节
点画在样本所属区域的中心。结果是一个分块常数函数，每一个叶节点一个区域。每个叶需要至
少一个训练样本来定义，所以 决策树不可能用来学习一个 局部极大值 比训练样本数量还多的函数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
128 第五章 机器学习基础
5.8无监督学习算法
回顾第 5.1.3节，无监督算法只处理 “特征’’，不操作监督信号。监督和无监督
算法之间的区别没有规范严格的定义，因为没有客观的判断来区分监督者提供的值
是特征还是目标。通俗地说， 无监督学习 的大多数尝试是指从不需要人为注释的 样
本的分布中抽取信息。该术语通常与密度估计相关，学习从分布中采样、学习从分
布中去噪、寻找数据分布的流形或是将数据中相关的 样本聚类。
一个经典的 无监督学习 任务是找到数据的 ‘‘最佳’’表示。 ‘‘最佳’’可以是不同的
表示，但是一般来说，是指该表示在比本身表示的信息 更简单或更易访问而受到一
些惩罚或限制的情况下，尽可能地保存关于 x更多的信息。
有很多方式定义较简单的表示。最常见的三种包括低维表示、稀疏表示和独立
表示。低维表示尝试将 x中的信息尽可能压缩在一个较小的表示中。稀疏表示将 数
据集嵌入到输入项大多数为零的表示中 (Barlow ,1989;Olshausen and Field ,1996;
Hinton and Ghahramani ,1997)。稀疏表示通常用于需要增加表示维数的情况，使得
大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布
在表示空间的坐标轴上。独立表示试图 分开数据分布中变化的来源，使得表示的维
度是统计独立的。
当然这三个标准并非相互排斥的。低维表示通常会产生比原始的高维数据具有
较少或较弱依赖关系的元素。这是因为减少表示大小的一种方式是找到并消除冗余。
识别并去除更多的冗余使得降维算法在丢失更少信息的同时显现更大的压缩。
表示的概念是 深度学习 核心主题之一，因此也是本书的核心主题之一。本节会
介绍表示学习算法中的一些简单示例。总的来说，这些示例算法会说明如何实施上
面的三个标准。剩余的大部分章节会介绍额外的表示学习算法，它们以不同方式处
理这三个标准或是引入其他标准。
5.8.1主成分分析
在第 2.12节中，我们看到 PCA算法提供了一种压缩数据的方式。我们也可以
将PCA视为学习数据表示的 无监督学习 算法。这种表示基于上述简单表示的两个标
准。 PCA学习一种比原始输入维数更低的表示。它也学习了一种元素之间彼此没有
线性相关的表示。这是学习表示中元素统计独立标准的第一步。要实现完全独立性，
表示学习算法也必须去掉变量间的非线性关系。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.8无监督学习算法 129
如图 5.8所示， PCA将输入 x投影表示成 z，学习数据的正交线性变换。在
第2.12节中，我们看到了如何学习重建原始数据的最佳一维表示（就 均方误差 而
言） ，这种表示其实对应着数据的第一个主要成分。因此，我们可以用 PCA作为保
留数据尽可能多信息的降维方法（再次就最小重构误差平方而言） 。在下文中，我们
将研究 PCA表示如何使原始数据表示 X去相关的 .
 20 10 0 10 20
x1 20 1001020x2
 20 10 0 10 20
z1 20 1001020z2
图5.8: PCA学习一种线性投影，使最大方差的方向和新空间的轴对齐。 (左)原始数据包含了 x
的样本。在这个空间中，方差的方向与轴的方向并不是对齐的。 (右)变换过的数据 z= x⊤W在
轴z1的方向上有最大的变化。第二大变化方差的方向沿着轴 z2。
假设有一个 mn的设计矩阵 X，数据的均值为零， E[x] = 0。若非如此，通
过预处理步骤使所有 样本减去均值，数据可以很容易地中心化。
X对应的无偏样本协方差矩阵给定如下
Var[x] =1
m 1X⊤X: (5.85)
PCA通过线性变换找到一个 Var[z]是对角矩阵的表示 z= W⊤x。
在第 2.12节，我们已知 设计矩阵 X的主成分由 X⊤X的特征向量给定。从这个
角度，我们有
X⊤X= WW⊤: (5.86)
本节中，我们会探索主成分的另一种推导。主成分也可以通过奇异值分解 (SVD)得
到。具体来说，它们是 X的右奇异向量。为了说明这点，假设 W是奇异值分解
X= UW⊤的右奇异向量。以 W作为特征向量基，我们可以得到原来的特征向量DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
130 第五章 机器学习基础
方程：
X⊤X=(
UW⊤)⊤UW⊤= W2W⊤: (5.87)
SVD有助于说明 PCA后的 Var[z]是对角的。使用 X的SVD分解， X的方差
可以表示为
Var[x] =1
m 1X⊤X (5.88)
=1
m 1(
UW⊤)⊤UW⊤(5.89)
=1
m 1W⊤U⊤UW⊤(5.90)
=1
m 1W2W⊤; (5.91)
其中，我们使用 U⊤U= I，因为根据奇异值的定义矩阵 U是正交的。这表明 z的
协方差满足对角的要求：
Var[z] =1
m 1Z⊤Z (5.92)
=1
m 1W⊤X⊤X⊤W (5.93)
=1
m 1W⊤W2W⊤W (5.94)
=1
m 12; (5.95)
其中，再次使用 SVD的定义有 W⊤W= I。
以上分析指明当我们通过线性变换 W将数据 x投影到 z时，得到的数据表示
的协方差矩阵是对角的（即 2） ，立刻可得 z中的元素是彼此无关的。
PCA这种将数据变换为元素之间彼此不相关表示的能力是 PCA的一个重要性
质。它是 消除数据中未知变化因素 的简单表示示例。在 PCA中，这个消除是通过寻
找输入空间的一个旋转（由 W确定） ，使得方差的主坐标和 z相关的新表示空间的
基对齐。
虽然相关性是数据元素间依赖关系的一个重要范畴，但我们对于能够消除更复
杂形式的 特征依赖的表示学习也很感兴趣。对此，我们需要比简单线性变换更强的
工具。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.8无监督学习算法 131
5.8.2 k-均值聚类
另外一个简单的表示学习算法是 k-均值聚类。 k-均值聚类算法将训练集分成 k
个靠近彼此的不同 样本聚类。因此我们可以认为该算法提供了 k-维的 one-hot编码
向量 h以表示输入 x。当 x属于聚类 i时，有 hi= 1，h的其他项为零。
k-均值聚类提供的 one-hot编码也是一种稀疏表示，因为每个输入的表示中大
部分元素为零。之后，我们会介绍能够学习更灵活的稀疏表示的一些其他算法（表
示中每个输入 x不只一个非零项） 。 one-hot编码是稀疏表示的一个极端示例，丢失
了很多分布式表示的优点。 one-hot编码仍然有一些统计优点（自然地传达了相同聚
类中的样本彼此相似的观点） ，也具有计算上的优势，因为整个表示可以用一个单独
的整数表示。
k-均值聚类初始化 k个不同的中心点f(1); : : : ;(k)g，然后迭代交换两个不同
的步骤直到收敛。步骤一，每个训练 样本分配到最近的中心点 (i)所代表的聚类 i。
步骤二，每一个中心点 (i)更新为聚类 i中所有训练 样本 x(j)的均值。
关于聚类的一个问题是聚类问题本身是病态的。这是说没有单一的标准去度量
聚类的数据在真实世界中效果如何。我们可以度量聚类的性质，例如类中元素到类
中心点的欧几里得距离的均值。这使我们可以判断从聚类分配中重建训练数据的效
果如何。然而我们不知道聚类的性质是否很好地对应到真实世界的性质。此外，可
能有许多不同的聚类都能很好地对应到现实世界的某些属性。我们可能希望找到和
一个特征相关的聚类，但是得到了一个和任务无关的，同样是合理的不同聚类。例
如，假设我们在包含红色卡车图片、红色汽车图片、灰色卡车图片和灰色汽车图片
的数据集上运行两个聚类算法。如果每个聚类算法聚两类，那么可能一个算法将汽
车和卡车各聚一类，另一个根据红色和灰色各聚一类。假设我们还运行了第三个聚
类算法，用来决定类别的数目。这有可能聚成了四类，红色卡车、红色汽车、灰色卡
车和灰色汽车。现在这个新的聚类至少抓住了属性的信息，但是丢失了相似性信息。
红色汽车和灰色汽车在不同的类中，正如红色汽车和灰色卡车也在不同的类中。该
聚类算法没有告诉我们灰色汽车和红色汽车的相似度比灰色卡车和红色汽车的相似
度更高。我们只知道它们是不同的。
这些问题说明了一些我们可能更偏好于分布式表示（相对于 one-hot表示而言）
的原因。分布式表示可以对每个车辆赋予两个属性——一个表示它颜色，一个表示
它是汽车还是卡车。目前仍然不清楚什么是最优的分布式表示（学习算法如何知道
我们关心的两个属性是颜色和是否汽车或卡车，而不是制造商和车龄？ ） ，但是多个DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
132 第五章 机器学习基础
属性减少了算法去猜我们关心哪一个属性的负担，允许我们通过比较很多属性而非
测试一个单一属性来细粒度地度量相似性。
5.9随机梯度下降
几乎所有的 深度学习 算法都用到了一个非常重要的算法： 随机梯度下降
（stochastic gradient descent ,SGD）。随机梯度下降 是第 4.3节介绍的 梯度下降 算
法的一个扩展。
机器学习 中反复出现的一个问题是好的泛化需要大的训练集，但大的训练集的
计算代价也更大。
机器学习 算法中的 代价函数 通常可以分解成每个 样本的代价函数 的总和。例如，
训练数据的负条件对数似然可以写成
J() =Ex;y^pdataL(x; y;) =1
mm∑
i=1L(x(i); y(i);); (5.96)
其中 L是每个样本的损失L(x; y;) = logp(yjx;)。
对于这些相加的 代价函数 ，梯度下降 需要计算
∇J() =1
mm∑
i=1∇L(x(i); y(i);): (5.97)
这个运算的计算代价是 O(m)。随着训练集规模增长为数十亿的 样本，计算一步梯度
也会消耗相当长的时间。
随机梯度下降 的核心是，梯度是期望。期望可使用小规模的样本近似估计。具
体而言，在算法的每一步，我们从训练集中均匀抽出一 小批量（minibatch ）样本
B=fx(1); : : : ; x(m′)g。小批量的数目 m′通常是一个相对较小的数，从一到几百。重
要的是，当训练集大小 m增长时， m′通常是固定的。我们可能在拟合几十亿的 样
本时，每次更新计算只用到几百个 样本。
梯度的估计可以表示成
g=1
m′∇m′∑
i=1L(x(i); y(i);): (5.98)
使用来自 小批量 B的样本。然后， 随机梯度下降 算法使用如下的 梯度下降 估计：
  ϵg; (5.99)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.10构建机器学习算法 133
其中， ϵ是学习率。
梯度下降 往往被认为很慢或不可靠。以前，将 梯度下降 应用到非凸优化问题被
认为很鲁莽或没有原则。现在，我们知道 梯度下降 用于本书第二部分中的训练时效
果不错。优化算法不一定能保证在合理的时间内达到一个局部最小值，但它通常能
及时地找到 代价函数 一个很小的值，并且是有用的。
随机梯度下降 在深度学习 之外有很多重要的应用。它是在大规模数据上训练大
型线性模型的主要方法。对于固定大小的模型，每一步 随机梯度下降 更新的计算量
不取决于训练集的大小 m。在实践中，当训练集大小增长时，我们通常会使用一个
更大的模型，但这并非是必须的。达到收敛所需的更新次数通常会随训练集规模增
大而增加。然而，当 m趋向于无穷大时，该模型最终会在 随机梯度下降 抽样完训练
集上的所有 样本之前收敛到可能的最优测试误差。继续增加 m不会延长达到模型可
能的最优测试误差的时间。从这点来看，我们可以认为用 SGD训练模型的渐近代价
是关于 m的函数的 O(1)级别。
在深度学习 兴起之前，学习非线性模型的主要方法是结合 核技巧的线性模型。
很多核学习算法需要构建一个 mm的矩阵 Gi;j=k(x(i);x(j))。构建这个矩阵的计
算量是 O(m2)。当数据集是几十亿个 样本时，这个计算量是不能接受的。在学术界，
深度学习 从2006年开始收到关注的原因是，在数以万计 样本的中等规模 数据集上，
深度学习 在新样本上比当时很多热门算法泛化得更好。不久后， 深度学习 在工业界
受到了更多的关注，因为其提供了一种训练大 数据集上的非线性模型的可扩展方式。
我们将会在第 八章继续探讨 随机梯度下降 及其很多改进方法。
5.10构建机器学习算法
几乎所有的深度学习算法都可以被描述为一个相当简单的配方：特定的 数据集、
代价函数 、优化过程和模型。
例如，线性回归 算法由以下部分组成： X和 y构成的数据集，代价函数
J(w; b) = Ex;y^pdata logpmodel (yjx); (5.100)
模型是 pmodel (yjx) =N(y;x⊤w+b;1)，在大多数情况下，优化算法可以定义为求
解代价函数 梯度为零的 正规方程 。
意识到我们可以替换独立于其他组件的大多数组件，因此我们能得到很多不同DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
134 第五章 机器学习基础
的算法。
通常代价函数 至少含有一项使学习过程进行统计估计的成分。最常见的 代价函
数是负对数似然，最小化 代价函数 导致的最大似然估计 。
代价函数 也可能含有附加项，如 正则化项 。例如，我们可以将权重衰减加到 线
性回归的代价函数 中
J(w; b) =∥w∥2
2 Ex;y^pdata logpmodel (yjx): (5.101)
该优化仍然有闭解。
如果我们将该模型变成非线性的，那么大多数 代价函数 不再能通过闭解优化。
这就要求我们选择一个迭代数值优化过程，如 梯度下降 等。
组合模型、 代价和优化算法来构建学习算法的配方同时适用于 监督学习 和无监
督学习。线性回归 示例说明了如何适用于 监督学习 的。无监督学习 时，我们需要定
义一个只包含 X的数据集、一个合适的无监督 代价和一个模型。例如，通过指定如
下损失函数 可以得到 PCA的第一个主向量
J(w) =Ex^pdata∥x r(x;w)∥2
2 (5.102)
模型定义为重构函数 r(x) = w⊤x w，并且 w有范数为 1的限制。
在某些情况下，由于计算原因，我们不能实际计算 代价函数 。在这种情况下，只
要我们有近似其梯度的方法，那么我们仍然可以使用迭代数值优化近似最小化 目标。
尽管有时候不显然，但大多数学习算法都用到了上述配方。如果一个 机器学习 算
法看上去特别独特或是手动设计的，那么通常需要使用特殊的优化方法进行求解。
有些模型，如决策树或 k-均值，需要特殊的优化，因为它们的 代价函数 有平坦的区
域，使其不适合通过基于梯度的优化去最小化。在我们认识到大部分 机器学习 算法
可以使用上述配方描述之后，我们可以将不同算法视为出于相同原因解决相关问题
的一类方法，而不是一长串各个不同的算法。
5.11促使深度学习发展的挑战
本章描述的简单 机器学习 算法在很多不同的重要问题上效果都良好。但是它们
不能成功解决人工智能中的核心问题，如语音识别或者对象识别。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.11促使深度学习发展的挑战 135
深度学习 发展动机的一部分原因是传统学习算法在这类人工智能问题上泛化能
力不足。
本节介绍为何处理高维数据时在新 样本上泛化特别困难，以及为何在传统 机器
学习中实现泛化的机制不适合学习高维空间中复杂的函数。这些空间经常涉及巨大
的计算代价。 深度学习 旨在克服这些以及其他一些难题。
5.11.1 维数灾难
当数据的维数很高时，很多 机器学习 问题变得相当困难。这种现象被称为 维数
灾难（curse of dimensionality ） 。特别值得注意的是，一组变量不同的可能配置数量
会随着变量数目的增加而指数级增长。
维数灾难发生在计算机科学的许多地方，在 机器学习 中尤其如此。
由维数灾难 带来的一个挑战是统计挑战。如图 5.9所示，统计挑战产生于 x的可
能配置数目远大于训练 样本的数目。为了充分理解这个问题，我们假设输入空间如
图所示被分成网格。低维时我们可以用由数据占据的少量网格去描述这个空间。泛
化到新数据点时，通过检测和新输入在相同网格中的训练 样本，我们可以判断如何
处理新数据点。例如，如果要估计某点 x处的概率密度，我们可以返回 x处单位体
积内训练 样本的数目除以训练 样本的总数。如果我们希望对一个 样本进行分类，我
们可以返回相同网格中训练 样本最多的类别。如果我们是做回归分析，我们可以平
均该网格中 样本对应的的 目标值。但是，如果该网格中没有 样本，该怎么办呢？因为
在高维空间中参数配置数目远大于 样本数目，大部分配置没有相关的 样本。我们如
何能在这些新配置中找到一些有意义的东西呢？许多传统 机器学习 算法只是简单地
假设在一个新点的输出应大致和最接近的训练点的输出相同。
5.11.2 局部不变性和平滑正则化
为了更好地泛化， 机器学习 算法需要由先验信念引导应该学习什么类型的函数。
此前，我们已经看到过由模型参数的概率分布形成的先验。通俗地讲，我们也可以说
先验信念直接影响 函数本身，而仅仅通过它们对函数的影响来间接改变参数。此外，
我们还能通俗地说，先验信念还间接地体现在选择一些偏好某类函数的算法，尽管
这些偏好并没有通过我们对不同函数置信程度的概率分布表现出来（也许根本没法
表现） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
136 第五章 机器学习基础
图5.9:当数据的相关维度增大时（从左向右） ，我们感兴趣的配置数目会随之指数级增长。 (左)在
这个一维的例子中，我们用一个变量来区分所感兴趣的仅仅 10个区域。当每个区域都有足够的样
本数时（图中每个样本对应了一个细胞） ，学习算法能够轻易地 泛化得很好。 泛化的一个直接方法
是估计目标函数在每个区域的值（可能是在相邻区域之间插值） 。 (中)在二维情况下，对每个变量
区分 10个不同的值更加困难。我们需要追踪 1010 = 100 个区域，至少需要很多样本来覆盖所
有的区域。 (右)三维情况下，区域数量增加到了 103= 1000，至少需要那么多的样本。对于需要
区分的 d维以及 v个值来说，我们需要 O(vd)个区域和样本。这就是 维数灾难 的一个示例。感谢
由Nicolas Chapados 提供的图片。
其中最广泛使用的隐式 ‘‘先验’’是平滑先验 （smoothness prior ） ，或局部不变
性先验（local constancy prior ） 。这个先验表明我们学习的函数不应在小区域内发生
很大的变化。
许多简单算法完全依赖于此先验达到良好的泛化，其结果是不能推广去解决 人
工智能级别任务中的统计挑战。本书中，我们将介绍 深度学习 如何引入额外的（显
式或隐式的）先验去降低复杂任务中的泛化误差。这里，我们解释为什么仅依靠平
滑先验不足以应对这类任务。
有许多不同的方法来显式或隐式地表示学习函数应该具有光滑或局部不变的先
验。所有这些不同的方法都旨在鼓励学习过程能够学习出函数 f对于大多数设置 x
和小变动 ϵ，都满足条件
f(x)f(x+ϵ): (5.103)
换言之，如果我们知道对应输入 x的答案（例如， x是个有标签的训练样本） ，那么
该答案对于 x的邻域应该也适用。如果在有些邻域中我们有几个好答案，那么我们
可以组合它们（通过某种形式的平均或插值法）以产生一个尽可能和大多数输入一
致的答案。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.11促使深度学习发展的挑战 137
局部不变方法的一个极端例子是 k-最近邻系列的学习算法。当一个区域里的所
有点 x在训练集中的 k个最近邻是一样的，那么对这些点的预测也是一样的。当
k= 1时，不同区域的数目不会比训练 样本还多。
虽然 k-最近邻算法复制了附近训练 样本的输出，大部分核机器也是在和附近训
练样本相关的训练集输出上插值。一类重要的核函数是 局部核（local kernel ） ，其核
函数 k(u;v)在 u= v时很大，当 u和 v距离拉大时而减小。局部核可以看作是执
行模版匹配的相似函数，用于度量测试 样本 x和每个训练 样本 x(i)有多么相似。近
年来深度学习的很多推动力源自研究局部模版匹配的局限性，以及 深度学习 如何克
服这些局限性 (Bengio et al. ,2006a )。
决策树也有平滑学习的局限性，因为它将输入空间分成和叶节点一样多的区间，
并在每个区间使用单独的参数（或者有些决策树的拓展有多个参数） 。如果 目标函数
需要至少拥有 n个叶节点的树才能精确表示，那么至少需要 n个训练样本去拟合。
需要几倍于 n的样本去达到预测输出上的某种统计置信度。
总的来说，区分输入空间中 O(k)个区间，所有的这些方法需要 O(k)个样本。
通常会有 O(k)个参数， O(1)参数对应于 O(k)区间之一。最近邻算法中，每个训
练样本至多用于定义一个区间，如图 5.10所示。
图5.10:最近邻算法如何划分输入空间的示例。每个区域内的一个样本（这里用圆圈表示）定义了
区域边界（这里用线表示） 。每个样本相关的 y值定义了对应区域内所有数据点的输出。由 最近
邻定义并且匹配几何模式的区域被称为 Voronoi 图。这些连续区域的数量不会比训练样本的数量
增加得更快。尽管此图具体说明了 最近邻算法的效果，其他的单纯依赖局部光滑先验的机器学习
算法也表现出了类似的 泛化能力：每个训练样本仅仅能告诉学习者如何在其周围的相邻区域 泛化。
有没有什么方法能表示区间数目比训练 样本数目还多的复杂函数？显然，只是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
138 第五章 机器学习基础
假设函数的平滑性不能做到这点。例如，想象 目标函数作用在西洋跳棋盘上。棋盘包
含许多变化，但只有一个简单的结构。想象一下，如果训练 样本数目远小于棋盘上
的黑白方块数目，那么会发生什么。基于局部泛化和平滑性或局部不变性先验，如
果新点和某个训练 样本位于相同的棋盘方块中，那么我们能够保证正确地预测新点
的颜色。但如果新点所在的方块没有训练 样本，学习器不一定能举一反三。如果仅
依靠这个先验，一个 样本只能告诉我们它所在的方块的颜色。获得整个棋盘颜色的
唯一方法是其上的每个方块至少要有一个 样本。
只要在要学习的真实函数的峰值和谷值处有足够多的 样本，那么平滑性假设和
相关的无参数学习算法的效果都非常好。当要学习的函数足够平滑，并且只在少数
几维变化，这样做一般没问题。在高维空间中，即使是非常平滑的函数，也会在不
同维度上有不同的变化方式。如果函数在不同的区间中表现不一样，那么就非常难
用一组训练 样本去刻画函数。如果函数是复杂的（我们想区分多于训练 样本数目的
大量区间） ，有希望很好地泛化么？
这些问题，即是否可以有效地表示复杂的函数以及所估计的函数是否可以很好
地泛化到新的输入，答案是有。关键观点是，只要我们通过额外假设生成数据的分
布来建立区域间的依赖关系，那么 O(k)个样本足以描述多如 O(2k)的大量区间。通
过这种方式，我们确实能做到非局部的泛化 (Bengio and Monperrus ,2005;Bengio
et al. ,2006b )。为了利用这些优势，许多不同的 深度学习 算法都提出了一些适用于多
种AI任务的隐式或显式的假设。
一些其他的 机器学习 方法往往会提出更强的，针对特定问题的假设。例如，假
设目标函数是周期性的，我们很容易解决棋盘问题。通常，神经网络不会包含这些很
强的（针对特定任务的）假设，因此神经网络可以泛化到更广泛的各种结构中。人
工智能任务的结构非常复杂，很难限制到简单的、人工手动指定的性质，如周期性，
因此我们希望学习算法具有更通用的假设。 深度学习 的核心思想是假设数据由 因素
或特征组合 产生，这些因素或特征可能来自一个层次结构的多个层级。许多其他类
似的通用假设进一步提高了 深度学习 算法。这些很温和的假设允许了 样本数目和可
区分区间数目之间的指数增益。这类指数增益将在第 6.4.1节、第 15.4节和第 15.5节
中更详尽地介绍。深度的 分布式表示 带来的指数增益有效地解决了 维数灾难 带来的
挑战。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.11促使深度学习发展的挑战 139
5.11.3 流形学习
流形是一个机器学习 中很多想法内在的重要概念。
流形（manifold ）指连接在一起的区域。数学上，它是指一组点，且每个点都
有其邻域。给定一个任意的点，其流形局部看起来像是欧几里得空间。日常生活中，
我们将地球视为二维平面，但实际上它是三维空间中的球状 流形。
每个点周围邻域的定义暗示着存在变换能够从一个位置移动到其邻域位置。例
如在地球表面这个流形中，我们可以朝东南西北走。
尽管术语 “流形’’有正式的数学定义，但是 机器学习 倾向于更松散地定义一组
点，只需要考虑少数嵌入在高维空间中的自由度或维数就能很好地近似。每一维都
对应着局部的变化方向。如图 5.11所示，训练数据位于二维空间中的一维流形中。
在机器学习 中，我们允许流形的维数从一个点到另一个点有所变化。这经常发生于
流形和自身相交的情况中。例如，数字 “8’’形状的流形在大多数位置只有一维，但
在中心的相交处有两维。
0:5 1:0 1:5 2:0 2:5 3:0 3:5 4:0 1:0 0:50:00:51:01:52:02:5
图5.11:从一个二维空间的分布中抽取的数据样本，这些样本实际上聚集在一维 流形附近，像一个
缠绕的带子。实线代表学习器应该推断的隐式 流形。
如果我们希望 机器学习 算法学习整个 Rn上有趣变化的函数，那么很多 机器学
习问题看上去都是无望的。 流形学习 （manifold learning ）算法通过一个假设来克服
这个障碍，该假设认为 Rn中大部分区域都是无效的输入，有意义的输入只分布在包
含少量数据点的子集构成的一组流形中，而学习函数的输出中，有意义的变化都沿
着流形的方向或仅发生在我们切换到另一流形时。流形学习最初用于连续数值和无DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
140 第五章 机器学习基础
监督学习的环境，尽管这个概率集中的想法也能够泛化到离散数据和 监督学习 的设
定下：关键假设仍然是概率质量高度集中。
图5.12:随机地均匀抽取图像（根据均匀分布随机地选择每一个像素）会得到噪声图像。尽管在人
工智能应用中以这种方式生成一个脸或者其他物体的图像是非零概率的，但是实际上我们从来没
有观察到这种现象。这也意味着人工智能应用中遇到的图像在所有图像空间中的占比可以是忽略
不计的。
数据位于低维流形的假设并不总是对的或者有用的。我们认为在人工智能的一
些场景中，如涉及到处理图像、声音或者文本时，流形假设至少是近似对的。这个
假设的支持证据包含两类观察结果。
第一个支持 流形假设 （manifold hypothesis ）的观察是现实生活中的图像、文
本、声音的概率分布都是高度集中的。均匀的 噪声从来不会与这类领域的结构化输DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
5.11促使深度学习发展的挑战 141
入类似。图 5.12显示均匀采样的点看上去像是没有信号时模拟电视上的静态模式。
同样，如果我们均匀地随机抽取字母来生成文件，能有多大的概率得到一个有意义
的英语文档？几乎是零。因为大部分字母长序列不对应着自然语言序列：自然语言
序列的分布只占了字母序列的总空间里非常小的一部分。
当然，集中的概率分布不足以说明数据位于一个相当小的流形中。我们还必须
确保，我们遇到的 样本和其他样本相互连接，每个 样本被其他高度相似的 样本包围，
而这些高度相似的样本可以通过变换来遍历该流形得到。支持流形假设的第二个论
点是，我们至少能够非正式地想象这些邻域和变换。在图像中，我们当然会认为有
很多可能的变换仍然允许我们描绘出图片空间的流形：我们可以逐渐变暗或变亮光
泽、逐步移动或旋转图中对象、逐渐改变对象表面的颜色等等。在大多数应用中很
有可能会涉及到多个流形。例如，人脸图像的 流形不太可能连接到猫脸图像的 流形。
这些支持流形假设的思维实验传递了一些支持它的直观理由。更严格的实
验(Cayton ,2005;Narayanan and Mitter ,2010;Schölkopf et al. ,1998a ;Roweis and
Saul,2000;Tenenbaum et al. ,2000;Brand ,2003a ;Belkin and Niyogi ,2003b ;Donoho
and Grimes ,2003;Weinberger and Saul ,2004a )在人工智能 中备受关注的一大类 数
据集上支持了这个假设。
当数据位于低维流形中时，使用流形中的坐标而非 Rn中的坐标表示 机器学习 数
据更为自然。日常生活中，我们可以认为道路是嵌入在三维空间的一维流形。我们
用一维道路中的地址号码确定地址，而非三维空间中的坐标。提取这些流形中的坐
标是非常具有挑战性的，但是很有希望改进许多 机器学习 算法。这个一般性原则能
够用在很多情况中。图 5.13展示了包含人脸的 数据集的流形结构。在本书的最后，
我们会介绍一些学习这样的流形结构的必备方法。在图 20.6中，我们将看到 机器学
习算法如何成功完成这个 目标。
第一部分介绍了数学和 机器学习 中的基本概念，这将用于本书其他章节中。至
此，我们已经做好了研究 深度学习 的准备。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
142 第五章 机器学习基础
图5.13: QMUL Multiview Face 数据集中的训练样本 (Gong et al. ,2000)，其中的物体是移动
的从而覆盖对应两个旋转角度的二维 流形。我们希望学习算法能够发现并且理出这些 流形坐标。
图20.6提供了这样一个示例。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第二部分
深层网络：现代实践
143DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
144
本书这一部分总结现代 深度学习 用于解决实际应用的现状。
深度学习 有着悠久的历史和许多愿景。数种提出的方法尚未完全结出果实。数
个雄心勃勃的目标尚未实现。这些较不发达的 深度学习 分支将出现在本书的最后部
分。
这一部分仅关注那些基本上已在工业中大量使用的技术方法。
现代深度学习 为监督学习 提供了一个强大的框架。通过添加更多层以及向层内
添加更多单元， 深度网络 可以表示复杂性不断增加的函数。给定足够大的模型和足
够大的标注训练数据集，我们可以通过 深度学习 将输入向量映射到输出向量，完成
大多数对人来说能迅速处理的任务。其他任务，比如不能被描述为将一个向量与另
一个相关联的任务，或者对于一个人来说足够困难并需要时间思考和反复琢磨才能
完成的任务，现在仍然超出了 深度学习 的能力范围。
本书这一部分描述参数化函数近似技术的核心，几乎所有现代实际应用的 深度
学习背后都用到了这一技术。首先，我们描述用于表示这些函数的前馈 深度网络 模
型。接着，我们提出正则化和优化这种模型的高级技术。将这些模型扩展到大输入
（如高分辨率图像或长时间序列）需要专门化。我们将会介绍扩展到大图像的 卷积网
络和用于处理时间序列的 循环神经网络 。最后，我们提出实用方法的一般准则，有
助于设计、构建和配置一些涉及 深度学习 的应用，并回顾其中一些应用。
这些章节对于从业者来说是最重要的，也就是现在想开始实现和使用 深度学
习算法解决现实问题的人需要阅读这些章节。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第六章 深度前馈网络
深度前馈网络 （deep feedforward network ） ， 也叫作 前馈神经网络 （feedforward
neural network ）或者多层感知机 （multilayer perceptron ,MLP） ，是典型的深度学
习模型。 前馈网络 的目标是近似某个函数 f。例如，对于分类器， y=f(x)将输入
x映射到一个类别 y。前馈网络 定义了一个映射 y=f(x;)，并且学习参数 的值，
使它能够得到最佳的函数近似。
这种模型被称为 前向（feedforward ）的，是因为信息流过 x的函数，流经用于
定义 f的中间计算过程，最终到达输出 y。在模型的输出和模型本身之间没有 反馈
（feedback ）连接。当前馈神经网络被扩展成包含 反馈连接时，它们被称为 循环神经
网络（recurrent neural network ） ，在第十章介绍。
前馈网络 对于机器学习的从业者是极其重要的。它们是许多重要商业应用的基
础。例如，用于对照片中的对象进行识别的 卷积神经网络 就是一种专门的 前馈网络 。
前馈网络 是通往循环网络 之路的概念基石，后者在自然语言的许多应用中发挥着巨
大作用。
前馈神经网络 被称作网络（network）是因为它们通常用许多不同函数复合
在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复
合在一起的。例如，我们有三个函数 f(1); f(2)和f(3)连接在一个链上以形成
f(x) =f(3)(f(2)(f(1)(x)))。这些链式结构是神经网络中最常用的结构。在这种情况
下，f(1)被称为网络的 第一层（ﬁrst layer ） ，f(2)被称为第二层（second layer ） ，以
此类推。链的全长称为模型的 深度（depth） 。正是因为这个术语才出现了 ‘‘深度学
习’’这个名字。 前馈网络 的最后一层被称为 输出层（output layer ） 。在神经网络训练
的过程中，我们让 f(x)去匹配 f(x)的值。训练数据为我们提供了在不同训练点上
取值的、含有噪声的 f(x)的近似实例。每个样本 x都伴随着一个标签 yf(x)。
训练样本直接指明了输出层在每一点 x上必须做什么；它必须产生一个接近 y的值。
145DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
146 第六章 深度前馈网络
但是训练数据并没有直接指明其他层应该怎么做。学习算法必须决定如何使用这些
层来产生想要的输出，但是训练数据并没有说每个单独的层应该做什么。相反，学
习算法必须决定如何使用这些层来最好地实现 f的近似。因为训练数据并没有给出
这些层中的每一层所需的输出，所以这些层被称为 隐藏层（hidden layer ） 。
最后，这些网络被称为 神经网络 是因为它们或多或少地受到神经科学的启
发。网络中的每个 隐藏层通常都是向量值的。这些 隐藏层的维数决定了模型的 宽度
（width） 。向量的每个元素都可以被视为起到类似一个神经元的作用。除了将层想
象成向量到向量的单个函数，我们也可以把层想象成由许多并行操作的 单元（unit）
组成，每个单元表示一个向量到标量的函数。每个单元在某种意义上类似一个神经
元，它接收的输入来源于许多其他的单元，并计算它自己的激活值。使用多层向量值
表示的想法来源于神经科学。用于计算这些表示的函数 f(i)(x)的选择，也或多或少
地受到神经科学观测的指引，这些观测是关于生物神经元计算功能的。然而，现代
的神经网络研究受到更多的是来自许多数学和工程学科的指引，并且神经网络的目
标并不是完美地给大脑建模。我们最好将 前馈神经网络 想成是为了实现统计 泛化而
设计出的函数近似机，它偶尔从我们了解的大脑中提取灵感，但并不是大脑功能的
模型。
一种理解 前馈网络 的方式是从线性模型开始，并考虑如何克服它的局限性。线
性模型，例如 逻辑回归 和线性回归，是非常吸引人的，因为无论是通过闭解形式还
是使用凸优化，它们都能高效且可靠地拟合。线性模型也有明显的缺陷，那就是该
模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。
为了扩展线性模型来表示 x的非线性函数，我们可以不把线性模型用于 x本身，
而是用在一个变换后的输入 ϕ(x)上，这里 ϕ是一个非线性变换。同样，我们可以
使用第 5.7.2节中描述的 核技巧，来得到一个基于隐含地使用 ϕ映射的非线性学习算
法。我们可以认为 ϕ提供了一组描述 x的特征，或者认为它提供了 x的一个新的表
示。
剩下的问题就是如何选择映射 ϕ。
1.其中一种选择是使用一个通用的 ϕ，例如无限维的 ϕ，它隐含地用在基
于RBF核的核机器上。如果 ϕ(x)具有足够高的维数，我们总是有足够的能力
来拟合训练集，但是对于测试集的 泛化往往不佳。非常通用的特征映射通常只
基于局部光滑的原则，并且没有将足够的先验信息进行编码来解决高级问题。
2.另一种选择是手动地设计 ϕ。在深度学习出现以前，这一直是主流的方法。这DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
147
种方法对于每个单独的任务都需要人们数十年的努力，从业者各自擅长特定的
领域（如语音识别或计算机视觉） ，并且不同领域之间很难迁移 (transfer) 。
3.深度学习的策略是去学习 ϕ。在这种方法中，我们有一个模型 y=f(x;;w) =
ϕ(x;)⊤w。我们现在有两种参数：用于从一大类函数中学习 ϕ的参数，以及
用于将 ϕ(x)映射到所需的输出的参数 w。这是深度前馈网络 的一个例子，其
中ϕ定义了一个 隐藏层。这是三种方法中唯一一种放弃训练问题的凸性的方
法，但是利大于弊。在这种方法中，我们将表示参数化为 ϕ(x;)，并且使用优
化算法来寻找 ，使它能够得到一个好的表示。如果我们想要的话，这种方法
也可以通过使它变得高度通用以获得第一种方法的优点——我们只需使用一个
非常广泛的函数族 ϕ(x;)。这种方法也可以获得第二种方法的优点。人类专家
可以将他们的知识编码进网络来帮助 泛化，他们只需要设计那些他们期望能够
表现优异的函数族 ϕ(x;)即可。这种方法的优点是人类设计者只需要寻找正
确的函数族即可，而不需要去寻找精确的函数。
这种通过学习特征来改善模型的一般化原则不仅仅适用于本章描述的 前馈神经
网络。它是深度学习中反复出现的主题，适用于全书描述的所有种类的模型。 前馈
神经网络 是这个原则的应用，它学习从 x到 y的确定性映射并且没有反馈连接。后
面出现的其他模型会把这些原则应用到学习随机映射、学习带有反馈的函数以及学
习单个向量的概率分布。
本章我们先从 前馈网络 的一个简单例子说起。接着，我们讨论部署一个 前馈网
络所需的每个设计决策。首先，训练一个 前馈网络 至少需要做和线性模型同样多的设
计决策：选择一个优化模型、代价函数以及输出单元的形式。我们先回顾这些基于梯
度学习的基本知识，然后去面对那些只出现在 前馈网络 中的设计决策。 前馈网络 已经
引入了隐藏层的概念，这需要我们去选择用于计算 隐藏层值的激活函数 （activation
function） 。我们还必须设计网络的结构，包括网络应该包含多少层、这些层应该如
何连接，以及每一层包含多少单元。在深度神经网络的学习中需要计算复杂函数的
梯度。我们给出 反向传播 （back propagation ）算法和它的现代推广，它们可以用来
高效地计算这些梯度。最后，我们以某些历史观点来结束这一章。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
148 第六章 深度前馈网络
6.1实例：学习 XOR
为了使前馈网络 的想法更加具体，我们首先从一个可以完整工作的 前馈网络 说
起。这个例子解决一个非常简单的任务：学习 XOR函数。
XOR函数（ ‘‘异或’’逻辑）是两个二进制值 x1和x2的运算。当这些二进制值
中恰好有一个为 1时，XOR函数返回值为 1。其余情况下返回值为 0。XOR函数提
供了我们想要学习的目标函数 y=f(x)。我们的模型给出了一个函数 y=f(x;)
并且我们的学习算法会不断调整参数 来使得 f尽可能接近 f。
在这个简单的例子中，我们不会关心统计 泛化。我们希望网络在这四个点
X=f[0;0]⊤;[0;1]⊤;[1;0]⊤;[1;1]⊤g上表现正确。我们会用全部这四个点来训练我们
的网络，唯一的挑战是拟合训练集。
我们可以把这个问题当作是回归问题，并使用 均方误差 损失函数。我们选择这
个损失函数是为了尽可能简化本例中用到的数学。在应用领域，对于二进制数据建
模时， MSE通常并不是一个合适的损失函数。更加合适的方法将在第 6.2.2.2节中讨
论。
评估整个训练集上表现的 MSE损失函数为
J() =1
4∑
x2X(f(x) f(x;))2: (6.1)
我们现在必须要选择我们模型 f(x;)的形式。假设我们选择一个线性模型， 
包含 w和b，那么我们的模型被定义成
f(x;w; b) = x⊤w+b: (6.2)
我们可以使用 正规方程 关于 w和b最小化 J()，来得到一个闭式解。
解正规方程 以后，我们得到 w= 0以及 b=1
2。线性模型仅仅是在任意一点都输
出0.5。为什么会发生这种事？图 6.1演示了线性模型为什么不能用来表示 XOR函
数。解决这个问题的其中一种方法是使用一个模型来学习一个不同的特征空间，在
这个空间上线性模型能够表示这个解。
具体来说，我们这里引入一个非常简单的 前馈神经网络 ，它有一层 隐藏层并且隐
藏层中包含两个单元。见图 6.2中对该模型的解释。这个 前馈网络 有一个通过函数
f(1)(x;W;c)计算得到的 隐藏单元 的向量 h。这些隐藏单元 的值随后被用作第二层的
输入。第二层就是这个网络的输出层。输出层仍然只是一个线性回归模型，只不过DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.1实例：学习 XOR 149
0
 1
x1
0
1x2Original xspace
0
 1
 2
h1
0
1h2Learned hspace
图6.1:通过学习一个表示来解决 XOR问题。图上的粗体数字标明了学得的函数必须在每个点输
出的值。 (左)直接应用于原始输入的线性模型不能实现 XOR函数。当 x1= 0时，模型的输出必
须随着 x2的增大而增大。当 x1= 1时，模型的输出必须随着 x2的增大而减小。线性模型必须对
x2使用固定的系数 w2。因此，线性模型不能使用 x1的值来改变 x2的系数，从而不能解决这个
问题。 (右)在由神经网络提取的特征表示的变换空间中，线性模型现在可以解决这个问题了。在
我们的示例解决方案中，输出必须为 1的两个点折叠到了特征空间中的单个点。换句话说，非线
性特征将 x= [1;0]⊤和 x= [0;1]⊤都映射到了特征空间中的单个点 h= [1;0]⊤。线性模型现在可
以将函数描述为 h1增大和 h2减小。在该示例中，学习特征空间的动机仅仅是使得模型的能力更
大，使得它可以拟合训练集。在更现实的应用中，学习的表示也可以帮助模型 泛化。
现在它作用于 h而不是 x。网络现在包含链接在一起的两个函数： h=f(1)(x;W;c)
和y=f(2)(h;w; b)，完整的模型是 f(x;W;c;w; b) =f(2)(f(1)(x))。
f(1)应该是哪种函数？线性模型到目前为止都表现不错，让 f(1)也是线性的似
乎很有诱惑力。不幸的是，如果 f(1)是线性的，那么 前馈网络 作为一个整体对于输
入仍然是线性的。暂时忽略截距项，假设 f(1)(x) = W⊤x并且 f(2)(h) = h⊤w，那么
f(x) = w⊤W⊤x。我们可以将这个函数重新表示成 f(x) = x⊤w′其中 w′= Ww。
显然，我们必须用非线性函数来描述这些特征。大多数神经网络通过仿射变换之
后紧跟着一个被称为激活函数的固定非线性函数来实现这个目标，其中仿射变换由
学得的参数控制。我们这里使用这种策略，定义 h=g(W⊤x+c)，其中 W是线性
变换的权重矩阵， c是偏置。此前，为了描述线性回归模型，我们使用权重向量和一
个标量的偏置参数来描述从输入向量到输出标量的仿射变换。现在，因为我们描述
的是向量 x到向量 h的仿射变换，所以我们需要一整个向量的偏置参数。激活函数
g通常选择对每个元素分别起作用的函数，有 hi=g(x⊤W:;i+ci)。在现代神经网络DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
150 第六章 深度前馈网络
yyhhxxWwyyh1h1x1x1h2h2x2x2
图6.2:使用两种不同样式绘制的 前馈网络 的示例。具体来说，这是我们用来解决 XOR问题的前
馈网络。它有单个 隐藏层，包含两个单元。 (左)在这种样式中，我们将每个单元绘制为图中的一个
节点。这种风格是清楚而明确的，但对于比这个例子更大的网络，它可能会消耗太多的空间。 (右)
在这种样式中，我们将表示每一层激活的整个向量绘制为图中的一个节点。这种样式更加紧凑。有
时，我们对图中的边使用参数名进行注释，这些参数是用来描述两层之间的关系的。这里，我们用
矩阵 W描述从 x到 h的映射，用向量 w描述从 h到y的映射。当标记这种图时，我们通常省
略与每个层相关联的截距参数。
中，默认的推荐是使用由激活函数 g(z) = maxf0; zg定义的整流线性单元 （rectiﬁed
linear unit ）或者称为 ReLU (Jarrett et al. ,2009b ;Nair and Hinton ,2010a ;Glorot
et al. ,2011a )，如图 6.3所示。
我们现在可以指明我们的整个网络是
f(x;W;c;w; b) = w⊤maxf0;W⊤x+cg+b: (6.3)
我们现在可以给出 XOR问题的一个解。令
W=[
1 1
1 1]
; (6.4)
c=[
0
 1]
; (6.5)
w=[
1
 2]
; (6.6)
以及 b= 0。
我们现在可以了解这个模型如何处理一批输入。令 X表示设计矩阵，它包含二DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.1实例：学习 XOR 151
0
z0g(z) = max {0,z}
图6.3:整流线性 激活函数。该激活函数是被推荐用于大多数 前馈神经网络 的默认激活函数。将此
函数用于线性变换的输出将产生非线性变换。然而，函数仍然非常接近线性，在这种意义上它是
具有两个线性部分的分段线性函数。由于 整流线性单元 几乎是线性的，因此它们保留了许多使得
线性模型易于使用基于梯度的方法进行优化的属性。它们还保留了许多使得线性模型能够 泛化良
好的属性。计算机科学的一个公共原则是，我们可以从最小的组件构建复杂的系统。就像图灵机
的内存只需要能够存储 0或1的状态，我们可以从 整流线性 函数构建一个 万能函数近似器 。
进制输入空间中全部的四个点，每个样本占一行，那么矩阵表示为：
X=2
666640 0
0 1
1 0
1 13
77775: (6.7)
神经网络的第一步是将输入矩阵乘以第一层的权重矩阵：
XW =2
666640 0
1 1
1 1
2 23
77775: (6.8)
然后，我们加上偏置向量 c，得到
2
666640 1
1 0
1 0
2 13
77775: (6.9)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
152 第六章 深度前馈网络
在这个空间中，所有的样本都处在一条斜率为 1的直线上。当我们沿着这条直线移
动时，输出需要从 0升到 1，然后再降回 0。线性模型不能实现这样一种函数。为了
用 h对每个样本求值，我们使用 整流线性变换 ：
2
666640 0
1 0
1 0
2 13
77775: (6.10)
这个变换改变了样本间的关系。它们不再处于同一条直线上了。如图 6.1所示，
它们现在处在一个可以用线性模型解决的空间上。
我们最后乘以一个权重向量 w:
2
666640
1
1
03
77775: (6.11)
神经网络对这一批次中的每个样本都给出了正确的结果。
在这个例子中，我们简单地指定了解决方案，然后说明它得到的误差为零。在
实际情况中，可能会有数十亿的模型参数以及数十亿的训练样本，所以不能像我们
这里做的那样进行简单地猜解。与之相对的，基于梯度的优化算法可以找到一些参
数使得产生的误差非常小。我们这里给出的 XOR问题的解处在损失函数的全局最
小点，所以梯度下降算法可以收敛到这一点。梯度下降算法还可以找到 XOR问题一
些其他的等价解。梯度下降算法的收敛点取决于参数的初始值。在实践中，梯度下
降通常不会找到像我们这里给出的那种干净的、容易理解的、整数值的解。
6.2基于梯度的学习
设计和训练神经网络与使用梯度下降训练其他任何机器学习模型并没有太大不
同。在第 5.10节中，我们描述了如何通过指定一个优化过程、代价函数和一个模型
族来构建一个机器学习算法。
我们到目前为止看到的线性模型和神经网络的最大区别，在于神经网络的非线
性导致大多数我们感兴趣的 代价函数 都变得非凸。这意味着神经网络的训练通常使DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 153
用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于
训练线性回归模型的线性方程求解器，或者用于训练 逻辑回归 或SVM的凸优化算
法那样保证全局收敛。凸优化从任何一种初始参数出发都会收敛（理论上如此——
在实践中也很鲁棒但可能会遇到数值问题） 。用于非凸损失函数的随机梯度下降没有
这种收敛性保证，并且对参数的初始值很敏感。对于 前馈神经网络 ，将所有的权重
值初始化为小随机数是很重要的。偏置可以初始化为零或者小的正值。这种用于训
练前馈神经网络 以及几乎所有深度模型的迭代的基于梯度的优化算法会在第第 八章
详细介绍，参数初始化会在第 8.4节中具体说明。就目前而言，只需要懂得，训练算
法几乎总是基于使用梯度来使得代价函数下降的各种方法即可。一些特别的算法是
对梯度下降思想的改进和提纯（在第 4.3节中介绍）还有一些更特别的，大多数是对
随机梯度下降算法的改进（在第 5.9节中介绍） 。
我们当然也可以用梯度下降来训练诸如线性回归和 支持向量机 之类的模型，并
且事实上当训练集相当大时这是很常用的。从这点来看，训练神经网络和训练其他
任何模型并没有太大区别。计算梯度对于神经网络会略微复杂一些，但仍然可以很
高效而精确地实现。第 6.5节将会介绍如何用 反向传播 算法以及它的现代扩展算法来
求得梯度。
和其他的机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个
代价函数，并且我们必须选择如何表示模型的输出。现在，我们重温这些设计上的
考虑，并且特别强调神经网络的情景。
6.2.1代价函数
深度神经网络设计中的一个重要方面是代价函数的选择。幸运的是，神经网络
的代价函数或多或少是和其他的参数模型例如线性模型的代价函数相同的。
在大多数情况下，我们的参数模型定义了一个分布 p(yjx;)并且我们简单地
使用最大似然原理。这意味着我们使用训练数据和模型预测间的 交叉熵作为代价函
数。
有时，我们使用一个更简单的方法，不是预测 y的完整概率分布，而是仅仅预
测在给定 x的条件下 y的某种统计量。某些专门的损失函数允许我们来训练这些估
计量的预测器。
用于训练神经网络的完整的代价函数，通常在我们这里描述的基本代价函数的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
154 第六章 深度前馈网络
基础上结合一个正则项。我们已经在第 5.2.2节中看到正则化应用到线性模型中的一
些简单的例子。用于线性模型的权重衰减方法也直接适用于深度神经网络，而且是
最流行的正则化策略之一。用于神经网络的更高级的正则化策略将在第 七章中讨论。
6.2.1.1 使用最大似然学习条件分布
大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数
似然，它与训练数据和模型分布间的 交叉熵等价。这个代价函数表示为
J() = Ex;y^pdata logpmodel (yjx): (6.12)
代价函数的具体形式随着模型而改变，取决于 logpmodel的具体形式。上述方程
的展开形式通常会有一些项不依赖于模型的参数，我们可以舍去。例如，正如我们
在第 5.1.1节中看到的，如果 pmodel (yjx) =N(y;f(x;);I)，那么我们恢复 均方误
差代价，
J() =1
2Ex;y^pdatajjy f(x;)jj2+const ; (6.13)
至少系数1
2和常数项不依赖于 。舍弃的常数是基于 高斯分布 的方差，在这种情况
下我们选择不把它参数化。之前，我们看到了对输出分布的最大似然估计和对线性
模型均方误差 的最小化之间的等价性，但事实上，这种等价性并不要求 f(x;)用于
预测高斯分布 的均值。
使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模型设计
代价函数的负担。明确一个模型 p(yjx)则自动地确定了一个代价函数 logp(yjx)。
贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具
有足够的预测性，来为学习算法提供一个好的指引。饱和（变得非常平）的函数破
坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于
产生隐藏单元 或者输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很
多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝
对值非常大的负值时会造成饱和。负对数似然代价函数中的对数函数消除了某些输
出单元中的指数效果。我们将会在第 6.2.2节中讨论代价函数和输出单元的选择间的
相互作用。
用于实现最大似然估计的 交叉熵代价函数有一个不同寻常的特性，那就是当它
被应用于实践中经常遇到的模型时，它通常没有最小值。对于离散型输出变量，大
多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 155
接近。逻辑回归 是其中一个例子。对于实值的输出变量，如果模型可以控制输出分
布的密度（例如，通过学习 高斯输出分布 的方差参数） ，那么它可能对正确的训练集
输出赋予极其高的密度，这将导致 交叉熵趋向负无穷。第 七章中描述的正则化技术
提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制
的收益。
6.2.1.2 学习条件统计量
有时我们并不是想学习一个完整的概率分布 p(yjx;)，而仅仅是想学习在给定
x时 y的某个条件统计量。
例如，我们可能有一个预测器 f(x;)，我们想用它来预测 y的均值。如果我
们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函
数中的任何一个函数 f，这个类仅仅被一些特征所限制，例如连续性和有界，而不
是具有特殊的参数形式。从这个角度来看，我们可以把代价函数看作是一个 泛函
（functional ）而不仅仅是一个函数。泛函是函数到实数的映射。我们因此可以将学习
看作是选择一个函数而不仅仅是选择一组参数。我们可以设计代价泛函在我们想要
的某些特殊函数处取得最小值。例如，我们可以设计一个代价泛函，使它的最小值处
于一个特殊的函数上，这个函数将 x映射到给定 x时 y的期望值。对函数求解优化
问题需要用到 变分法（calculus of variations ）这个数学工具，我们将在第 19.4.2节
中讨论。理解 变分法对于理解本章的内容不是必要的。目前，只需要知道 变分法可
以被用来导出下面的两个结果。
我们使用 变分法导出的第一个结果是解优化问题
f= arg min
fEx;ypdatajjy f(x)jj2(6.14)
得到
f(x) =Eypdata(yjx)[y]; (6.15)
要求这个函数处在我们要优化的类里。换句话说，如果我们能够用无穷多的、来源
于真实的数据生成分布的样本进行训练，最小化 均方误差 代价函数将得到一个函数，
它可以用来对每个 x的值预测出 y的均值。
不同的代价函数给出不同的统计量。第二个使用 变分法得到的结果是
f= arg min
fEx;ypdatajjy f(x)jj1 (6.16)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
156 第六章 深度前馈网络
将得到一个函数可以对每个 x预测 y取值的中位数，只要这个函数在我们要优化的
函数族里。这个代价函数通常被称为 平均绝对误差 （mean absolute error ） 。
可惜的是， 均方误差 和平均绝对误差 在使用基于梯度的优化方法时往往成效不
佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。这就是为什
么交叉熵代价函数比 均方误差 或者平均绝对误差 更受欢迎的原因之一了，即使是在
没必要估计整个 p(yjx)分布时。
6.2.2输出单元
代价函数的选择与输出单元的选择紧密相关。大多数时候，我们简单地使用数
据分布和模型分布间的 交叉熵。选择如何表示输出决定了 交叉熵函数的形式。
任何可用作输出的神经网络单元，也可以被用作 隐藏单元 。这里，我们着重讨
论将这些单元用作模型输出时的情况，不过原则上它们也可以在内部使用。我们将
在第 6.3节中重温这些单元，并且给出当它们被用作 隐藏单元 时一些额外的细节。
在本节中，我们假设 前馈网络 提供了一组定义为 h=f(x;)的隐藏特征。输出
层的作用是随后对这些特征进行一些额外的变换来完成整个网络必须完成的任务。
6.2.2.1 用于高斯输出分布的线性单元
一种简单的输出单元是基于仿射变换的输出单元，仿射变换不具有非线性。这
些单元往往被直接称为线性单元。
给定特征 h，线性输出单元层产生一个向量 ^y= W⊤h+b。
线性输出层经常被用来产生条件 高斯分布 的均值：
p(yjx) =N(y;^y;I): (6.17)
最大化其对数似然此时等价于最小化 均方误差 。
最大似然框架也使得学习 高斯分布 的协方差矩阵更加容易，或更容易地使 高斯
分布的协方差矩阵作为输入的函数。然而，对于所有输入，协方差矩阵都必须被限
定成一个正定矩阵。线性输出层很难满足这种限定，所以通常使用其他的输出单元
来对协方差参数化。对协方差建模的方法将在第 6.2.2.4节中简要介绍。
因为线性模型不会饱和，所以它们易于采用基于梯度的优化算法，甚至可以使
用其他多种优化算法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 157
6.2.2.2 用于Bernoulli 输出分布的 sigmoid 单元
许多任务需要预测二值型变量 y的值。具有两个类的分类问题可以归结为这种
形式。
此时最大似然的方法是定义 y在 x条件下的 Bernoulli 分布。
Bernoulli 分布仅需单个参数来定义。神经网络只需要预测 P(y= 1jx)即可。
为了使这个数是有效的概率，它必须处在区间 [0;1]中。
为满足该约束条件需要一些细致的设计工作。假设我们打算使用线性单元，并
且通过阈值来限制它成为一个有效的概率：
P(y= 1jx) = max{
0;minf1;w⊤h+bg}
: (6.18)
这的确定义了一个有效的条件概率分布，但我们无法使用梯度下降来高效地训练它。
当 w⊤h+b处于单位区间外时，模型的输出对其参数的梯度都将为 0。梯度为 0通
常是有问题的，因为学习算法对于如何改善相应的参数不再具有指导意义。
相反，最好是使用一种新的方法来保证无论何时模型给出了错误的答案时，总
能有一个较大的梯度。这种方法是基于使用 sigmoid输出单元结合最大似然来实现
的。
sigmoid输出单元定义为
^y=(
w⊤h+b)
; (6.19)
这里 是第 3.10节中介绍的 logistic sigmoid 函数。
我们可以认为 sigmoid输出单元具有两个部分。首先，它使用一个线性层来计
算z= w⊤h+b。接着，它使用 sigmoid激活函数将 z转化成概率。
我们暂时忽略对于 x的依赖性，只讨论如何用 z的值来定义 y的概率分布。
sigmoid可以通过构造一个非归一化（和不为 1）的概率分布 ~P(y)来得到。我们可
以随后除以一个合适的常数来得到有效的概率分布。如果我们假定非归一化的对数
概率对 y和z是线性的，可以对它取指数来得到非归一化的概率。我们然后对它归DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
158 第六章 深度前馈网络
一化，可以发现这服从 Bernoulli 分布，该分布受 z的sigmoid变换控制：
log~P(y) =yz; (6.20)
~P(y) = exp(yz); (6.21)
P(y) =exp(yz)∑1
y′=0 exp(y′z); (6.22)
P(y) =((2y 1)z): (6.23)
基于指数和归一化的概率分布在统计建模的文献中很常见。用于定义这种二值型变
量分布的变量 z被称为分对数（logit） 。
这种在对数空间里预测概率的方法可以很自然地使用最大似然学习。因为用于
最大似然的代价函数是  logP(yjx)，代价函数中的 log抵消了 sigmoid中的 exp。
如果没有这个效果， sigmoid的饱和性会阻止基于梯度的学习做出好的改进。我们使
用最大似然来学习一个由 sigmoid参数化的 Bernoulli 分布，它的损失函数为
J() = logP(yjx) (6.24)
= log((2y 1)z) (6.25)
=((1 2y)z): (6.26)
这个推导使用了第 3.10节中的一些性质。通过将损失函数写成 softplus函数的
形式，我们可以看到它仅仅在 (1 2y)z取绝对值非常大的负值时才会饱和。因此饱
和只会出现在模型已经得到正确答案时——当 y= 1且z取非常大的正值时，或者
y= 0且z取非常小的负值时。当 z的符号错误时， softplus函数的变量 (1 2y)z
可以简化为jzj。当jzj变得很大并且 z的符号错误时， softplus函数渐近地趋向于它
的变量jzj。对 z求导则渐近地趋向于 sign(z)，所以，对于极限情况下极度不正确的
z，softplus函数完全不会收缩梯度。这个性质很有用，因为它意味着基于梯度的学
习可以很快地改正错误的 z。
当我们使用其他的损失函数，例如 均方误差 之类的，损失函数会在 (z)饱和时
饱和。 sigmoid激活函数在 z取非常小的负值时会饱和到 0，当 z取非常大的正值时
会饱和到 1。这种情况一旦发生，梯度会变得非常小以至于不能用来学习，无论此时
模型给出的是正确还是错误的答案。因此，最大似然几乎总是训练 sigmoid输出单
元的优选方法。
理论上， sigmoid的对数总是确定和有限的，因为 sigmoid的返回值总是被限制
在开区间 (0;1)上，而不是使用整个闭区间 [0;1]的有效概率。在软件实现时，为了DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 159
避免数值问题，最好将负的对数似然写作 z的函数，而不是 ^y=(z)的函数。如
果sigmoid函数下溢到零，那么之后对 ^y取对数会得到负无穷。
6.2.2.3 用于Multinoulli 输出分布的 softmax 单元
任何时候当我们想要表示一个具有 n个可能取值的离散型随机变量的分布时，
我们都可以使用 softmax函数。它可以看作是 sigmoid函数的扩展，其中 sigmoid函
数用来表示二值型变量的分布。
softmax 函数最常用作分类器的输出，来表示 n个不同类上的概率分布。比较
少见的是， softmax 函数可以在模型内部使用，例如如果我们想要在某个内部变量的
n个不同选项中进行选择。
在二值型变量的情况下，我们希望计算一个单独的数
^y=P(y= 1jx): (6.27)
因为这个数需要处在 0和1之间，并且我们想要让这个数的对数可以很好地用于对
数似然的基于梯度的优化，我们选择去预测另外一个数 z= log^P(y= 1jx)。对其
指数化和归一化，我们就得到了一个由 sigmoid函数控制的 Bernoulli 分布。
为了推广到具有 n个值的离散型变量的情况，我们现在需要创造一个向量 ^y，
它的每个元素是 ^yi=P(y=ijx)。我们不仅要求每个 ^yi元素介于 0和1之间，还
要使得整个向量的和为 1，使得它表示一个有效的概率分布。用于 Bernoulli 分布的
方法同样可以推广到 Multinoulli 分布。首先，线性层预测了未归一化的对数概率：
z= W⊤h+b; (6.28)
其中 zi= log^P(y=ijx)。softmax 函数然后可以对 z指数化和归一化来获得需要
的^y。最终， softmax 函数的形式为
softmax (z)i=exp(zi)∑
jexp(zj): (6.29)
和logistic sigmoid 一样，当使用最大化对数似然训练 softmax 来输出目标值 y
时，使用指数函数工作地非常好。这种情况下，我们想要最大化 logP(y=i;z) =
logsoftmax (z)i。将 softmax 定义成指数的形式是很自然的因为对数似然中的 log可
以抵消 softmax 中的 exp：
logsoftmax (z)i=zi log∑
jexp(zj): (6.30)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
160 第六章 深度前馈网络
式(6.30)中的第一项表示输入 zi总是对代价函数有直接的贡献。因为这一项不
会饱和，所以即使 zi对式 (6.30)的第二项的贡献很小，学习依然可以进行。当最大化
对数似然时， 第一项鼓励 zi被推高， 而第二项则鼓励所有的 z被压低。 为了对第二项
log∑
jexp(zj)有一个直观的理解，注意到这一项可以大致近似为 max jzj。这种近似
是基于对任何明显小于 max jzj的zk，exp(zk)都是不重要的。我们能从这种近似中
得到的直觉是，负对数似然代价函数总是强烈地惩罚最活跃的不正确预测。如果正确
答案已经具有了 softmax 的最大输入，那么  zi项和 log∑
jexp(zj) max jzj=zi
项将大致抵消。这个样本对于整体训练代价贡献很小，这个代价主要由其他未被正
确分类的样本产生。
到目前为止我们只讨论了一个例子。总体来说，未正则化的最大似然会驱动模
型去学习一些参数，而这些参数会驱动 softmax 函数来预测在训练集中观察到的每
个结果的比率：
softmax (z(x;))i∑m
j=11y(j)=i;x(j)=x∑m
j=11x(j)=x: (6.31)
因为最大似然是一致的估计量，所以只要模型族能够表示训练的分布，这就能保证
发生。在实践中，有限的模型能力和不完美的优化将意味着模型只能近似这些比率。
除了对数似然之外的许多目标函数对 softmax 函数不起作用。具体来说，那些
不使用对数来抵消 softmax 中的指数的目标函数，当指数函数的变量取非常小的负
值时会造成梯度消失，从而无法学习。特别是，平方误差对于 softmax 单元来说是一
个很差的损失函数，即使模型做出高度可信的不正确预测，也不能训练模型改变其
输出 (Bridle ,1990)。要理解为什么这些损失函数可能失败，我们需要检查 softmax
函数本身。
像sigmoid一样， softmax 激活函数可能会饱和。 sigmoid函数具有单个输出，
当它的输入极端负或者极端正时会饱和。对于 softmax 的情况，它有多个输出值。
当输入值之间的差异变得极端时，这些输出值可能饱和。当 softmax 饱和时，基于
softmax 的许多代价函数也饱和，除非它们能够转化饱和的激活函数。
为了说明 softmax 函数对于输入之间差异的响应，观察到当对所有的输入都加
上一个相同常数时 softmax 的输出不变：
softmax (z) =softmax (z+c): (6.32)
使用这个性质，我们可以导出一个数值方法稳定的 softmax 函数的变体：
softmax (z) =softmax (z max
izi): (6.33)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 161
变换后的形式允许我们在对 softmax 函数求值时只有很小的数值误差，即使是当 z
包含极正或者极负的数时。观察 softmax 数值稳定的变体，可以看到 softmax 函数
由它的变量偏离 max izi的量来驱动。
当其中一个输入是最大（ zi= max izi）并且 zi远大于其他的输入时，相应的
输出 softmax (z)i会饱和到 1。当 zi不是最大值并且最大值非常大时，相应的输出
softmax (z)i也会饱和到 0。这是 sigmoid单元饱和方式的一般化，并且如果损失函
数不被设计成对其进行补偿，那么也会造成类似的学习困难。
softmax 函数的变量 z可以通过两种方式产生。最常见的是简单地使神经网络
较早的层输出 z的每个元素，就像先前描述的使用线性层 z=W⊤h+b。虽然很直
观，但这种方法是对分布的过度参数化。 n个输出总和必须为 1的约束意味着只有
n 1个参数是必要的；第 n个概率值可以通过 1减去前面 n 1个概率来获得。因
此，我们可以强制要求 z的一个元素是固定的。例如，我们可以要求 zn= 0。事实
上，这正是 sigmoid单元所做的。定义 P(y= 1jx) =(z)等价于用二维的 z以及
z1= 0来定义 P(y= 1jx) =softmax (z)1。无论是 n 1个变量还是 n个变量的方
法，都描述了相同的概率分布，但会产生不同的学习机制。在实践中，无论是过度
参数化的版本还是限制的版本都很少有差别，并且实现过度参数化的版本更为简单。
从神经科学的角度看，有趣的是认为 softmax 是一种在参与其中的单元之间形
成竞争的方式： softmax 输出总是和为 1，所以一个单元的值增加必然对应着其他单
元值的减少。这与被认为存在于皮质中相邻神经元间的侧抑制类似。在极端情况下
（当最大的 ai和其他的在幅度上差异很大时） ，它变成了 赢者通吃 （winner-take-all ）
的形式（其中一个输出接近 1，其他的接近 0） 。
“softmax’’ 的名称可能会让人产生困惑。这个函数更接近于 argmax函数而不是
max函数。 “soft’’这个术语来源于 softmax 函数是连续可微的。 “argmax’’ 函数的结
果表示为一个 one-hot向量（只有一个元素为 1，其余元素都为 0的向量） ，不是连续
和可微的。 softmax 函数因此提供了 argmax的‘‘软化’’版本。 max函数相应的软化
版本是 softmax (z)⊤z。可能最好是把 softmax 函数称为 “softargmax’’ ，但当前名称
已经是一个根深蒂固的习惯了。
6.2.2.4 其他的输出类型
之前描述的线性、 sigmoid和softmax 输出单元是最常见的。神经网络可以推广
到我们希望的几乎任何种类的输出层。最大似然原则给如何为几乎任何种类的输出DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
162 第六章 深度前馈网络
层设计一个好的代价函数提供了指导。
一般的，如果我们定义了一个条件分布 p(yjx;)，最大似然原则建议我们使用
 logp(yjx;)作为代价函数。
一般来说，我们可以认为神经网络表示函数 f(x;)。这个函数的输出不是对 y
值的直接预测。相反， f(x;) =!提供了 y分布的参数。我们的损失函数就可以表
示成 logp(y;!(x))。
例如，我们想要学习在给定 x时， y的条件高斯分布 的方差。简单情况下，方
差2是一个常数，此时有一个解析表达式，这是因为方差的最大似然估计量仅仅是
观测值 y与它们的期望值的差值的平方平均。一种计算上代价更加高但是不需要写
特殊情况代码的方法是简单地将方差作为分布 p(yjx)的其中一个属性，这个分布
由!=f(x;)控制。负对数似然  logp(y;!(x))将为代价函数提供一个必要的合
适项来使我们的优化过程可以逐渐地学到方差。在标准差不依赖于输入的简单情况
下，我们可以在网络中创建一个直接复制到 !中的新参数。这个新参数可以是 本
身，或者可以是表示 2的参数 v，或者可以是表示1
2的参数 ，取决于我们怎样
对分布参数化。我们可能希望模型对不同的 x值预测出 y不同的方差。这被称为 异
方差（heteroscedastic ）模型。在异方差情况下，我们简单地把方差指定为 f(x;)
其中一个输出值。实现它的典型方法是使用精度而不是方差来表示 高斯分布 ，就像
式(3.22)所描述的。在多维变量的情况下，最常见的是使用一个对角精度矩阵
diag(): (6.34)
这个公式适用于梯度下降，因为由 参数化的 高斯分布 的对数似然的公式仅涉及 i
的乘法和 logi的加法。乘法、加法和对数运算的梯度表现良好。相比之下，如果
我们用方差来参数化输出，我们需要用到除法。除法函数在零附近会变得任意陡峭。
虽然大梯度可以帮助学习，但任意大的梯度通常导致不稳定。如果我们用标准差来
参数化输出，对数似然仍然会涉及除法，并且还将涉及平方。通过平方运算的梯度
可能在零附近消失，这使得学习被平方的参数变得困难。无论我们使用的是标准差，
方差还是精度，我们必须确保 高斯分布 的协方差矩阵是正定的。因为精度矩阵的特
征值是协方差矩阵特征值的倒数，所以这等价于确保精度矩阵是正定的。如果我们
使用对角矩阵，或者是一个常数乘以单位矩阵1，那么我们需要对模型输出强加的唯
一条件是它的元素都为正。如果我们假设 a是用于确定对角精度的模型的原始激活，
1译者注：这里原文是 “If we use a diagonal matrix, or a scalar times the diagonal matrix... ’’ 即‘‘如果我们使
用对角矩阵，或者是一个标量乘以对角矩阵 ... ’’，但一个标量乘以对角矩阵和对角矩阵没区别，结合上下文可以看出，
这里原作者误把 “identity’’ 写成了 “diagonal matrix’’ ，因此这里采用 ‘‘常数乘以单位矩阵 ’’的译法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.2基于梯度的学习 163
那么可以用 softplus函数来获得正的精度向量： =(a)。这种相同的策略对于方
差或标准差同样适用，也适用于常数乘以单位阵的情况。
学习一个比对角矩阵具有更丰富结构的协方差或者精度矩阵是很少见的。如果
协方差矩阵是满的和有条件的，那么参数化的选择就必须要保证预测的协方差矩阵
是正定的。这可以通过写成 (x) = B(x)B⊤(x)来实现，这里 B是一个无约束的
方阵。如果矩阵是满秩的，那么一个实际问题是计算代价似然是很高的，计算一个
dd的矩阵的行列式或者 (x)的逆（或者等价地并且更常用地，对它特征值分解
或者 B(x)的特征值分解）需要 O(d3)的计算量。
我们经常想要执行多峰回归 (multimodal regression) ，即预测条件分布 p(yjx)
的实值，该条件分布对于相同的 x值在 y空间中有多个不同的峰值。在这种情况下，
高斯混合是输出的自然表示 (Jacobs et al. ,1991;Bishop ,1994)。将高斯混合作为其
输出的神经网络通常被称为 混合密度网络 （mixture density network ） 。具有 n个分
量的高斯混合输出由下面的条件分布定义：
p(yjx) =n∑
i=1p(c=ijx)N(y;(i)(x);(i)(x)): (6.35)
神经网络必须有三个输出：定义 p(c=ijx)的向量，对所有的 i给出(i)(x)的矩
阵，以及对所有的 i给出(i)(x)的张量。这些输出必须满足不同的约束：
1.混合组件 p(c=ijx)：它们由 潜变量2c关联着，在 n个不同组件上形
成Multinoulli 分布。这个分布通常可以由 n维向量的 softmax 来获得，以确
保这些输出是正的并且和为 1。
2.均值(i)(x)：它们指明了与第 i个高斯组件相关联的中心或者均值，并且是无
约束的（通常对于这些输出单元完全没有非线性） 。如果 y是个 d维向量，那
么网络必须输出一个由 n个这种 d维向量组成的 nd的矩阵。用最大似然来
学习这些均值要比学习只有一个输出模式的分布的均值稍稍复杂一些。我们只
想更新那个真正产生观测数据的组件的均值。在实践中，我们并不知道是哪个
组件产生了观测数据。负对数似然表达式将每个样本对每个组件的贡献进行赋
权，权重的大小由相应的组件产生这个样本的概率来决定。
2我们之所以认为 c是潜在的，是因为我们不能直接在数据中观测到它：给定输入 x和目标 y，不可能确切地知道
是哪个高斯组件产生 y，但我们可以想象 y是通过选择其中一个来产生的，并且将那个未被观测到的选择作为随机变
量。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
164 第六章 深度前馈网络
3.协方差 (i)(x)：它们指明了每个组件 i的协方差矩阵。和学习单个高斯组件时
一样，我们通常使用对角矩阵来避免计算行列式。和学习混合均值时一样，最
大似然是很复杂的，它需要将每个点的部分责任分配给每个混合组件。如果给
定了混合模型的正确的负对数似然，梯度下降将自动地遵循正确的过程。
有报告说基于梯度的优化方法对于混合条件高斯（作为神经网络的输出）可能是不
可靠的，部分是因为涉及到除法（除以方差）可能是数值不稳定的（当某个方差对于
特定的实例变得非常小时，会导致非常大的梯度） 。一种解决方法是 梯度截断 （clip
gradient） （见第 10.11.1节） ，另外一种是启发式缩放梯度 (Murray and Larochelle ,
2014)。
高斯混合输出在语音生成模型 (Schuster ,1999)和物理运动 (Graves ,2013)中特
别有效。混合密度策略为网络提供了一种方法来表示多种输出模式，并且控制输出
的方差，这对于在这些实数域中获得高质量的结果是至关重要的。混合密度网络的
一个实例如图 6.4所示。
xy
图6.4:从具有混合密度输出层的神经网络中抽取的样本。输入 x从均匀分布 中采样，输出 y从
pmodel (yjx)中采样。神经网络能够学习从输入到输出分布的参数的非线性映射。这些参数包括控
制三个组件中的哪一个将产生输出的概率，以及每个组件各自的参数。每个混合组件都是 高斯分
布，具有预测的均值和方差。输出分布的这些方面都能够相对输入 x变化，并且以非线性的方式
改变。
一般的，我们可能希望继续对包含更多变量的、更大的向量 y来建模，并在
这些输出变量上施加更多更丰富的结构。例如，我们可能希望神经网络输出字符序
列形成一个句子。在这些情况下，我们可以继续使用最大似然原理应用到我们的模DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.3隐藏单元 165
型p(y;!(x))上，但我们用来描述 y的模型会变得非常复杂，超出了本章的范畴。
第十章描述了如何使用循环神经网络来定义这种序列上的模型，第 三部分描述了对
任意概率分布进行建模的高级技术。
6.3隐藏单元
到目前为止，我们集中讨论了神经网络的设计选择，这对于使用基于梯度的优化
方法来训练的大多数参数化机器学习模型都是通用的。现在我们转向一个 前馈神经
网络独有的问题：该如何选择 隐藏单元 的类型，这些 隐藏单元 用在模型的 隐藏层中。
隐藏单元 的设计是一个非常活跃的研究领域，并且还没有许多明确的指导性理
论原则。
整流线性单元 是隐藏单元 极好的默认选择。许多其他类型的 隐藏单元 也是可用
的。决定何时使用哪种类型的 隐藏单元 是困难的事（尽管 整流线性单元 通常是一个
可接受的选择） 。我们这里描述对于每种 隐藏单元 的一些基本直觉。这些直觉可以用
来建议我们何时来尝试一些单元。通常不可能预先预测出哪种 隐藏单元 工作得最好。
设计过程充满了试验和错误，先直觉认为某种 隐藏单元 可能表现良好，然后用它组
成神经网络进行训练，最后用验证集来评估它的性能。
这里列出的一些 隐藏单元 可能并不是在所有的输入点上都是可微的。例如， 整
流线性单元 g(z) = maxf0; zg在z= 0处不可微。这似乎使得 g对于基于梯度的学
习算法无效。在实践中，梯度下降对这些机器学习模型仍然表现得足够好。部分原因
是神经网络训练算法通常不会达到代价函数的局部最小值，而是仅仅显著地减小它
的值，如图 4.3所示。这些想法会在第 八章中进一步描述。因为我们不再期望训练能
够实际到达梯度为 0的点，所以代价函数的最小值对应于梯度未定义的点是可以接
受的。不可微的 隐藏单元 通常只在少数点上不可微。一般来说，函数 g(z)具有左导
数和右导数，左导数定义为紧邻在 z左边的函数的斜率，右导数定义为紧邻在 z右
边的函数的斜率。只有当函数在 z处的左导数和右导数都有定义并且相等时，函数
在z点处才是可微的。神经网络中用到的函数通常对左导数和右导数都有定义。在
g(z) = maxf0; zg的情况下，在 z= 0处的左导数是 0，右导数是 1。神经网络训练
的软件实现通常返回左导数或右导数的其中一个，而不是报告导数未定义或产生一
个错误。这可以通过观察到在数字计算机上基于梯度的优化总是会受到数值误差的
影响来启发式地给出理由。当一个函数被要求计算 g(0)时，底层值真正为 0是不太DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
166 第六章 深度前馈网络
可能的。相对的，它可能是被舍入为 0的一个小量 ϵ。在某些情况下，理论上有更好
的理由，但这些通常对神经网络训练并不适用。重要的是，在实践中，我们可以放
心地忽略下面描述的 隐藏单元 激活函数的不可微性。
除非另有说明，大多数的 隐藏单元 都可以描述为接受输入向量 x，计算仿射变
换 z= W⊤x+b，然后使用一个逐元素的非线性函数 g(z)。大多数 隐藏单元 的区别
仅仅在于激活函数 g(z)的形式。
6.3.1整流线性单元及其扩展
整流线性单元 使用激活函数 g(z) = maxf0; zg。
整流线性单元 易于优化，因为它们和线性单元非常类似。线性单元和 整流线性
单元的唯一区别在于 整流线性单元 在其一半的定义域上输出为零。这使得只要 整流
线性单元 处于激活状态，它的导数都能保持较大。它的梯度不仅大而且一致。整流
操作的二阶导数几乎处处为 0，并且在 整流线性单元 处于激活状态时，它的一阶导数
处处为 1。这意味着相比于引入二阶效应的激活函数来说，它的梯度方向对于学习来
说更加有用。
整流线性单元 通常作用于仿射变换之上：
h=g(W⊤x+b): (6.36)
当初始化仿射变换的参数时，可以将 b的所有元素设置成一个小的正值，例如 0.1。
这使得整流线性单元 很可能初始时就对训练集中的大多数输入呈现激活状态，并且
允许导数通过。
有很多整流线性单元 的扩展存在。大多数这些扩展的表现比得上 整流线性单元 ，
并且偶尔表现得更好。
整流线性单元 的一个缺陷是它们不能通过基于梯度的方法学习那些使它们激活
为零的样本。 整流线性单元 的各种扩展保证了它们能在各个位置都接收到梯度。
整流线性单元 的三个扩展基于当 zi<0时使用一个非零的斜率 i：hi=
g(z;)i= max(0; zi) +imin(0; zi)。绝对值整流 （absolute value rectiﬁcation ）固
定i= 1来得到 g(z) =jzj。 它用于图像中的对象识别 (Jarrett et al. ,2009a )， 其中
寻找在输入照明极性反转下不变的特征是有意义的。 整流线性单元 的其他扩展比这
应用地更广泛。 渗漏整流线性单元 （Leaky ReLU ）(Maas et al. ,2013)将i固定成DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.3隐藏单元 167
一个类似 0.01的小值， 参数化整流线性单元 （parametric ReLU ）或者 PReLU 将
i作为学习的参数 (Heet al. ,2015)。
maxout 单元（maxout unit ）(Goodfellow et al. ,2013a )进一步扩展了 整流线
性单元。maxout单元将 z划分为每组具有 k个值的组，而不是使用作用于每个元
素的函数 g(z)。每个 maxout单元则输出每组中的最大元素：
g(z)i= max
j2G(i)zj (6.37)
这里G(i)是组 i的输入索引集f(i 1)k+ 1; : : : ; ikg。这提供了一种方法来学习对输
入 x空间中多个方向响应的分段线性函数。
maxout单元可以学习具有多达 k段的分段线性的凸函数。 maxout单元因此可
以视为学习激活函数 本身而不仅仅是单元之间的关系。使用足够大的 k，maxout单
元可以以任意的精确度来近似任何凸函数。特别地，具有两块的 maxout层可以学
习实现和传统层相同的输入 x的函数，这些传统层可以使用 整流线性 激活函数、 绝
对值整流 、渗漏整流线性单元 或参数化整流线性单元 ，或者可以学习实现与这些都
不同的函数。 maxout层的参数化当然也将与这些层不同，所以即使是 maxout学习
去实现和其他种类的层相同的 x的函数这种情况下，学习的机理也是不一样的。
每个 maxout单元现在由 k个权重向量来参数化， 而不仅仅是一个， 所以 maxout
单元通常比整流线性单元 需要更多的正则化。如果训练集很大并且每个单元的块数
保持很低的话，它们可以在没有正则化的情况下工作得不错 (Cai et al. ,2013)。
maxout单元还有一些其他的优点。在某些情况下，要求更少的参数可以获得一
些统计和计算上的优点。具体来说，如果由 n个不同的线性过滤器描述的特征可以
在不损失信息的情况下，用每一组 k个特征的最大值来概括的话，那么下一层可以
获得 k倍更少的权重数。
因为每个单元由多个过滤器驱动， maxout单元具有一些冗余来帮助它们抵抗一
种被称为 灾难遗忘 （catastrophic forgetting ）的现象，这个现象是说神经网络忘记
了如何执行它们过去训练的任务 (Goodfellow et al. ,2014a )。
整流线性单元 和它们的这些扩展都是基于一个原则，那就是如果它们的行为更
接近线性，那么模型更容易优化。使用线性行为更容易优化的一般性原则同样也适
用于除深度线性网络以外的情景。循环网络可以从序列中学习并产生状态和输出的
序列。当训练它们时，需要通过一些 时间步来传播信息，当其中包含一些线性计算
（具有大小接近 1的某些方向导数）时，这会更容易。作为性能最好的循环网络结构DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
168 第六章 深度前馈网络
之一， LSTM通过求和在时间上传播信息，这是一种特别直观的线性激活。它将在
第10.10节中进一步讨论。
6.3.2 logistic sigmoid 与双曲正切函数
在引入整流线性单元 之前，大多数神经网络使用 logistic sigmoid 激活函数
g(z) =(z) (6.38)
或者是双曲正切激活函数
g(z) =tanh (z): (6.39)
这些激活函数紧密相关，因为 tanh (z) = 2 (2z) 1。
我们已经看过 sigmoid单元作为输出单元用来预测二值型变量取值为 1的概率。
与分段线性单元不同， sigmoid单元在其大部分定义域内都饱和——当 z取绝对值
很大的正值时，它们饱和到一个高值，当 z取绝对值很大的负值时，它们饱和到一
个低值，并且仅仅当 z接近 0时它们才对输入强烈敏感。 sigmoid单元的广泛饱和
性会使得基于梯度的学习变得非常困难。因为这个原因，现在不鼓励将它们用作前
馈网络中的 隐藏单元 。当使用一个合适的代价函数来抵消 sigmoid的饱和性时，它
们作为输出单元可以与基于梯度的学习相兼容。
当必须要使用 sigmoid激活函数时，双曲正切激活函数通常要比 logistic sig-
moid函数表现更好。在 tanh (0) = 0而(0) =1
2的意义上，它更像是单位函数。因
为tanh在0附近与单位函数类似，训练深层神经网络 ^y= w⊤tanh (U⊤tanh (V⊤x))
类似于训练一个线性模型 ^y= w⊤U⊤V⊤x，只要网络的激活能够被保持地很小。这
使得训练 tanh网络更加容易。
sigmoid激活函数在除了 前馈网络 以外的情景中更为常见。循环网络、许多概率
模型以及一些 自编码器 有一些额外的要求使得它们不能使用分段线性激活函数，并
且使得 sigmoid单元更具有吸引力，尽管它存在饱和性的问题。
6.3.3其他隐藏单元
也存在许多其他种类的 隐藏单元 ，但它们并不常用。
一般来说，很多种类的可微函数都表现得很好。许多未发布的激活函数与流行
的激活函数表现得一样好。为了提供一个具体的例子，作者在 MNIST数据集上使DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.3隐藏单元 169
用 h= cos(Wx +b)测试了一个 前馈网络 ，并获得了小于 1%的误差率，这可以与
更为传统的激活函数获得的结果相媲美。在新技术的研究和开发期间，通常会测试
许多不同的激活函数，并且会发现许多标准方法的变体表现非常好。这意味着，通
常新的隐藏单元 类型只有在被明确证明能够提供显著改进时才会被发布。新的 隐藏
单元类型如果与已有的 隐藏单元 表现大致相当的话，那么它们是非常常见的，不会
引起别人的兴趣。
列出文献中出现的所有 隐藏单元 类型是不切实际的。我们只对一些特别有用和
独特的类型进行强调。
其中一种是完全没有激活函数 g(z)。也可以认为这是使用单位函数作为激活函
数的情况。我们已经看过线性单元可以用作神经网络的输出。它也可以用作 隐藏单
元。如果神经网络的每一层都仅由线性变换组成，那么网络作为一个整体也将是线
性的。然而，神经网络的一些层是纯线性也是可以接受的。考虑具有 n个输入和 p
个输出的神经网络层 h=g(W⊤x+b)。我们可以用两层来代替它，一层使用权重矩
阵 U，另一层使用权重矩阵 V。如果第一层没有激活函数，那么我们对基于 W的
原始层的权重矩阵进行因式分解。分解方法是计算 h=g(V⊤U⊤x+b)。如果 U产
生了 q个输出，那么 U和V一起仅包含 (n+p)q个参数，而 W包含 np个参数。
如果 q很小，这可以在很大程度上节省参数。这是以将线性变换约束为低秩的代价
来实现的，但这些低秩关系往往是足够的。线性 隐藏单元 因此提供了一种减少网络
中参数数量的有效方法。
softmax 单元是另外一种经常用作输出的单元（如第 6.2.2.3节中所描述的） ，但
有时也可以用作 隐藏单元 。softmax 单元很自然地表示具有 k个可能值的离散型随
机变量的概率分布，所以它们可以用作一种开关。这些类型的 隐藏单元 通常仅用于
明确地学习操作内存的高级结构中，将在第 10.12节中描述。
其他一些常见的 隐藏单元 类型包括：
•径向基函数 （radial basis function ,RBF） ：hi= exp(
 1
2
ijjW:;i xjj2)
。这个
函数在 x接近模板 W:;i时更加活跃。因为它对大部分 x都饱和到 0，因此很
难优化。
•softplus 函数： g(a) =(a) = log(1 + ea)。这是整流线性单元 的平滑版本，
由Dugas et al. (2001b )引入用于函数近似，由 Nair and Hinton (2010a )引入
用于无向概率模型的条件分布。 Glorot et al. (2011a )比较了 softplus和整流线
性单元，发现后者的结果更好。通常不鼓励使用 softplus函数。softplus表明隐DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
170 第六章 深度前馈网络
藏单元类型的性能可能是非常反直觉的——因为它处处可导或者因为它不完全
饱和，人们可能希望它具有优于 整流线性单元 的点，但根据经验来看，它并没
有。
•硬双曲正切函数 （hard tanh ） ：它的形状和 tanh以及整流线性单元 类似，但是
不同于后者，它是有界的， g(a) = max( 1;min(1; a))。它由 Collobert (2004)
引入。
隐藏单元 的设计仍然是一个活跃的研究领域，许多有用的 隐藏单元 类型仍有待
发现。
6.4架构设计
神经网络设计的另一个关键点是确定它的架构。 架构（architecture ）一词是指
网络的整体结构：它应该具有多少单元，以及这些单元应该如何连接。
大多数神经网络被组织成称为层的单元组。大多数神经网络架构将这些层布置
成链式结构，其中每一层都是前一层的函数。在这种结构中，第一层由下式给出：
h(1)=g(1)(
W(1)⊤x+b(1))
; (6.40)
第二层由
h(2)=g(2)(
W(2)⊤h(1)+b(2))
; (6.41)
给出，以此类推。
在这些链式架构中，主要的架构考虑是选择网络的深度和每一层的宽度。我们
将会看到，即使只有一个 隐藏层的网络也足够适应训练集。更深层的网络通常能够
对每一层使用更少的单元数和更少的参数，并且经常容易泛化到测试集，但是通常
也更难以优化。对于一个具体的任务，理想的网络架构必须通过实验，观测在验证
集上的误差来找到。
6.4.1万能近似性质和深度
线性模型，通过矩阵乘法将特征映射到输出，顾名思义，仅能表示线性函数。它
具有易于训练的优点，因为当使用线性模型时，许多损失函数会导出凸优化问题。不
幸的是，我们经常希望我们的系统学习非线性函数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.4架构设计 171
乍一看，我们可能认为学习非线性函数需要为我们想要学习的那种非线性专
门设计一类模型族。幸运的是，具有 隐藏层的前馈网络 提供了一种万能近似框架。
具体来说， 万能近似定理 （universal approximation theorem ）(Hornik et al. ,1989;
Cybenko ,1989)表明，一个 前馈神经网络 如果具有线性输出层和至少一层具有任何
一种 ‘‘挤压’’性质的激活函数（例如 logistic sigmoid 激活函数）的 隐藏层，只要给予
网络足够数量的 隐藏单元 ，它可以以任意的精度来近似任何从一个有限维空间到另
一个有限维空间的 Borel可测函数。 前馈网络 的导数也可以任意好地来近似函数的
导数 (Hornik et al. ,1990)。Borel可测的概念超出了本书的范畴；对于我们想要实
现的目标，只需要知道定义在 Rn的有界闭集上的任意连续函数是 Borel可测的，
因此可以用神经网络来近似。神经网络也可以近似从任何有限维离散空间映射到另
一个的任意函数。虽然原始定理最初以具有特殊激活函数的单元的形式来描述，这
个激活函数当变量取绝对值非常大的正值和负值时都会饱和， 万能近似定理 也已经
被证明对于更广泛类别的激活函数也是适用的，其中就包括现在常用的 整流线性单
元(Leshno et al. ,1993)。
万能近似定理 意味着无论我们试图学习什么函数，我们知道一个大的 MLP一
定能够表示这个函数。然而，我们不能保证训练算法能够 学得这个函数。即使 MLP
能够表示该函数，学习也可能因两个不同的原因而失败。首先，用于训练的优化算
法可能找不到用于期望函数的参数值。其次，训练算法可能由于过拟合而选择了错
误的函数。回忆第 5.2.1节中的 ‘‘没有免费的午餐 ’’定理，说明了没有普遍优越的机
器学习算法。 前馈网络 提供了表示函数的万能系统，在这种意义上，给定一个函数，
存在一个 前馈网络 能够近似该函数。不存在万能的过程既能够验证训练集上的特殊
样本，又能够选择一个函数来扩展到训练集上没有的点。
万能近似定理 说明了，存在一个足够大的网络能够达到我们所希望的任意精度，
但是定理并没有说这个网络有多大。 Barron (1993)提供了单层网络近似一大类函数
所需大小的一些界。不幸的是，在最坏情况下，可能需要指数数量的 隐藏单元 （可能
一个隐藏单元 对应着一个需要区分的输入配置） 。这在二进制情况下很容易看到：向
量 v2f0;1gn上的可能的二进制函数的数量是 22n，并且选择一个这样的函数需要
2n位，这通常需要 O(2n)的自由度。
总之，具有单层的 前馈网络 足以表示任何函数，但是网络层可能大得不可实现，
并且可能无法正确地学习和 泛化。在很多情况下，使用更深的模型能够减少表示期
望函数所需的单元的数量，并且可以减少 泛化误差。
存在一些函数族能够在网络的深度大于某个值 d时被高效地近似，而当深度被DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
172 第六章 深度前馈网络
限制到小于或等于 d时需要一个远远大于之前的模型。在很多情况下，浅层模型所
需的隐藏单元 的数量是 n的指数级。这个结果最初被证明是在那些不与连续可微的
神经网络类似的机器学习模型中出现，但现在已经扩展到了这些模型。第一个结果
是关于逻辑门电路的 (Håstad ,1986)。后来的工作将这些结果扩展到了具有非负权
重的线性阈值单元 (Håstad and Goldmann ,1991;Hajnal et al. ,1993)，然后扩展到
了具有连续值激活的网络 (Maass ,1992;Maass et al. ,1994)。许多现代神经网络使
用整流线性单元 。Leshno et al. (1993)证明带有一大类非多项式激活函数族的浅层
网络，包括 整流线性单元 ，具有万能的近似性质，但是这些结果并没有强调深度或
效率的问题——它们仅指出足够宽的 整流网络 能够表示任意函数。 Montufar et al.
(2014)指出一些用深度 整流网络 表示的函数可能需要浅层网络（一个 隐藏层）指数
级的隐藏单元 才能表示。更确切的说，他们说明分段线性网络（可以通过整流非线
性或 maxout单元获得）可以表示区域的数量是网络深度的指数级的函数。图 6.5解
释了带有 绝对值整流 的网络是如何创建函数的镜像图像的，这些函数在某些 隐藏单
元的顶部计算，作用于 隐藏单元 的输入。每个 隐藏单元 指定在哪里折叠输入空间，来
创造镜像响应（在绝对值非线性的两侧） 。通过组合这些折叠操作，我们获得指数级
的分段线性区域，他们可以概括所有种类的规则模式（例如，重复） 。
图6.5:关于更深的整流网络具有指数优势的一个直观的几何解释，来自 Montufar et al. (2014)。
(左)绝对值整流 单元对其输入中的每对镜像点有相同的输出。镜像的对称轴由单元的权重和偏置
定义的超平面给出。在该单元顶部计算的函数（绿色决策面）将是横跨该对称轴的更简单模式的
一个镜像。 (中)该函数可以通过折叠对称轴周围的空间来得到。 (右)另一个重复模式可以在第一
个的顶部折叠（由另一个下游单元）以获得另外的对称性（现在重复四次，使用了两个 隐藏层） 。
经Montufar et al. (2014)许可改编此图。
Montufar et al. (2014)的主要定理指出，具有 d个输入、深度为 l、每个隐藏DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.4架构设计 173
层具有 n个单元的深度 整流网络 可以描述的线性区域的数量是
O((n
d)d(l 1)
nd)
; (6.42)
意味着，这是深度 l的指数级。在每个单元具有 k个过滤器的 maxout网络中，线
性区域的数量是
O(
k(l 1)+d)
: (6.43)
当然，我们不能保证在机器学习（特别是 AI）的应用中我们想要学得的函数类
型享有这样的属性。
我们还可能出于统计原因来选择深度模型。任何时候，当我们选择一个特定的机
器学习算法时，我们隐含地陈述了一些先验，这些先验是关于算法应该学得什么样的
函数的。选择深度模型默许了一个非常普遍的信念，那就是我们想要学得的函数应该
涉及几个更加简单的函数的组合。这可以从表示学习的观点来解释，我们相信学习的
问题包含发现一组潜在的 变差因素 ，它们可以根据其他更简单的潜在的 变差因素 来
描述。或者，我们可以将深度结构的使用解释为另一种信念，那就是我们想要学得的
函数是包含多个步骤的计算机程序，其中每个步骤使用前一步骤的输出。这些中间
输出不一定是 变差因素 ，而是可以类似于网络用来组织其内部处理的计数器或指针。
根据经验，更深的模型似乎确实在广泛的任务中泛化得更好 (Bengio et al. ,2007b ;
Erhan et al. ,2009;Bengio ,2009;Mesnil et al. ,2011;Ciresan et al. ,2012;Krizhevsky
et al. ,2012a ;Sermanet et al. ,2013;Farabet et al. ,2013;Couprie et al. ,2013;Kahou
et al. ,2013;Goodfellow et al. ,2014d ;Szegedy et al. ,2014a )。图 6.6和图 6.7展示了
一些实验结果的例子。这表明使用深层架构确实在模型学习的函数空间上表示了一
个有用的先验。
6.4.2其他架构上的考虑
目前为止，我们都将神经网络描述成层的简单链式结构，主要的考虑因素是网
络的深度和每层的宽度。在实践中，神经网络显示出相当的多样性。
许多神经网络架构已经被开发用于特定的任务。用于计算机视觉的卷积神经网
络的特殊架构将在第 九章中介绍。 前馈网络 也可以推广到用于序列处理的循环神经
网络，但有它们自己的架构考虑，将在第 十章中介绍。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
174 第六章 深度前馈网络
3 4 5 6 7 8 9 10 11
Number of hidden layers92:092:593:093:594:094:595:095:596:096:5Test accuracy (percent)
图6.6:深度的影响。实验结果表明，当从地址照片转录多位数字时，更深层的网络能够更好地 泛
化。数据来自 Goodfellow et al. (2014d )。测试集上的准确率随着深度的增加而不断增加。图 6.7给
出了一个对照实验，它说明了对模型尺寸其他方面的增加并不能产生相同的效果。
0:0 0:2 0:4 0:6 0:8 1:0
Number of parameters 10891929394959697Test accuracy (percent)
3, convolutional
3, fully connected
11, convolutional
图6.7:参数数量的影响。更深的模型往往表现更好。这不仅仅是因为模型更大。 Goodfellow et al.
(2014d )的这项实验表明，增加 卷积网络 层中参数的数量，但是不增加它们的深度，在提升测试集
性能方面几乎没有效果，如此图所示。图例标明了用于画出每条曲线的网络深度，以及曲线表示
的是卷积层还是全连接层的大小变化。我们可以观察到，在这种情况下，浅层模型在参数数量达
到2000万时就过拟合，而深层模型在参数数量超过 6000万时仍然表现良好。这表明，使用深层
模型表达出了对模型可以学习的函数空间的有用偏好。具体来说，它表达了一种信念，即该函数
应该由许多更简单的函数复合在一起而得到。这可能导致学习由更简单的表示所组成的表示（例
如，由边所定义的角）或者学习具有顺序依赖步骤的程序（例如，首先定位一组对象，然后分割它
们，之后识别它们） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 175
一般的，层不需要连接在链中，尽管这是最常见的做法。许多架构构建了一个
主链，但随后又添加了额外的架构特性，例如从层 i到层 i+ 2或者更高层的跳跃连
接。这些跳跃连接使得梯度更容易从输出层流向更接近输入的层。
架构设计考虑的另外一个关键点是如何将层与层之间连接起来。默认的神经网
络层采用矩阵 W描述的线性变换，每个输入单元连接到每个输出单元。在之后章节
中的许多专用网络具有较少的连接，使得输入层中的每个单元仅连接到输出层单元
的一个小子集。这些用于减少连接数量的策略减少了参数的数量以及用于评估网络
的计算量，但通常高度依赖于问题。例如，第 九章描述的卷积神经网络使用对于计
算机视觉问题非常有效的稀疏连接的专用模式。在这一章中，很难对通用神经网络
的架构给出更多具体的建议。我们在随后的章节中介绍一些特殊的架构策略，可以
在不同的领域工作良好。
6.5反向传播和其他的微分算法
当我们使用 前馈神经网络 接收输入 x并产生输出 ^y时，信息通过网络向前流
动。输入 x提供初始信息，然后传播到每一层的 隐藏单元 ，最终产生输出 ^y。这称
之为前向传播 （forward propagation ） 。在训练过程中，前向传播可以持续向前直
到它产生一个标量代价函数 J()。反向传播 （back propagation ）算法 (Rumelhart
et al. ,1986c )，经常简称为 backprop ，允许来自代价函数的信息通过网络向后流动，
以便计算梯度。
计算梯度的解析表达式是很直观的，但是数值化地求解这样的表达式在计算上
的代价可能很大。反向传播算法使用简单和廉价的程序来实现这个目标。
反向传播这个术语经常被误解为用于多层神经网络的整个学习算法。实际上，
反向传播仅指用于计算梯度的方法，而另一种算法，例如随机梯度下降，使用该梯度
来进行学习。此外，反向传播经常被误解为仅适用于多层神经网络，但是原则上它
可以计算任何函数的导数（对于一些函数，正确的响应是报告函数的导数是未定义
的） 。特别地，我们会描述如何计算一个任意函数 f的梯度∇ xf(x;y)，其中 x是一
组变量，我们需要它们的导数，而 y是函数的另外一组输入变量，但我们并不需要
它们的导数。在学习算法中，我们最常需要的梯度是代价函数关于参数的梯度，即
∇J()。许多机器学习任务需要计算其他导数，来作为学习过程的一部分，或者用
来分析学得的模型。反向传播算法也适用于这些任务，不局限于计算代价函数关于DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
176 第六章 深度前馈网络
参数的梯度。通过在网络中传播信息来计算导数的想法非常普遍，它还可以用于计
算诸如多输出函数 f的Jacobian 的值。我们这里描述的是最常用的情况，其中 f
只有单个输出。
6.5.1计算图
目前为止，我们已经用相对非正式的图形语言讨论了神经网络。为了更精确地
描述反向传播算法，使用更精确的 计算图（computational graph ）语言是很有帮助
的。
将计算形式化为图形的方法有很多。
这里，我们使用图中的每一个节点来表示一个变量。变量可以是标量、向量、矩
阵、张量、或者甚至是另一类型的变量。
为了形式化我们的图形，我们还需引入 操作（operation ）这一概念。操作是指
一个或多个变量的简单函数。我们的图形语言伴随着一组被允许的操作。我们可以
通过将多个操作复合在一起来描述更为复杂的函数。
不失一般性，我们定义一个操作仅返回单个输出变量。这并没有失去一般性，是
因为输出变量可以有多个条目，例如向量。反向传播的软件实现通常支持具有多个
输出的操作，但是我们在描述中避免这种情况，因为它引入了对概念理解不重要的
许多额外细节。
如果变量 y是变量 x通过一个操作计算得到的，那么我们画一条从 x到y的有
向边。我们有时用操作的名称来注释输出的节点，当上下文很明确时，有时也会省
略这个标注。
计算图的实例可以参考图 6.8。
6.5.2微积分中的链式法则
微积分中的链式法则（为了不与概率中的链式法则相混淆）用于计算复合函数
的导数。反向传播是一种计算链式法则的算法，使用高效的特定运算顺序。
设x是实数， f和g是从实数映射到实数的函数。假设 y=g(x)并且 z=DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 177
zzxxyy(a)⇥xxww(b)u(1)u(1)dotbbu(2)u(2)+ˆyˆy 
(c)XXWWU(1)U(1)matmulbbU(2)U(2)+HHrelu
xxww(d)ˆyˆydot  u(1)u(1)sqru(2)u(2)sumu(3)u(3)⇥
图6.8:一些计算图的示例。 (a)使用操作计算 z=xy的图。 (b)用于逻辑回归 预测 ^y=
(x⊤w+b)的图。一些中间表达式在代数表达式中没有名称，但在图形中却需要。我们简单地将
第i个这样的变量命名为 u(i)。(c)表达式 H= maxf0;XW +bg的计算图，在给定包含小批量
输入数据的设计矩阵 X时，它计算 整流线性单元 激活的设计矩阵 H。(d)示例 a-c对每个变量最
多只实施一个操作，但是对变量实施多个操作也是可能的。这里我们展示一个计算图，它对线性
回归模型的权重 w实施多个操作。这个权重不仅用于预测 ^y，也用于权重衰减罚项 ∑
iw2
i。
f(g(x)) =f(y)。那么链式法则是说
dz
dx=dz
dydy
dx: (6.44)
我们可以将这种标量情况进行扩展。假设 x2Rm;y2Rn，g是从Rm到Rn的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
178 第六章 深度前馈网络
映射， f是从Rn到R的映射。如果 y=g(x)并且 z=f(y)，那么
@z
@xi=∑
j@z
@yj@yj
@xi: (6.45)
使用向量记法，可以等价地写成
∇ xz=(@y
@x)⊤
∇ yz; (6.46)
这里@y
@x是g的nm的Jacobian 矩阵。
从这里我们看到，变量 x的梯度可以通过 Jacobian 矩阵@y
@x和梯度∇ yz相乘来
得到。反向传播算法由图中每一个这样的 Jacobian 梯度的乘积操作所组成。
通常我们将反向传播算法应用于任意维度的张量，而不仅仅用于向量。从概念
上讲，这与使用向量的反向传播完全相同。唯一的区别是如何将数字排列成网格以
形成张量。我们可以想象，在我们运行反向传播之前，将每个张量变平为一个向量，
计算一个向量值梯度，然后将该梯度重新构造成一个张量。从这种重新排列的观点
上看，反向传播仍然只是将 Jacobian 乘以梯度。
为了表示值 z关于张量 X的梯度，我们记为 ∇Xz，就像 X是向量一样。 X的
索引现在有多个坐标——例如，一个 3维的张量由三个坐标索引。我们可以通过
使用单个变量 i来表示完整的索引元组，从而完全抽象出来。对所有可能的元组 i，
(∇Xz)i给出@z
@Xi。这与向量中索引的方式完全一致， (∇ xz)i给出@z
@xi。使用这种记
法，我们可以写出适用于张量的链式法则。如果 Y=g(X)并且 z=f(Y)，那么
∇Xz=∑
j(∇XYj)@z
@Yj: (6.47)
6.5.3递归地使用链式法则来实现反向传播
使用链式规则，我们可以直接写出某个标量关于计算图中任何产生该标量的节
点的梯度的代数表达式。然而，实际在计算机中计算该表达式时会引入一些额外的
考虑。
具体来说，许多子表达式可能在梯度的整个表达式中重复若干次。任何计算梯
度的程序都需要选择是存储这些子表达式还是重新计算它们几次。图 6.9给出了一个
例子来说明这些重复的子表达式是如何出现的。在某些情况下，计算两次相同的子
表达式纯粹是浪费。在复杂图中，可能存在指数多的这种计算上的浪费，使得简单DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 179
的链式法则不可实现。在其他情况下，计算两次相同的子表达式可能是以较高的运
行时间为代价来减少内存开销的有效手段。
我们首先给出一个版本的反向传播算法，它指明了梯度的直接计算方式（算
法6.2以及相关的正向计算的算法 6.1） ，按照它实际完成的顺序并且递归地使用链
式法则。我们可以直接执行这些计算或者将算法的描述视为用于计算反向传播的计
算图的符号表示。然而，这些公式并没有明确地操作和构造用于计算梯度的符号图。
这些公式将在后面的第 6.5.6节和算法 6.5中给出，其中我们还推广到了包含任意张
量的节点。
首先考虑描述如何计算单个标量 u(n)（例如训练样本上的损失函数）的计算图。
我们想要计算这个标量对 ni个输入节点 u(1)到u(ni)的梯度。换句话说，我们希望
对所有的 i2f1;2; : : : ; n ig计算@u(n)
@u(i)。在使用反向传播计算梯度来实现参数的梯度
下降时， u(n)将对应单个或者小批量实例的代价函数，而 u(1)到u(ni)则对应于模型
的参数。
我们假设图的节点已经以一种特殊的方式被排序，使得我们可以一个接一个地
计算他们的输出，从 u(ni+1)开始，一直上升到 u(n)。如算法 6.1中所定义的，每个
节点 u(i)与操作 f(i)相关联，并且通过对以下函数求值来得到
u(i)=f(A(i)); (6.48)
其中A(i)是u(i)所有父节点的集合。
该算法详细说明了前向传播的计算，我们可以将其放入图 G中。为了执行反向
传播，我们可以构造一个依赖于 G并添加额外一组节点的计算图。这形成了一个子
图B，它的每个节点都是 G的节点。B中的计算和G中的计算顺序完全相反，而且
B中的每个节点计算导数@u(n)
@u(i)与前向图中的节点 u(i)相关联。这通过对标量输出
u(n)使用链式法则来完成：
@u(n)
@u(j)=∑
i:j2Pa(u(i))@u(n)
@u(i)@u(i)
@u(j)(6.49)
这在算法 6.2中详细说明。子图 B恰好包含每一条对应着 G中从节点 u(j)到节点
u(i)的边。从 u(j)到u(i)的边对应着计算@u(i)
@u(j)。另外，对于每个节点都要执行一个
内积，内积的一个因子是对于 uj子节点 u(i)的已经计算的梯度，另一个因子是对于
相同子节点 u(i)的偏导数@u(i)
@u(j)组成的向量。总而言之，执行反向传播所需的计算量
与G中的边的数量成比例，其中每条边的计算包括计算偏导数（节点关于它的一个DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
180 第六章 深度前馈网络
算法 6.1计算将 ni个输入 u(1)到u(ni)映射到一个输出 u(n)的程序。这定义了一
个计算图，其中每个节点通过将函数 f(i)应用到变量集合 A(i)上来计算 u(i)的值，
A(i)包含先前节点 u(j)的值满足 j < i且j2Pa(u(i))。计算图的输入是向量 x，并
且被分配给前 ni个节点 u(1)到u(ni)。计算图的输出可以从最后一个（输出）节点
u(n)读出。
fori= 1; : : : ; n ido
u(i) xi
end for
fori=ni+ 1; : : : ; n do
A(i) fu(j)jj2Pa(u(i))g
u(i) f(i)(A(i))
end for
return u(n)
父节点的偏导数）以及执行一次乘法和一次加法。下面，我们将此分析推广到张量
值节点，这只是在同一节点中对多个标量值进行分组并能够更高效地实现。
反向传播算法被设计为减少公共子表达式的数量而不考虑存储的开销。具体来
说，它大约对图中的每个节点执行一个 Jacobian 乘积。这可以从算法 6.2中看出，反
向传播算法访问了图中的节点 u(j)到节点 u(i)的每条边一次，以获得相关的偏导数
@u(i)
@u(j)。反向传播因此避免了重复子表达式的指数爆炸。然而，其他算法可能通过对
计算图进行简化来避免更多的子表达式，或者也可能通过重新计算而不是存储这些
子表达式来节省内存。我们将在描述完反向传播算法本身后再重新审视这些想法。
6.5.4全连接 MLP中的反向传播计算
为了阐明反向传播的上述定义，让我们考虑一个与全连接的多层 MLP相关联
的特定图。
算法 6.3首先给出了前向传播，它将参数映射到与单个训练样本（输入，目标）
(x;y)相关联的监督损失函数 L(^y;y)，其中 ^y是当 x提供输入时神经网络的输出。
算法 6.4随后说明了将反向传播应用于改图所需的相关计算。
算法 6.3和算法 6.4是简单而直观的演示。然而，它们专门针对特定的问题。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 181
zz
xxyy
wwfff
图6.9:计算梯度时导致重复子表达式的计算图。令 w2R为图的输入。我们对链中的每一步使
用相同的操作函数 f:R!R，这样 x=f(w); y=f(x); z=f(y)。为了计算@z
@w，我们应用
式(6.44)得到：
@z
@w(6.50)
=@z
@y@y
@x@x
@w(6.51)
=f′(y)f′(x)f′(w) (6.52)
=f′(f(f(w)))f′(f(w))f′(w): (6.53)
式(6.52)建议我们采用的实现方式是，仅计算 f(w)的值一次并将它存储在变量 x中。这是 反
向传播算法所采用的方法。式 (6.53)提出了一种替代方法，其中子表达式 f(w)出现了不止一
次。在替代方法中，每次只在需要时重新计算 f(w)。当存储这些表达式的值所需的存储较少时，
式(6.52)的反向传播 方法显然是较优的，因为它减少了运行时间。然而，式 (6.53)也是链式法则的
有效实现，并且当存储受限时它是有用的。
现在的软件实现基于之后第 6.5.6节中描述的一般形式的反向传播，它可以通过
显式地操作表示符号计算的数据结构，来适应任何计算图。
6.5.5符号到符号的导数
代数表达式和计算图都对 符号（symbol）或不具有特定值的变量进行操作。这
些代数或者基于图的表达式被称为 符号表示 （symbolic representation ） 。当我们实DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
182 第六章 深度前馈网络
算法 6.2反向传播 算法的简化版本，用于计算 u(n)关于图中变量的导数。这个示
例旨在通过演示所有变量都是标量的简化情况来进一步理解 反向传播 算法，这里我
们希望计算关于 u(1); : : : ; u(ni)的导数。这个简化版本计算了关于图中所有节点的导
数。假定与每条边相关联的偏导数计算需要恒定的时间的话，该算法的计算成本与
图中边的数量成比例。这与 前向传播 的计算次数具有相同的阶。每个@u(i)
@u(j)是u(i)的
父节点 u(j)的函数，从而将前向图的节点链接到 反向传播 图中添加的节点。
运行前向传播 (对于此例是算法 6.1)获得网络的激活。
初始化 grad_table ，用于存储计算好的导数的数据结构。 grad_table [u(i)]将存
储@u(n)
@u(i)计算好的值。
grad_table [u(n)] 1
forj=n 1down to 1 do
下一行使用存储的值计算@u(n)
@u(j)=∑
i:j2Pa(u(i))@u(n)
@u(i)@u(i)
@u(j)：
grad_table [u(j)] ∑
i:j2Pa(u(i))grad_table [u(i)]@u(i)
@u(j)
end for
returnfgrad_table [u(i)]ji= 1; : : : ; n ig
际使用或者训练神经网络时，我们必须给这些符号赋特定的值。我们用一个特定
的数值（numeric value ）来替代网络的符号输入 x，例如 [1:2;3;765; 1:8]⊤。
一些反向传播的方法采用计算图和一组用于图的输入的数值，然后返回在这些
输入值处梯度的一组数值。我们将这种方法称为 符号到数值 的微分。这种方法用在
诸如 Torch ( Collobert et al. ,2011b )和Caﬀe ( Jia,2013)之类的库中。
另一种方法是采用计算图以及添加一些额外的节点到计算图中，这些额外的节
点提供了我们所需导数的符号描述。这是 Theano ( Bergstra et al. ,2010b ;Bastien
et al. ,2012b )和TensorFlow ( Abadi et al. ,2015)所采用的方法。图 6.10给出了该方
法如何工作的一个例子。这种方法的主要优点是导数可以使用与原始表达式相同的
语言来描述。因为导数只是另外一张计算图，我们可以再次运行反向传播，对导数
再进行求导就能得到更高阶的导数。高阶导数的计算在第 6.5.10节中描述。
我们将使用后一种方法，并且使用构造导数的计算图的方法来描述反向传播算
法。图的任意子集之后都可以使用特定的数值来求值。这允许我们避免精确地指明
每个操作应该在何时计算。相反，通用的图计算引擎只要当一个节点的父节点的值
都可用时就可以进行求值。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 183
算法 6.3典型深度神经网络中的 前向传播 和代价函数的计算。损失函数 L(^y;y)取
决于输出 ^y和目标 y（参考第 6.2.1.1节中损失函数的示例） 。为了获得总代价 J，损
失函数可以加上正则项 Ω()，其中 包含所有参数（权重和偏置） 。算法 6.4说明了
如何计算 J关于参数 W和 b的梯度。为简单起见，该演示仅使用单个输入样本 x。
实际应用应该使用 小批量。请参考第 6.5.7节以获得更加真实的演示。
Require: 网络深度， l
Require: W(i); i2f1; : : : ; lg，模型的权重矩阵
Require: b(i); i2f1; : : : ; lg，模型的偏置参数
Require: x，程序的输入
Require: y，目标输出
h(0)= x
fork= 1; : : : ; l do
a(k)= b(k)+W(k)h(k 1)
h(k)=f(a(k))
end for
^y= h(l)
J=L(^y;y) +Ω()
基于符号到符号的方法的描述包含了符号到数值的方法。符号到数值的方法可
以理解为执行了与符号到符号的方法中构建图的过程中完全相同的计算。关键的区
别是符号到数值的方法不会显示出计算图。
6.5.6一般化的反向传播
反向传播算法非常简单。为了计算某个标量 z关于图中它的一个祖先 x的梯
度，我们首先观察到它关于 z的梯度由dz
dz= 1给出。然后，我们可以计算对图中 z
的每个父节点的梯度，通过现有的梯度乘以产生 z的操作的 Jacobian 。我们继续乘
以Jacobian ，以这种方式向后穿过图，直到我们到达 x。对于从 z出发可以经过两
个或更多路径向后行进而到达的任意节点，我们简单地对该节点来自不同路径上的
梯度进行求和。
更正式地，图G中的每个节点对应着一个变量。为了实现最大的一般化，我们
将这个变量描述为一个张量 V。张量通常可以具有任意维度，并且包含标量、向量DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
184 第六章 深度前馈网络
算法 6.4深度神经网络中算法 6.3的反向计算，它不止使用了输入 x和目标 y。该
计算对于每一层 k都产生了对激活 a(k)的梯度，从输出层开始向后计算一直到第一
个隐藏层。这些梯度可以看作是对每层的输出应如何调整以减小误差的指导，根据
这些梯度可以获得对每层参数的梯度。权重和偏置上的梯度可以立即用作随机梯度
更新的一部分（梯度算出后即可执行更新） ，或者与其他基于梯度的优化方法一起使
用。
在前向计算完成后，计算顶层的梯度：
g ∇ ^yJ=∇^yL(^y;y)
fork=l; l 1; : : : ; 1do
将关于层输出的梯度转换为非线性激活输入前的梯度（如果 f是逐元素的，则
逐元素地相乘） ：
g ∇a(k)J= g⊙f′(a(k))
计算关于权重和偏置的梯度（如果需要的话，还要包括正则项） ：
∇b(k)J= g+∇b(k)Ω()
∇W(k)J= g h(k 1)⊤+∇W(k)Ω()
关于下一更低层的 隐藏层传播梯度：
g ∇h(k 1)J= W(k)⊤g
end forDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 185
zz
xxyy
wwfffzz
xxyy
wwfffdzdydzdyf0dydxdydxf0dzdxdzdx⇥dxdwdxdwf0dzdwdzdw⇥
图6.10:使用符号到符号的方法计算导数的示例。在这种方法中， 反向传播 算法不需要访问任何实
际的特定数值。相反，它将节点添加到计算图中来描述如何计算这些导数。通用图形求值引擎可
以在随后计算任何特定数值的导数。 (左)在这个例子中，我们从表示 z=f(f(f(w)))的图开始。
(右)我们运行 反向传播 算法，指导它构造表达式dz
dw对应的图。在这个例子中，我们不解释 反向
传播算法如何工作。我们的目的只是说明想要的结果是什么：符号描述的导数的计算图。
和矩阵。
我们假设每个变量 V与下列子程序相关联：
•get_operation (V)：它返回用于计算 V的操作，代表了在计算图中流入 V
的边。例如，可能有一个 Python或者 C++的类表示矩阵乘法操作，以
及get_operation 函数。假设我们的一个变量是由矩阵乘法产生的， C= AB。
那么， get_operation (V)返回一个指向相应 C++类的实例的指针。
•get_consumers (V;G)：它返回一组变量，是计算图 G中V的子节点。
•get_inputs (V;G)：它返回一组变量，是计算图 G中V的父节点。
每个操作 op也与 bprop操作相关联。该 bprop操作可以计算如式 (6.47)所描
述的 Jacobian 向量积。这是反向传播算法能够实现很大通用性的原因。每个操作负
责了解如何通过它参与的图中的边来反向传播。例如，我们可以使用矩阵乘法操作
来产生变量 C= AB。假设标量 z关于 C的梯度是 G。矩阵乘法操作负责定义两
个反向传播规则，每个规则对应于一个输入变量。如果我们调用 bprop方法来请求DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
186 第六章 深度前馈网络
关于 A的梯度，那么在给定输出的梯度为 G的情况下，矩阵乘法操作的 bprop方
法必须说明关于 A的梯度是 GB⊤。类似的，如果我们调用 bprop方法来请求关
于 B的梯度，那么矩阵操作负责实现 bprop方法并指定希望的梯度是 A⊤G。反向
传播算法本身并不需要知道任何微分法则。它只需要使用正确的参数调用每个操作
的bprop方法即可。正式地， op.bprop(inputs ;X;G)必须返回
∑
i(∇Xop.f(inputs )i)Gi; (6.54)
这只是如式 (6.47)所表达的链式法则的实现。这里， inputs是提供给操作的一组输
入， op.f是操作实现的数学函数， X是输入，我们想要计算关于它的梯度， G是操
作对于输出的梯度。
op.bprop 方法应该总是假装它的所有输入彼此不同，即使它们不是。例如，如
果mul操作传递两个 x来计算 x2，op.bprop 方法应该仍然返回 x作为对于两个输
入的导数。反向传播算法后面会将这些变量加起来获得 2x，这是 x上总的正确的导
数。
反向传播算法的软件实现通常提供操作和其 bprop方法，所以深度学习软件库
的用户能够对使用诸如矩阵乘法、指数运算、对数运算等等常用操作构建的图进行
反向传播。构建反向传播新实现的软件工程师或者需要向现有库添加自己的操作的
高级用户通常必须手动为新操作推导 op.bprop 方法。
反向传播算法的正式描述参考算法 6.5。
在第 6.5.2节中，我们使用反向传播作为一种策略来避免多次计算链式法则中的
相同子表达式。由于这些重复子表达式的存在，简单的算法可能具有指数运行时间。
现在我们已经详细说明了反向传播算法，我们可以去理解它的计算成本。如果我们
假设每个操作的执行都有大致相同的开销，那么我们可以依据执行操作的数量来分
析计算成本。注意这里我们将一个操作记为计算图的基本单位，它实际可能包含许
多算术运算（例如，我们可能将矩阵乘法视为单个操作） 。在具有 n个节点的图中计
算梯度，将永远不会执行超过 O(n2)个操作，或者存储超过 O(n2)个操作的输出。
这里我们是对计算图中的操作进行计数，而不是由底层硬件执行的单独操作，所以
重要的是要记住每个操作的运行时间可能是高度可变的。例如，两个矩阵相乘可能
对应着图中的一个单独的操作，但这两个矩阵可能每个都包含数百万个元素。我们
可以看到，计算梯度至多需要 O(n2)的操作，因为在最坏的情况下，前向传播的步
骤将在原始图的全部 n个节点上运行（取决于我们想要计算的值，我们可能不需要
执行整个图） 。反向传播算法在原始图的每条边添加一个 Jacobian 向量积，可以用DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 187
算法 6.5反向传播 算法最外围的骨架。这部分做简单的设置和清理工作。大多数重
要的工作发生在算法 6.6的子程序 build_grad 中。
Require: T，需要计算梯度的目标变量集
Require:G，计算图
Require: z，要微分的变量
令G′为G剪枝后的计算图，其中仅包括 z的祖先以及 T中节点的后代。
初始化 grad_table ，它是关联张量和对应导数的数据结构。
grad_table [z] 1
forVinTdo
build _grad (V;G;G′;grad_table )
end for
Return grad_table restricted to T
O(1)个节点来表达。因为计算图是有向无环图，它至多有 O(n2)条边。对于实践中
常用图的类型，情况会更好。大多数神经网络的代价函数大致是链式结构的，使得
反向传播只有 O(n)的成本。这远远胜过简单的方法，简单方法可能需要在指数级
的节点上运算。这种潜在的指数级代价可以通过非递归地扩展和重写递归链式法则
（式 (6.49)）来看出：
@u(n)
@u(j)=∑
path (u(1);u(2);:::;u(t));
from 1=jtot=nt∏
k=2@u(k)
@u(k 1): (6.55)
由于节点 j到节点 n的路径数目可以关于这些路径的长度上指数地增长，所以上述
求和符号中的项数（这些路径的数目） ，可能以前向传播图的深度的指数级增长。会
产生如此大的成本是因为对于@u(i)
@u(j)，相同的计算会重复进行很多次。为了避免这种
重新计算，我们可以将反向传播看作一种表填充算法，利用存储的中间结果@u(n)
@u(i)来
对表进行填充。图中的每个节点对应着表中的一个位置，这个位置存储对该节点的
梯度。通过顺序填充这些表的条目，反向传播算法避免了重复计算许多公共子表达
式。这种表填充策略有时被称为 动态规划 （dynamic programming ） 。
6.5.7实例：用于 MLP训练的反向传播
作为一个例子，我们利用反向传播算法来训练 多层感知机 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
188 第六章 深度前馈网络
算法 6.6反向传播 算法的内循环子程序 build _grad (V;G;G′;grad_table )，由算
法6.5中定义的 反向传播 算法调用。
Require: V，应该被加到G和grad_table 的变量。
Require:G，要修改的图。
Require:G′，根据参与梯度的节点 G的受限图。
Require: grad_table ，将节点映射到对应梯度的数据结构。
ifVis in grad_table then
Return grad_table [V]
end if
i 1
forCin get_consumers (V;G′)do
op get_operation (C)
D build _grad (C;G;G′;grad_table )
G(i) op:bprop (get_inputs (C;G′);V;D)
i i+ 1
end for
G ∑
iG(i)
grad_table [V] =G
插入G和将其生成到G中的操作
Return G
这里，我们考虑一个具有单个 隐藏层的非常简单的 多层感知机 。为了训练这个
模型，我们将使用 小批量随机梯度下降算法。反向传播算法用于计算单个 小批量上
的代价的梯度。具体来说，我们使用训练集上的一 小批量实例，将其规范化为一个设
计矩阵 X以及相关联的类标签向量 y。网络计算隐藏特征层 H= maxf0;XW(1)g。
为了简化表示，我们在这个模型中不使用偏置。假设我们的图语言包含 relu操作，
该操作可以对 maxf0;Zg表达式的每个元素分别进行计算。类的非归一化对数概率
的预测将随后由 HW(2)给出。假设我们的图语言包含 cross_entropy 操作，用以
计算目标 y和由这些未归一化对数概率定义的概率分布间的 交叉熵。所得到的 交叉
熵定义了代价函数 JMLE。最小化这个 交叉熵将执行对分类器的最大似然估计。然而，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 189
为了使得这个例子更加真实，我们也包含一个正则项。总的代价函数为
J=JMLE+(∑
i;j(
W(1)
i;j)2
+∑
i;j(
W(2)
i;j)2)
(6.56)
包含了交叉熵和系数为 的权重衰减项。它的计算图在图 6.11中给出。
XXW(1)W(1)U(1)U(1)matmulHHrelu
U(3)U(3)sqru(4)u(4)sum  u(7)u(7)W(2)W(2)U(2)U(2)matmulyyJMLEJMLEcross_entropy
U(5)U(5)sqru(6)u(6)sumu(8)u(8)JJ+⇥+
图6.11:用于计算代价函数的计算图，这个代价函数是使用 交叉熵损失以及权重衰减训练我们的
单层 MLP示例所产生的。
这个示例的梯度计算图实在太大，以致于绘制或者阅读都将是乏味的。这显示
出了反向传播算法的优点之一，即它可以自动生成梯度，而这种计算对于软件工程
师来说需要进行直观但冗长的手动推导。
我们可以通过观察图 6.11中的正向传播图来粗略地描述反向传播算法的行为。
为了训练，我们希望计算 ∇W(1)J和∇W(2)J。有两种不同的路径从 J后退到权重：
一条通过 交叉熵代价，另一条通过权重衰减代价。权重衰减代价相对简单，它总是
对 W(i)上的梯度贡献 2W(i)。
另一条通过 交叉熵代价的路径稍微复杂一些。令 G是由 cross_entropy 操作
提供的对未归一化对数概率 U(2)的梯度。反向传播算法现在需要探索两个不同的分
支。在较短的分支上，它使用对矩阵乘法的第二个变量的反向传播规则，将 H⊤G加DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
190 第六章 深度前馈网络
到 W(2)的梯度上。另一条更长些的路径沿着网络逐步下降。首先，反向传播算法使
用对矩阵乘法的第一个变量的反向传播规则，计算 ∇ HJ= GW(2)⊤。接下来， relu
操作使用其反向传播规则来对关于 U(1)的梯度中小于 0的部分清零。记上述结果为
G′。反向传播算法的最后一步是使用对 matmul操作的第二个变量的反向传播规则，
将 X⊤G′加到 W(1)的梯度上。
在计算了这些梯度以后，梯度下降算法或者其他优化算法所要做的就是使用这
些梯度来更新参数。
对于 MLP，计算成本主要来源于矩阵乘法。在前向传播阶段，我们乘以每个权
重矩阵，得到了 O(w)数量的乘 -加，其中 w是权重的数量。在反向传播阶段，我们
乘以每个权重矩阵的转置，这具有相同的计算成本。算法主要的存储成本是我们需
要将输入存储到 隐藏层的非线性中去。这些值从被计算时开始存储，直到反向过程
回到了同一点。因此存储成本是 O(mnh)，其中 m是小批量中样本的数目， nh是隐
藏单元的数量。
6.5.8复杂化
我们这里描述的反向传播算法要比实践中实际使用的实现要简单。
正如前面提到的，我们将操作的定义限制为返回单个张量的函数。大多数软件
实现需要支持可以返回多个张量的操作。例如，如果我们希望计算张量中的最大值
和该值的索引，则最好在单次运算中计算两者，因此将该过程实现为具有两个输出
的操作效率更高。
我们还没有描述如何控制反向传播的内存消耗。反向传播经常涉及将许多张量
加在一起。在朴素方法中，将分别计算这些张量中的每一个，然后在第二步中对所
有这些张量求和。朴素方法具有过高的存储瓶颈，可以通过保持一个缓冲器，并且
在计算时将每个值加到该缓冲器中来避免该瓶颈。
反向传播的现实实现还需要处理各种数据类型，例如 32位浮点数、 64位浮点
数和整型。处理这些类型的策略需要特别的设计考虑。
一些操作具有未定义的梯度，并且重要的是跟踪这些情况并且确定用户请求的
梯度是否是未定义的。
各种其他技术的特性使现实世界的微分更加复杂。这些技术性并不是不可逾越
的，本章已经描述了计算微分所需的关键知识工具，但重要的是要知道还有许多的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.5反向传播和其他的微分算法 191
精妙之处存在。
6.5.9深度学习界以外的微分
深度学习界在某种程度上已经与更广泛的计算机科学界隔离开来，并且在很大
程度上发展了自己关于如何进行微分的文化态度。更一般地， 自动微分 （automatic
diﬀerentiation ）领域关心如何以算法方式计算导数。这里描述的反向传播算法只是
自动微分的一种方法。它是一种称为 反向模式累加 （reverse mode accumulation ）的
更广泛类型的技术的特殊情况。其他方法以不同的顺序来计算链式法则的子表达式。
一般来说，确定一种计算的顺序使得计算开销最小，是困难的问题。找到计算梯度
的最优操作序列是 NP完全问题 (Naumann ,2008)，在这种意义上，它可能需要将
代数表达式简化为它们最廉价的形式。
例如，假设我们有变量 p1; p2: : : ; p n表示概率，以及变量 z1; z2; : : : ; z n表示未
归一化的对数概率。假设我们定义
qi=exp(zi)∑
iexp(zi); (6.57)
其中我们通过指数化、求和与除法运算构建 softmax 函数，并构造 交叉熵损失函数
J= ∑
ipilogqi。人类数学家可以观察到 J对zi的导数采用了非常简单的形式：
piqi pi。3反向传播算法不能够以这种方式来简化梯度，而是会通过原始图中的所
有对数和指数操作显式地传播梯度。一些软件库如 Theano ( Bergstra et al. ,2010b ;
Bastien et al. ,2012b )能够执行某些种类的代数替换来改进由纯反向传播算法提出的
图。
当前向图G具有单个输出节点，并且每个偏导数@u(i)
@u(j)都可以用恒定的计算量
来计算时，反向传播保证梯度计算的计算数目和前向计算的计算数目是同一个量级：
这可以在算法 6.2中看出，因为每个局部偏导数@u(i)
@u(j)以及递归链式公式（式 (6.49)）
中相关的乘和加都只需计算一次。因此，总的计算量是 O(#edges )。然而，可能通过
对反向传播算法构建的计算图进行简化来减少这些计算量，并且这是 NP完全问题。
诸如 Theano和TensorFlow 的实现使用基于匹配已知简化模式的试探法，以便重复
地尝试去简化图。我们定义反向传播仅用于计算标量输出的梯度，但是反向传播可
以扩展到计算 Jacobian 矩阵（该 Jacobian 矩阵或者来源于图中的 k个不同标量节
点，或者来源于包含 k个值的张量值节点） 。朴素的实现可能需要 k倍的计算：对于
3译者注：这里作者误写成了 qi pi。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
192 第六章 深度前馈网络
原始前向图中的每个内部标量节点，朴素的实现计算 k个梯度而不是单个梯度。当
图的输出数目大于输入的数目时，有时更偏向于使用另外一种形式的自动微分，称
为前向模式累加 （forward mode accumulation ） 。前向模式计算已经被提出用于循
环神经网络梯度的实时计算，例如 (Williams and Zipser ,1989)。这也避免了存储整
个图的值和梯度的需要，是计算效率和内存使用的折中。前向模式和后向模式的关
系类似于左乘和右乘一系列矩阵之间的关系，例如
ABCD ; (6.58)
其中的矩阵可以认为是 Jacobian 矩阵。例如，如果 D是列向量，而 A有很多行，
那么这对应于一幅具有单个输出和多个输入的图，并且从最后开始乘，反向进行，只
需要矩阵 -向量的乘积。这对应着反向模式。相反，从左边开始乘将涉及一系列的矩
阵-矩阵乘积，这使得总的计算变得更加昂贵。然而，如果 A的行数小于 D的列数，
则从左到右乘更为便宜，这对应着前向模式。
在机器学习以外的许多社区中，更常见的是使用传统的编程语言来直接实现微
分软件，例如用 Python或者 C来编程，并且自动生成使用这些语言编写的不同函
数的程序。在深度学习界中，计算图通常使用由专用库创建的明确的数据结构表示。
专用方法的缺点是需要库开发人员为每个操作定义 bprop方法，并且限制了库的用
户仅使用定义好的那些操作。然而，专用方法也允许定制每个操作的反向传播规则，
允许开发者以非显而易见的方式提高速度或稳定性，对于这种方式自动的过程可能
不能复制。
因此，反向传播不是计算梯度的唯一方式或最佳方式，但它是一个非常实用的
方法，继续为深度学习社区服务。在未来，深度网络的微分技术可能会提高，因为
深度学习的从业者更加懂得了更广泛的自动微分领域的进步。
6.5.10 高阶微分
一些软件框架支持使用高阶导数。在深度学习软件框架中，这至少包括 Theano
和TensorFlow 。这些库使用一种数据结构来描述要被微分的原始函数，它们使用相
同类型的数据结构来描述这个函数的导数表达式。这意味着符号微分机制可以应用
于导数（从而产生高阶导数） 。
在深度学习的相关领域，很少会计算标量函数的单个二阶导数。相反，我们通
常对 Hessian矩阵的性质比较感兴趣。如果我们有函数 f:Rn!R，那么 HessianDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.6历史小记 193
矩阵的大小是 nn。在典型的深度学习应用中， n将是模型的参数数量，可能很容
易达到数十亿。因此，完整的 Hessian矩阵甚至不能表示。
典型的深度学习方法是使用 Krylov 方法（Krylov method ） ，而不是显式地计
算Hessian矩阵。 Krylov方法是用于执行各种操作的一组迭代技术，这些操作包括
像近似求解矩阵的逆、或者近似矩阵的特征值或特征向量等，而不使用矩阵 -向量乘
法以外的任何操作。
为了在 Hesssian 矩阵上使用 Krylov方法，我们只需要能够计算 Hessian矩阵
H和一个任意向量 v间的乘积即可。实现这一目标的一种直观方法 (Christianson ,
1992)是
Hv=∇ x[
(∇ xf(x))⊤v]
: (6.59)
该表达式中两个梯度的计算都可以由适当的软件库自动完成。注意，外部梯度表达
式是内部梯度表达式的函数的梯度。
如果 v本身是由计算图产生的一个向量，那么重要的是指定自动微分软件不要
对产生 v的图进行微分。
虽然计算 Hessian通常是不可取的，但是可以使用 Hessian向量积。可以对
所有的 i= 1; : : : ; n简单地计算 He(i)，其中 e(i)是e(i)
i= 1并且其他元素都为 0
的one-hot向量。
6.6历史小记
前馈网络 可以被视为一种高效的非线性函数近似器，它以使用梯度下降来最小
化函数近似误差为基础。从这个角度来看，现代 前馈网络 是一般函数近似任务的几
个世纪进步的结晶。
处于反向传播算法底层的链式法则是 17世纪发明的 (Leibniz ,1676;L’Hôpital ,
1696)。微积分和代数长期以来被用于求解优化问题的封闭形式，但梯度下降直到 19
世纪才作为优化问题的一种迭代近似的求解方法被引入 (Cauchy ,1847)。
从20世纪 40年代开始，这些函数近似技术被用于导出诸如感知机的机器学习
模型。然而，最早的模型都是基于线性模型。来自包括 Marvin Minsky 的批评指出
了线性模型族的几个缺陷，例如它无法学习 XOR函数，这导致了对整个神经网络方
法的抵制。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
194 第六章 深度前馈网络
学习非线性函数需要 多层感知机 的发展和计算该模型梯度的方法。基于动态规
划的链式法则的高效应用开始出现在 20世纪 60年代和 70年代，主要用于控制领
域(Kelley ,1960;Bryson and Denham ,1961;Dreyfus ,1962;Bryson and Ho ,1969;
Dreyfus ,1973)，也用于灵敏度分析 (Linnainmaa ,1976)。Werbos (1981)提出应用这
些技术来训练人工神经网络。这个想法以不同的方式被独立地重新发现后 (LeCun ,
1985;Parker ,1985;Rumelhart et al. ,1986a )，最终在实践中得以发展。 并行分布式
处理（Parallel Distributed Processing ）一书在其中一章提供了第一次成功使用反向
传播的一些实验的结果 (Rumelhart et al. ,1986b )，这对反向传播的普及做出了巨大
的贡献，并且开启了一个研究多层神经网络非常活跃的时期。然而，该书作者提出
的想法，特别是 Rumelhart 和Hinton提出的想法远远超过了反向传播。它们包括一
些关键思想，关于可能通过计算实现认知和学习的几个核心方面，后来被冠以 “联
结主义 ’’的名称，因为它强调了神经元之间的连接作为学习和记忆的轨迹的重要性。
特别地，这些想法包括分布式表示的概念 (Hinton et al. ,1986)。
在反向传播的成功之后，神经网络研究获得了普及，并在 20世纪 90年代初达
到高峰。随后，其他机器学习技术变得更受欢迎，直到 2006年开始的现代深度学习
复兴。
现代前馈网络 的核心思想自 20世纪 80年代以来没有发生重大变化。仍然使用
相同的反向传播算法和相同的梯度下降方法。 1986年至 2015年神经网络性能的大
部分改进可归因于两个因素。首先，较大的数据集减少了统计 泛化对神经网络的挑
战的程度。第二，神经网络由于更强大的计算机和更好的软件基础设施已经变得更
大。然而，少量算法上的变化也显著改善了神经网络的性能。
其中一个算法上的变化是用损失函数的 交叉熵族替代均方误差 。均方误差 在20
世纪 80年代和 90年代流行， 但逐渐被 交叉熵损失替代， 并且最大似然原理的想法在
统计学界和机器学习界之间广泛传播。使用 交叉熵损失大大提高了具有 sigmoid和
softmax 输出的模型的性能，而当使用 均方误差 损失时会存在饱和和学习缓慢的问
题。
另一个显著改善 前馈网络 性能的算法上的主要变化是使用分段线性 隐藏单元 来
替代 sigmoid隐藏单元 ，例如用 整流线性单元 。使用 maxf0; zg函数的整流在早期
神经网络中已经被引入，并且至少可以追溯到认知机（ Cognitron ）和神经认知机
(Neocognitron)( Fukushima ,1975,1980)。这些早期的模型没有使用 整流线性单元 ，
而是将整流用于非线性函数。尽管整流在早期很普及，在 20世纪 80年代，整流很
大程度上被 sigmoid所取代，也许是因为当神经网络非常小时， sigmoid表现更好。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
6.6历史小记 195
到21世纪初，由于有些迷信的观念，认为必须避免具有不可导点的激活函数，所
以避免了 整流线性单元 。这在 2009年开始发生改变。 Jarrett et al. (2009b )观察到，
在神经网络结构设计的几个不同因素中 ‘‘使用整流非线性是提高识别系统性能的最
重要的唯一因素 ’’。
对于小的数据集， Jarrett et al. (2009b )观察到，使用整流非线性甚至比学习 隐
藏层的权重值更加重要。随机的权重足以通过 整流网络 传播有用的信息，允许在顶
部的分类器层学习如何将不同的特征向量映射到类标识。
当有更多数据可用时，学习开始提取足够的有用知识来超越随机选择参数的性
能。Glorot et al. (2011a )说明，在深度 整流网络 中的学习比在激活函数具有曲率或
两侧饱和的深度网络中的学习更容易。
整流线性单元 还具有历史意义，因为它们表明神经科学继续对深度学习算法的
发展产生影响。 Glorot et al. (2011a )从生物学考虑 整流线性单元 的导出。半整流非
线性旨在描述生物神经元的这些性质： (1)对于某些输入，生物神经元是完全不活
跃的。 (2)对于某些输入，生物神经元的输出和它的输入成比例。 (3)大多数时间，
生物神经元是在它们不活跃的状态下进行操作（即它们应该具有 稀疏激活 （sparse
activation ） ） 。
当2006年深度学习开始现代复兴时， 前馈网络 仍然有不良的声誉。从 2006年
至2012年，人们普遍认为， 前馈网络 不会表现良好，除非它们得到其他模型的辅助，
例如概率模型。现在已经知道，只要具备适当的资源和工程实践， 前馈网络 表现得
非常好。今天， 前馈网络 中基于梯度的学习被用作发展概率模型的工具，例如第 二
十章中描述的 变分自编码器 和生成式对抗网络。 前馈网络 中基于梯度的学习自 2012
年以来一直被视为一种强大的技术，并应用于许多其他机器学习任务，而不是被视
为必须由其他技术支持的不可靠技术。在 2006年，业内使用无监督学习来支持监督
学习，现在更讽刺的是，更常见的是使用监督学习来支持无监督学习。
前馈网络 还有许多未实现的潜力。未来，我们期望它们用于更多的任务，优化
算法和模型设计的进步将进一步提高它们的性能。本章主要描述了神经网络模型族。
在接下来的章节中，我们将讨论如何使用这些模型——如何对它们进行正则化和训
练。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第七章 深度学习中的正则化
机器学习 中的一个核心问题是设计不仅在训练数据上表现好，并且能在新输入
上泛化好的算法。在 机器学习 中，许多策略显式地被设计为减少测试误差（可能会
以增大训练误差为代价） 。这些策略被统称为 正则化。我们将在后文看到， 深度学
习工作者可以使用许多不同形式的 正则化策略。事实上，开发更有效的 正则化策略
已成为本领域的主要研究工作之一。
第五章介绍了 泛化、欠拟合、过拟合、偏差、方差和正则化的基本概念。如果你
不熟悉这些概念，请参考该章节再继续阅读本章。
在本章中，我们会更详细地介绍 正则化，重点介绍深度模型（或组成深度模型
的模块）的 正则化策略。
本章中的某些章节涉及 机器学习 中的标准概念。如果你已经熟悉了这些概念，
可以随意跳过相关章节。然而，本章的大多数内容涉及这些基本概念在特定 神经网
络中的扩展概念。
在第 5.2.2节中，我们将 正则化定义为 ‘‘对学习算法的修改——旨在减少 泛化误
差而不是训练误差 ’’。目前有许多 正则化策略。有些策略向 机器学习 模型添加限制参
数的额外约束。有些策略向 目标函数 增加参数值软约束的额外项。如果我们仔细选
择，这些额外的约束和惩罚可以改善模型在测试集上的表现。有时侯，这些约束和
惩罚被设计为编码特定类型的先验知识；其他时候，这些约束和惩罚被设计为偏好
简单模型，以便提高 泛化能力。有时，惩罚和约束对于确定欠定的问题是必要的。其
他形式的 正则化（如集成方法）结合多个假说来解释训练数据。
在深度学习 的背景下，大多数 正则化策略都会对 估计进行正则化。估计的正则
化以偏差的增加换取 方差的减少。一个有效的 正则化是有利的 ‘‘交易’’，也就是能显
著减少方差而不过度增加 偏差。我们在第 五章中讨论 泛化和过拟合时，主要侧重模
196DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.1参数范数惩罚 197
型族训练的 3个情形： （ 1）不包括真实的数据生成过程——对应 欠拟合和含有偏
差的情况， （ 2）匹配真实数据生成过程， （ 3）除了包括真实的数据生成过程，还包
括许多其他可能的生成过程—— 方差（而不是 偏差）主导的 过拟合。正则化的目标
是使模型从第三种情况转化为第二种情况。
在实践中，过于复杂的模型族不一定包括目标函数或真实数据生成过程，甚至
也不包括近似过程。我们几乎从未知晓真实数据的生成过程，所以我们永远不知道
被估计的模型族是否包括生成过程。然而， 深度学习 算法的大多数应用都是针对这
样的情况，其中真实数据的生成过程几乎肯定在模型族之外。 深度学习 算法通常应
用于极为复杂的领域，如图像、音频序列和文本，本质上这些领域的真实生成过程
涉及模拟整个宇宙。从某种程度上说，我们总是持方枘（数据生成过程）而欲内圆
凿（我们的模型族） 。
这意味着控制模型的复杂度不是找到合适规模的模型（带有正确的参数个数）
这样一个简单的事情。相反，我们可能会发现，或者说在实际的深度学习场景中我
们几乎总是会发现，最好的拟合模型（从最小化 泛化误差的意义上）是一个适当 正
则化的大型模型。
现在我们回顾几种策略，以创建这些 正则化的大型深度模型。
7.1参数范数惩罚
正则化在深度学习 的出现前就已经被使用了数十年。 线性模型 ，如线性回归 和逻
辑回归可以使用简单、直接、有效的 正则化策略。
许多正则化方法通过对 目标函数 J添加一个参数范数惩罚 Ω()，限制模型
（如神经网络 、线性回归 或逻辑回归 ）的学习能力。我们将正则化后的 目标函数 记为
~J：
~J(;X;y) =J(;X;y) +Ω(); (7.1)
其中 2[0;1)是权衡范数惩罚项 Ω和标准目标函数 J(X;)相对贡献的超参数。
将设为 0表示没有 正则化。越大，对应 正则化惩罚越大。
当我们的训练算法最小化 正则化后的目标函数 ~J时，它会降低原始目标 J关于
训练数据的误差并同时减小参数 的规模（或在某些衡量下参数子集的规模） 。选择
不同的参数范数 Ω会偏好不同的解法。在本节中，我们会讨论各种范数惩罚对模型DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
198 第七章 深度学习中的正则化
的影响。
在探究不同范数的 正则化表现之前，我们需要说明一下，在神经网络中我们通
常只对每一层仿射变换的 权重做惩罚而不对 偏置做正则惩罚。精确拟合 偏置所需的
数据通常比拟合权重少得多。每个权重会指定两个变量如何相互作用。我们需要在
各种条件下观察这两个变量才能良好地拟合权重。而每个 偏置仅控制一个单变量。
这意味着，我们不对其进行 正则化也不会导致太大的 方差。另外， 正则化偏置参数
可能会导致明显的 欠拟合。因此，我们使用向量 w表示所有应受范数惩罚影响的权
重，而向量表示所有参数 (包括 w和无需正则化的参数 )。
在神经网络 的情况下，有时希望对网络的每一层使用单独的惩罚，并分配不同
的系数。拟合多个超参数的代价很大，因此为了减少搜索空间，我们会在所有层
使用相同的 权重衰减 。
7.1.1 L2参数正则化
在第 5.2节中我们已经看到过最简单和最常见的参数范数惩罚，即通常被称为 权
重衰减（weight decay ）的 L2参数范数惩罚。这个 正则化策略通过向 目标函数 添加
一个正则项 Ω() =1
2∥w∥2
2，使权重更加接近原点1。在其他学术圈， L2也被称为 岭
回归或Tikhonov 正则。
我们可以通过研究 正则化化后目标函数 的梯度，洞察一些 权重衰减 的正则化表
现。为了简单起见，我们假定其中没有 偏置参数，因此就是 w。这样一个模型具
有以下总的 目标函数 ：
~J(w;X;y) =
2w⊤w+J(w;X;y); (7.2)
与之对应的 梯度为
∇ w~J(w;X;y) =w+∇ wJ(w;X;y): (7.3)
使用单步 梯度下降更新权重，即执行以下更新：
w w ϵ(w+∇ wJ(w;X;y)): (7.4)
1更一般地，我们可以将参数 正则化为接近空间中的任意特定点，令人惊讶的是这样也仍有 正则化效果，但是特定
点越接近真实值结果越好。当我们不知道正确的值应该是正还是负时，零是有意义的默认值。由于模型参数 正则化为
零的情况更为常见，我们将只探讨这种特殊情况。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.1参数范数惩罚 199
换种写法就是：
w (1 ϵ)w ϵ∇ wJ(w;X;y): (7.5)
我们可以看到，加入 权重衰减 后会引起学习规则的修改，即在每步执行通常的 梯度更
新之前先收缩权重向量（将权重向量乘以一个常数因子） 。这是单个步骤发生的变
化。但是，在训练的整个过程会发生什么呢？
我们进一步简化分析，令 w为不含正则化的目标函数 取得最小训练误差时的
权重向量，即 w= arg min wJ(w)，并在 w的邻域对 目标函数 做二次近似。如果 目
标函数确实是二次的 (如以均方误差拟合 线性回归 模型的情况 )，则该近似是完美的。
近似的 ^J()如下
^J() =J(w) +1
2(w w)⊤H(w w); (7.6)
其中 H是J在 w处计算的 Hessian矩阵 (关于 w)。因为 w被定义为最优，即梯
度消失为 0，所以该二次近似中没有一阶项。同样地，因为 w是J的一个最优点，
我们可以得出 H是半正定的结论。
当^J取得最小时，其梯度
∇ w^J(w) = H(w w) (7.7)
为0。
为了研究 权重衰减 带来的影响，我们在式 (7.7)中添加权重衰减 的梯度。现在我
们探讨最小化含有 正则化的^J。我们使用变量 ~w表示此时的最优点 :
~w+H(~w w) = 0 (7.8)
(H+I)~w= Hw(7.9)
~w= ( H+I) 1Hw(7.10)
当趋向于 0时，正则化的解 ~w会趋向 w。那么当 增加时会发生什么呢？
因为 H是实对称的，所以我们可以将其分解为一个对角矩阵 和一组特征向量的
标准正交基 Q，并且有 H= QQ⊤。将其应用于式 (7.10)，可得：
~w= ( QQ⊤+I) 1QQ⊤w(7.11)
= [ Q(+I)Q⊤] 1QQ⊤w(7.12)
= Q(+I) 1Q⊤w: (7.13)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
200 第七章 深度学习中的正则化
我们可以看到 权重衰减 的效果是沿着由 H的特征向量所定义的轴缩放 w。具体来
说，我们会根据i
i+因子缩放与 H第i个特征向量对齐的 w的分量。（不妨查
看图 2.3回顾这种缩放的原理） 。
沿着 H特征值较大的方向 (如i≫)正则化的影响较小。而 i≪的分量将
会收缩到几乎为零。这种效应如图 7.1所示。
w1w2w
~w
图7.1:L2（或权重衰减 ）正则化对最佳 w值的影响。实线椭圆表示没有 正则化目标的等值线。虚
线圆圈表示 L2正则化项的等值线。在 ~w点，这两个竞争目标达到平衡。目标函数 J的Hessian的
第一维特征值很小。当从 w水平移动时， 目标函数 不会增加得太多。因为 目标函数 对这个方向没
有强烈的偏好，所以正则化项对该轴具有强烈的影响。正则化项将 w1拉向零。而 目标函数 对沿着
第二维远离 w的移动非常敏感。对应的特征值较大，表示高 曲率。因此， 权重衰减 对w2的位置
影响相对较小。
只有在显著减小 目标函数 方向上的参数会保留得相对完好。在无助于 目标函
数减小的方向（对应 Hessian矩阵较小的特征值）上改变参数不会显著增加 梯度。这
种不重要方向对应的分量会在训练过程中因 正则化而衰减掉。
目前为止，我们讨论了 权重衰减 对优化一个抽象通用的二次 代价函数 的影响。
这些影响具体是怎么和机器学习关联的呢？我们可以研究 线性回归 ，它的真实 代价
函数是二次的，因此我们可以使用相同的方法分析。再次应用分析，我们会在这种
情况下得到相同的结果，但这次我们使用训练数据的术语表述。 线性回归 的代价函
数是平方误差之和：
(Xw y)⊤(Xw y): (7.14)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.1参数范数惩罚 201
我们添加 L2正则项后， 目标函数 变为
(Xw y)⊤(Xw y) +1
2w⊤w: (7.15)
这将普通方程的解从
w= ( X⊤X) 1X⊤y (7.16)
变为
w= ( X⊤X+I) 1X⊤y: (7.17)
式(7.16)中的矩阵 X⊤X与协方差矩阵1
mX⊤X成正比。 L2正则项将这个矩阵替换
为式 (7.17)中的 (X⊤X+I) 1这个新矩阵与原来的是一样的，不同的仅仅是在对
角加了 。这个矩阵的对角项对应每个输入特征的 方差。我们可以看到， L2正则化能
让学习算法 ‘‘感知’’到具有较高方差的输入 x，因此与输出目标的 协方差较小（相对
增加方差）的特征的权重将会收缩。
7.1.2 L1参数正则化
L2权重衰减 是权重衰减 最常见的形式，我们还可以使用其他的方法限制模型参
数的规模。比如我们还可以使用 L1正则化。
形式地，对模型参数 w的L1正则化被定义为：
Ω() =∥w∥1=∑
ijwij; (7.18)
即各个参数的绝对值之和2。接着我们将讨论 L1正则化对简单线性回归 模型的影响，
与分析 L2正则化时一样不考虑 偏置参数。我们尤其感兴趣的是找出 L1和L2正则
化之间的差异。与 L2权重衰减 类似，我们也可以通过缩放惩罚项 Ω的正超参数 
来控制 L1权重衰减 的强度。因此， 正则化的目标函数 ~J(w;X;y)如下所示
~J(w;X;y) =∥w∥1+J(w;X;y); (7.19)
对应的梯度 (实际上是次梯度 )：
∇ w~J(w;X;y) =sign(w) +∇ wJ(w;X;y); (7.20)
2如同 L2正则化，我们能将参数 正则化到其他非零值 w(o)。在这种情况下， L1正则化将会引入不同的项
Ω() =∥w  w(o)∥1=∑
ijwi w(o)
ij。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
202 第七章 深度学习中的正则化
其中 sign(w)只是简单地取 w各个元素的正负号。
观察式 (7.20)，我们立刻发现 L1的正则化效果与 L2大不一样。具体来说，我
们可以看到 正则化对梯度的影响不再是线性地缩放每个 wi；而是添加了一项与
sign(wi)同号的常数。使用这种形式的 梯度之后，我们不一定能得到 J(X;y;w)二
次近似的直接算术解（ L2正则化时可以） 。
简单线性模型 具有二次 代价函数 ，我们可以通过 泰勒级数表示。或者我们可以
设想，这是逼近更复杂模型的 代价函数 的截断泰勒级数。在这个设定下， 梯度由下
式给出
∇ w^J(w) = H(w w); (7.21)
同样， H是J在 w处的Hessian矩阵 (关于 w)。
由于 L1惩罚项在满的、一般的 Hessian的情况下，无法得到直接清晰的代数表
达式，因此我们将进一步简化假设 Hessian是对角的，即 H=diag([H1;1; : : : ; H n;n])，
其中每个 Hi;i>0。如果线性回归 问题中的数据已被预处理（如可以使用 PCA） ，去
除了输入特征之间的相关性，那么这一假设成立。
我们可以将 L1正则化目标函数的二次近似分解成关于参数的求和：
^J(w;X;y) =J(w;X;y) +∑
i[
1
2Hi;i(wi w
i)2+jwij]
: (7.22)
如下列形式的解析解（对每一维 i）可以最小化这个近似 代价函数 ：
wi=sign(w
i)max{
jw
ij 
Hi;i;0}
: (7.23)
考虑所有 i且w
i>0的情形，会有两种可能输出：
1.w
i
Hi;i的情况。 正则化后目标中的 wi最优值是 wi= 0。这是因为在方向 i
上J(w;X;y)对^J(w;X;y)的贡献受到抑制， L1正则化项将 wi推向 0。
2.w
i>
Hi;i的情况。在这种情况下， 正则化不会将 wi的最优值推向 0，而仅仅
在那个方向上移动
Hi;i的距离。
w
i<0的情况与之类似，但是 L1惩罚项使 wi更接近 0(增加
Hi;i)或者为 0。
相比 L2正则化，L1正则化会产生更 稀疏（sparse）的解。此处 稀疏性指的是
最优值中的一些参数为 0。和 L2正则化相比， L1正则化的稀疏性具有本质的不同。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.2作为约束的范数惩罚 203
式(7.13)给出了 L2正则化的解 ~w。如果我们使用 Hessian矩阵 H为对角正定矩阵
的假设（与 L1正则化分析时一样） ，重新考虑这个等式，我们发现 ~wi=Hi;i
Hi;i+w
i。
如果 w
i不是零，那么 ~wi也会保持非零。这表明 L2正则化不会使参数变得 稀疏，而
L1正则化有可能通过足够大的 实现稀疏。
由L1正则化导出的稀疏性质已经被广泛地用于 特征选择 （feature selection ）机
制。特征选择 从可用的特征子集选择出有意义的特征，化简 机器学习 问题。著名的
LASSO ( Tibshirani ,1995)（Least Absolute Shrinkage and Selection Operator ）模
型将 L1惩罚和线性模型 结合，并使用最小二乘 代价函数 。L1惩罚使部分子集的权
重为零，表明相应的特征可以被安全地忽略。
在第 5.6.1节，我们看到许多 正则化策略可以被解释为 MAP贝叶斯推断，特别
是L2正则化相当于权重是高斯先验的 MAP贝叶斯推断。对于 L1正则化，用于正则
化代价函数 的惩罚项 Ω( w) =∑
ijwij与通过 MAP贝叶斯推断最大化的对数先
验项是等价的（ w2Rn并且权重先验是各向同性的拉普拉斯分布（式 (3.26)） ） ：
logp(w) =∑
ilogLaplace (wi; 0;1
) = ∥w∥1+nlog nlog2: (7.24)
因为是关于 w最大化进行学习，我们可以忽略 log log2项，因为它们与 w无关。
7.2作为约束的范数惩罚
考虑通过参数范数 正则化的代价函数 ：
~J(;X;y) =J(;X;y) +Ω(): (7.25)
回顾第 4.4节我们可以构造一个 广义 Lagrange 函数来最小化带约束的函数，
即在原始 目标函数 上添加一系列惩罚项。每个惩罚是一个系数之间的乘积，被称
为Karush–Kuhn–Tucker（Karush–Kuhn–Tucker）乘子，以及一个表示约束是否
满足的函数。如果我们想约束 Ω()小于某个常数 k，我们可以构建 广义 Lagrange
函数
L(; ;X;y) =J(;X;y) +(Ω() k): (7.26)
这个约束问题的解由下式给出
= arg min
max
;0L(; ): (7.27)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
204 第七章 深度学习中的正则化
如第 4.4节中描述的，解决这个问题我们需要同时改变 和。第 4.5节给出了
一个带 L2约束的线性回归 实例。还有许多不同的优化方法，有些可能会使用 梯度下
降而其他可能会使用 梯度为0的解析解，但在所有程序中 在Ω()> k时必须增
加，在 Ω()< k时必须减小。所有正值的 都鼓励 Ω()收缩。最优值 也将鼓
励Ω()收缩，但不会像 Ω()小于 k时那么强烈。
为了洞察约束的影响，我们可以固定 ，把这个问题看成只跟 有关的函数：
= arg min
L(; ) = arg min
J(;X;y) +Ω(): (7.28)
这和最小化 ~J的正则化训练问题是完全一样的。因此，我们可以把参数范数惩罚看
作对权重强加的约束。如果 Ω是L2范数，那么权重就是被约束在一个 L2球中。如
果Ω是L1范数，那么权重就是被约束在一个 L1范数限制的区域中。通常我们不
知道权重衰减 系数 约束的区域大小，因为 的值不直接告诉我们 k的值。原则
上我们可以解得 k，但 k和之间的关系取决于 J的形式。虽然我们不知道约束
区域的确切大小，但我们可以通过增加或者减小 来大致扩大或收缩约束区域。较
大的 ，将得到一个较小的约束区域。较小的 ，将得到一个较大的约束区域。
有时候，我们希望使用显式的限制，而不是惩罚。如第 4.4节所述，我们可以修
改下降算法（如 随机梯度下降 算法） ，使其先计算 J()的下降步，然后将 投影到
满足 Ω()< k的最近点。如果我们知道什么样的 k是合适的，而不想花时间寻找对
应于此 k处的 值，这会非常有用。
另一个使用显式约束和重投影而不是使用惩罚强加约束的原因是惩罚可能会导
致目标函数 非凸而使算法陷入局部极小 (对应于小的） 。当训练 神经网络 时，这通
常表现为训练带有几个 ‘‘死亡单元 ’’的神经网络 。这些单元不会对网络学到的函数
有太大影响，因为进入或离开它们的权重都非常小。当使用权重范数的惩罚训练时，
即使可以通过增加权重以显著减少 J，这些配置也可能是局部最优的。因为重投影
实现的显式约束不鼓励权重接近原点，所以在这些情况下效果更好。通过重投影实
现的显式约束只在权重变大并试图离开限制区域时产生作用。
最后，因为重投影的显式约束还对优化过程增加了一定的稳定性，所以这是另
一个好处。当使用较高的学习率时，很可能进入正反馈，即大的权重诱导大 梯度，然
后使得权重获得较大更新。如果这些更新持续增加权重的大小， 就会迅速增大，直
到离原点很远而发生溢出。重投影的显式约束可以防止这种反馈环引起权重无限制
地持续增加。 Hinton et al. (2012b )建议结合使用约束和高学习速率，这样能更快地
探索参数空间，并保持一定的稳定性。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.3正则化和欠约束问题 205
Hinton et al. (2012b )尤其推荐由 Srebro and Shraibman (2005)引入的策略：约
束神经网络 层的权重矩阵每列的范数，而不是限制整个权重矩阵的 Frobenius 范数。
分别限制每一列的范数可以防止某一 隐藏单元 有非常大的权重。如果我们将此约束
转换成 Lagrange 函数中的一个惩罚，这将与 L2权重衰减 类似但每个 隐藏单元 的权
重都具有单独的 KKT乘子。每个 KKT乘子分别会被动态更新，以使每个 隐藏单
元服从约束。在实践中，列范数的限制总是通过重投影的显式约束来实现。
7.3正则化和欠约束问题
在某些情况下，为了正确定义 机器学习 问题，正则化是必要的。 机器学习 中许
多线性模型 ，包括线性回归 和PCA，都依赖于求逆矩阵 X⊤X。只要 X⊤X是奇异
的，这些方法就会失效。当数据生成分布在一些方向上确实没有差异时，或因为例
子较少（即相对输入特征（ X的列）来说）而在一些方向上没有观察到 方差时，这
个矩阵就是奇异的。在这种情况下， 正则化的许多形式对应求逆 X⊤X+I。这个正
则化矩阵可以保证是可逆的。
相关矩阵可逆时，这些线性问题有 闭式解。没有闭式解的问题也可能是欠定的。
一个例子是应用于线性可分问题的 逻辑回归 。如果权重向量 w能够实现完美分类，
那么 2w也会以较高似然实现完美分类。类似 随机梯度下降 的迭代优化算法将持续
增加 w的大小，理论上永远不会停止。在实践中，数值实现的 梯度下降 最终会达到
导致数值溢出的超大权重，此时的行为将取决于程序员如何处理这些不是真正数字
的值。
大多数形式的 正则化能够保证应用于欠定问题的迭代方法收敛。例如，当似然
的斜率等于 权重衰减 的系数时， 权重衰减 将阻止梯度下降 继续增加权重的大小。
使用正则化解决欠定问题的想法超出了 机器学习 的范畴。同样的想法在几个基
本线性代数问题中也非常有用。
正如我们在第 2.9节看到的，我们可以使用 Moore-Penrose 求解欠定线性方程。
回想 X伪逆 X+的一个定义：
X+= lim
↘0(X⊤X+I) 1X⊤: (7.29)
现在我们可以将第 7.29节看作进行具有 权重衰减 的线性回归 。具体来说， 当 正则化系
数趋向 0时，式 (7.29)是式 (7.17)的极限。因此，我们可以将伪逆解释为使用 正则DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
206 第七章 深度学习中的正则化
化来稳定欠定问题。
7.4数据集增强
让机器学习 模型泛化得更好的最好办法是使用更多的数据进行训练。当然，在
实践中，我们拥有的数据量是很有限的。解决这个问题的一种方法是创建假数据并
添加到训练集中。对于一些 机器学习 任务，创建新的假数据相当简单。
对分类来说这种方法是最简单的。分类器需要一个复杂的高维输入 x，并用单
个类别标识 y概括 x。这意味着分类面临的一个主要任务是要对各种各样的变换保
持不变。我们可以轻易通过转换训练集中的 x来生成新的 (x; y)对。
这种方法对于其他许多任务来说并不那么容易。例如，除非我们已经解决了密
度估计问题，否则在密度估计任务中生成新的假数据是很困难的。
数据集增强对一个具体的分类问题来说是特别有效的方法：对象识别。图像是
高维的并包括各种巨大的变化因素，其中有许多可以轻易地模拟。即使模型已使用
卷积和池化技术（第 九章）对部分平移保持不变，沿训练图像每个方向平移几个像
素的操作通常可以大大改善泛化。许多其他操作如旋转图像或缩放图像也已被证明
非常有效。
我们必须要小心，不能使用会改变类别的转换。例如，光学字符识别任务需要
认识到 “b’’和“d’’以及 “6’’和“9’’的区别，所以对这些任务来说，水平翻转和旋转
180◦并不是合适的数据集增强方式。
能保持我们希望的分类不变，但不容易执行的转换也是存在的。例如，平面外
绕轴转动难以通过简单的几何运算在输入像素上实现。
数据集增强对语音识别任务也是有效的 (Jaitly and Hinton ,2013)。
在神经网络 的输入层注入噪声 (Sietsma and Dow ,1991)也可以被看作是数据增
强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输
入，任务仍应该是能够被解决的。然而， 神经网络 被证明对噪声不是非常健壮 (Tang
and Eliasmith ,2010)。改善神经网络 健壮性的方法之一是简单地将随机噪声添加到
输入再进行训练。输入噪声注入是一些 无监督学习 算法的一部分，如 去噪自编码
器(Vincent et al. ,2008a )。向隐藏单元 施加噪声也是可行的，这可以被看作在多个抽
象层上进行的数据集增强。 Poole et al. (2014)最近表明，噪声的幅度被细心调整后，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.5噪声鲁棒性 207
该方法是非常高效的。我们将在第 7.12节介绍一个强大的 正则化策略 Dropout，该
策略可以被看作是通过与噪声 相乘构建新输入的过程。
在比较机器学习 基准测试的结果时，考虑其采取的数据集增强是很重要的。通
常情况下，人工设计的数据集增强方案可以大大减少 机器学习 技术的泛化误差。将
一个机器学习 算法的性能与另一个进行对比时，对照实验是必要的。在比较 机器学
习算法 A和机器学习 算法 B时，应该确保这两个算法使用同一人工设计的数据集增
强方案进行评估。假设算法 A在没有数据集增强时表现不佳，而 B结合大量人工转
换的数据后表现良好。在这样的情况下，很可能是合成转化引起了性能改进，而不
是机器学习 算法 B比算法 A更好。有时候，确定实验是否已经适当控制需要主观
判断。例如，向输入注入噪声的 机器学习 算法是执行数据集增强的一种形式。通常，
普适操作（例如，向输入添加高斯噪声）被认为是 机器学习 算法的一部分，而特定
于一个应用领域（如随机地裁剪图像）的操作被认为是独立的预处理步骤。
7.5噪声鲁棒性
第7.4节已经提出将噪声作用于输入，作为数据集增强策略。对于某些模型而言，
向输入添加方差极小的噪声等价于对权重施加范数惩罚 (Bishop ,1995a ,b)。 在一般情
况下，噪声注入远比简单地收缩参数强大，特别是噪声被添加到 隐藏单元 时会更加强
大。向隐藏单元 添加噪声是值得单独讨论重要的话题；在第 7.12节所述 Dropout 算
法是这种做法的主要发展方向。
另一种正则化模型的噪声使用方式是将其加到的权重。这项技术主要用于 循环
神经网络 (Jim et al. ,1996;Graves ,2011)。这可以被解释为关于权重的贝叶斯 推断的
随机实现。贝叶斯学习过程将权重视为不确定的，并且可以通过概率分布表示这种
不确定性。向权重添加噪声是反映这种不确定性的一种实用的随机方法。
在某些假设下，施加于权重的噪声可以被解释为与更传统的 正则化形式等同，
鼓励要学习的函数保持稳定。我们研究回归的情形，也就是训练将一组特征 x映射
成一个标量的函数 ^y(x)，并使用最小二乘 代价函数 衡量模型预测值 ^y(x)与真实值 y
的误差：
J=Ep(x;y)[(^y(x) y)2]: (7.30)
训练集包含 m对标注样例f(x(1); y(1)); : : : ; (x(m); y(m))g。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
208 第七章 深度学习中的正则化
现在我们假设对每个输入表示，网络权重添加随机扰动 ϵwN (ϵ; 0; I)。想象
我们有一个标准的 l层MLP。我们将扰动模型记为 ^yϵW(x)。尽管有噪声注入，我们
仍然希望减少网络输出误差的平方。因此目标函数变为：
~JW=Ep(x;y;ϵ W)[(^yϵW(x) y)2] (7.31)
=Ep(x;y;ϵ W)[^y2
ϵW(x) 2y^yϵW(x) +y2]: (7.32)
对于小的 ，最小化带权重噪声（方差为 I）的 J等同于最小化附加 正则化项
的J：Ep(x;y)[∥∇ W^y(x)∥2]。这种形式的 正则化鼓励参数进入权重小扰动对输出相对
影响较小的参数空间区域。换句话说，它推动模型进入对权重小的变化相对不敏感
的区域，找到的点不只是极小点，还是由平坦区域所包围的最小点 (Hochreiter and
Schmidhuber ,1995)。在简化的线性回归中（例如， ^y(x) = w⊤x+b） ，正则项退化为
Ep(x)[∥x∥2]，这与函数的参数无关，因此不会对 ~Jw关于模型参数的梯度有影响。
7.5.1向输出目标注入噪声
大多数数据集的 y标签都有一定错误。错误的 y不利于最大化 logp(yjx)。避
免这种情况的一种方法是显式地对标签上的噪声进行建模。例如，我们可以假设，对
于一些小常数 ϵ，训练集标记 y是正确的概率是 1 ϵ， （以 ϵ的概率）任何其他可能
的标签也可能是正确的。这个假设很容易就能解析地与 代价函数 结合，而不用显式
地抽取噪声样本。例如， 标签平滑 （label smoothing ）通过把确切分类目标从 0和
1替换成ϵ
k 1和1 ϵ，正则化具有 k个输出的 softmax 函数的模型。标准交叉熵
损失可以用在这些非确切目标的输出上。使用 softmax 函数和明确目标的最大似然
学习可能永远不会收敛—— softmax 函数永远无法真正预测 0概率或 1概率，因此
它会继续学习越来越大的权重，使预测更极端。使用如 权重衰减 等其他正则化策略
能够防止这种情况。标签平滑的优势是能够防止模型追求确切概率而不影响模型学
习正确分类。这种策略自 20世纪 80年代就已经被使用，并在现代神经网络继续保
持显著特色 (Szegedy et al. ,2015)。
7.6半监督学习
在半监督学习 的框架下， P(x)产生的未标记样本和 P(x;y)中的标记样本都用
于估计 P(yjx)或者根据 x预测 y。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.7多任务学习 209
在深度学习 的背景下， 半监督学习 通常指的是学习一个 表示 h=f(x)。学习表
示的目的是使相同类中的 样本有类似的表示。 无监督学习 可以为如何在 表示空间聚
集样本提供有用线索。在输入空间紧密聚集的 样本应该被映射到类似的表示。在许
多情况下，新空间上的线性分类器可以达到较好的泛化 (Belkin and Niyogi ,2002;
Chapelle et al. ,2003)。这种方法的一个经典变种是使用 主成分分析 作为分类前（在
投影后的数据上分类）的预处理步骤。
我们可以构建这样一个模型， 其中生成模型 P(x)或P(x;y)与判别模型 P(yjx)
共享参数，而不用分离 无监督和监督部分。我们权衡 监督模型准则 logP(yjx)
和无监督或生成模型 准则（如 logP(x)或 logP(x;y)） 。生成模型 准则表达了
对监督学习 问题解的特殊形式的先验知识 (Lasserre et al. ,2006)，即 P(x)的结构通
过某种共享参数的方式连接到 P(yjx)。通过控制在总 准则中的生成 准则，我们可以
获得比纯生成或纯判别训练 准则更好的权衡 (Lasserre et al. ,2006;Larochelle et al. ,
2008)。
Salakhutdinov and Hinton (2008)描述了一种学习回归 核机器中核函数的方法，
其中建模 P(x)时使用的未标记样本大大提高了 P(yjx)的效果。
更多半监督学习 的信息，请参阅 Chapelle et al. (2006a )。
7.7多任务学习
多任务学习 (Caruana ,1993)是通过合并几个任务中的样例（可以视为对参数
施加的软约束）来提高泛化的一种方式。额外的训练样本以同样的方式将模型的参
数推向泛化更好的方向，当模型的一部分在任务之间共享时，模型的这一部分更多
地被约束为良好的值（假设共享是合理的） ，往往能更好地泛化。
图7.2展示了多任务学习 中非常普遍的一种形式，其中不同的 监督任务（给定 x
预测 y(i)）共享相同的输入 x以及一些中间层表示 h(share )，能学习共同的因素池。
该模型通常可以分为两类相关的参数：
1.具体任务的参数（只能从各自任务的样本中实现良好的泛化） 。如图 7.2中的上
层。
2.所有任务共享的通用参数（从所有任务的汇集数据中获益） 。如图 7.2中的下层。
因为共享参数，其统计强度可大大提高（共享参数的样本数量相对于单任务模DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
210 第七章 深度学习中的正则化
h(1)h(1)h(2)h(2)h(3)h(3)y(1)y(1)y(2)y(2)
h(shared)h(shared)xx
图7.2:多任务学习 在深度学习框架中可以以多种方式进行，该图说明了任务共享相同输入但涉及
不同目标随机变量的常见情况。 深度网络 的较低层（无论是 监督前馈的，还是包括向下箭头的生
成组件）可以跨这样的任务共享，而任务特定的参数（分别与从 h(1)和 h(2)进入和发出的权重）
可以在共享表示 h(shared )之上学习。这里的基本假设是存在解释输入 x变化的共同因素池，而每
个任务与这些因素的子集相关联。在该示例中，额外假设顶层 隐藏单元 h(1)和 h(2)专用于每个任
务（分别预测 y(1)和 y(2)） ，而一些中间层表示 h(shared )在所有任务之间共享。在 无监督学习 情
况下，一些顶层因素不与输出任务 (h(3))的任意一个关联是有意义的：这些因素可以解释一些输
入变化但与预测 y(1)或 y(2)不相关。
式增加的比例） ，并能改善泛化和泛化误差的范围 (Baxter ,1995)。当然，仅当不同
的任务之间存在某些统计关系的假设是合理（意味着某些参数能通过不同任务共享）
时才会发生这种情况。
从深度学习 的观点看，底层的先验知识如下： 能解释数据变化（在与之相关联
的不同任务中观察到）的因素中，某些因素是跨两个或更多任务共享的。
7.8提前终止
当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，训练误
差会随着时间的推移逐渐降低但验证集的误差会再次上升。图 7.3是这些现象的一个
例子，这种现象几乎一定会出现。
这意味着如果我们返回使验证集误差最低的参数设置，就可以获得更好的模型
（因此，有希望获得更好的测试误差） 。在每次验证集误差有所改善后，我们存储模DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.8提前终止 211
型参数的副本。当训练算法终止时，我们返回这些参数而不是最新的参数。当验证
集上的误差在事先指定的循环次数内没有进一步改善时，算法就会终止。此过程在
算法 7.1中有更正式的说明。
这种策略被称为 提前终止 （early stopping ） 。这可能是 深度学习 中最常用的 正
则化形式。它的流行主要是因为有效性和简单性。
算法7.1用于确定最佳训练时间量的 提前终止 元算法。这种元算法是一种通用策略，
可以很好地在各种训练算法和各种量化验证集误差的方法上工作。
令n为评估间隔的步数。
令p为‘‘耐心 (patience)’’ ，即观察到较坏的验证集表现 p次后终止。
令o为初始参数。
 o
i 0
j 0
v 1
 
i i
while j < p do
运行训练算法 n步，更新。
i i+n
v′ ValidationSetError ()
ifv′< vthen
j 0
 
i i
v v′
else
j j+ 1
end if
end while
最佳参数为，最佳训练步数为 i
我们可以认为 提前终止 是非常高效的超参数选择算法。按照这种观点，训练步DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
212 第七章 深度学习中的正则化
数仅是另一个超参数。我们从图 7.3可以看到，这个超参数在验证集上具有 U型性能
曲线。很多控制模型容量的超参数在验证集上都是这样的 U型性能曲线，如图 7.3。
在提前终止 的情况下，我们通过拟合训练集的步数来控制模型的有效容量。大多数
超参数的选择必须使用高代价的猜测和检查过程，我们需要在训练开始时猜测一个
超参数，然后运行几个步骤检查它的训练效果。 ‘‘训练时间 ’’是唯一只要跑一次训练
就能尝试很多值的超参数。通过 提前终止 自动选择超参数的唯一显著的代价是训练
期间要定期评估验证集。在理想情况下，这可以并行在与主训练过程分离的机器上，
或独立的 CPU，或独立的 GPU上完成。如果没有这些额外的资源，可以使用比训
练集小的验证集或较不频繁地评估验证集来减小评估代价，较粗略地估算取得最佳
的训练时间。
另一个提前终止 的额外代价是需要保持最佳的参数副本。这种代价一般是可忽
略的，因为可以将它储存在较慢较大的存储器上（例如，在 GPU内存中训练，但将
最佳参数存储在主存储器或磁盘驱动器上） 。由于最佳参数的写入很少发生而且从不
在训练过程中读取，这些偶发的慢写入对总训练时间的影响不大。
0 50 100 150 200 250
Time (epochs)0:000:050:100:150:20Loss (negative log-likelihood)
Training set loss
Validation set loss
图7.3:学习曲线显示负对数似然损失如何随时间变化（表示为遍历数据集的训练迭代数，或 轮数
（epochs） ） 。在这个例子中，我们在 MNIST上训练了一个 maxout网络。我们可以观察到训练目
标随时间持续减小，但验证集上的平均损失最终会再次增加，形成不对称的 U形曲线。
提前终止 是一种非常不显眼的 正则化形式，它几乎不需要改变基本训练过程、
目标函数 或一组允许的参数值。这意味着，无需破坏学习动态就能很容易地使用 提
前终止。相对于 权重衰减 ，必须小心不能使用太多的 权重衰减 ，以防网络陷入不良 局
部极小点 (对应于病态的小权重 )。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.8提前终止 213
提前终止 可单独使用或与其他的 正则化策略结合使用。即使为鼓励更好泛化，使
用正则化策略改进 目标函数 ，在训练目标的 局部极小点 达到最好泛化也是非常罕见
的。
提前终止 需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地
利用这一额外的数据，我们可以在完成 提前终止 的首次训练之后，进行额外的训练。
在第二轮额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策略都
可以用于第二轮训练过程。
一个策略（算法 7.2）是再次初始化模型，然后使用所有数据再次训练。在这个
第二轮训练过程中，我们使用第一轮 提前终止 训练确定的最佳步数。此过程有一些
细微之处。例如，我们没有办法知道重新训练时，对参数进行相同次数的更新和对
数据集进行相同的遍数哪一个更好。由于训练集变大了，在第二轮训练时，每一次
遍历数据集将会更多次地更新参数。
另一个策略是保持从第一轮训练获得的参数，然后使用全部的数据 继续训练。
在这个阶段，已经没有验证集指导我们需要在训练多少步后终止。相反，我们可以监
控验证集的平均损失函数，并继续训练，直到它低于 提前终止 过程终止时的目标值。
此策略避免了重新训练模型的高成本，但表现并没有那么好。例如，验证集的目标
不一定能达到之前的目标值，所以这种策略甚至不能保证终止。我们会在算法 7.3中
更正式地介绍这个过程。
提前终止 对减少训练过程的计算成本也是有用的。除了由于限制训练的迭代次
数而明显减少的计算成本，还带来了 正则化的益处（不需要添加惩罚项的 代价函
数或计算这种附加项的 梯度） 。
算法7.2使用提前终止 确定训练步数，然后在所有数据上训练的元算法。
令 X(train )和 y(train )为训练集。
将 X(train )和 y(train )分别分割为 (X(subtrain ),X(valid ))和(y(subtrain ),y(valid ))。
从随机开始，使用 X(subtrain )和 y(subtrain )作为训练集， X(valid )和 y(valid )作为
验证集，运行 (算法 7.1)。这将返回最佳训练步数 i。
将再次设为随机值。
在 X(train )和 y(train )上训练 i步。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
214 第七章 深度学习中的正则化
算法 7.3使用提前终止 确定将会 过拟合的目标值，然后在所有数据上训练直到再次
达到该值的元算法。
令 X(train )和 y(train )为训练集。
将 X(train )和 y(train )分别分割为 (X(subtrain ),X(valid ))和(y(subtrain ),y(valid ))。
从随机开始，使用 X(subtrain )和 y(subtrain )作为训练集， X(valid )和 y(valid )作为
验证集，运行 (算法 7.1)。这会更新。
ϵ J(;X(subtrain );y(subtrain ))
while J(;X(valid );y(valid ))> ϵdo
在 X(train )和 y(train )上训练 n步。
end while
提前终止 为何具有 正则化效果:目前为止，我们已经声明 提前终止 是一种正则化策
略，但我们只通过展示验证集误差的学习曲线是一个 U型曲线来支持这种说法。
提前终止 正则化模型的真正机制是什么呢？ Bishop (1995a )和Sjöberg and Ljung
(1995)认为提前终止 可以将优化过程的参数空间限制在初始参数值 0的小邻域内。
更具体地，想象用学习率 ϵ进行 个优化步骤（对应于 个训练迭代） 。我们可以
将ϵ作为有效 容量的度量。假设 梯度有界，限制迭代的次数和学习速率能够限制从
0到达的参数空间的大小，如图 7.4所示。在这个意义上， ϵ的效果就好像是 权重
衰减系数的倒数。
事实上，在二次误差的简单 线性模型 和简单的 梯度下降 情况下，我们可以展示 提
前终止相当于 L2正则化。
为了与经典 L2正则化比较，我们只考察唯一的参数是线性权重（ = w）的简
单情形。我们在权重 w的经验最佳值 w附近以二次近似建模 代价函数 J：
^J() =J(w) +1
2(w w)⊤H(w w); (7.33)
其中 H是J关于 w在 w点的Hessian。鉴于假设 w是J(w)的最小点，我们知
道 H为半正定。在局部 泰勒级数逼近下， 梯度由下式给出：
∇ w^J(w) = H(w w): (7.34)
接下来我们研究训练时参数向量的轨迹。为简化起见，我们将参数向量初始化
为原点3，也就是 w(0)= 0。我们通过分析 ^J上的梯度下降 来研究 J上近似的 梯度
3对于神经网络 ，我们需要打破 隐藏单元 间的对称平衡因此不能将所有参数都初始化为 0（如第 6.2节所讨论的） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.8提前终止 215
图7.4:提前终止 效果的示意图。 (左)实线轮廓线表示负对数似然的轮廓。虚线表示从原点开始
的SGD所经过的轨迹。 提前终止 的轨迹在较早的点 ~w处停止，而不是停止在最小化代价的点 w
处。(右)为了对比，使用 L2正则化效果的示意图。虚线圆圈表示 L2惩罚的轮廓， L2惩罚使得总
代价的最小值比非 正则化代价的最小值更靠近原点。
下降的效果：
w()= w( 1) ϵ∇ w^J(w( 1)) (7.35)
= w( 1) ϵH(w( 1) w); (7.36)
w() w= ( I ϵH)(w( 1) w): (7.37)
现在让我们在 H特征向量的空间中改写表达式，利用 H的特征分解： H= QQ⊤，
其中是对角矩阵， Q是特征向量的一组标准正交基。
w() w= ( I ϵQQ⊤)(w( 1) w) (7.38)
Q⊤(w() w) = ( I ϵ)Q⊤(w( 1) w) (7.39)
假定 w(0)= 0并且 ϵ选择得足够小以保证 j1 ϵij<1，经过 次参数更新后轨迹
如下：
Q⊤w()= [ I (I ϵ)]Q⊤w: (7.40)
现在，式 (7.13)中 Q⊤~w的表达式能被重写为：
Q⊤~w= (+I) 1Q⊤w; (7.41)
Q⊤~w= [ I (+I) 1]Q⊤w: (7.42)
然而，对于其他任何初始值 w(0)该论证都成立DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
216 第七章 深度学习中的正则化
比较式 (7.40)和式 (7.42)，我们能够发现，如果超参数 ϵ; 和满足如下：
(I ϵ)= (+I) 1; (7.43)
那么 L2正则化和提前终止 可以被看作是等价的（至少在 目标函数 的二次近似下） 。
进一步取对数，使用 log(1 +x)的级数展开，我们可以得出结论：如果所有 i是
小的（即 ϵi≪1且i/≪1） ，那么
1
ϵ; (7.44)
1
ϵ: (7.45)
也就是说，在这些假设下，训练迭代次数 起着与 L2参数成反比的作用， ϵ的倒
数与权重衰减 系数的作用类似。
对应显著曲率（ 目标函数 ）方向的参数值 正则化小于小曲率方向。当然，在 提
前终止的情况下，这实际上意味着对应于显著曲率方向的参数比较小的曲率方向的
参数更早地停止学习。
本节中的推导表明长度为 的轨迹结束于 L2正则化目标的极小点。当然， 提前
终止比简单的轨迹长度限制更丰富；相反， 提前终止 通常涉及监控验证集误差，以便
在空间特别好的点处终止轨迹。因此 提前终止 比权重衰减 更具有优势， 提前终止 能
自动确定 正则化的正确量，而 权重衰减 需要多个训练实验测试其超参数的不同值。
7.9参数绑定和参数共享
目前为止，本章讨论对参数添加约束或惩罚时，一直是相对于固定的区域或点。
例如， L2正则化（或权重衰减 ）对参数偏离零的固定值进行惩罚。然而，有时我们
可能需要其他的方式来表达我们对模型参数适当值的先验知识。有时候，我们可能
无法准确地知道应该使用什么样的参数，但我们根据领域和模型结构方面的知识得
知模型参数之间应该存在一些相关性。
我们经常想要表达的一种常见依赖是某些参数应当彼此接近。考虑以下情形：
我们有两个模型执行相同的分类任务（具有相同类别） ，但输入分布稍有不同。形式
地，我们有参数为 w(A)的模型 A和参数为 w(B)的模型 B。这两种模型将输入映射
到两个不同但相关的输出： ^y(A)=f(w(A);x)和^y(B)=f(w(B);x)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.10稀疏表示 217
我们可以想象，这些任务会足够相似（或许具有相似的输入和输出分布） ，因
此我们认为模型参数应彼此靠近： 8i; w(A)
i应该与 w(B)
i接近。我们可以通过 正则
化利用此信息。具体来说，我们可以使用以下形式的参数范数惩罚： Ω( w(A);w(B)) =w(A) w(B)2
2。在这里我们使用 L2惩罚，但也可以使用其他选择。
这种方法由 Lasserre et al. (2006)提出，正则化一个模型（ 监督模式下训练的分
类器）的参数，使其接近另一个 无监督模式下训练的模型（捕捉观察到的输入数据
的分布）的参数。这种构造架构使得许多分类模型中的参数能与之对应的 无监督模
型的参数匹配。
参数范数惩罚是 正则化参数使其彼此接近的一种方式，而更流行的方法是使用
约束：强迫某些参数相等 。由于我们将各种模型或模型组件解释为共享唯一的一组
参数，这种 正则化方法通常被称为 参数共享 （parameter sharing ） 。和正则化参数使
其接近（通过范数惩罚）相比， 参数共享 的一个显著优点是，只有参数（唯一一个集
合）的子集需要被存储在内存中。对于某些特定模型，如 卷积神经网络 ，这可能可
以显著减少模型所占用的内存。
7.9.1卷积神经网络
目前为止，最流行和广泛使用的 参数共享 出现在应用于 计算机视觉 的卷积神经
网络（CNN）中。自然图像有许多统计属性是对转换不变的。例如，猫的照片即使
向右边移了一个像素，仍保持猫的照片。 CNN通过在图像多个位置共享参数来考虑
这个特性。相同的特征（具有相同权重的 隐藏单元 ）在输入的不同位置上计算获得。
这意味着无论猫出现在图像中的第 i列或 i+ 1列，我们都可以使用相同的猫探测器
找到猫。
参数共享 显著降低了 CNN模型的参数数量，并显著提高了网络的大小而不需要
相应地增加训练数据。它仍然是将领域知识有效地整合到网络架构的最佳范例之一。
我们将会在第 九章中更详细地讨论 卷积神经网络 。
7.10稀疏表示
前文所述的 权重衰减 直接惩罚模型参数。另一种策略是惩罚 神经网络 中的激活
单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
218 第七章 深度学习中的正则化
我们已经讨论过（在第 7.1.2节中） L1惩罚如何诱导 稀疏的参数，即许多参数为
零（或接近于零） 。 表示的稀疏，在另一方面描述了许多元素是零（或接近零）的 表
示。我们可以 线性回归 的情况下简单说明这种区别：
2
6666666418
5
15
 9
 33
77777775
y2Rm=2
666666644 0 0 2 0 0
0 0 1 0 3 0
0 5 0 0 0 0
1 0 0 1 0 4
1 0 0 0 5 03
77777775
A2Rmn2
66666666642
3
 2
 5
1
43
7777777775
x2Rn(7.46)
2
66666664 14
1
19
2
233
77777775
y2Rm=2
666666643 1 2 5 4 1
4 2 3 1 1 3
 1 5 4 2  3 2
3 1 2 3 0 3
 5 4 2 2 5 13
77777775
B2Rmn2
66666666640
2
0
0
 3
03
7777777775
h2Rn(7.47)
第一个表达式是参数 稀疏的线性回归 模型的例子。第二个表达式是数据 x具
有稀疏表示 h的线性回归。也就是说， h是 x的一个函数，在某种意义上 表示存在
于 x中的信息，但只是用一个 稀疏向量表示。
表示的正则化可以使用参数 正则化中同种类型的机制实现。
表示的范数惩罚 正则化是通过向 损失函数 J添加对表示的范数惩罚来实现的。
我们将这个惩罚记作 Ω( h)。和以前一样，我们将 正则化后的损失函数记作 ~J：
~J(;X;y) =J(;X;y) +Ω( h); (7.48)
其中 2[0;1]权衡范数惩罚项的相对贡献，越大的 对应越多的 正则化。
正如对参数的 L1惩罚诱导参数 稀疏性，对表示元素的 L1惩罚诱导 稀疏的表示：
Ω( h) =∥h∥1=∑
ijhij。当然 L1惩罚是使 表示稀疏的方法之一。其他方法还包括
从表示上的Student- t先验导出的惩罚 (Olshausen and Field ,1996;Bergstra ,2011)
和KL散度惩罚 (Larochelle and Bengio ,2008a )有利于表示元素约束于单位区间上。
Lee et al. (2008)和Goodfellow et al. (2009)都提供了 正则化几个样本平均激活的例
子，即令1
m∑
ih(i)接近某些目标值（如每项都是 :01的向量） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.11 BAGGING 和其他集成方法 219
还有一些其他方法通过激活值的硬性约束来获得 表示稀疏。例如， 正交匹配追
踪(orthogonal matching pursuit)( Pati et al. ,1993)通过解决 约束优化 问题将输入值
x编码成表示 h
arg min
h;∥h∥0<k∥x Wh∥2; (7.49)
其中∥h∥0是 h中非零项的个数。当 W被约束为正交时，我们可以高效地解决这个
问题。这种方法通常被称为 OMP- k，通过 k指定允许的非零特征数量。 Coates and
Ng(2011)证明OMP- 1可以成为深度架构中非常有效的特征提取器。
含有隐藏单元 的模型在本质上都能变得 稀疏。在本书中，我们将看到在各种情
况下使用 稀疏正则化的例子。
7.11 Bagging 和其他集成方法
Bagging （bootstrap aggregating ）是通过结合几个模型降低泛化误差的技术
(Breiman ,1994)。主要想法是分别训练几个不同的模型，然后让所有模型表决测
试样例的输出。这是 机器学习 中常规策略的一个例子，被称为 模型平均 （model
averaging ） 。采用这种策略的技术被称为 集成方法。
模型平均 （model averaging ）奏效的原因是不同的模型通常不会在测试集上产
生完全相同的误差。
假设我们有 k个回归模型。假设每个模型在每个例子上的误差是 ϵi，这个误差
服从零均值 方差为E[ϵ2
i] =v且协方差为E[ϵiϵj] =c的多维正态分布。通过所有 集
成模型的平均预测所得误差是1
k∑
iϵi。集成预测器平方误差的期望是
E[(
1
k∑
iϵi)2]
=1
k2E[∑
i(
ϵ2
i+∑
j̸=iϵiϵj)]
; (7.50)
=1
kv+k 1
kc: (7.51)
在误差完全相关即 c=v的情况下，均方误差减少到 v，所以模型平均 没有任何帮
助。在错误完全不相关即 c= 0的情况下，该 集成平方误差的期望仅为1
kv。这意味
着集成平方误差的期望会随着 集成规模增大而线性减小。换言之， 集成平均至少与
它的任何成员表现得一样好，并且如果成员的误差是独立的， 集成将显著地比其成
员表现得更好。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
220 第七章 深度学习中的正则化
不同的集成方法以不同的方式构建 集成模型。例如， 集成的每个成员可以使用
不同的算法和 目标函数 训练成完全不同的模型。 Bagging是一种允许重复多次使用同
一种模型、训练算法和 目标函数 的方法。
具体来说， Bagging涉及构造 k个不同的数据集。每个数据集从原始数据集中重
复采样构成，和原始数据集具有相同数量的样例。这意味着，每个数据集以高概率
缺少一些来自原始数据集的例子，还包含若干重复的例子（如果所得训练集与原始
数据集大小相同，那所得数据集中大概有原始数据集 2/3的实例） 。模型 i在数据集
i上训练。每个数据集所含样本的差异导致了训练模型之间的差异。图 7.5是一个例
子。
8
8
First ensemble memberSecond ensemble memberOriginal datasetFirst resampled datasetSecond resampled dataset
图7.5:描述Bagging如何工作的草图。假设我们在上述数据集（包含一个 8,一个 6和一个 9）上
训练数字 8的检测器。假设我们制作了两个不同的重采样数据集。 Bagging训练程序通过替换采样
构建这些数据集。第一个数据集忽略 9并重复 8。在这个数据集上，检测器得知数字顶部有一个
环就对应于一个 8。第二个数据集中，我们忽略 6并重复 9。在这种情况下，检测器得知数字底部
有一个环就对应于一个 8。这些单独的分类规则中的每一个都是不可靠的，但如果我们平均它们的
输出，就能得到鲁棒的检测器，只有当 8的两个环都存在时才能实现最大置信度。
神经网络 的解能达到足够多的变化意味着他们可以从 模型平均 中受益 (即使所
有模型都在同一数据集上训练 )。神经网络 中随机初始化的差异、 小批量的随机选择、
超参数的差异或不同输出的非确定性实现往往足以使得 集成中的不同成员具有部分
独立的误差。
模型平均 是一个减少泛化误差的非常强大可靠的方法。在作为科学论文算法的
基准时，它通常是不鼓励使用的，因为任何 机器学习 算法都可以从 模型平均 中大幅
获益（以增加计算和存储为代价） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.12 DROPOUT 221
机器学习 比赛中的取胜算法通常是使用超过几十种 模型平均 的方法。最近一个
突出的例子是 Netﬂix Grand Prize( Koren ,2009)。
不是所有构建 集成的技术都是为了让 集成模型比单一模型更加 正则化。例如，一
种被称为 Boosting （Boosting ）的技术 (Freund and Schapire ,1996b ,a)构建比单个
模型容量更高的集成模型。通过向 集成逐步添加 神经网络 ，Boosting 已经被应用于构
建神经网络的 集成(Schwenk and Bengio ,1998)。通过逐渐增加 神经网络 的隐藏单元 ，
Boosting 也可以将单个神经网络解释为一个 集成。
7.12 Dropout
Dropout （Dropout）(Srivastava et al. ,2014)提供了正则化一大类模型的方
法，计算方便但功能强大。在第一种近似下， Dropout可以被认为是 集成大量深层 神
经网络的实用 Bagging方法。 Bagging涉及训练多个模型，并在每个测试样本上评估
多个模型。当每个模型都是一个很大的 神经网络 时，这似乎是不切实际的，因为训
练和评估这样的网络需要花费很多运行时间和内存。通常我们只能 集成五至十个神
经网络，如 Szegedy et al. (2014a )集成了六个神经网络赢得 ILSVRC，超过这个数量
就会迅速变得难以处理。 Dropout提供了一种廉价的 Bagging集成近似，能够训练和
评估指数级数量的 神经网络 。
具体而言， Dropout训练的集成包括所有从基础网络除去非输出单元后形成的子
网络，如图 7.6所示。最先进的 神经网络 基于一系列仿射变换和非线性变换，我们只
需将一些单元的输出乘零就能有效地删除一个单元。这个过程需要对模型（如径向
基函数网络，单元的状态和参考值之间存在一定区别）进行一些修改。为了简单起
见，我们在这里提出乘零的简单 Dropout算法，但是它被简单修改后，可以与从网络
中移除单元的其他操作结合使用。
回想一下 Bagging学习，我们定义 k个不同的模型，从训练集有放回采样构造
k个不同的数据集，然后在训练集 i上训练模型 i。Dropout的目标是在指数级数
量的神经网络 上近似这个过程。具体来说，在训练中使用 Dropout时，我们会使用
基于小批量的学习算法和较小的步长，如 梯度下降 等。我们每次在 小批量中加载一
个样本，然后随机抽样应用于网络中所有输入和 隐藏单元 的不同二值 掩码。对于每
个单元， 掩码是独立采样的。 掩码值为 1的采样概率（导致包含一个单元）是训练
开始前一个固定的超参数。它不是模型当前参数值或输入样本的函数。通常在每一DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
222 第七章 深度学习中的正则化
yyh1h1h2h2x1x1x2x2yyh1h1h2h2x1x1x2x2yyh1h1h2h2x2x2yyh1h1h2h2x1x1yyh2h2x1x1x2x2yyh1h1x1x1x2x2yyh1h1h2h2yyx1x1x2x2yyh2h2x2x2yyh1h1x1x1yyh1h1x2x2yyh2h2x1x1yyx1x1yyx2x2yyh2h2yyh1h1yyBase network
Ensemble of subnetworks
图7.6:Dropout 训练由所有子网络组成的 集成，其中子网络通过从基本网络中删除非输出单元构
建。我们从具有两个可见单元和两个 隐藏单元 的基本网络开始。这四个单元有十六个可能的子集。
右图展示了从原始网络中丢弃不同的单元子集而形成的所有十六个子网络。在这个小例子中，所
得到的大部分网络没有输入单元或没有从输入连接到输出的路径。当层较宽时，丢弃所有从输入
到输出的可能路径的概率变小，所以这个问题不太可能在出现层较宽的网络中。
个小批量训练的神经网络中，一个输入单元被包括的概率为 0:8，一个隐藏单元 被包
括的概率为 0:5。然后，我们运行和之前一样的前向传播、反向传播以及学习更新。
图7.7说明了在 Dropout下的前向传播。
更正式地说，假设一个 掩码向量指定被包括的单元， J(;)是由参数和掩
码定义的模型代价。那么 Dropout训练的目标是最小化 EJ(;)。期望包含多达
指数级的项，但我们可以通过抽样 获得梯度的无偏估计。
Dropout训练与 Bagging训练不太一样。在 Bagging的情况下，所有模型都是独立DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.12 DROPOUT 223
ˆx1ˆx1µx1µx1x1x1ˆx2ˆx2x2x2µx2µx2h1h1h2h2µh1µh1µh2µh2ˆh1ˆh1ˆh2ˆh2yyyyh1h1h2h2x1x1x2x2
图7.7:在使用 Dropout 的前馈网络中前向传播的示例。 (顶部)在此示例中，我们使用具有两个输入
单元，具有两个 隐藏单元 的隐藏层以及一个输出单元的前馈网络。 (底部)为了执行具有 Dropout 的
前向传播，我们随机地对向量 进行采样，其中网络中的每个输入或 隐藏单元 对应一项。中的
每项都是二值的且独立于其他项采样。超参数的采样概率为 1，隐藏层的采样概率通常为 0:5，输
入的采样概率通常为 0:8。网络中的每个单元乘以相应的 掩码，然后正常地继续沿着网络的其余部
分前向传播。这相当于从图 7.6中随机选择一个子网络并沿着前向传播。
的。在 Dropout的情况下，所有模型共享参数，其中每个模型继承父 神经网络 参数
的不同子集。 参数共享 使得在有限可用的内存下表示指数级数量的模型变得可能。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
224 第七章 深度学习中的正则化
在Bagging的情况下，每一个模型在其相应训练集上训练到收敛。在 Dropout的情况
下，通常大部分模型都没有显式地被训练，因为通常父 神经网络 会很大，以致于到
宇宙毁灭都不可能采样完所有的子网络。取而代之的是，在单个步骤中我们训练一
小部分的子网络， 参数共享 会使得剩余的子网络也能有好的参数设定。这些是仅有
的区别。除了这些， Dropout与Bagging算法一样。例如，每个子网络中遇到的训练
集确实是替换采样的原始训练集的一个子集。
Bagging集成必须根据所有成员的累积投票做一个预测。在这种背景下，我们
将这个过程称为 推断（inference ） 。目前为止，我们在介绍 Bagging和Dropout时没
有要求模型具有明确的概率。现在，我们假定该模型的作用是输出一个概率分布。
在Bagging的情况下，每个模型 i产生一个概率分布 p(i)(yjx)。集成的预测由这些
分布的算术平均值给出，
1
kk∑
i=1p(i)(yjx): (7.52)
在Dropout的情况下，通过 掩码定义每个子模型的概率分布 p(yjx;)。所
有掩码的算术平均值由下式给出
∑
p()p(yjx;); (7.53)
其中 p()是训练时采样 的概率分布。
因为这个求和包含多达指数级的项，除非该模型的结构允许某种形式的简化，
否则是不可能计算的。目前为止，无法得知深度 神经网络 是否允许某种可行的简化。
相反，我们可以通过采样近似 推断，即平均许多 掩码的输出。即使是 10 20个掩
码就足以获得不错的表现。
然而，一个更好的方法能不错地近似整个 集成的预测，且只需一个前向传播
的代价。要做到这一点，我们改用 集成成员预测分布的几何平均而不是算术平均。
Warde-Farley et al. (2014)提出的论点和经验证据表明，在这个情况下几何平均与
算术平均表现得差不多。
多个概率分布的几何平均不能保证是一个概率分布。为了保证结果是一个概率
分布，我们要求没有子模型给某一事件分配概率 0，并重新标准化所得分布。通过几DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.12 DROPOUT 225
何平均直接定义的非标准化概率分布由下式给出
~pensemble (yjx) = 2d√∏
p(yjx;); (7.54)
其中 d是可被丢弃的单元数。这里为简化介绍，我们使用均匀分布的 ，但非均匀
分布也是可以的。为了作出预测，我们必须重新标准化 集成：
pensemble (yjx) =~pensemble (yjx)∑
y′~pensemble (y′jx): (7.55)
涉及Dropout的一个重要观点 (Hinton et al. ,2012b )是，我们可以通过评估模型
中p(yjx)来近似 pensemble：该模型具有所有单元，但我们将模型的权重修改为和单
元i的概率的乘积。这个修改的动机是得到从该单元输出的正确期望值。我们把这
种方法称为 权重比例推断规则 （weight scaling inference rule ） 。目前还没有在深度
非线性网络上对这种近似推断规则的准确性作任何理论分析，但经验上表现得很好。
因为我们通常使用1
2的包含概率，权重比例规则一般相当于在训练结束后将权
重除 2，然后像平常一样使用模型。实现相同结果的另一种方法是在训练期间将单元
的状态乘 2。无论哪种方式，我们的目标是确保在测试时一个单元的期望总输入与在
训练时该单元的期望总输入是大致相同的（即使近半单位在训练时丢失） 。
对许多不具有非线性 隐藏单元 的模型族而言， 权重比例推断规则 是精确的。举
个简单的例子，考虑 softmax 函数回归分类，其中由向量 v表示 n个输入变量：
P(y= yjv) =softmax(
W⊤v+b)
y: (7.56)
我们可以根据二值向量 d逐元素的乘法将一类子模型进行索引：
P(y= yjv;d) =softmax(
W⊤(d⊙v) + b)
y: (7.57)
集成预测器被定义为重新标准化所有 集成成员预测的几何平均：
Pensemble (y= yjv) =~Pensemble (y= yjv)∑
y′~Pensemble (y= y′jv); (7.58)
其中
~Pensemble (y= yjv) = 2n√∏
d2f0;1gnP(y= yjv;d): (7.59)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
226 第七章 深度学习中的正则化
为了证明 权重比例推断规则 是精确的，我们简化 ~Pensemble：
~Pensemble (y= yjv) = 2n√∏
d2f0;1gnP(y= yjv;d) (7.60)
= 2n√∏
d2f0;1gnsoftmax (W⊤(d⊙v) + b)y (7.61)
=2nvuut∏
d2f0;1gnexp(W⊤
y;:(d⊙v) + by)
∑
y′exp(W⊤
y′;;(d⊙v) + by′)(7.62)
=2n√∏
d2f0;1gnexp(W⊤
y;:(d⊙v) + by)
2n√∏
d2f0;1gn∑
y′exp(W⊤
y′;:(d⊙v) + by′)(7.63)
由于 ~P将被标准化，我们可以放心地忽略那些相对 y不变的乘法：
~Pensemble (y= yjv)/ 2n√∏
d2f0;1gnexp(W⊤
y;:(d⊙v) + by) (7.64)
= exp(
1
2n∑
d2f0;1gnW⊤
y;;(d⊙v) + by)
(7.65)
= exp(1
2W⊤
y;:v+by)
: (7.66)
将其代入式 (7.58)，我们得到了一个权重为1
2W的softmax 函数分类器。
权重比例推断规则 在其他设定下也是精确的，包括条件正态输出的回归网络以
及那些隐藏层不包含非线性的深度网络。然而， 权重比例推断规则 对具有非线性的
深度模型仅仅是一个近似。虽然这个近似尚未有理论上的分析，但在实践中往往效
果很好。 Goodfellow et al. (2013b )实验发现， 集成预测权重比例推断规则 比蒙特卡
罗近似的效果更好（在分类精度方面） 。即使允许 蒙特卡罗 近似采样多达 1000子网
络时也比不过 集成。Gal and Ghahramani (2015)发现一些模型可以通过二十个样本
和蒙特卡罗 近似获得更好的分类精度。似乎 推断近似的最佳选择是与问题相关的。
Srivastava et al. (2014)显示， Dropout比其他标准的计算开销小的 正则化方法
（如权重衰减 、过滤器范数约束和 稀疏激活的正则化）更有效。 Dropout也可以与其
他形式的 正则化合并，得到进一步的提升。
计算方便是 Dropout的一个优点。训练过程中使用 Dropout产生 n个随机二进制
数与状态相乘，每个样本每次更新只需 O(n)的计算复杂度。根据实现，也可能需要DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.12 DROPOUT 227
O(n)的存储空间来持续保存这些二进制数（直到反向传播阶段） 。使用训练好的模
型推断时，计算每个样本的代价与不使用 Dropout是一样的，尽管我们必须在开始运
行推断前将权重除以 2。
Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。几乎在所有
使用分布式表示 且可以用 随机梯度下降 训练的模型上都表现很好。包括前馈神经网
络、概率模型，如 受限玻尔兹曼机 (Srivastava et al. ,2014)，以及循环神经网络 (Bayer
and Osendorfer ,2014;Pascanu et al. ,2014a )。许多效果差不多的其他 正则化策略对
模型结构的限制更严格。
虽然Dropout在特定模型上每一步的代价是微不足道的，但在一个完整的系统
上使用 Dropout的代价可能非常显著。因为 Dropout是一个正则化技术，它减少了模
型的有效容量。为了抵消这种影响，我们必须增大模型规模。不出意外的话，使
用Dropout时最佳验证集的误差会低很多，但这是以更大的模型和更多训练算法的迭
代次数为代价换来的。对于非常大的数据集， 正则化带来的泛化误差减少得很小。在
这些情况下，使用 Dropout和更大模型的计算代价可能超过 正则化带来的好处。
只有极少的训练样本可用时， Dropout不会很有效。在只有不到 5000的样本
的Alternative Splicing 数据集上 (Xiong et al. ,2011)，贝叶斯神经网络 (Neal,1996)
比Dropout表现得更好 (Srivastava et al. ,2014)。当有其他未分类的数据可用时， 无
监督特征学习也比 Dropout更有优势。
Wager et al. (2013)表明，当 Dropout作用于线性回归 时，相当于每个输入特征
具有不同 权重衰减 系数的 L2权重衰减 。每个特征的 权重衰减 系数的大小是由其方差
来确定的。其他 线性模型 也有类似的结果。而对于深度模型而言， Dropout与权重衰
减是不等同的。
使用Dropout训练时的随机性不是这个方法成功的必要条件。它仅仅是近似所有
子模型总和的一个方法。 Wang and Manning (2013)导出了近似这种边缘分布的解
析解。他们的近似被称为 快速Dropout （fast dropout ） ，减小梯度计算中的随机性
而获得更快的收敛速度。这种方法也可以在测试时应用，能够比 权重比例推断规则 更
合理地（但计算也更昂贵）近似所有子网络的平均。 快速 Dropout在小神经网络上
的性能几乎与标准的 Dropout相当，但在大问题上尚未产生显著改善或尚未应用。
随机性对实现 Dropout的正则化效果不是必要的，同时也不是充分的。为了证明
这一点， Warde-Farley et al. (2014)使用一种被称为 Dropout Boosting （Dropout
Boosting ）的方法设计了一个对照实验，具有与传统 Dropout方法完全相同的噪声 掩DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
228 第七章 深度学习中的正则化
码，但缺乏 正则化效果。 Dropout Boosting 训练整个 集成以最大化训练集上的似然。
从传统 Dropout类似于 Bagging的角度来看，这种方式类似于 Boosting 。如预期一样，
和单一模型训练整个网络相比， Dropout Boosting 几乎没有 正则化效果。这表明，使
用Bagging解释Dropout比使用稳健性噪声解释 Dropout更好。只有当随机抽样的 集
成成员相互独立地训练好后，才能达到 Bagging集成的正则化效果。
Dropout启发其他以随机方法训练指数量级的共享权重的 集成。DropConnect 是
Dropout的一个特殊情况，其中一个标量权重和单个 隐藏单元 状态之间的每个乘积
被认为是可以丢弃的一个单元 (Wan et al. ,2013)。随机池化是构造卷积神经网络 集
成的一种随机 池化的形式 (见第 9.3节)，其中每个卷积网络参与每个特征图的不同空
间位置。目前为止， Dropout仍然是最广泛使用的隐式 集成方法。
一个关于 Dropout的重要见解是，通过随机行为训练网络并平均多个随机决定进
行预测，实现了一种 参数共享 的Bagging形式。早些时候，我们将 Dropout描述为通
过包括或排除单元形成模型 集成的Bagging。然而，这种 参数共享 策略不一定要基于
包括和排除。原则上，任何一种随机的修改都是可接受的。在实践中，我们必须选
择让神经网络 能够学习对抗的修改类型。在理想情况下，我们也应该使用可以快速
近似推断的模型族。我们可以认为由向量 参数化的任何形式的修改，是对 所有
可能的值训练 p(yjx;)的集成。注意，这里不要求 具有有限数量的值。例如，
可以是实值。 Srivastava et al. (2014)表明，权重乘以 N (1;I)比基于二值 掩
码Dropout表现得更好。由于 E[] = 1，标准网络自动实现 集成的近似推断，而不需
要权重比例推断规则 。
目前为止，我们将 Dropout介绍为一种纯粹高效近似 Bagging的方法。然而，还
有比这更进一步的 Dropout观点。 Dropout不仅仅是训练一个 Bagging的集成模型，并
且是共享 隐藏单元 的集成模型。这意味着无论其他 隐藏单元 是否在模型中，每个 隐藏
单元必须都能够表现良好。 隐藏单元 必须准备好进行模型之间的交换和互换。 Hinton
et al. (2012c )由生物学的想法受到启发：有性繁殖涉及到两个不同生物体之间交换
基因，进化产生的压力使得基因不仅是良好的而且要准备好不同有机体之间的交换。
这样的基因和这些特点对环境的变化是非常稳健的，因为它们一定会正确适应任何
一个有机体或模型不寻常的特性。因此 Dropout正则化每个隐藏单元 不仅是一个很好
的特征，更要在许多情况下是良好的特征。 Warde-Farley et al. (2014)将Dropout与
大集成的训练相比并得出结论：相比独立模型 集成获得泛化误差， Dropout会带来额
外的改进。
Dropout强大的大部分原因来自施加到 隐藏单元 的掩码噪声，了解这一事实是重DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.13对抗训练 229
要的。这可以看作是对输入内容的信息高度智能化、自适应破坏的一种形式，而不
是对输入原始值的破坏。例如，如果模型学得通过鼻检测脸的 隐藏单元 hi，那么丢
失hi对应于擦除图像中有鼻子的信息。模型必须学习另一种 hi，要么是鼻子存在的
冗余编码，要么是脸部的另一特征，如嘴。传统的噪声注入技术，在输入端加非结
构化的噪声不能够随机地从脸部图像中抹去关于鼻子的信息，除非噪声的幅度大到
几乎能抹去图像中所有的信息。破坏提取的特征而不是原始值，让破坏过程充分利
用该模型迄今获得的关于输入分布的所有知识。
Dropout的另一个重要方面是噪声是乘性的。如果是固定规模的加性噪声，那么
加了噪声 ϵ的整流线性 隐藏单元 可以简单地学会使 hi变得很大（使增加的噪声 ϵ变
得不显著） 。乘性噪声不允许这样病态地解决噪声鲁棒性问题。
另一种深度学习 算法—— 批标准化 ，在训练时向 隐藏单元 引入加性和乘性噪声
重新参数化模型。 批标准化 的主要目的是改善优化，但噪声具有 正则化的效果，有
时没必要再使用 Dropout。批标准化 将会在第 8.7.1节中被更详细地讨论。
7.13对抗训练
在许多情况下， 神经网络 在独立同分布的测试集上进行评估已经达到了人类表
现。因此，我们自然要怀疑这些模型在这些任务上是否获得了真正的人类层次的理
解。为了探索网络对底层任务的理解层次，我们可以探索这个模型错误分类的例子。
Szegedy et al. (2014b )发现，在精度达到人类水平的 神经网络 上通过优化过程故意
构造数据点，其上的误差率接近 100%，模型在这个输入点 x′的输出与附近的数据
点 x非常不同。在许多情况下， x′与 x非常近似，人类观察者不会察觉原始样本
和对抗样本 （adversarial example ）之间的差异，但是网络会作出非常不同的预测。
见图 7.8中的例子。
对抗样本 在很多领域有很多影响，例如计算机安全，这超出了本章的范围。然
而，它们在 正则化的背景下很有意思，因为我们可以通过 对抗训练 （adversarial
training）减少原有独立同分布的测试集的错误率——在对抗扰动的训练集样本上训
练网络 (Szegedy et al. ,2014b ;Goodfellow et al. ,2014b )。
Goodfellow et al. (2014b )表明，这些 对抗样本 的主要原因之一是过度线性。 神
经网络主要是基于线性块构建的。因此在一些实验中，它们实现的整体函数被证明
是高度线性的。这些线性函数很容易优化。不幸的是，如果一个线性函数具有许多DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
230 第七章 深度学习中的正则化
+:007
 =
x sign(∇ xJ(;x; y))x+
ϵsign(∇ xJ(;x; y))
y=“panda” “nematode” “gibbon”
w/ 57.7%
conﬁdencew/ 8.2%
conﬁdencew/ 99.3 %
conﬁdence
图7.8:在ImageNet 上应用 GoogLeNet ( Szegedy et al. ,2014a )的对抗样本 生成的演示。通过添
加一个不可察觉的小向量（其中元素等于 代价函数 相对于输入的梯度元素的符号） ，我们可以改变
GoogLeNet 对此图像的分类结果。经 Goodfellow et al. (2014b )许可转载。
输入，那么它的值可以非常迅速地改变。如果我们用 ϵ改变每个输入，那么权重为
w的线性函数可以改变 ϵ∥w∥1之多，如果 w是高维的这会是一个非常大的数。 对
抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线
性行为。这可以被看作是一种明确地向 监督神经网络 引入局部恒定先验的方法。
对抗训练有助于体现积极 正则化与大型函数族结合的力量。纯粹的 线性模型 ，
如逻辑回归 ，由于它们被限制为线性而无法抵抗 对抗样本 。神经网络 能够将函数从
接近线性转化为局部近似恒定，从而可以灵活地捕获到训练数据中的线性趋势同时
学习抵抗局部扰动。
对抗样本 也提供了一种实现 半监督学习 的方法。在与数据集中的标签不相关联
的点 x处，模型本身为其分配一些标签 ^y。模型的标记 ^y未必是真正的标签，但如
果模型是高品质的，那么 ^y提供正确标签的可能性很大。我们可以搜索一个 对抗样
本 x′，导致分类器输出一个标签 y′且y′̸= ^y。不使用真正的标签，而是由训练好
的模型提供标签产生的 对抗样本 被称为虚拟对抗样本 （virtual adversarial example ）
(Miyato et al. ,2015)。我们可以训练分类器为 x和 x′分配相同的标签。这鼓励分类
器学习一个沿着未标签数据所在流形上任意微小变化都很鲁棒的函数。驱动这种方
法的假设是，不同的类通常位于分离的流形上，并且小扰动不会使数据点从一个类
的流形跳到另一个类的流形上。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.14切面距离、正切传播和流形正切分类器 231
7.14切面距离、正切传播和流形正切分类器
如第 5.11.3节所述，许多 机器学习 的目标旨在假设数据位于低维流形附近来克
服维数灾难。
一个利用流形假设的早期尝试是 切面距离 （tangent distance ）算法 (Simard
et al. ,1993,1998)。它是一种非参数的最近邻算法，其中使用的度量不是通用的欧几
里德距离，而是根据邻近流形关于聚集概率的知识导出的。这个算法假设我们尝试
分类的样本和同一流形上的样本具有相同的类别。由于分类器应该对局部因素（对
应于流形上的移动）的变化保持不变，一种合理的度量是将点 x1和 x2各自所在流
形M1和M2的距离作为点 x1和 x2之间的最近邻距离。然而这可能在计算上是困
难的（它需要解决一个寻找 M1和M2最近点对的优化问题） ，一种局部合理的廉价
替代是使用 xi点处切平面近似 Mi，并测量两条切平面或一个切平面和点之间的距
离。这可以通过求解一个低维线性系统（就流形的维数而言）来实现。当然，这种算
法需要制定一个切向量。
受相关启发， 正切传播 （tangent prop ）算法 (Simard et al. ,1992)（图 7.9）训
练带有额外惩罚的 神经网络 分类器，使 神经网络 的每个输出 f(x)对已知的变化因素
是局部不变的。这些变化因素对应于沿着的相同样本聚集的流形的移动。这里实现
局部不变性的方法是要求 ∇ xf(x)与已知流形的切向 v(i)正交，或者等价地通过 正
则化惩罚 Ω使f在 x的 v(i)方向的导数较小：
Ω(f) =∑
i(
(∇ xf(x)⊤v(i)))2
: (7.67)
这个正则化项当然可以通过适当的超参数缩放，并且对于大多数 神经网络 ，我们需
要对许多输出求和 (此处为描述简单， f(x)为唯一输出 )。与切面距离 算法一样，我
们根据切向量推导先验，通常从变换（如平移、旋转和缩放图像）的效果获得形式知
识。正切传播 不仅用于 监督学习 (Simard et al. ,1992)，还在强化学习 (Thrun ,1995)
中有所应用。
正切传播 与数据集增强密切相关。在这两种情况下，该算法的用户通过指定一
组不改变网络输出的转换，编码其先验知识。不同的是在数据集增强的情况下，网
络显式地训练正确分类这些施加大量变换后产生的不同输入。 正切传播 不需要显式
访问一个新的输入点。取而代之，它解析地对模型 正则化从而在指定转换的方向抵
抗扰动。虽然这种解析方法是聪明优雅的，但是它有两个主要的缺点。首先，模型
的正则化只能抵抗无穷小的扰动。显式的数据集增强能抵抗较大的扰动。其次，我DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
232 第七章 深度学习中的正则化
x1x2NormalTangent
图7.9:正切传播 算法 (Simard et al. ,1992)和流形正切分类器主要思想的示意图 (Rifai et al. ,
2011c )，它们都 正则化分类器的输出函数 f(x)。每条曲线表示不同类别的 流形，这里表示嵌入二
维空间中的一维 流形。在一条曲线上，我们选择单个点并绘制一个与类别 流形（平行并接触 流形）
相切的向量以及与类别 流形（与流形正交）垂直的向量。在多维情况下，可以存在许多切线方向和
法线方向。我们希望分类函数在垂直于 流形方向上快速改变，并且在类别 流形的方向上保持不变。
正切传播 和流形正切分类器都会 正则化 f(x)，使其不随 x沿流形的移动而剧烈变化。 正切传播 需
要用户手动指定正切方向的计算函数（例如指定小平移后的图像保留在相同类别的 流形中） ，而流
形正切分类器通过训练 自编码器 拟合训练数据来估计 流形的正切方向。我们将在第 十四章中讨论
使用自编码器 来估计流形。
们很难在基于 整流线性单元 的模型上使用无限小的方法。这些模型只能通过关闭单
元或缩小它们的权重才能缩小它们的导数。它们不能像 sigmoid或tanh单元一样通过
较大权重在高值处饱和以收缩导数。数据集增强在 整流线性单元 上工作得很好，因
为不同的整流单元会在每一个原始输入的不同转换版本上被激活。
正切传播 也涉及到 双反向传播 (Drucker and LeCun ,1992)和对抗训练 (Szegedy
et al. ,2014a ;Goodfellow et al. ,2014b )。双反向传播 正则化使Jacobian 矩阵偏小，
而对抗训练 找到原输入附近的点，训练模型在这些点上产生与原来输入相同的输出。
正切传播 和手动指定转换的数据集增强都要求模型在输入变化的某些特定的方向
上保持不变。 双反向传播 和对抗训练 都要求模型对输入所有方向中的变化（只要该
变化较小）都应当保持不变。正如数据集增强是 正切传播 非无限小的版本， 对抗训
练是双反向传播 非无限小的版本。
流形正切分类器 (Rifai et al. ,2011d )无需知道切线向量的先验。我们将在第 十
四章看到， 自编码器 可以估算流形的切向量。流形正切分类器使用这种技术来避免DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
7.14切面距离、正切传播和流形正切分类器 233
用户指定切向量。如图 14.10所示，这些估计的切向量不仅对图像经典几何变换（如
转化、旋转和缩放）保持不变，还必须掌握对特定对象（如移动身体的部分）保持
不变的因素。因此根据流形正切分类器提出的算法相当简单：（ 1）使用自编码器 通
过无监督学习 来学习流形的结构，以及（ 2）如正切传播 （式 (7.67)）一样使用这些
切面正则化神经网络 分类器。
在本章中，我们已经描述了大多数用于 正则化神经网络 的通用策略。 正则化是机
器学习的中心主题，因此我们将不时在其余各章中重新回顾。 机器学习 的另一个中
心主题是优化，我们将在下一章描述。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第八章 深度模型中的优化
深度学习 算法在许多情况下都涉及到优化。例如，模型中的进行推断（如 PCA）
涉及到求解优化问题。我们经常使用解析优化去证明或设计算法。在 深度学习 涉及
到的诸多优化问题中，最难的是 神经网络 训练。甚至是用几百台机器投入几天到几
个月来解决单个 神经网络 训练问题，也是很常见的。因为这其中的优化问题很重要，
代价也很高，因此研究者们开发了一组专门为此设计的优化技术。本章会介绍 神经
网络训练中的这些优化技术。
如果你不熟悉基于梯度优化的基本原则，我们建议回顾第 四章。该章简要概述
了一般的 数值优化 。
本章主要关注这一类特定的优化问题：寻找 神经网络 上的一组参数 ，它能显
著地降低 代价函数 J()，该代价函数 通常包括整个 训练集上的性能评估和额外的 正
则化项。
首先，我们会介绍在 机器学习 任务中作为训练算法使用的优化与纯优化有哪些
不同。接下来，我们会介绍导致 神经网络 优化困难的几个具体挑战。然后，我们会介
绍几个实用算法，包括优化算法本身和初始化参数的策略。更高级的算法能够在训
练中自适应调整 学习率，或者使用 代价函数 二阶导数包含的信息。最后，我们会介
绍几个将简单优化算法结合成高级过程的优化策略，以此作为总结。
8.1学习和纯优化有什么不同
用于深度模型 训练的优化算法与传统的优化算法在几个方面有所不同。 机器学
习通常是间接作用的。在大多数 机器学习 问题中，我们关注某些性能度量 P，其定
义于测试集上并且可能是不可解的。因此，我们只是间接地优化 P。我们希望通过
234DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.1学习和纯优化有什么不同 235
降低代价函数 J()来提高 P。这一点与纯优化不同，纯优化最小化目标 J本身。训
练深度模型 的优化算法通常也会包括一些针对 机器学习 目标函数 的特定结构进行的
特化。
通常，代价函数 可写为训练集上的平均，如
J() =E(x;y)^pdataL(f(x;); y); (8.1)
其中 L是每个样本的 损失函数 ，f(x;)是输入 x时所预测的输出， ^pdata是经验分
布。监督学习 中，y是目标输出。在本章中，我们会介绍不带 正则化的监督学习， L
的变量是 f(x;)和y。不难将这种 监督学习 扩展成其他形式，如包括 或者 x作
为参数，或是去掉参数 y，以发展不同形式的 正则化或是无监督学习 。
式(8.1)定义了训练集上的目标函数 。通常，我们更希望最小化取自 数据生成分
布pdata的期望，而不仅仅是有限 训练集上的对应 目标函数 ：
J() =E(x;y)pdataL(f(x;); y): (8.2)
8.1.1经验风险最小化
机器学习 算法的目标是降低式 (8.2)所示的期望 泛化误差 。这个数据量被称为 风
险（risk） 。在这里，我们强调该期望取自真实的 潜在分布 pdata。如果我们知道了真
实分布 pdata(x; y)，那么最小化风险变成了一个可以被优化算法解决的优化问题。然
而，我们遇到的 机器学习 问题，通常是不知道 pdata(x; y)，只知道 训练集中的样本。
将机器学习 问题转化回一个优化问题的最简单方法是最小化 训练集上的期望损
失。这意味着用 训练集上的经验分布 ^p(x; y)替代真实分布 p(x; y)。现在，我们将最
小化经验风险 （empirical risk ） ：
Ex;y^pdata[L(f(x;); y)] =1
mm∑
i=1L(f(x(i);); y(i)); (8.3)
其中 m表示训练样本的数目。
基于最小化这种平均 训练误差 的训练过程被称为 经验风险最小化 （empirical
risk minimization ） 。在这种情况下， 机器学习 仍然和传统的直接优化很相似。我们
并不直接最优化 风险，而是最优化 经验风险 ，希望也能够很大地降低 风险。一系列
不同的理论构造了一些条件，使得在这些条件下真实 风险的期望可以下降不同的量。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
236 第八章 深度模型中的优化
然而，经验风险最小化 很容易导致 过拟合。高容量的模型会简单地记住 训练集。
在很多情况下， 经验风险最小化 并非真的可行。最有效的现代优化算法是基于 梯度
下降的，但是很多有用的 损失函数 ，如 0 1损失，没有有效的导数（导数要么为
零，要么处处未定义） 。这两个问题说明，在 深度学习 中我们很少使用 经验风险最小
化。反之，我们会使用一个稍有不同的方法，我们真正优化的目标会更加不同于我
们希望优化的目标。
8.1.2代理损失函数和提前终止
有时，我们真正关心的 损失函数 （比如分类误差）并不能被高效地优化。例如，
即使对于 线性分类器 而言，精确地最小化 0 1损失通常是不可解的（复杂度是输入
维数的指数级别） (Marcotte and Savard ,1992)。在这种情况下，我们通常会优化 代
理损失函数 （surrogate loss function ） 。代理损失函数 作为原目标的代理，还具备一
些优点。例如，正确类别的负对数似然通常用作 0 1损失的替代。负对数似然允许
模型估计给定样本的类别的条件概率，如果该模型效果好，那么它能够输出期望最
小分类误差所对应的类别。
在某些情况下， 代理损失函数 比原函数学到的更多。例如，使用对数似然替代
函数时，在 训练集上的 0 1损失达到 0之后，测试集上的 0 1损失还能持续下降
很长一段时间。这是因为即使 0 1损失期望是零时，我们还能拉开不同类别的距离
以改进分类器的鲁棒性，获得一个更强壮的、更值得信赖的分类器，从而，相对于
简单地最小化 训练集上的平均 0 1损失，它能够从训练数据中抽取更多信息。
一般的优化和我们用于训练算法的优化有一个重要不同：训练算法通常不会
停止在局部极小点 。反之， 机器学习 通常优化 代理损失函数 ，但是在基于 提前终止
（第 7.8节）的收敛条件满足时停止。通常， 提前终止 使用真实 潜在损失函数 ，如验
证集上的 0 1损失，并设计为在 过拟合发生之前终止。与纯优化不同的是， 提前终
止时代理损失函数 仍然有较大的导数，而纯优化终止时导数较小。
8.1.3批量算法和小批量算法
机器学习 算法和一般优化算法不同的一点是， 机器学习 算法的目标函数 通常可
以分解为训练样本上的求和。 机器学习 中的优化算法在计算参数的每一次更新时通
常仅使用整个 代价函数 中一部分项来估计 代价函数 的期望值。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.1学习和纯优化有什么不同 237
例如，最大似然估计 问题可以在对数空间中分解成各个样本的总和：
ML= arg max
m∑
i=1logpmodel (x(i); y(i);): (8.4)
最大化这个总和等价于最大化 训练集在经验分布 上的期望：
J() =Ex;y^pdata logpmodel (x; y;): (8.5)
优化算法用到的 目标函数 J中的大多数属性也是 训练集上的期望。例如，最常
用的属性是梯度：
∇J() =Ex;y^pdata∇logpmodel (x; y;): (8.6)
准确计算这个期望的计算代价非常大，因为我们需要在整个数据集上的每个样
本上评估模型。在实践中，我们可以从数据集中随机采样少量的样本，然后计算这
些样本上的平均值。
回想一下， n个样本均值的 标准差（式 (5.46)）是 /pn，其中 是样本值真实
的标准差。分母pn表明使用更多样本来估计梯度的方法的回报是低于线性的。比
较两个假想的梯度计算，一个基于 100个样本，另一个基于 10;000个样本。后者需
要的计算量是前者的 100倍，但却只降低了 10倍的均值 标准差。如果能够快速地
计算出梯度估计值，而不是缓慢地计算准确值，那么大多数优化算法会收敛地更快
（就总的计算量而言，而不是指更新次数） 。
另一个促使我们从小数目样本中获得梯度的统计估计的动机是 训练集的冗余。
在最坏的情况下， 训练集中所有的 m个样本都是彼此相同的拷贝。基于采样的梯度
估计可以使用单个样本计算出正确的梯度，而比原来的做法少花了 m倍时间。实践
中，我们不太可能真的遇到这种最坏情况，但我们可能会发现大量样本都对梯度做
出了非常相似的贡献。
使用整个 训练集的优化算法被称为 批量（batch）或确定性（deterministic ）梯
度算法，因为它们会在一个大 批量中同时处理所有样本。这个术语可能有点令人困
惑，因为这个词 “批量’’也经常被用来描述 小批量随机梯度下降 算法中用到的 小批
量样本。通常，术语 “批量梯度下降 ’’指使用全部 训练集，而术语 “批量’’单独出现
时指一组样本。例如，我们普遍使用术语 “批量大小’’表示小批量的大小。
每次只使用单个样本的优化算法有时被称为 随机（stochastic ）或者在线（on-
line）算法。术语 “在线’’通常是指从连续产生样本的数据流中抽取样本的情况，而
不是从一个固定大小的 训练集中遍历多次采样的情况。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
238 第八章 深度模型中的优化
大多数用于 深度学习 的算法介于以上两者之间，使用一个以上，而又不是全部
的训练样本。传统上，这些会被称为 小批量（minibatch ）或小批量随机 （minibatch
stochastic ）方法，现在通常将它们简单地称为 随机（stochastic ）方法。
随机方法的典型示例是 随机梯度下降 ，这将在第 8.3.1节中详细描述。
小批量的大小通常由以下几个因素决定：
•更大的批量会计算更精确的梯度估计，但是回报却是小于线性的。
•极小批量通常难以充分利用多核架构。这促使我们使用一些绝对最小 批量，低
于这个值的小 批量处理不会减少计算时间。
•如果批量处理中的所有样本可以并行地处理（通常确是如此） ，那么内存消耗
和批量大小会正比。对于很多硬件设施，这是 批量大小的限制因素。
•在某些硬件上使用特定大小的数组时， 运行时间会更少。 尤其是在使用 GPU时，
通常使用 2的幂数作为 批量大小可以获得更少的运行时间。一般， 2的幂数的
取值范围是 32到256，16有时在尝试大模型时使用。
•可能是由于小 批量在学习过程中加入了 噪声， 它们会有一些 正则化效果 (Wilson
and Martinez ,2003)。泛化误差 通常在批量大小为 1时最好。因为梯度估计的
高方差，小 批量训练需要较小的 学习率以保持稳定性。因为降低的 学习率和消
耗更多步骤来遍历整个 训练集都会产生更多的步骤，所以会导致总的运行时间
非常大。
不同的算法使用不同的方法从 小批量中获取不同的信息。有些算法对采样误差
比其他算法更敏感，这通常有两个可能原因。一个是它们使用了很难在少量样本上
精确估计的信息，另一个是它们以放大采样误差的方式使用了信息。仅基于梯度 g
的更新方法通常相对鲁棒，并能使用较小的 批量获得成功，如 100。使用 Hessian矩
阵 H，计算如 H 1g更新的二阶方法通常需要更大的 批量，如 10;000。这些大 批
量需要最小化估计 H 1g的波动。假设 H被精确估计，但是有 病态条件 数。乘以 H
或是其逆会放大之前存在的误差（这个示例中是指 g的估计误差） 。即使 H被精确
估计， g中非常小的变化也会导致更新值 H 1g中非常大的变化。当然，我们通常只
会近似地估计 H，因此相对于我们使用具有较差条件的操作去估计 g，更新 H 1g
会含有更多的误差。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.1学习和纯优化有什么不同 239
小批量是随机抽取的这点也很重要。从一组样本中计算出梯度期望的 无偏估计
要求这些样本是独立的。我们也希望两个连续的梯度估计是互相独立的，因此两个连
续的小批量样本也应该是彼此独立的。很多现实的数据集自然排列，从而使得连续
的样本之间具有高度相关性。例如，假设我们有一个很长的血液样本测试结果清单。
清单上的数据有可能是这样获取的，头五个血液样本于不同时间段取自第一个病人，
接下来三个血液样本取自第二个病人，再随后的血液样本取自第三个病人，等等。如
果我们从这个清单上顺序抽取样本，那么我们的每个 小批量数据的偏差都很大，因
为这个小批量很可能只代表着数据集上众多患者中的某一个患者。在这种数据集中
的顺序有很大影响的情况下，很有必要在抽取 小批量样本前打乱样本顺序。对于非
常大的数据集，如数据中心含有几十亿样本的数据集，我们每次构建 小批量样本时
都将样本完全均匀地抽取出来是不太现实的。幸运的是，实践中通常将样本顺序打
乱一次，然后按照这个顺序存储起来就足够了。之后训练模型时会用到的一组组 小
批量连续样本是固定的，每个独立的模型每次遍历训练数据时都会重复使用这个顺
序。然而，这种偏离真实随机采样的方法并没有很严重的有害影响。不以某种方式
打乱样本顺序才会极大地降低算法的性能。
很多机器学习 上的优化问题都可以分解成并行地计算不同样本上单独的更新。
换言之，我们在计算 小批量样本 X上最小化 J(X)的更新时，同时可以计算其他 小
批量样本上的更新。这类 异步并行分布式方法将在第 12.1.3节中进一步讨论。
小批量随机梯度下降 的一个有趣动机是，只要没有重复使用样本，它将遵循着
真实泛化误差 （式 (8.2)）的梯度。很多 小批量随机梯度下降 方法的实现都会打乱数
据顺序一次，然后多次遍历数据来更新参数。第一次遍历时，每个 小批量样本都用
来计算真实 泛化误差 的无偏估计。第二次遍历时，估计将会是 有偏的，因为它重新
抽取了已经用过的样本，而不是从和原先样本相同的 数据生成分布 中获取新的无偏
的样本。
我们不难从 在线学习 的情况中看出 随机梯度下降 最小化泛化误差 的原因。这时
样本或者 小批量都是从数据 流（stream）中抽取出来的。换言之， 学习器好像是一
个每次看到新样本的人，每个样本 (x; y)都来自数据生成分布 pdata(x; y)，而不是使
用大小固定的 训练集。这种情况下，样本永远不会重复；每次更新的样本是从分布
pdata中采样获得的无偏样本。
在 x和y是离散时，以上的等价性很容易得到。在这种情况下， 泛化误差DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
240 第八章 深度模型中的优化
（式 (8.2)）可以表示为
J() =∑
x∑
ypdata(x; y)L(f(x;); y); (8.7)
上式的准确梯度为
g=∇J() =∑
x∑
ypdata(x; y)∇L(f(x;); y): (8.8)
在式 (8.5)和式 (8.6)中，我们已经在对数似然中看到了相同的结果；现在我们发现这
一点在包括似然的其他函数 L上也是成立的。在一些关于 pdata和L的温和假设下，
在 x和y是连续时也能得到类似的结果。
因此，我们可以从 数据生成分布 pdata抽取小批量样本fx(1); : : : ; x(m)g以及对
应的目标 y(i)，然后计算该 小批量上损失函数关于对应参数的梯度
^g=1
m∇∑
iL(f(x(i);); y(i)): (8.9)
以此获得 泛化误差 准确梯度的 无偏估计。最后，在 泛化误差 上使用 SGD方法在方向
^g上更新。
当然，这个解释只能用于样本没有重复使用的情况。然而，除非 训练集特别大，
通常最好是多次遍历 训练集。当多次遍历数据集更新时，只有第一遍满足 泛化误差 梯
度的无偏估计。但是，额外的遍历更新当然会由于减小 训练误差 而得到足够的好处，
以抵消其带来的 训练误差 和测试误差 间差距的增加。
随着数据集的规模迅速增长，超越了计算能力的增速， 机器学习 应用每个样本
只使用一次的情况变得越来越常见，甚至是不完整地使用 训练集。在使用一个非常
大的训练集时，过拟合不再是问题，而 欠拟合和计算效率变成了主要的顾虑。读者
也可以参考 Bottou and Bousquet (2008a )中关于训练样本数目增长时， 泛化误差 上
计算瓶颈影响的讨论。
8.2神经网络优化中的挑战
优化通常是一个极其困难的任务。传统的 机器学习 会小心设计 目标函数 和约束，
以确保优化问题是凸的，从而避免一般优化问题的复杂度。在训练 神经网络 时，我
们肯定会遇到一般的 非凸情况。即使是 凸优化，也并非没有任何问题。在这一节中，
我们会总结几个训练 深度模型 时会涉及到的主要挑战。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.2神经网络优化中的挑战 241
8.2.1病态
在优化凸函数时，会遇到一些挑战。这其中最突出的是 Hessian矩阵 H的病
态。这是数值优化 、凸优化或其他形式的优化中普遍存在的问题，更多细节请回顾
第4.3.1节。
病态问题一般被认为存在于 神经网络 训练过程中。 病态体现在随机梯度下降 会
‘‘卡’’在某些情况，此时即使很小的更新步长也会增加 代价函数 。
回顾式 (4.9)，代价函数 的二阶泰勒级数展开预测 梯度下降 中的 ϵg会增加
1
2ϵ2g⊤Hg ϵg⊤g (8.10)
到代价中。当1
2ϵ2g⊤Hg超过 ϵg⊤g时，梯度的 病态会成为问题。判断 病态是否不利
于神经网络 训练任务，我们可以监测平方梯度范数 g⊤g和 g⊤Hg。在很多情况中，
梯度范数不会在训练过程中显著缩小，但是 g⊤Hg的增长会超过一个数量级。其结
果是尽管梯度很强，学习会变得非常缓慢，因为 学习率必须收缩以弥补更强的 曲率。
如图 8.1所示，成功训练的 神经网络 中，梯度显著增加。
 50050100 150 200 250
Training time (epochs) 20246810121416Gradient norm
0 50 100 150 200 250
Training time (epochs)0:10:20:30:40:50:60:70:80:91:0Classication error rate
图8.1:梯度下降 通常不会到达任何类型的 临界点。此示例中，在用于对象检测的 卷积网络 的整个
训练期间，梯度范数持续增加。 (左)各个梯度计算的范数如何随时间分布的散点图。为了方便作
图，每轮仅绘制一个梯度范数。我们将所有梯度范数的移动平均绘制为实曲线。梯度范数明显随时
间增加，而不是如我们所期望的那样随训练过程收敛到 临界点而减小。 (右)尽管梯度递增，训练
过程却相当成功。 验证集上的分类误差可以降低到较低水平。
尽管病态还存在于除了 神经网络 训练的其他情况中，有些适用于其他情况的解
决病态的技术并不适用于 神经网络 。例如， 牛顿法在解决带有 病态条件 的Hessian矩DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
242 第八章 深度模型中的优化
阵的凸优化问题时，是一个非常优秀的工具，但是我们将会在以下小节中说明 牛顿
法运用到神经网络 时需要很大的改动。
8.2.2局部极小值
凸优化问题的一个突出特点是其可以简化为寻找一个 局部极小点 的问题。任何
一个局部极小点 都是全局最小点 。有些凸函数的底部是一个平坦的区域，而不是单
一的全局最小点 ，但该平坦区域中的任意点都是一个可以接受的解。优化一个凸问
题时，若发现了任何形式的 临界点，我们都会知道已经找到了一个不错的可行解。
对于非凸函数时，如 神经网络 ，有可能会存在多个 局部极小值 。事实上，几乎所
有的深度模型 基本上都会有非常多的 局部极小值 。然而，我们会发现这并不是主要
问题。
由于模型可辨识性 （model identiﬁability ）问题， 神经网络 和任意具有多个等
效参数化 潜变量的模型都会具有多个 局部极小值 。如果一个足够大的 训练集可以唯
一确定一组模型参数，那么该模型被称为 可辨认的 。带有潜变量的模型通常是不 可
辨认的，因为通过相互交换 潜变量我们能得到等价的模型。例如，考虑 神经网络 的
第一层，我们可以交换单元 i和单元 j的传入权重向量、传出权重向量而得到等价
的模型。如果 神经网络 有m层，每层有 n个单元，那么会有 n!m种排列隐藏单元 的
方式。这种不可辨认性被称为 权重空间对称性 （weight space symmetry ） 。
除了权重空间对称性 ，很多神经网络 还有其他导致不可辨认的原因。例如，在
任意整流线性 网络或者 maxout网络中，我们可以将传入权重和 偏置扩大 倍，然
后将传出权重扩大1
倍，而保持模型等价。这意味着，如果 代价函数 不包括如 权重
衰减这种直接依赖于权重而非模型输出的项，那么 整流线性 网络或者 maxout网络
的每一个 局部极小点 都在等价的 局部极小值 的(mn)维双曲线上。
这些模型可辨识性 问题意味着 神经网络 代价函数 具有非常多、甚至不可数无限
多的局部极小值 。然而，所有这些由于不可辨识性问题而产生的 局部极小值 都有相
同的代价函数 值。因此，这些 局部极小值 并非是非凸所带来的问题。
如果局部极小值 相比全局最小点 拥有很大的 代价，局部极小值 会带来很大的隐
患。我们可以构建没有 隐藏单元 的小规模 神经网络 ，其局部极小值 的代价比全局最
小点的代价大很多 (Sontag and Sussman ,1989;Brady et al. ,1989;Gori and Tesi ,
1992)。如果具有很大 代价的局部极小值 是常见的，那么这将给基于梯度的优化算法DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.2神经网络优化中的挑战 243
带来极大的问题。
对于实际中感兴趣的网络，是否存在大量 代价很高的局部极小值 ，优化算法是
否会碰到这些 局部极小值 ，都是尚未解决的公开问题。多年来，大多数从业者认为 局
部极小值 是困扰神经网络 优化的常见问题。如今，情况有所变化。这个问题仍然是学
术界的热点问题，但是学者们现在猜想，对于足够大的 神经网络 而言，大部分 局部极
小值都具有很小的 代价函数 ，我们能不能找到真正的 全局最小点 并不重要，而是需
要在参数空间中找到一个 代价很小（但不是最小）的点 (Saxe et al. ,2013;Dauphin
et al. ,2014;Goodfellow et al. ,2015;Choromanska et al. ,2014)。
很多从业者将 神经网络 优化中的所有困难都归结于 局部极小值 。我们鼓励从业
者要仔细分析特定的问题。一种能够排除 局部极小值 是主要问题的检测方法是画出
梯度范数随时间的变化。如果梯度范数没有缩小到一个微小的值，那么该问题既不
是局部极小值 ，也不是其他形式的 临界点。在高维空间中，很难明确证明 局部极小
值是导致问题的原因。许多并非 局部极小值 的结构也具有很小的梯度。
8.2.3高原、鞍点和其他平坦区域
对于很多高维 非凸函数而言， 局部极小值 （以及极大值）事实上都远少于另一
类梯度为零的点： 鞍点。鞍点附近的某些点比 鞍点有更大的 代价，而其他点则有更
小的代价。在鞍点处，Hessian矩阵同时具有正负特征值。位于正特征值对应的特征
向量方向的点比 鞍点有更大的 代价，反之，位于负特征值对应的特征向量方向的点
有更小的 代价。我们可以将 鞍点视为代价函数 某个横截面上的 局部极小点 ，同时也
可以视为 代价函数 某个横截面上的 局部极大点 。图 4.5给了一个示例。
多类随机函数表现出以下性质：低维空间中， 局部极小值 很普遍。在更高维空
间中，局部极小值 很罕见，而 鞍点则很常见。对于这类函数 f:Rn!R而言，鞍
点和局部极小值 的数目比率的期望随 n指数级增长。我们可以从直觉上理解这种现
象—— Hessian矩阵在局部极小点 处只有正特征值。而在 鞍点处，Hessian矩阵则同
时具有正负特征值。试想一下，每个特征值的正负号由抛硬币决定。在一维情况下，
很容易抛硬币得到正面朝上一次而获取 局部极小点 。在 n-维空间中，要抛掷 n次硬
币都正面朝上的难度是指数级的。具体可以参考 Dauphin et al. (2014)，它回顾了相
关的理论工作。
很多随机函数一个惊人性质是，当我们到达 代价较低的区间时， Hessian矩阵
的特征值为正的可能性更大。和抛硬币类比，这意味着如果我们处于低 代价的临界DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
244 第八章 深度模型中的优化
点时，抛掷硬币正面朝上 n次的概率更大。这也意味着， 局部极小值 具有低代价的可
能性比高 代价要大得多。具有高 代价的临界点更有可能是 鞍点。具有极高 代价的临
界点就很可能是 局部极大值 了。
以上现象出现在许多种类的随机函数中。那么是否在 神经网络 中也有发生呢？
Baldi and Hornik (1989)从理论上证明，不具非线性的浅层 自编码器 （第十四章中
将介绍的一种将输出训练为输入拷贝的 前馈网络 ）只有全局极小值 和鞍点，没有代
价比全局极小值 更大的局部极小值 。他们还发现这些结果能够扩展到不具非线性的
更深的网络上，不过没有证明。这类网络的输出是其输入的线性函数，但它们仍然有
助于分析非线性 神经网络 模型，因为它们的 损失函数 是关于参数的 非凸函数。这类
网络本质上是多个矩阵组合在一起。 Saxe et al. (2013)精确解析了这类网络中完整
的学习动态，表明这些模型的学习能够捕捉到许多在训练具有非线性 激活函数 的深
度模型时观察到的定性特征。 Dauphin et al. (2014)通过实验表明，真实的 神经网
络也存在包含很多高 代价鞍点的损失函数 。Choromanska et al. (2014)提供了额外
的理论论点，表明另一类和 神经网络 相关的高维随机函数也满足这种情况。
鞍点激增对于训练算法来说有哪些影响呢？对于只使用梯度信息的一阶优化算
法而言，目前情况还不清楚。 鞍点附近的梯度通常会非常小。另一方面，实验中 梯度
下降似乎可以在许多情况下逃离 鞍点。Goodfellow et al. (2015)可视化了最新 神经
网络的几个学习轨迹，图 8.2给了一个例子。这些可视化显示，在突出的 鞍点附近，
代价函数 都是平坦的，权重都为零。但是他们也展示了 梯度下降 轨迹能够迅速逸出
该区间。 Goodfellow et al. (2015)也主张，应该可以通过分析来表明连续时间的 梯度
下降会逃离而不是吸引到 鞍点，但对梯度下降 更现实的使用场景来说，情况或许会
有所不同。
对于牛顿法而言，鞍点显然是一个问题。 梯度下降 旨在朝 ‘‘下坡’’移动，而非
明确寻求 临界点。而牛顿法的目标是寻求梯度为零的点。如果没有适当的修改， 牛
顿法就会跳进一个 鞍点。高维空间中 鞍点的激增或许解释了在 神经网络 训练中为什
么二阶方法 无法成功取代 梯度下降 。Dauphin et al. (2014)介绍了二阶优化的 无鞍
牛顿法（saddle-free Newton method ） ，并表明和传统算法相比有显著改进。 二阶方
法仍然难以扩展到大型 神经网络 ，但是如果这类无鞍算法能够扩展的话，还是很有
希望的。
除了极小值和鞍点，还存在其他梯度为零的点。例如从优化的角度看与 鞍点很
相似的极大值，很多算法不会被吸引到 极大值，除了未经修改的 牛顿法。和极小值一
样，许多种类的随机函数的 极大值在高维空间中也是指数级稀少。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.2神经网络优化中的挑战 245
Projection 2 of
Projection 1 of
J(
)
图8.2:神经网络 代价函数 的可视化。这些可视化对应用于真实 对象识别 和自然语言处理 任务的前
馈神经网络 、卷积网络 和循环网络 而言是类似的。令人惊讶的是，这些可视化通常不会显示出很多
明显的障碍。大约 2012年，在随机梯度下降 开始成功训练非常大的模型之前，相比这些投影所显
示的神经网络 代价函数 的表面通常被认为有更多的 非凸结构。该投影所显示的主要障碍是初始参
数附近的高 代价鞍点，但如由蓝色路径所示， SGD训练轨迹能轻易地逃脱该鞍点。大多数训练时
间花费在横穿 代价函数 中相对平坦的峡谷，可能由于梯度中的高噪声、或该区域中 Hessian 矩阵
的病态条件 ，或者需要经过间接的弧路径绕过图中可见的高 ‘‘山”。图经 Goodfellow et al. (2015)
许可改编。
也可能存在恒值的、宽且平坦的区域。在这些区域，梯度和 Hessian矩阵都是
零。这种退化的情形是所有 数值优化 算法的主要问题。在凸问题中，一个宽而平坦
的区间肯定包含 全局极小值 ，但是对于一般的优化问题而言，这样的区域可能会对
应着目标函数 中一个较高的值。
8.2.4悬崖和梯度爆炸
多层神经网络 通常存在像悬崖一样的斜率较大区域，如图 8.3所示。这是由于几
个较大的权重相乘导致的。遇到斜率极大的悬崖结构时，梯度更新会很大程度地改
变参数值，通常会完全跳过这类悬崖结构。
不管我们是从上还是从下接近悬崖，情况都很糟糕，但幸运的是我们可以用使
用第 10.11.1节介绍的启发式 梯度截断 （gradient clipping ）来避免其严重的后果。其
基本想法源自梯度并没有指明最佳步长，只说明了在无限小区域内的最佳方向。当
传统的梯度下降 算法提议更新很大一步时，启发式 梯度截断 会干涉来减小步长，从DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
246 第八章 深度模型中的优化
w
bJ(w;b)
图8.3:高度非线性的 深度神经网络 或循环神经网络 的目标函数 通常包含由几个参数连乘而导致的
参数空间中尖锐非线性。这些非线性在某些区域会产生非常大的导数。当参数接近这样的悬崖区
域时，梯度下降 更新可以使参数弹射得非常远，可能会使大量已完成的优化工作成为无用功。图
经Pascanu et al. (2013a )许可改编。
而使其不太可能走出梯度近似为 最陡下降 方向的悬崖区域。悬崖结构在 循环神经网
络的代价函数 中很常见，因为这类模型会涉及到多个因子的相乘，其中每个因子对
应一个时间步。因此，长期时间序列会产生大量相乘。
8.2.5长期依赖
当计算图变得极深时， 神经网络 优化算法会面临的另外一个难题就是 长期依
赖问题——由于变深的结构使模型丧失了学习到先前信息的能力，让优化变得极
其困难。深层的 计算图不仅存在于 前馈网络 ，还存在于之后介绍的 循环网络 中（在
第十章中描述） 。因为 循环网络 要在很长时间序列的各个时刻重复应用相同操作来构
建非常深的计算图，并且模型参数共享，这使问题更加凸显。
例如，假设某个 计算图中包含一条反复与矩阵 W相乘的路径。那么 t步后，相
当于乘以 Wt。假设 W有特征值分解 W= Vdiag()V 1。在这种简单的情况下，
很容易看出
Wt= ( Vdiag()V 1)t= Vdiag()tV 1: (8.11)
当特征值 i不在 1附近时，若在量级上大于 1则会爆炸；若小于 1时则会消失。 梯
度消失与爆炸问题 （vanishing and exploding gradient problem ）是指该 计算图上的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.2神经网络优化中的挑战 247
梯度也会因为 diag()t大幅度变化。 梯度消失 使得我们难以知道参数朝哪个方向移
动能够改进 代价函数 ，而梯度爆炸 会使得学习不稳定。之前描述的促使我们使用 梯
度截断的悬崖结构便是 梯度爆炸 现象的一个例子。
此处描述的在各 时间步重复与 W相乘非常类似于寻求矩阵 W的最大特征值及
对应特征向量的 幂方法（power method ） 。从这个观点来看， x⊤Wt最终会丢弃 x
中所有与 W的主特征向量正交的成分。
循环网络 在各时间步上使用相同的矩阵 W，而前馈网络 并没有。因而即使是非
常深层的 前馈网络 也能一定程度上避免 梯度消失与爆炸问题 (Sussillo ,2014)。
在更详细地描述 循环网络 之后，我们将会在第 10.7节进一步讨论 循环网络 训练
中的挑战。
8.2.6非精确梯度
大多数优化算法的先决条件都是我们知道精确的梯度或是 Hessian矩阵。在实践
中，通常这些量会有 噪声，甚至是 有偏的估计。几乎每一个 深度学习 算法都需要基
于采样的估计，至少使用训练样本的 小批量来计算梯度。
在其他情况，我们希望最小化的 目标函数 实际上是难以处理的。当 目标函数 不
可解时，通常其梯度也是难以处理的。在这种情况下，我们只能近似梯度。这些问题
主要出现在第三部分中更高级的模型中。例如， 对比散度 是用来近似 玻尔兹曼机 中
难以处理的对数似然梯度的一种技术。
各种神经网络 优化算法的设计都考虑到了梯度估计的缺陷。我们可以选择比真
实损失函数 更容易估计的 代理损失函数 来避免这个问题。
8.2.7局部和全局结构间的弱对应
迄今为止，我们讨论的许多问题都是关于 损失函数 在单个点的性质——若 J()
是当前点的病态条件 ，或者在悬崖中，或者 是一个下降方向不明显的 鞍点，
那么会很难更新当前步。
如果该方向在局部改进很大，但并没有指向 代价低得多的遥远区域，那么我们
有可能在单点处克服以上所有困难，但仍然表现不佳。
Goodfellow et al. (2015)认为大部分训练的运行时间取决于到达解决方案的轨DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
248 第八章 深度模型中的优化
迹长度。如图 8.2所示，学习轨迹将花费大量的时间探寻一个围绕山形结构的宽弧。
大多数优化研究的难点集中于训练是否找到了 全局最小点 、局部极小点 或是鞍
点，但在实践中 神经网络 不会到达任何一种 临界点。图 8.1表明神经网络 通常不会到
达梯度很小的区域。甚至，这些 临界点不一定存在。例如， 损失函数 logp(yjx;)
可以没有 全局最小点 ，而是当随着训练模型逐渐稳定后，渐近地收敛于某个值。对
于具有离散的 y和softmax 分布 p(yjx)的分类器而言，若模型能够正确分类 训
练集上的每个样本，则负对数似然可以无限趋近但不会等于零。同样地，实值模型
p(yjx) =N(y;f();  1)的负对数似然会趋向于负无穷——如果 f()能够正确预
测所有训练集中的目标 y，学习算法会无限制地增加 。图 8.4给出了一个失败的例
子，即使没有 局部极小值 和鞍点，该例还是不能从局部优化中找到一个良好的 代价
函数值。
J()
图8.4:如果局部表面没有指向全局解，基于局部下坡移动的优化可能就会失败。这里我们提供一
个例子，说明即使在没有 鞍点或局部极小值 的情况下，优化过程会如何失败。此例中的 代价函数 仅
包含朝向低值而不是 极小值的渐近线。在这种情况下，造成这种困难的主要原因是初始化在 ‘‘山’’
的错误一侧，并且无法遍历。在高维空间中，学习算法通常可以环绕过这样的高山，但是相关的轨
迹可能会很长，并且导致过长的训练时间，如图 8.2所示。
未来的研究需要进一步探索影响学习轨迹长度和更好地表征训练过程的结果。
许多现有研究方法在求解具有困难全局结构的问题时，旨在寻求良好的初始点，
而不是开发非局部范围更新的算法。
梯度下降 和基本上所有的可以有效训练 神经网络 的学习算法，都是基于局部较
小更新。之前的小节主要集中于为何这些局部范围更新的正确方向难以计算。我们DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.2神经网络优化中的挑战 249
也许能计算 目标函数 的一些性质，如近似的有偏梯度或正确方向估计的方差。在这
些情况下，难以确定局部下降能否定义通向有效解的足够短的路径，但我们并不能
真的遵循局部下降的路径。 目标函数 可能有诸如 病态条件 或不连续梯度的问题，使
得梯度为 目标函数 提供较好近似的区间非常小。在这些情况下，步长为 ϵ的局部下
降可能定义了到达解的合理的短路经，但是我们只能计算步长为 ≪ϵ的局部下降
方向。在这些情况下，局部下降或许能定义通向解的路径，但是该路径包含很多次
更新，因此遵循该路径会带来很高的计算代价。有时，比如说当 目标函数 有一个宽
而平的区域，或是我们试图寻求精确的 临界点（通常来说后一种情况只发生于显式
求解临界点的方法，如 牛顿法）时，局部信息不能为我们提供任何指导。在这些情况
下，局部下降 完全无法定义通向解的路径。在其他情况下，局部移动可能太过贪心，
朝着下坡方向移动，却和所有可行解南辕北辙，如图 8.4所示，或者是用舍近求远的
方法来求解问题，如图 8.2所示。目前，我们还不了解这些问题中的哪一个与 神经网
络优化中的难点最相关，这是研究领域的热点方向。
不管哪个问题最重要，如果存在一个区域，我们遵循 局部下降 便能合理地直接
到达某个解，并且我们能够在该良好区域上初始化学习，那么这些问题都可以避免。
最终的观点还是建议在传统优化算法上研究怎样选择更佳的初始化点，以此来实现
目标更切实可行。
8.2.8优化的理论限制
一些理论结果表明，我们为 神经网络 设计的任何优化算法都有性能限制 (Blum
and Rivest ,1992;Judd ,1989;Wolpert and MacReady ,1997)。通常这些结果不影
响神经网络 在实践中的应用。
一些理论结果仅适用于 神经网络 的单元输出离散值的情况。然而，大多数 神经
网络单元输出光滑的连续值，使得局部搜索求解优化可行。一些理论结果表明，存在
某类问题是不可解的，但很难判断一个特定问题是否属于该类。其他结果表明，寻
找给定规模的网络的一个可行解是很困难的，但在实际情况中，我们通过设置更多
参数，使用更大的网络，能轻松找到可接受的解。此外，在 神经网络 训练中，我们
通常不关注某个函数的精确 极小点，而只关注将其值下降到足够小以获得一个良好
的泛化误差 。对优化算法是否能完成此目标进行理论分析是非常困难的。因此，研
究优化算法更现实的性能上界仍然是学术界的一个重要目标。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
250 第八章 深度模型中的优化
8.3基本算法
之前我们已经介绍了 梯度下降 （第 4.3节） ，即沿着整个 训练集的梯度方向下降。
这可以使用 随机梯度下降 很大程度地加速，沿着随机挑选的 小批量数据的梯度下降
方向，就像第 5.9节和第 8.1.3节中讨论的一样。
8.3.1随机梯度下降
随机梯度下降 （SGD）及其变种很可能是一般 机器学习 中应用最多的的优化算
法，特别是在 深度学习 中。如第 8.1.3节中所讨论的，按照 数据生成分布 抽取 m个小
批量（独立同分布的）样本，通过计算它们梯度均值，我们可以得到梯度的 无偏估
计。
算法 8.1展示了如何沿着这个梯度的估计下降。
算法8.1随机梯度下降 （SGD）在第 k个训练迭代的更新
Require: 学习率 ϵk
Require: 初始参数
while停止准则未满足 do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，其中 x(i)对应目标为
y(i)。
计算梯度估计： ^g +1
m∇∑
iL(f(x(i););y(i))
应用更新：  ϵ^g
end while
SGD算法中的一个关键参数是 学习率。之前，我们介绍的 SGD使用固定的 学
习率。在实践中，有必要随着时间的推移逐渐降低 学习率，因此我们将第 k步迭代
的学习率记作 ϵk。
这是因为 SGD中梯度估计引入的噪声源（ m个训练样本的随机采样）并不会
在极小点处消失。相比之下，当我们使用 批量梯度下降 到达极小点时，整个 代价函
数的真实梯度会变得很小，之后为 0，因此批量梯度下降 可以使用固定的 学习率。保
证SGD收敛的一个充分条件是
1∑
k=1ϵk=1; (8.12)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.3基本算法 251
且
1∑
k=1ϵ2
k<1: (8.13)
实践中，一般会线性衰减 学习率直到第 次迭代：
ϵk= (1 )ϵ0+ϵ (8.14)
其中 =k
。在 步迭代之后，一般使 ϵ保持常数。
学习率可通过试验和误差来选取，通常最好的选择方法是监测 目标函数 值随时
间变化的学习曲线。与其说是科学，这更像是一门艺术，我们应该谨慎地参考关于
这个问题的大部分指导。使用线性策略时，需要选择的参数为 ϵ0，ϵ，。通常 被
设为需要反复遍历 训练集几百次的迭代次数。通常 ϵ应设为大约 ϵ0的1%。主要问
题是如何设置 ϵ0。若 ϵ0太大，学习曲线将会剧烈振荡， 代价函数 值通常会明显增
加。温和的振荡是良好的，容易在训练随机 代价函数 （例如使用 Dropout 的代价函
数）时出现。如果 学习率太小，那么学习过程会很缓慢。如果初始 学习率太低，那么
学习可能会卡在一个相当高的 代价值。通常，就总训练时间和最终 代价值而言，最
优初始学习率的效果会好于大约迭代 100次左右后最佳的效果。因此，通常最好是
检测最早的几轮迭代，选择一个比在效果上表现最佳的 学习率更大的学习率，但又
不能太大导致严重的震荡。
SGD及相关的 小批量亦或更广义的基于梯度优化的在线学习算法，一个重要的
性质是每一步更新的计算时间不依赖训练样本数目的多寡。即使训练样本数目非常
大时，它们也能收敛。对于足够大的数据集， SGD可能会在处理整个 训练集之前就
收敛到最终 测试集误差的某个固定容差范围内。
研究优化算法的收敛率，一般会衡量 额外误差 （excess error ）J() minJ()，
即当前代价函数 超出最低可能 代价的量。 SGD应用于凸问题时， k步迭代后的 额外
误差量级是 O(1p
k)，在强凸情况下是 O(1
k)。除非假定额外的条件，否则这些界限
不能进一步改进。 批量梯度下降 在理论上比 随机梯度下降 有更好的收敛率。然而，
Cramér-Rao 界限 (Cramér ,1946;Rao,1945)指出，泛化误差 的下降速度不会快于
O(1
k)。Bottou and Bousquet (2008b )因此认为对于 机器学习 任务，不值得探寻收敛
快于 O(1
k)的优化算法——更快的收敛可能对应着 过拟合。此外，渐近分析掩盖了 随
机梯度下降 在少量更新步之后的很多优点。对于大数据集， SGD只需非常少量样本
计算梯度从而实现初始快速更新，远远超过了其缓慢的渐近收敛。本章剩余部分介
绍的大多数算法在实践中都受益于这种性质，但是损失了常数倍 O(1
k)的渐近分析。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
252 第八章 深度模型中的优化
我们也可以在学习过程中逐渐增大 小批量的大小，以此权衡 批量梯度下降 和随机梯
度下降两者的优点。
了解 SGD更多的信息，请查看 Bottou (1998)。
8.3.2动量
虽然随机梯度下降 仍然是非常受欢迎的优化方法，但其学习过程有时会很慢。
动量方法 (Polyak ,1964)旨在加速学习，特别是处理高 曲率、小但一致的梯度，或是
带噪声的梯度。 动量算法积累了之前梯度指数级衰减的移动平均，并且继续沿该方
向移动。 动量的效果如图 8.5所示。
 30 20 10 0 10 20 30 20 1001020
图8.5:动量的主要目的是解决两个问题： Hessian矩阵的病态条件 和随机梯度的方差。我们通
过此图说明 动量如何克服这两个问题的第一个。等高线描绘了一个二次 损失函数 （具有病态条
件的Hessian矩阵） 。横跨轮廓的红色路径表示 动量学习规则所遵循的路径，它使该函数最小化。
我们在该路径的每个步骤画一个箭头，表示 梯度下降 将在该点采取的步骤。我们可以看到，一个 病
态条件的二次目标函数 看起来像一个长而窄的山谷或具有陡峭边的峡谷。 动量正确地纵向穿过峡
谷，而普通的梯度步骤则会浪费时间在峡谷的窄轴上来回移动。比较图 4.6，它也显示了没有 动
量的梯度下降 的行为。
从形式上看， 动量算法引入了变量 v充当速度角色——它代表参数在参数空间
移动的方向和速率。速度被设为负梯度的指数衰减平均。名称 动量（momentum ）
来自物理类比，根据牛顿运动定律，负梯度是移动参数空间中粒子的力。 动量在物
理学上定义为质量乘以速度。在 动量学习算法中，我们假设是单位质量，因此速度
向量 v也可以看作是粒子的 动量。超参数 2[0;1)决定了之前梯度的贡献衰减得有DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.3基本算法 253
多快。更新规则如下：
v v ϵ∇(
1
mm∑
i=1L(f(x(i););y(i)))
; (8.15)
 +v: (8.16)
速度 v累积了梯度元素∇(1
m∑m
i=1L(f(x(i););y(i)))。相对于 ϵ，越大，之前梯度
对现在方向的影响也越大。带 动量的SGD算法如算法 8.2所示。
算法8.2使用动量的随机梯度下降 （SGD）
Require: 学习率 ϵ，动量参数 
Require: 初始参数，初始速度 v
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
计算梯度估计： g 1
m∇∑
iL(f(x(i););y(i))
计算速度更新： v v ϵg
应用更新： +v
end while
之前，步长只是梯度范数乘以 学习率。现在，步长取决于梯度 序列的大小和排
列。当许多连续的梯度指向相同的方向时，步长最大。如果 动量算法总是观测到梯
度 g，那么它会在方向  g上不停加速，直到达到最终速度，其中步长大小为
ϵ∥g∥
1 : (8.17)
因此将动量的超参数视为1
1 有助于理解。例如， = 0:9对应着最大速度 10倍
于梯度下降 算法。
在实践中， 的一般取值为 0:5，0:9和0:99。和学习率一样， 也会随着时间
不断调整。一般初始值是一个较小的值，随后会慢慢变大。随着时间推移调整 没
有收缩 ϵ重要。
我们可以将 动量算法视为模拟连续时间下牛顿动力学下的粒子。这种物理类比
有助于直觉上理解 动量和梯度下降 算法是如何表现的。
粒子在任意时间点的位置由 (t)给定。粒子会受到净力 f(t)。该力会导致粒子
加速：
f(t) =@2
@t2(t): (8.18)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
254 第八章 深度模型中的优化
与其将其视为位置的二阶 微分方程 ，我们不如引入表示粒子在时间 t处速度的变量
v(t)，将牛顿动力学重写为一阶 微分方程 ：
v(t) =@
@t(t); (8.19)
f(t) =@
@tv(t): (8.20)
由此，动量算法包括通过数值模拟求解 微分方程 。求解微分方程 的一个简单数值方
法是欧拉方法，通过在每个梯度方向上小且有限的步来简单模拟该等式定义的动力
学。
这解释了 动量更新的基本形式，但具体什么是力呢？力正比于 代价函数 的负梯
度 ∇J()。该力推动粒子沿着 代价函数 表面下坡的方向移动。 梯度下降 算法基于
每个梯度简单地更新一步，而使用 动量算法的牛顿方案则使用该力改变粒子的速度。
我们可以将粒子视作在冰面上滑行的冰球。每当它沿着表面最陡的部分下降时，它
会累积继续在该方向上滑行的速度，直到其开始向上滑动为止。
另一个力也是必要的。如果 代价函数 的梯度是唯一的力，那么粒子可能永远不
会停下来。想象一下，假设理想情况下冰面没有摩擦，一个冰球从山谷的一端下滑，
上升到另一端，永远来回振荡。要解决这个问题，我们添加另一个正比于  v(t)的
力。在物理术语中，此力对应于粘性阻力，就像粒子必须通过一个抵抗介质，如糖
浆。这会导致粒子随着时间推移逐渐失去能量，最终收敛到 局部极小点 。
为什么要特别使用  v(t)和粘性阻力呢？部分原因是因为  v(t)在数学上的便
利——速度的整数幂很容易处理。然而，其他物理系统具有基于速度的其他整数幂
的其他类型的阻力。例如，颗粒通过空气时会受到正比于速度平方的湍流阻力，而颗
粒沿着地面移动时会受到恒定大小的摩擦力。这些选择都不合适。湍流阻力，正比于
速度的平方，在速度很小时会很弱。不够强到使粒子停下来。非零值初始速度的粒
子仅受到湍流阻力，会从初始位置永远地移动下去，和初始位置的距离大概正比于
O(logt)。因此我们必须使用速度较低幂次的力。如果幂次为零，相当于干摩擦，那
么力太强了。当 代价函数 的梯度表示的力很小但非零时，由于摩擦导致的恒力会使
得粒子在达到 局部极小点 之前就停下来。粘性阻力避免了这两个问题——它足够弱，
可以使梯度引起的运动直到达到最小，但又足够强，使得坡度不够时可以阻止运动。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.4参数初始化策略 255
8.3.3 Nesterov 动量
受Nesterov 加速梯度算法 (Nesterov ,1983,2004)启发， Sutskever et al. (2013)
提出了动量算法的一个变种。这种情况的更新规则如下：
v v ϵ∇[
1
mm∑
i=1L(
f(x(i);+v);y(i))]
; (8.21)
 +v; (8.22)
其中参数 和ϵ发挥了和标准 动量方法中类似的作用。 Nesterov 动量和标准动量之
间的区别体现在梯度计算上。 Nesterov 动量中， 梯度计算在施加当前速度之后。 因此，
Nesterov 动量可以解释为往标准 动量方法中添加了一个 校正因子 。完整的 Nesterov
动量算法如算法 8.3所示。
算法8.3使用 Nesterov 动量的随机梯度下降 （SGD）
Require: 学习率 ϵ，动量参数 
Require: 初始参数，初始速度 v
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
应用临时更新： ~ +v
计算梯度（在临时点） ： g 1
m∇~∑
iL(f(x(i);~);y(i))
计算速度更新： v v ϵg
应用更新： +v
end while
在凸批量梯度的情况下， Nesterov 动量将额外误差 收敛率从 O(1/k)（k步后）
改进到 O(1/k2)，如 Nesterov (1983)所示。可惜，在随机梯度的情况下， Nesterov
动量没有改进收敛率。
8.4参数初始化策略
有些优化算法本质上是非迭代的，只是求解一个解点。有些其它优化算法本质
上是迭代的，但是应用于这一类的优化问题时，能在可接受的时间内收敛到可接受
的解，并且与初始值无关。 深度学习 训练算法通常没有这两种奢侈的性质。 深度学DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
256 第八章 深度模型中的优化
习模型的训练算法通常是迭代的，因此要求使用者指定一些开始迭代的初始点。此
外，训练 深度模型 是一个足够困难的问题，以致于大多数算法都很大程度地受到初
始化选择的影响。初始点能够决定算法是否收敛，有些初始点十分不稳定，使得该
算法会遭遇数值困难，并完全失败。当学习收敛时，初始点可以决定学习收敛得多
块，以及是否收敛到一个 代价高或低的点。此外，差不多 代价的点可以具有区别极
大的泛化误差 ，初始点也可以影响 泛化。
现代的初始化策略是简单的、启发式的。设定改进的初始化策略是一项困难的
任务，因为 神经网络 优化至今还未被很好地理解。大多数初始化策略基于在 神经网
络初始化时实现一些很好的性质。然而，我们并没有很好地理解这些性质中的哪些会
在学习开始进行后的哪些情况下得以保持。进一步的难点是，有些初始点从优化的
观点看或许是有利的，但是从 泛化的观点看是不利的。我们对于初始点如何影响 泛
化的理解是相当原始的，几乎没有提供如何选择初始点的任何指导。
也许完全确知的唯一特性是初始参数需要在不同单元间 ‘‘破坏对称性 ’’。如果具
有相同激活函数 的两个隐藏单元 连接到相同的输入，那么这些单元必须具有不同的
初始参数。如果它们具有相同的初始参数，然后应用到确定性损失和模型的确定性
学习算法将一直以相同的方式更新这两个单元。即使模型或训练算法能够使用随机
性为不同的单元计算不同的更新（例如使用 Dropout的训练） ，通常来说，最好还是
初始化每个单元使其和其他单元计算不同的函数。这或许有助于确保没有输入模式
丢失在前向传播 的零空间中，没有梯度模式丢失在 反向传播 的零空间中。每个单元
计算不同函数的目标促使了参数的随机初始化。我们可以明确地搜索一大组彼此互
不相同的基函数，但这经常会导致明显的计算代价。例如，如果我们有和输出一样
多的输入，我们可以使用 Gram-Schmidt 正交化于初始的权重矩阵，保证每个单元
计算彼此非常不同的函数。在高维空间上使用高熵分布来随机初始化，计算代价小
并且不太可能分配单元计算彼此相同的函数。
通常情况下，我们可以为每个单元的 偏置设置启发式挑选的常数，仅随机初始
化权重。额外的参数（例如用于编码预测条件方差的参数）通常和偏差一样设置为
启发式选择的常数。
我们几乎总是初始化模型的权重为高斯或均匀分布中随机抽取的值。高斯或均
匀分布的选择似乎不会有很大的差别，但也没有被详尽地研究。然而，初始分布的
大小确实对优化过程的结果和网络 泛化能力都有很大的影响。
更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。它们DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.4参数初始化策略 257
也有助于避免在每层线性成分的前向或 反向传播 中丢失信号——矩阵中更大的值在
矩阵乘法中有更大的输出。如果初始权重太大，那么会在 前向传播 或反向传播 中产
生爆炸的值。在循环网络中，很大的权重也可能导致 混沌（chaos） （对于输入中很
小的扰动非常敏感，导致确定性 前向传播 过程表现随机） 。在一定程度上，梯度爆炸
问题可以通过 梯度截断 来缓解（执行 梯度下降 步骤之前设置梯度的阈值） 。较大的权
重也会产生使得 激活函数 饱和的值，导致饱和单元的梯度完全丢失。这些竞争因素
决定了权重的理想初始大小。
关于如何初始化网络， 正则化和优化有着非常不同的观点。优化观点建议权重
应该足够大以成功传播信息，但是 正则化希望其小一点。诸如 随机梯度下降 这类对
权重较小的增量更新，趋于停止在更靠近初始参数的区域（不管是由于卡在低梯度
的区域，还是由于触发了基于 过拟合的提前终止 准则）的优化算法倾向于最终参数
应接近于初始参数。回顾第 7.8节，在某些模型上， 提前终止 的梯度下降 等价于权重
衰减。在一般情况下， 提前终止 的梯度下降 和权重衰减 不同，但是提供了一个宽松
的类比去考虑初始化的影响。我们可以将初始化参数 为0类比于强置均值为 0
的高斯先验 p()。从这个角度来看，选择 0接近 0是有道理的。这个先验表明，单
元间彼此互不交互比交互更有可能。只有在目标函数的似然项表达出对交互很强的
偏好时，单元才会交互。另一方面，如果我们初始化 0为很大的值，那么我们的先
验指定了哪些单元应互相交互，以及它们应如何交互。
有些启发式方法可用于选择权重的初始大小。一种初始化 m个输入和 n输出的
全连接层的权重的启发式方法是从分布 U( 1pm;1pm)中采样权重，而 Glorot et al.
(2011a )建议使用 标准初始化 （normalized initialization ）
Wi;jU(
 √
6
m+n;√
6
m+n)
: (8.23)
后一种启发式方法初始化所有的层，折衷于使其具有相同激活方差和使其具有相同
梯度方差之间。这假设网络是不含非线性的链式矩阵乘法，据此推导得出。现实的 神
经网络显然会违反这个假设，但很多设计于线性模型的策略在其非线性对应中的效
果也不错。
Saxe et al. (2013)推荐初始化为随机正交矩阵，仔细挑选负责每一层非线性缩
放或增益 (gain)因子 g。他们得到了用于不同类型的非线性 激活函数 的特定缩放因
子。这种初始化方案也是启发于不含非线性的矩阵相乘序列的 深度网络 。在该模型
下，这个初始化方案保证了达到收敛所需的训练迭代总数独立于深度。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
258 第八章 深度模型中的优化
增加缩放因子 g将网络推向网络 前向传播 时激活范数增加， 反向传播 时梯度范
数增加的区域。 Sussillo (2014)表明，正确设置缩放因子足以训练深达 1000层的网
络，而不需要使用正交初始化。这种方法的一个重要观点是，在 前馈网络 中，激活
和梯度会在每一步 前向传播 或反向传播 中增加或缩小，遵循随机游走行为。这是因
为前馈网络 在每一层使用了不同的权重矩阵。如果该随机游走调整到保持范数，那
么前馈网络 能够很大程度地避免相同权重矩阵用于每层的 梯度消失与爆炸问题 ，如
第8.2.5节所述。
可惜，这些初始权重的最佳准则往往不会带来最佳效果。这可能有三种不同的
原因。首先，我们可能使用了错误的标准——它实际上并不利于保持整个网络信号
的范数。其次，初始化时强加的性质可能在学习开始进行后不能保持。最后，该标
准可能成功提高了优化速度，但意外地增大了 泛化误差 。在实践中，我们通常需要
将权重范围视为 超参数，其最优值大致接近，但并不完全等于理论预测。
数值范围准则的一个缺点是，设置所有的初始权重具有相同的标准差，例如
1pm，会使得层很大时每个单一权重会变得极其小。 Martens (2010)提出了一种被称
为稀疏初始化 （sparse initialization ）的替代方案，每个单元初始化为恰好有 k个
非零权重。这个想法保持该单元输入的总数量独立于输入数目 m，而不使单一权重
元素的大小随 m缩小。稀疏初始化有助于实现单元之间在初始化时更具多样性。但
是，它也非常偏好于具有很大高斯值的权重。因为 梯度下降 需要很长时间缩小 ‘‘不正
确’’的大值，这个初始化方案可能会导致某些单元出问题，例如 maxout单元有几个
过滤器，互相之间必须仔细调整。
计算资源允许的话，将每层权重的初始数值范围设为 超参数通常是个好主意，使
用第 11.4.2节介绍的 超参数搜索算法，如随机搜索，挑选这些数值范围。是否选择使
用密集或稀疏初始化也可以设为一个 超参数。作为替代，我们可以手动搜索最优初
始范围。一个好的挑选初始数值范围的经验法则是观测单个 小批量数据上的激活或
梯度的幅度或标准差。如果权重太小，那么当激活值在 小批量上前向传播 于网络时，
激活值的幅度会缩小。通过重复识别具有小得不可接受的激活值的第一层，并提高
其权重，最终有可能得到一个初始激活全部合理的网络。如果学习在这点上仍然很
慢，观测梯度的幅度或标准差可能也会有所帮助。这个过程原则上是自动的，且通
常计算量低于基于 验证集误差的超参数优化，因为它是基于初始模型在单批数据上
的行为反馈，而不是在 验证集上训练模型的反馈。由于这个协议很长时间都被启发
式使用，最近 Mishkin and Matas (2015)更正式地研究了该协议。
目前为止，我们关注在权重的初始化上。幸运的是，其他参数的初始化通常更DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.4参数初始化策略 259
容易。
设置偏置的方法必须和设置权重的方法协调。设置 偏置为零通常在大多数权重
初始化方案中是可行的。存在一些我们可能设置 偏置为非零值的情况：
•如果偏置是作为输出单元，那么初始化 偏置以获取正确的输出边缘统计通常是
有利的。要做到这一点，我们假设初始权重足够小，该单元的输出仅由 偏置决
定。这说明设置 偏置为应用于 训练集上输出边缘统计的 激活函数 的逆。例如，
如果输出是类上的分布，且该分布是高度偏态分布，第 i类的边缘概率由某个
向量 c的第 i个元素给定，那么我们可以通过求解方程 softmax (b) = c来设
置偏置向量 b。这不仅适用于分类器，也适用于我们将在第三部分遇到的模型，
例如自编码器 和玻尔兹曼机 。这些模型拥有输出类似于输入数据 x的网络层，
非常有助于初始化这些层的偏置以匹配 x上的边缘分布。
•有时，我们可能想要选择 偏置以避免初始化引起太大饱和。例如，我们可能会
将ReLU的隐藏单元 设为 0:1而非 0，以避免 ReLU在初始化时饱和。尽管这
种方法违背不希望偏置具有很强输入的权重初始化准则。例如，不建议使用随
机游走初始化 (Sussillo ,2014)。
•有时，一个单元会控制其他单元能否参与到等式中。在这种情况下，我们有
一个单元输出 u，另一个单元 h2[0;1]，那么我们可以将 h视作门，以决定
uh1还是 uh0。在这种情形下，我们希望设置 偏置 h，使得在初始化的大
多数情况下 h1。否则， u没有机会学习。例如， Jozefowicz et al. (2015)提
议设置 LSTM模型遗忘门的 偏置为1，如第 10.10节所述。
另一种常见类型的参数是方差或精确度参数。例如，我们用以下模型进行带条
件方差估计的 线性回归
p(yjx) =N(yjw⊤x+b;1/); (8.24)
其中 是精确度参数。通常我们能安全地初始化方差或精确度参数为 1。另一种方
法假设初始权重足够接近零，设置偏置可以忽略权重的影响，然后设定偏置以产生
输出的正确边缘均值，并将方差参数设置为 训练集输出的边缘方差。
除了这些初始化模型参数的简单常数或随机方法，还有可能使用 机器学习 初始
化模型参数。在本书第三部分讨论的一个常用策略是使用相同的输入数据集，用无
监督模型训练出来的参数来初始化监督模型。我们也可以在相关问题上使用监督训DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
260 第八章 深度模型中的优化
练。即使是在一个不相关的任务上运行监督训练，有时也能得到一个比随机初始化
具有更快收敛率的初始值。这些初始化策略有些能够得到更快的收敛率和更好的 泛
化误差，因为它们编码了模型初始参数的分布信息。其他策略显然效果不错的原因
主要在于它们设置参数为正确的数值范围，或是设置不同单元计算互相不同的函数。
8.5自适应学习率算法
神经网络 研究员早就意识到 学习率肯定是难以设置的 超参数之一，因为它对模
型的性能有显著的影响。正如我们在第 4.3节和第 8.2节中所探讨的，损失通常高度
敏感于参数空间中的某些方向，而不敏感于其他。 动量算法可以在一定程度缓解这
些问题，但这样做的代价是引入了另一个 超参数。在这种情况下，自然会问有没有
其他方法。如果我们相信方向敏感度在某种程度是轴对齐的，那么每个参数设置不
同的学习率，在整个学习过程中自动适应这些 学习率是有道理的。
Delta-bar-delta 算法 (Jacobs ,1988)是一个早期的在训练时适应模型参数各
自学习率的启发式方法。该方法基于一个很简单的想法，如果损失对于某个给定模
型参数的偏导保持相同的符号，那么 学习率应该增加。如果对于该参数的偏导变化
了符号，那么 学习率应减小。当然，这种方法只能应用于全 批量优化中。
最近，提出了一些增量（或者基于 小批量）的算法来自适应模型参数的 学习率。
这节将简要回顾其中一些算法。
8.5.1 AdaGrad
AdaGrad （AdaGrad ）算法， 如算法 8.4所示， 独立地适应所有模型参数的 学习
率，缩放每个参数反比于其所有梯度历史平方值总和的平方根 (Duchi et al. ,2011)。
具有损失最大偏导的参数相应地有一个快速下降的 学习率，而具有小偏导的参数
在学习率上有相对较小的下降。净效果是在参数空间中更为平缓的倾斜方向会取得
更大的进步。
在凸优化背景中， AdaGrad 算法具有一些令人满意的理论性质。然而，经验上
已经发现，对于训练 深度神经网络 模型而言， 从训练开始时 积累梯度平方会导致有
效学习率过早和过量的减小。 AdaGrad 在某些深度学习 模型上效果不错，但不是全
部。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.5自适应学习率算法 261
算法8.4AdaGrad 算法
Require: 全局学习率 ϵ
Require: 初始参数
Require: 小常数 ，为了数值稳定大约设为 10 7
初始化梯度累积变量 r= 0
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
计算梯度： g 1
m∇∑
iL(f(x(i););y(i))
累积平方梯度： r r+g⊙g
计算更新： ∆  ϵ
+pr⊙g（逐元素地应用除和求平方根）
应用更新： + ∆
end while
8.5.2 RMSProp
RMSProp 算法 (Hinton ,2012)修改 AdaGrad 以在非凸设定下效果更好，改
变梯度积累为指数加权的移动平均。 AdaGrad 旨在应用于凸问题时快速收敛。当应
用于非凸函数训练 神经网络 时，学习轨迹可能穿过了很多不同的结构，最终到达一
个局部是凸碗的区域。 AdaGrad 根据平方梯度的整个历史收缩 学习率，可能使得 学
习率在达到这样的凸结构前就变得太小了。 RMSProp 使用指数衰减平均以丢弃遥远
过去的历史，使其能够在找到凸碗状结构后快速收敛，它就像一个初始化于该碗状
结构的 AdaGrad 算法实例。
RMSProp 的标准形式如算法 8.5所示，结合 Nesterov 动量的形式如算法 8.6所
示。相比于 AdaGrad ，使用移动平均引入了一个新的 超参数 ，用来控制移动平均的
长度范围。
经验上， RMSProp 已被证明是一种有效且实用的 深度神经网络 优化算法。目前
它是深度学习 从业者经常采用的优化方法之一。
8.5.3 Adam
Adam (Kingma and Ba ,2014)是另一种 学习率自适应的优化算法， 如算法 8.7所
示。“Adam’’ 这个名字派生自短语 “adaptive moments’’ 。早期算法背景下，它也许DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
262 第八章 深度模型中的优化
算法8.5RMSProp 算法
Require: 全局学习率 ϵ，衰减速率 
Require: 初始参数
Require: 小常数 ，通常设为 10 6（用于被小数除时的数值稳定）
初始化累积变量 r= 0
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
计算梯度： g 1
m∇∑
iL(f(x(i););y(i))
累积平方梯度： r r+ (1 )g⊙g
计算参数更新： ∆= ϵp+r⊙g(1p+r逐元素应用 )
应用更新： + ∆
end while
最好被看作结合 RMSProp 和具有一些重要区别的 动量的变种。首先，在 Adam中，
动量直接并入了梯度一阶矩（指数加权）的估计。将 动量加入 RMSProp 最直观的
方法是将 动量应用于缩放后的梯度。结合缩放的 动量使用没有明确的理论动机。其
次，Adam包括偏置修正，修正从原点初始化的一阶矩（ 动量项）和（非中心的）二
阶矩的估计（算法 8.7） 。RMSProp 也采用了（非中心的）二阶矩估计，然而缺失了
修正因子。因此，不像 Adam，RMSProp 二阶矩估计可能在训练初期有很高的偏置。
Adam通常被认为对 超参数的选择相当鲁棒，尽管 学习率有时需要从建议的默认修
改。
8.5.4选择正确的优化算法
在本节中，我们讨论了一系列算法，通过自适应每个模型参数的 学习率以解决
优化深度模型 中的难题。此时，一个自然的问题是：该选择哪种算法呢？
遗憾的是，目前在这一点上没有达成共识。 Schaul et al. (2014)展示了许多优
化算法在大量学习任务上极具价值的比较。虽然结果表明，具有自适应 学习率（以
RMSProp 和AdaDelta 为代表）的算法族表现得相当鲁棒，不分伯仲，但没有哪个
算法能脱颖而出。
目前，最流行并且使用很高的优化算法包括 SGD、具动量的SGD、RMSProp 、
具动量的RMSProp 、AdaDelta 和Adam。此时，选择哪一个算法似乎主要取决于DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.5自适应学习率算法 263
算法8.6使用 Nesterov 动量的RMSProp 算法
Require: 全局学习率 ϵ，衰减速率 ，动量系数 
Require: 初始参数，初始参数 v
初始化累积变量 r= 0
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
计算临时更新： ~ +v
计算梯度： g 1
m∇~∑
iL(f(x(i);~);y(i))
累积梯度： r r+ (1 )g⊙g
计算速度更新： v v ϵpr⊙g(1pr逐元素应用 )
应用更新： +v
end while
使用者对算法的熟悉程度（以便调节 超参数） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
264 第八章 深度模型中的优化
算法8.7Adam算法
Require: 步长 ϵ（建议默认为： 0:001）
Require: 矩估计的指数衰减速率， 1和2在区间 [0;1)内。（建议默认为：分别
为0:9和0:999）
Require: 用于数值稳定的小常数 （建议默认为： 10 8）
Require: 初始参数
初始化一阶和二阶矩变量 s= 0,r= 0
初始化时间步 t= 0
while没有达到停止 准则do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量，对应目标为 y(i)。
计算梯度： g 1
m∇∑
iL(f(x(i););y(i))
t t+ 1
更新有偏一阶矩估计： s 1s+ (1 1)g
更新有偏二阶矩估计： r 2r+ (1 2)g⊙g
修正一阶矩的 偏差：^s s
1 t
1
修正二阶矩的 偏差：^r r
1 t
2
计算更新： ∆= ϵ^sp
^r+（逐元素应用操作）
应用更新： + ∆
end while
8.6二阶近似方法
在本节中，我们会讨论训练 深度神经网络 的二阶方法。参考 LeCun and Cortes
(1998)了解该问题的早期处理方法。为表述简单起见，我们只考察 目标函数 为经验
风险：
J() =Ex;y^pdata(x;y)[L(f(x;); y)] =1
mm∑
i=1L(f(x(i);); y(i)): (8.25)
然而，我们在这里讨论的方法很容易扩展到更一般的 目标函数 ，例如，第 七章讨论
的包括参数正则项的函数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.6二阶近似方法 265
8.6.1牛顿法
在第 4.3节，我们介绍了二阶梯度方法。与一阶方法相比，二阶方法使用二阶导
数改进了优化。最广泛使用的二阶方法是 牛顿法。我们现在更详细地描述 牛顿法，重
点在其应用于 神经网络 的训练。
牛顿法是基于二阶泰勒级数展开在某点 0附近来近似 J()的优化方法，其忽
略了高阶导数：
J()J(0) + ( 0)⊤∇J(0) +1
2( 0)⊤H( 0); (8.26)
其中 H是J相对于的Hessian矩阵在0处的估计。如果我们再求解这个函数
的临界点，我们将得到牛顿参数更新规则：
=0 H 1∇J(0): (8.27)
因此，对于局部的二次函数（具有正定的 H） ，用 H 1重新调整梯度， 牛顿法会直
接跳到极小值。如果 目标函数 是凸的但非二次的（有高阶项） ，该更新将是迭代的，
得到和牛顿法相关的算法，如算法 8.8所示。
对于非二次的表面，只要 Hessian矩阵保持正定， 牛顿法能够迭代地应用。这意
味着一个两步迭代过程。首先，更新或计算 Hessian逆（通过更新二阶近似） 。其次，
根据式 (8.27)更新参数。
在第 8.2.3节，我们讨论了 牛顿法只适用于 Hessian矩阵是正定的情况。在 深度
学习中，目标函数 的表面通常 非凸（有很多特征） ，如 鞍点。因此使用 牛顿法是有问
题的。如果 Hessian矩阵的特征值并不都是正的，例如，靠近 鞍点处，牛顿法实际上
会导致更新朝错误的方向移动。这种情况可以通过正则化 Hessian矩阵来避免。常用
的正则化策略包括在 Hessian矩阵对角线上增加常数 。正则化更新变为
=0 [H(f(0)) +I] 1∇f(0): (8.28)
这个正则化策略用于 牛顿法的近似，例如 Levenberg-Marquardt 算法 (Levenberg ,
1944;Marquardt ,1963)，只要 Hessian矩阵的负特征值仍然相对接近零，效果就会
很好。在 曲率方向更极端的情况下， 的值必须足够大，以抵消负特征值。然而，如
果持续增加， Hessian矩阵会变得由对角矩阵 I主导，通过 牛顿法所选择的方向
会收敛到普通梯度除以 。当很强的负 曲率存在时， 可能需要特别大，以致于 牛顿
法比选择合适 学习率的梯度下降 的步长更小。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
266 第八章 深度模型中的优化
算法8.8目标为 J() =1
m∑m
i=1L(f(x(i);); y(i))的牛顿法
Require: 初始参数0
Require: 包含 m个样本的 训练集
while没有达到停止 准则do
计算梯度： g 1
m∇∑
iL(f(x(i););y(i))
计算 Hessian矩阵： H 1
m∇2
∑
iL(f(x(i););y(i))
计算 Hessian逆： H 1
计算更新： ∆= H 1g
应用更新：=+ ∆
end while
除了目标函数 的某些特征带来的挑战，如 鞍点，牛顿法用于训练大型 神经网络 还
受限于其显著的计算负担。 Hessian矩阵中元素数目是参数数量的平方，因此，如果
参数数目为 k（甚至是在非常小的 神经网络 中k也可能是百万级别） ， 牛顿法需要计
算kk矩阵的逆，计算复杂度为 O(k3)。另外，由于参数将每次更新都会改变， 每
次训练迭代 都需要计算 Hessian矩阵的逆。其结果是，只有参数很少的网络才能在实
际中用牛顿法训练。在本节的剩余部分，我们将讨论一些试图保持 牛顿法优点，同
时避免计算障碍的替代算法。
8.6.2共轭梯度
共轭梯度 是一种通过迭代下降的 共轭方向 （conjugate directions ）以有效避
免Hessian矩阵求逆计算的方法。这种方法的灵感来自于对最速下降方法弱点的仔细
研究（详细信息请查看第 4.3节） ，其中线性搜索迭代地用于与梯度相关的方向上。
图8.6说明了该方法在二次碗型目标中如何表现的，是一个相当低效的来回往复，锯
齿形模式。这是因为每一个由梯度给定的线性搜索方向，都保证正交于上一个线性
搜索方向。
假设上一个搜索方向是 dt 1。在极小值处，线性搜索终止，方向 dt 1处的方向
导数为零：∇J()dt 1= 0。因为该点的梯度定义了当前的搜索方向， dt=∇J()
将不会贡献于方向 dt 1。因此方向 dt正交于 dt 1。最速下降多次迭代中，方向 dt 1
和 dt之间的关系如图 8.6所示。如图展示的，下降正交方向的选择不会保持前一搜
索方向上的最小值。这产生了锯齿形的过程。在当前梯度方向下降到极小值，我们DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.6二阶近似方法 267
−30−20−1001020−30−20−1001020
图8.6:将最速下降法应用于二次代价表面。在每个步骤，最速下降法沿着由初始点处的梯度定义
的线跳到最低代价的点。这解决了图 4.6中使用固定 学习率所遇到的一些问题，但即使使用最佳步
长，算法仍然朝最优方向曲折前进。根据定义，在沿着给定方向的目标最小值处，最终点处的梯度
与该方向正交。
必须重新最小化之前梯度方向上的目标。因此，通过遵循每次线性搜索结束时的梯
度，我们在某种程度上撤销了在之前线性搜索的方向上取得的进展。 共轭梯度 试图
解决这个问题。
在共轭梯度 法中，我们寻求一个和先前线性搜索方向 共轭（conjugate ）的搜索
方向，即它不会撤销该方向上的进展。在训练迭代 t时，下一步的搜索方向 dt的形
式如下：
dt=∇J() +tdt 1; (8.29)
其中，系数 t的大小控制我们应沿方向 dt 1加回多少到当前搜索方向上。
如果 d⊤
tHdt 1= 0，其中 H是Hessian矩阵，则两个方向 dt和 dt 1被称为共
轭的。
适应共轭的直接方法会涉及到 H特征向量的计算以选择 t。这将无法满足我们
的开发目标：寻找在大问题比 牛顿法计算更加可行的方法。我们能否不进行这些计
算而得到共轭方向？幸运的是这个问题的答案是肯定的。
两种用于计算 t的流行方法是：
1.Fletcher-Reeves:
t=∇J(t)⊤∇J(t)
∇J(t 1)⊤∇J(t 1)(8.30)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
268 第八章 深度模型中的优化
2.Polak-Ribière:
t=(∇J(t) ∇J(t 1))⊤∇J(t)
∇J(t 1)⊤∇J(t 1)(8.31)
对于二次曲面而言，共轭方向确保梯度沿着前一方向大小不变。因此，我们在前一
方向上仍然是极小值。其结果是，在 k-维参数空间中， 共轭梯度 只需要至多 k次线
性搜索就能达到极小值。 共轭梯度 算法如算法 8.9所示。
算法8.9共轭梯度 方法
Require: 初始参数0
Require: 包含 m个样本的 训练集
初始化0= 0
初始化 g0= 0
初始化 t= 1
while没有达到停止 准则do
初始化梯度 gt= 0
计算梯度： gt 1
m∇∑
iL(f(x(i););y(i))
计算 t=(gt gt 1)⊤gt
g⊤
t 1gt 1(Polak-Ribière)
(非线性共轭梯度 ：视情况可重置 t为零，例如 t是常数 k的倍数时，如 k= 5)
计算搜索方向： t= gt+tt 1
执行线搜索寻找： ϵ= argmin ϵ1
m∑m
i=1L(f(x(i);t+ϵt);y(i))
（对于真正二次的 代价函数 ，存在 ϵ的解析解，而无需显式地搜索）
应用更新：t+1=t+ϵt
t t+ 1
end while
非线性共轭梯度 ：目前，我们已经讨论了用于二次 目标函数 的共轭梯度 法。当然，
本章我们主要关注于探索训练 神经网络 和其他相关 深度学习 模型的优化方法，其对
应的目标函数 比二次函数复杂得多。或许令人惊讶， 共轭梯度 法在这种情况下仍然
是适用的，尽管需要作一些修改。没有目标是二次的保证，共轭方向也不再保证在
以前方向上的目标仍是极小值。其结果是， 非线性共轭梯度 算法会包括一些偶尔的
重设，共轭梯度 法沿未修改的梯度重启线性搜索。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.6二阶近似方法 269
实践者报告在实践中使用 非线性共轭梯度 算法训练 神经网络 是合理的，尽管在
开始非线性共轭梯度 前使用随机梯度下降 迭代若干步来初始化效果更好。另外，尽
管（非线性） 共轭梯度 算法传统上作为批方法， 小批量版本已经成功用于训练 神经
网络 (Le Roux et al. ,2011)。针对神经网路的 共轭梯度 应用早已被提出，例如缩放
的共轭梯度 算法 (Moller ,1993)。
8.6.3 BFGS
Broyden-Fletcher-Goldfarb-Shanno （BFGS）算法具有 牛顿法的一些优
点，但没有 牛顿法的计算负担。在这方面， BFGS和CG很像。然而， BFGS使用了
一个更直接的方法近似牛顿更新。回顾牛顿更新由下式给出
=0 H 1∇J(0); (8.32)
其中， H是J相对于的Hessian矩阵在0处的估计。运用 牛顿法的主要计算难
点在于计算 Hessian逆 H 1。拟牛顿法所采用的方法（ BFGS是其中最突出的）是使
用矩阵 Mt近似逆，迭代地低秩更新精度以更好地近似 H 1。
BFGS近似的说明和推导出现在很多关于优化的教科书中，包括 Luenberger
(1984)。
当Hessian逆近似 Mt更新时，下降方向 t为t= Mtgt。该方向上的线性搜
索用于决定该方向上的步长 ϵ。参数的最后更新为：
t+1=t+ϵt: (8.33)
和共轭梯度 法相似， BFGS算法迭代一系列线性搜索，其方向含二阶信息。然而
和共轭梯度 不同的是，该方法的成功并不严重依赖于线性搜索寻找该方向上和真正
极小值很近的一点。因此，相比于 共轭梯度 ，BFGS的优点是其花费较少的时间改
进每个线性搜索。在另一方面， BFGS算法必须存储 Hessian逆矩阵 M，需要 O(n2)
的存储空间，使 BFGS不适用于大多数具有百万级参数的现代 深度学习 模型。
存储受限的 BFGS（或L-BFGS ）通过避免存储完整的 Hessian逆近似 M，
BFGS算法的存储代价可以显著降低。 L-BFGS 算法使用和 BFGS算法相同的方法计
算 M的近似，但起始假设是 M(t 1)是单位矩阵，而不是一步一步都要存储近似。
如果使用精确的线性搜索， L-BFGS 定义的方向会是相互共轭的。然而，不同于 共轭DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
270 第八章 深度模型中的优化
梯度法，即使只是近似线性搜索的极小值，该过程的效果仍然不错。这里描述的无
存储的 L-BFGS 方法可以拓展为包含 Hessian矩阵更多的信息，每步存储一些用于更
新 M的向量，且每步的存储代价是 O(n)。
8.7优化策略和元算法
许多优化技术并非真正的算法，而是一般化的模板，可以特定地产生算法，或
是并入到很多不同的算法中。
8.7.1批标准化
批标准化 (Ioﬀe and Szegedy ,2015)是优化深度神经网络 中最激动人心的最新创
新之一。实际上它并不是一个优化算法，而是一个自适应的重参数化的方法，试图
解决训练非常深的模型的困难。
非常深的模型会涉及多个函数或层组合。在其他层不改变的假设下，梯度用于
如何更新每一个参数。在实践中，我们同时更新所有层。当我们进行更新时，可能会
发生一些意想不到的结果，这是因为许多组合在一起的函数同时改变时，计算更新
的假设是其他函数保持不变。举一个简单的例子，假设我们有一个 深度神经网络 ，每
一层只有一个单元，并且在每个 隐藏层不使用激活函数 ：^y=xw1w2w3: : : w l。此处，
wi表示用于层 i的权重。层 i的输出是 hi=hi 1wi。输出 ^y是输入 x的线性函数，
但是权重 wi的非线性函数。假设我们的 代价函数 ^y上的梯度为 1，所以我们希望稍
稍降低 ^y。然后反向传播 算法可以计算梯度 g=∇ w^y。想想我们在更新 w w ϵg
时会发生什么。近似 ^y的一阶泰勒级数会预测 ^y的值下降 ϵg⊤g。如果我们希望 ^y下
降0:1，那么梯度中的一阶信息表明我们应设置 学习率 ϵ为0:1
g⊤g。然而，实际的更新
将包括二阶，三阶，直到 l阶的影响。 ^y的更新值为
x(w1 ϵg1)(w2 ϵg2): : :(wl ϵgl); (8.34)
这个更新中所产生的一个二阶项示例是 ϵ2g1g2∏l
i=3wi。如果∏l
i=3wi很小，那么该
项可以忽略不计。而如果层 3到层 l的权重都比 1大时，该项可能会指数级大。这
使得我们很难选择一个合适的 学习率，因为某一层中参数更新的效果很大程度上取
决于其他所有层。二阶优化算法通过考虑二阶相互影响来解决这个问题，但我们可
以看到，在非常深的网络中，更高阶的相互影响会很显著。即使是二阶优化算法，计DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.7优化策略和元算法 271
算代价也很高，并且通常需要大量近似，以免真正计算所有的重要二阶相互作用。因
此对于 n >2的情况，建立 n阶优化算法似乎是无望的。那么我们可以做些什么呢？
批标准化 提出了一种几乎可以重参数化所有 深度网络 的优雅方法。重参数化显
著减少了多层之间协调更新的问题。 批标准化 可应用于网络的任何输入层或 隐藏层。
设 H是需要标准化的某层的 小批量激活函数 ，排布为设计矩阵，每个样本的激活出
现在矩阵的每一行中。为了标准化 H，我们将其替换为
H′=H 
; (8.35)
其中是包含每个单元均值的向量， 是包含每个单元标准差的向量。此处的算术
是基于广播向量 和向量应用于矩阵 H的每一行。在每一行内，运算是逐元素
的，因此 Hi;j标准化为减去 j再除以 j。网络的其余部分操作 H′的方式和原网
络操作 H的方式一样。
在训练阶段，
=1
m∑
iHi;: (8.36)
和
=√
+1
m∑
i(H )2
i; (8.37)
其中 是个很小的正值，比如 10 8，以强制避免遇到pz的梯度在 z= 0处未定义
的问题。至关重要的是， 我们反向传播这些操作 ，来计算均值和标准差，并应用它们
于标准化 H。这意味着，梯度不会再简单地增加 hi的标准差或均值；标准化操作会
除掉这一操作的影响，归零其在梯度中的元素。这是 批标准化 方法的一个重大创新。
以前的方法添加 代价函数 的惩罚，以鼓励单元标准化激活统计量，或是在每个 梯度
下降步骤之后重新标准化单元统计量。前者通常会导致不完全的标准化，而后者通
常会显著地消耗时间，因为学习算法会反复改变均值和方差而标准化步骤会反复抵
消这种变化。 批标准化 重参数化模型，以使一些单元总是被定义标准化，巧妙地回
避了这两个问题。
在测试阶段， 和可以被替换为训练阶段收集的运行均值。这使得模型可以
对单一样本评估，而无需使用定义于整个 小批量的和。
回顾例子 ^y=xw1w2: : : w l，我们看到，我们可以通过标准化 hl 1很大程度地
解决了学习这个模型的问题。假设 x采样自一个单位高斯。那么 hl 1也是来自高
斯，因为从 x到hl的变换是线性的。然而， hl 1不再有零均值和单位方差。使用 批DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
272 第八章 深度模型中的优化
标准化后，我们得到的归一化 ^hl 1恢复了零均值和单位方差的特性。对于底层的几
乎任意更新而言， ^hl 1仍然保持着单位高斯。然后输出 ^y可以学习为一个简单的线
性函数 ^y=wl^hl 1。现在学习这个模型非常简单，因为低层的参数在大多数情况下
没有什么影响；它们的输出总是重新标准化为单位高斯。只在少数个例中，低层会
有影响。改变某个低层权重为 0，可能使输出退化；改变低层权重的符号可能反转
^hl 1和y之间的关系。这些情况都是非常罕见的。没有标准化，几乎每一个更新都
会对 hl 1的统计量有着极端的影响。因此， 批标准化 显著地使得模型更易学习。在
这个示例中，容易学习的代价是使得底层网络没有用。在我们的线性示例中，较低
层不再有任何有害的影响，但它们也不再有任何有益的影响。这是因为我们已经标
准化了一阶和二阶统计量，这是线性网络可以影响的所有因素。在具有非线性 激活
函数的深度神经网络 中，较低层可以进行数据的非线性变换，所以它们仍然是有用
的。批标准化 仅标准化每个单元的均值和方差，以稳定化学习，但允许单元和单个
单元的非线性统计量之间的关系发生变化。
由于网络的最后一层能够学习线性变换，实际上我们可能希望移除一层内单元
之间的所有线性关系。事实上，这是 Guillaume Desjardins (2015)中采用的方法，
为批标准化 提供了灵感。令人遗憾的是，消除所有的线性关联比标准化各个独立单
元的均值和 标准差代价更高，因此 批标准化 仍是迄今最实用的方法。
标准化一个单元的均值和标准差会降低包含该单元的 神经网络 的表达能力。为
了保持网络的表现力，通常会将 批量隐藏单元 激活 H替换为 H′+，而不是简单
地使用标准化的 H′。变量和是允许新变量有任意均值和 标准差的学习参数。
乍一看，这似乎是无用的——为什么我们将均值设为 0，然后又引入参数允许它被重
设为任意值？答案是新的参数可以表示旧参数作为输入的同一族函数，但是新参
数有不同的学习动态。在旧参数中， H的均值取决于 H下层中参数的复杂关联。在
新参数中，H′+的均值仅由确定。新参数很容易通过 梯度下降 来学习。
大多数神经网络 层会采取 ϕ(XW +b)的形式，其中 ϕ是某个固定的非线性 激
活函数，如整流线性 变换。自然想到我们应该将 批标准化 应用于输入 X还是变换后
的值 XW +b。Ioﬀe and Szegedy (2015)推荐后者。更具体地， XW +b应替换为
XW的标准化形式。偏置项应被忽略，因为参数 会加入批标准化 重参数化，它是
冗余的。一层的输入通常是前一层的非线性 激活函数 （如整流线性 函数）的输出。因
此，输入的统计量更符合非高斯，而更不服从线性操作的标准化。
第九章所述的卷积网络，在特征映射中每个空间位置同样地标准化 和是很
重要的，能使特征映射的统计量不因空间位置而保持相同。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.7优化策略和元算法 273
8.7.2坐标下降
在某些情况下，将一个优化问题分解成几个部分，可以更快地解决原问题。如
果我们相对于某个单一变量 xi最小化 f(x)，然后相对于另一个变量 xj等等，反
复循环所有的变量，我们会保证到达（局部）极小值。这种做法被称为 坐标下降
（coordinate descent ） ，因为我们一次优化一个坐标。更一般地， 块坐标下降 （block
coordinate descent ）是指对于某个子集的变量同时最小化。术语 “坐标下降 ’’通常既
指块坐标下降，也指严格的单个坐标下降。
当优化问题中的不同变量能够清楚地分成相对独立的组，或是当优化一组变量
明显比优化所有变量效率更高时，坐标下降最有意义。例如，考虑 代价函数
J(H;W) =∑
i;jjHi;jj+∑
i;j(
X W⊤H)2
i;j: (8.38)
该函数描述了一种被称为 稀疏编码 的学习问题，其目标是寻求一个权重矩阵 W，可
以线性解码激活值矩阵 H以重构训练集 X。稀疏编码 的大多数应用还涉及到 权重衰
减或 W列范数的约束，以避免极小 H和极大 W的病态解。
函数 J不是凸的。然而，我们可以将训练算法的输入分成两个集合：字典参数
W和编码表示 H。最小化关于这两者之一的任意一组变量的 目标函数 都是凸问题。
因此，块坐标下降允许我们使用高效的 凸优化算法，交替固定 H优化 W和固定 W
优化 H。
当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是一个很
好的方法，如函数 f(x) = (x1 x2)2+(x2
1+x2
2)，其中 是正值常数。第一项鼓
励两个变量具有相似的值，而第二项鼓励它们接近零。解是两者都为零。 牛顿法可
以一步解决这个问题，因为它是一个正定二次问题。但是，对于小值 而言，坐标
下降会使进展非常缓慢，因为第一项不允许单个变量变为和其他变量当前值显著不
同的值。
8.7.3 Polyak 平均
Polyak平均 (Polyak and Juditsky ,1992)会平均优化算法在参数空间访问轨迹
中的几个点。如果 t次迭代梯度下降 访问了点(1); : : : ;(t)，那么 Polyak平均算法
的输出是 ^(t)=1
t∑
i(i)。在某些问题中，如 梯度下降 应用于凸问题时，这种方法具
有较强的收敛保证。当应用于 神经网络 时，其验证更多是启发式的，但在实践中表DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
274 第八章 深度模型中的优化
现良好。基本想法是，优化算法可能会来回穿过山谷好几次而没经过山谷底部附近
的点。尽管两边所有位置的均值应比较接近谷底。
在非凸问题中，优化轨迹的路径可以非常复杂，并且经过了许多不同的区域。包
括参数空间中遥远过去的点，可能与当前点在 代价函数 上相隔很大的障碍，看上去
不像一个有用的行为。其结果是，当应用 Polyak平均于非凸问题时，通常会使用指
数衰减计算平均值：
^(t)=^(t 1)+ (1 )(t): (8.39)
这个计算平均值的方法被用于大量数值应用中。 最近的例子请查看 Szegedy et al.
(2015)。
8.7.4监督预训练
有时，如果模型太复杂难以优化，或是如果任务非常困难，直接训练模型来解
决特定任务的挑战可能太大。有时训练一个较简单的模型来求解问题，然后使模型
更复杂会更有效。训练模型来求解一个简化的问题，然后转移到最后的问题，有时
也会更有效些。这些在直接训练目标模型求解目标问题之前，训练简单模型求解简
化问题的方法统称为 预训练（pretraining ） 。
贪心算法 （greedy algorithm ）将问题分解成许多部分，然后独立地在每个部分
求解最优值。令人遗憾的是，结合各个最佳的部分不能保证得到一个最佳的完整解。
然而，贪心算法计算上比求解最优联合解的算法高效得多，并且贪心算法的解在不是
最优的情况下，往往也是可以接受的。贪心算法也可以紧接一个 精调（ﬁne-tuning ）
阶段，联合优化算法搜索全问题的最优解。使用贪心解初始化联合优化算法，可以
极大地加速算法，并提高寻找到的解的质量。
预训练算法，特别是贪心 预训练，在深度学习 中是普遍存在的。在本节中，我们
会具体描述这些将监督学习问题分解成其他简化的监督学习问题的 预训练算法。这
种方法被称为 贪心监督预训练 （greedy supervised pretraining ） 。
在贪心监督预训练 的原始版本 (Bengio et al. ,2007c )中，每个阶段包括一个仅
涉及最终 神经网络 的子集层的监督学习训练任务。 贪心监督预训练 的一个例子如
图8.7所示，其中每个附加的 隐藏层作为浅层监督 多层感知机 的一部分 预训练，以先
前训练的 隐藏层输出作为输入。 Simonyan and Zisserman (2015)预训练深度卷积网
络（11层权重） ，然后使用该网络前四层和最后三层初始化更深的网络（多达 19层DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.7优化策略和元算法 275
权重） ，并非一次 预训练一层。非常深的新网络的中间层是随机初始化的。然后联合
训练新网络。还有一种选择，由 Yuet al. (2010)提出，将先前训练 多层感知机 的输
出，以及原始输入，作为每个附加阶段的输入。
yyh(1)h(1)xx(a)U(1)U(1)W(1)W(1)yyh(1)h(1)xx(b)U(1)U(1)W(1)W(1)
yyh(1)h(1)xx(c)U(1)U(1)W(1)W(1)h(2)h(2)yyU(2)U(2)W(2)W(2)yyh(1)h(1)xx(d)U(1)U(1)W(1)W(1)h(2)h(2)yU(2)U(2)W(2)W(2)
图8.7:一种形式的 贪心监督预训练 的示意图 (Bengio et al. ,2007a )。(a)我们从训练一个足够浅
的架构开始。 (b)同一个架构的另一描绘。 (c)我们只保留原始网络的输入到隐藏层，并丢弃隐藏
到输出层。我们将第一层 隐藏层的输出作为输入发送到另一监督单隐层 MLP（使用与第一个网络
相同的目标训练） ，从而可以添加第二层 隐藏层。这可以根据需要重复多层。 (d)所得架构的另一
种描绘，可视为 前馈网络 。为了进一步改进优化，我们可以联合地 精调所有层（仅在该过程的结束
或者该过程的每个阶段） 。
为什么贪心监督预训练 会有帮助呢？最初由 Bengio et al. (2007d )提出的假说DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
276 第八章 深度模型中的优化
是，其有助于更好地指导深层结构的中间层的学习。一般情况下， 预训练对于优化
和泛化都是有帮助的。
另一个与监督 预训练有关的方法扩展了迁移学习的想法： Yosinski et al. (2014)
在一组任务上 预训练了8层权重的深度卷积网络（ 1000个ImageNet 对象类的子
集） ，然而用该网络的前 k层初始化同样规模的网络。然后第二个网络的所有层（上
层随机初始化）联合训练以执行不同的任务（ 1000个ImageNet 对象类的另一个子
集） ，但训练样本少于第一个任务。 神经网络 中另一个和迁移学习相关的方法将在
第15.2节讨论。
另一条相关的工作线是 FitNets (Romero et al. ,2015)方法。这种方法始于训
练深度足够低和宽度足够大（每层单元数） ，容易训练的网络。然后，这个网络成为
第二个网络（被指定为 学生）的老师。学生网络更深更窄（ 11至19层） ，且在正
常情况下很难用 SGD训练。训练学生网络不仅需要预测原任务的输出，还需要预
测教师网络中间层的值，这样使得训练学生网络变得更容易。这个额外的任务说明
了隐藏层应如何使用，并且能够简化优化问题。附加参数被引入来从更深的学生网
络中间层去回归 5层教师网络的中间层。然而，该目标是预测教师网络的中间 隐藏
层，并非预测最终分类目标。学生网络的低层因而具有两个目标：帮助学生网络的
输出完成其目标和预测教师网络的中间层。尽管一个窄而深的网络似乎比宽而浅的
网络更难训练，但窄而深网络的泛化能力可能更好，并且如果其足够窄，参数足够
少，那么其计算代价更小。没有 隐藏层的提示，学生网络在 训练集和测试集上的实
验表现都很差。因而中间层的提示是有助于训练很难训练的网络的方法之一，但是
其他优化技术或是架构上的变化也可能解决这个问题。
8.7.5设计有助于优化的模型
改进优化的最好方法并不总是改进优化算法。相反， 深度模型 中优化的许多改
进来自于设计易于优化的模型。
原则上，我们可以使用呈锯齿非单调模式上上下下的 激活函数 ，但是，这将使
优化极为困难。在实践中， 选择一族容易优化的模型比使用一个强大的优化算法更
重要。神经网络 学习在过去 30年的大多数进步主要来自于改变模型族，而非改变优
化过程。 1980年代用于训练 神经网络 的带动量的随机梯度下降 ，仍然是现代 神经网
络应用中的前沿算法。
具体来说，现代 神经网络 的设计选择 体现在层之间的线性变换，几乎处处可导DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.7优化策略和元算法 277
的激活函数 ，和大部分定义域都有明显的梯度。特别地，创新的模型，如 LSTM，整
流线性单元 和maxout单元都比先前的模型（如基于 sigmoid单元的深度网络 ）使用
更多的线性函数。这些模型都具有简化优化的性质。如果线性变换的 Jacobian 具有
相对合理的奇异值，那么梯度能够流经很多层。此外，线性函数在一个方向上一致
增加，所以即使模型的输出远离正确值，也可以简单清晰地计算梯度，使其输出方
向朝降低 损失函数 的方向移动。换言之，现代 神经网络 的设计方案旨在使其 局部梯
度信息合理地对应着移向一个遥远的解。
其他的模型设计策略有助于使优化更简单。例如，层之间的线性路径或是跳
跃连接减少了从较低层参数到输出最短路径的长度，因而缓解了梯度消失的问题
(Srivastava et al. ,2015)。一个和跳跃连接相关的想法是添加和网络中间 隐藏层相
连的输出的额外副本，如 GoogLeNet ( Szegedy et al. ,2014a )和深度监督网络 (Lee
et al. ,2014)。这些 ‘‘辅助头 ’’被训练来执行和网络顶层主要输出相同的任务，以确
保底层网络能够接受较大的梯度。当训练完成时，辅助头可能被丢弃。这是之前小
节介绍到的 预训练策略的替代方法。以这种方式，我们可以在一个阶段联合训练所
有层，而不改变架构，使得中间层（特别是低层）能够通过更短的路径得到一些有
些如何更新的有用信息。这些信息为底层提供了误差信号。
8.7.6延拓法和课程学习
正如第 8.2.7节探讨的，许多优化挑战都来自于 代价函数 的全局结构，不能仅通
过局部更新方向上更好的估计来解决。解决这个问题的主要方法是尝试初始化参数
到某种区域内，该区域可以通过局部下降很快连接到参数空间中的解。
延拓法（continuation method ）是一族通过挑选初始点使优化更容易的方法，
以确保局部优化花费大部分时间在表现良好的空间。 延拓法的背后想法是构造一系
列具有相同参数的 目标函数 。为了最小化 代价函数 J()，我们构建新的 代价函数
fJ(0); : : : ; J(n)g。这些代价函数 的难度逐步提高，其中 J(0)是最容易最小化的， J(n)
是最难的，真正的 代价函数 驱动整个过程。当我们说 J(i)比J(i+1)更容易时，是指
其在更多的空间上表现良好。随机初始化更有可能落入局部下降可以成功最小
化代价函数 的区域，因为其良好区域更大。这系列 代价函数 设计为前一个解是下一
个的良好初始点。因此，我们首先解决一个简单的问题，然后改进解以解决逐步变
难的问题，直到我们求解真正问题的解。
传统的延拓法（用于神经网络 训练之前的 延拓法）通常基于平滑 目标函数 。读DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
278 第八章 深度模型中的优化
者可以查看 Wu(1997)了解这类方法的示例，以及一些相关方法的综述。 延拓法也
和参数中加入 噪声的模拟退火紧密相关 (Kirkpatrick et al. ,1983)。延拓法在最近几
年非常成功。参考 Mobahi and Fisher (2015)了解近期文献的概述，特别是在 AI方
面的应用。
传统上， 延拓法主要用来克服 局部极小值 的问题。具体地，它被设计来在有很
多局部极小值 的情况下，求解一个 全局最小点 。这些连续方法会通过 ‘‘模糊’’原来
的代价函数 来构建更容易的 代价函数 。这些模糊操作可以是用采样来近似
J(i)() =E′N(′;;(i)2)J(′) (8.40)
这个方法的直觉是有些 非凸函数在模糊后会近似凸的。在许多情况下，这种模糊保
留了关于全局极小值的足够信息，我们可以通过逐步求解模糊更少的问题来求解全
局极小值。这种方法有三种可能失败的方式。首先，它可能成功地定义了一连串 代
价函数，并从开始的一个凸函数起（逐一地）沿着函数链最佳轨迹逼近全局最小值，
但可能需要非常多的逐步 代价函数 ，整个过程的成本仍然很高。另外，即使 延拓法可
以适用， NP-hard 的优化问题仍然是 NP-hard 。其他两种 延拓法失败的原因是不实
用。其一，不管如何模糊，函数都没法变成凸的，比如函数 J() = ⊤。其二，函
数可能在模糊后是凸的，但模糊函数的最小值可能会追踪到一个局部最小值，而非
原始代价函数 的全局最小值。
尽管延拓法最初用来解决局部最小值的问题，而局部最小值已不再认为是 神经
网络优化中的主要问题了。幸运的是， 延拓法仍然有所帮助。 延拓法引入的简化 目
标函数能够消除平坦区域，减少梯度估计的方差，提高 Hessian矩阵的条件数，使局
部更新更容易计算，或是改进局部更新方向与朝向全局解方向之间的对应关系。
Bengio et al. (2009)指出被称为 课程学习 （curriculum learning ）或者塑造
（shaping）的方法可以被解释为 延拓法。课程学习 基于规划学习过程的想法，首先
学习简单的概念，然后逐步学习依赖于这些简化概念的复杂概念。之前这一基本
策略被用来加速动物训练过程 (Skinner ,1958;Peterson ,2004;Krueger and Dayan ,
2009)和机器学习 过程 (Solomonoﬀ ,1989;Elman ,1993;Sanger ,1994)。Bengio et al.
(2009)验证这一策略为 延拓法，通过增加简单样本的影响（通过分配它们较大的系
数到代价函数 ，或者更频繁地采样） ，先前的 J(i)会变得更容易。实验证明，在大
规模的神经语言模型任务上使用 课程学习 ，可以获得更好的结果。课程学习已经成
功应用于大量的自然语言 (Spitkovsky et al. ,2010;Collobert et al. ,2011a ;Mikolov
et al. ,2011b ;Tu and Honavar ,2011)和计算机视觉 (Kumar et al. ,2010;Lee andDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
8.7优化策略和元算法 279
Grauman ,2011;Supancic and Ramanan ,2013)任务上。 课程学习 被证实为与人类
教学方式一致 (Khan et al. ,2011)：教师刚开始会展示更容易、更典型的示例，然
后帮助学习者在不太显然的情况下提炼决策面。在人类教学上，基于 课程学习 的
策略比基于样本均匀采样的策略 更有效，也能提高其他学习策略的效率 (Basu and
Christensen ,2013)。
课程学习 研究的另一个重要贡献体现在训练循环 神经网络 捕获长期依赖：
Zaremba and Sutskever (2014)发现使用 随机课程 获得了更好的结果，其中容易和困
难的示例混合在一起，随机提供给学习者，更难示例（这些具有长期依赖）的平均
比例在逐渐上升。具有确定性课程，没有发现超过基线（完整 训练集的普通训练）的
改进。
现在我们已经介绍了一些基本的 神经网络 模型，以及如何进行正则化和优化。
在接下来的章节中，我们转向特化的 神经网络 家族，允许其扩展到能够处理很大规
模的数据和具有特殊结构的数据。在本章中讨论的优化算法在较少改动后或者无需
改动，通常就可以直接用于这些特化的架构。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第九章 卷积网络
卷积网络 （convolutional network ）(LeCun ,1989)，也叫做 卷积神经网络 （con-
volutional neural network ,CNN） ，是一种专门用来处理具有类似网格结构的数据的
神经网络。例如时间序列数据（可以认为是在时间轴上有规律地采样形成的一维网
格）和图像数据（可以看作是二维的像素网格） 。 卷积网络 在诸多应用领域都表现优
异。“卷积神经网络 ’’一词表明该网络使用了 卷积（convolution ）这种数学运算。卷
积是一种特殊的线性运算。 卷积网络 是指那些至少在网络的一层中使用卷积运算来
替代一般的矩阵乘法运算的神经网络。
本章，我们首先说明什么是卷积运算。接着，我们会解释在神经网络中使用卷
积运算的动机。然后我们会介绍 池化（pooling） ，这是一种几乎所有的 卷积网络 都会
用到的操作。通常来说， 卷积神经网络 中用到的卷积运算和其他领域（例如工程领
域以及纯数学领域）中的定义并不完全一致。我们会对神经网络实践中广泛应用的
几种卷积函数的变体进行说明。我们也会说明如何在多种不同维数的数据上使用卷
积运算。之后我们讨论使得卷积运算更加高效的一些方法。 卷积网络 是神经科学原
理影响深度学习的典型代表。我们之后也会讨论这些神经科学的原理，并对 卷积网
络在深度学习发展史中的作用作出评价。本章没有涉及如何为你的 卷积网络 选择合
适的结构，因为本章的目标是说明 卷积网络 提供的各种工具。第 十一章将会对如何
在具体环境中选择使用相应的工具给出通用的准则。对于 卷积网络 结构的研究进展
得如此迅速，以至于针对特定基准 (benchmark) ，数月甚至几周就会公开一个新的
最优的网络结构，甚至在写这本书时也不好描述究竟哪种结构是最好的。然而，最
好的结构也是由本章所描述的基本部件逐步搭建起来的。
280DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.1卷积运算 281
9.1卷积运算
在通常形式中，卷积是对两个实变函数的一种数学运算1。为了给出卷积的定义，
我们从两个可能会用到的函数的例子出发。
假设我们正在用激光传感器追踪一艘宇宙飞船的位置。我们的激光传感器给出
一个单独的输出 x(t)，表示宇宙飞船在时刻 t的位置。 x和t都是实值的，这意味
着我们可以在任意时刻从传感器中读出飞船的位置。
现在假设我们的传感器受到一定程度的噪声干扰。为了得到飞船位置的低噪声
估计，我们对得到的测量结果进行平均。显然，时间上越近的测量结果越相关，所
以我们采用一种加权平均的方法，对于最近的测量结果赋予更高的权重。我们可以
采用一个加权函数 w(a)来实现，其中 a表示测量结果距当前时刻的时间间隔。如果
我们对任意时刻都采用这种加权平均的操作，就得到了一个新的对于飞船位置的平
滑估计函数 s：
s(t) =∫
x(a)w(t a)da: (9.1)
这种运算就叫做 卷积（convolution ） 。卷积运算通常用星号表示：
s(t) = (xw)(t): (9.2)
在我们的例子中， w必须是一个有效的概率密度函数，否则输出就不再是一个
加权平均。另外，在参数为负值时， w的取值必须为 0，否则它会预测到未来，这不
是我们能够推测得了的。但这些限制仅仅是对我们这个例子来说。通常，卷积被定
义在满足上述积分式的任意函数上，并且也可能被用于加权平均以外的目的。
在卷积网络 的术语中，卷积的第一个参数（在这个例子中，函数 x）通常叫做 输
入（input） ，第二个参数（函数 w）叫做核函数（kernel function ） 。输出有时被称
作特征映射 （feature map ） 。
在本例中，激光传感器在每个瞬间反馈测量结果的想法是不切实际的。一般地，
当我们用计算机处理数据时，时间会被离散化，传感器会定期地反馈数据。所以在我
们的例子中，假设传感器每秒反馈一次测量结果是比较现实的。这样，时刻 t只能取
整数值。如果我们假设 x和w都定义在整数时刻 t上，就可以定义离散形式的卷积：
s(t) = (xw)(t) =1∑
a= 1x(a)w(t a): (9.3)
1译者注：本书中 operation 视语境有时翻译成 ‘‘运算’’，有时翻译成 ‘‘操作’’。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
282 第九章 卷积网络
在机器学习的应用中，输入通常是多维数组的数据，而核通常是由学习算法优
化得到的多维数组的参数。我们把这些多维数组叫做张量。因为在输入与核中的每
一个元素都必须明确地分开存储，我们通常假设在存储了数值的有限点集以外，这
些函数的值都为零。这意味着在实际操作中，我们可以通过对有限个数组元素的求
和来实现无限求和。
最后，我们经常一次在多个维度上进行卷积运算。例如，如果把一张二维的图
像I作为输入，我们也许也想要使用一个二维的核 K：
S(i; j) = (IK)(i; j) =∑
m∑
nI(m; n)K(i m; j n): (9.4)
卷积是可交换的 (commutative) ，我们可以等价地写作：
S(i; j) = (KI)(i; j) =∑
m∑
nI(i m; j n)K(m; n): (9.5)
通常，下面的公式在机器学习库中实现更为简单，因为 m和n的有效取值范围
相对较小。
卷积运算可交换性的出现是因为我们将核相对输入进行了 翻转（ﬂip） ，从 m增
大的角度来看，输入的索引在增大，但是核的索引在减小。我们将核翻转的唯一目
的是实现可交换性。尽管可交换性在证明时很有用，但在神经网络的应用中却不是
一个重要的性质。与之不同的是，许多神经网络库会实现一个相关的函数，称为 互
相关函数 （cross-correlation ） ，和卷积运算几乎一样但是并没有对核进行翻转：
S(i; j) = (IK)(i; j) =∑
m∑
nI(i+m; j +n)K(m; n): (9.6)
许多机器学习的库实现的是互相关函数但是称之为卷积。在这本书中我们遵循把两
种运算都叫做卷积的这个传统，在与核翻转有关的上下文中，我们会特别指明是否
对核进行了翻转。在机器学习中，学习算法会在核合适的位置学得恰当的值，所以一
个基于核翻转的卷积运算的学习算法所学得的核，是对未进行翻转的算法学得的核
的翻转。单独使用卷积运算在机器学习中是很少见的，卷积经常与其他的函数一起
使用，无论卷积运算是否对它的核进行了翻转，这些函数的组合通常是不可交换的。
图9.1演示了一个在 2维张量上的卷积运算（没有对核进行翻转）的例子。
离散卷积可以看作矩阵的乘法，然而，这个矩阵的一些元素被限制为必须和另外
一些元素相等。例如对于单变量的离散卷积，矩阵每一行中的元素都与上一行对应DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.1卷积运算 283
abcdefghijklwxyz
aw+bx+ey+fzaw+bx+ey+fzbw+cx+fy+gzbw+cx+fy+gzcw+dx+gy+hzcw+dx+gy+hzew+fx+iy+jzew+fx+iy+jzfw+gx+jy+kzfw+gx+jy+kzgw+hx+ky+lzgw+hx+ky+lzInputKernel
Output
图9.1:一个 2维卷积的例子（没有对核进行翻转） 。我们限制只对核完全处在图像中的位置进行
输出，在一些上下文中称为 “有效’’卷积。我们用画有箭头的盒子来说明输出张量的左上角元素是
如何通过对输入张量相应的左上角区域应用核进行卷积得到的。
位置平移一个单位的元素相同。这种矩阵叫做 Toeplitz 矩阵（Toeplitz matrix ） 。对
于二维情况，卷积对应着一个 双重分块循环矩阵 （doubly block circulant matrix ） 。
除了这些元素相等的限制以外，卷积通常对应着一个非常稀疏的矩阵（一个几乎所
有元素都为零的矩阵） 。这是因为核的大小通常要远小于输入图像的大小。任何一个
使用矩阵乘法但是并不依赖矩阵结构的特殊性质的神经网络算法，都适用于卷积运
算，并且不需要对神经网络做出大的修改。典型的 卷积神经网络 为了更有效地处理
大规模输入，确实使用了一些专门化的技巧，但这些在理论分析方面并不是严格必
要的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
284 第九章 卷积网络
9.2动机
卷积运算通过三个重要的思想来帮助改进机器学习系统： 稀疏交互 （sparse
interactions ） 、参数共享 （parameter sharing ） 、等变表示 （equivariant representa-
tions） 。另外，卷积提供了一种处理大小可变的输入的方法。我们下面依次介绍这些
思想。
传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩
阵中每一个单独的参数都描述了一个输入单元与一个输出单元间的交互。这意
味着每一个输出单元与每一个输入单元都产生交互。然而， 卷积网络 具有稀疏交
互（sparse interactions ）（也叫做 稀疏连接 （sparse connectivity ）或者稀疏权重
（sparse weights ） ）的特征。这是使核的大小远小于输入的大小来达到的。举个例子，
当处理一张图像时，输入的图像可能包含成千上万个像素点，但是我们可以通过只
占用几十到上百个像素点的核来检测一些小的有意义的特征，例如图像的边缘。这
意味着我们需要存储的参数更少，不仅减少了模型的存储需求，而且提高了它的统
计效率。这也意味着为了得到输出我们只需要更少的计算量。这些效率上的提高往
往是很显著的。如果有 m个输入和 n个输出，那么矩阵乘法需要 mn个参数并
且相应算法的时间复杂度为 O(mn)（对于每一个例子） 。如果我们限制每一个输
出拥有的连接数为 k，那么稀疏的连接方法只需要 kn个参数以及 O(kn)的运
行时间。在很多实际应用中，只需保持 k比m小几个数量级，就能在机器学习的
任务中取得好的表现。 稀疏连接 的图形化解释如图 9.2和图 9.3所示。在深度 卷积网
络中，处在网络深层的单元可能与绝大部分输入是 间接交互的，如图 9.4所示。这允
许网络可以通过只描述 稀疏交互 的基石来高效地描述多个变量的复杂交互。
参数共享 （parameter sharing ）是指在一个模型的多个函数中使用相同的参数。
在传统的神经网络中，当计算一层的输出时，权重矩阵的每一个元素只使用一次，当
它乘以输入的一个元素后就再也不会用到了。作为 参数共享 的同义词，我们可以说
一个网络含有 绑定的权重 （tied weights ） ，因为用于一个输入的权重也会被绑定在
其他的权重上。在 卷积神经网络 中，核的每一个元素都作用在输入的每一位置上（是
否考虑边界像素取决于对边界决策的设计） 。卷积运算中的 参数共享 保证了我们只需
要学习一个参数集合，而不是对于每一位置都需要学习一个单独的参数集合。这虽
然没有改变 前向传播 的运行时间（仍然是 O(kn)） ，但它显著地把模型的存储需求
降低至 k个参数，并且 k通常要比 m小很多个数量级。因为 m和n通常有着大致
相同的大小， k在实际中相对于 mn是很小的。因此，卷积在存储需求和统计效DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.2动机 285
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
图9.2:稀疏连接 ，对每幅图从下往上看。我们强调了一个输入单元 x3以及在 s中受该单元影响
的输出单元。 (上)当 s是由核宽度为 3的卷积产生时，只有三个输出受到 x的影响2。(下)当 s
是由矩阵乘法产生时，连接不再是稀疏的，所以所有的输出都会受到 x3的影响。
率方面极大地优于稠密矩阵的乘法运算。图 9.5演示了参数共享 是如何实现的。
作为前两条原则的一个实际例子，图 9.6说明了稀疏连接 和参数共享 是如何显著
提高线性函数在一张图像上进行边缘检测的效率的。
对于卷积， 参数共享 的特殊形式使得神经网络层具有对平移 等变（equivariance ）
的性质。如果一个函数满足输入改变，输出也以同样的方式改变这一性质，我们就说
它是等变 (equivariant) 的。特别地，如果函数 f(x)与g(x)满足 f(g(x)) =g(f(x))，
我们就说 f(x)对于变换 g具有等变性。对于卷积来说，如果令 g是输入的任意平
移函数，那么卷积函数对于 g具有等变性。举个例子，令 I表示图像在整数坐标上
的亮度函数， g表示图像函数的变换函数（把一个图像函数映射到另一个图像函数
的函数）使得 I′=g(I)，其中图像函数 I′满足 I′(x; y) =I(x 1; y)。这个函数把 I
中的每个像素向右移动一个单位。如果我们先对 I进行这种变换然后进行卷积操作
所得到的结果，与先对 I进行卷积然后再对输出使用平移函数 g得到的结果是一样
的4。当处理时间序列数据时，这意味着通过卷积可以得到一个由输入中出现不同特
4译者注：原文将此处误写成了 I′。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
286 第九章 卷积网络
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
图9.3:稀疏连接 ，对每幅图从上往下看。我们强调了一个输出单元 s3以及 x中影响该单元的输
入单元。这些单元被称为 s3的接受域（receptive ﬁeld ）3。(上)当 s是由核宽度为 3的卷积产生
时，只有三个输入影响 s3。(下)当 s是由矩阵乘法产生时，连接不再是稀疏的，所以所有的输入
都会影响 s3。
x1x1x2x2x3x3h2h2h1h1h3h3x4x4h4h4x5x5h5h5g2g2g1g1g3g3g4g4g5g5
图9.4:处于卷积网络 更深的层中的单元，它们的 接受域要比处在浅层的单元的 接受域更大。如果
网络还包含类似 步幅卷积（图 9.12）或者池化（第 9.3节）之类的结构特征，这种效应会加强。这
意味着在 卷积网络 中尽管直接连接都是很稀疏的，但处在更深的层中的单元可以 间接地连接到全
部或者大部分输入图像。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.2动机 287
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
x1x1x2x2x3x3x4x4x5x5s2s2s1s1s3s3s4s4s5s5
图9.5:参数共享 。黑色箭头表示在两个不同的模型中使用了特殊参数的连接。 (上)黑色箭头表示
在卷积模型中对 3元素核的中间元素的使用。因为 参数共享 ，这个单独的参数被用于所有的输入
位置。 (下)这个单独的黑色箭头表示在全连接模型中对权重矩阵的中间元素的使用。这个模型没
有使用参数共享 ，所以参数只使用了一次。
征的时刻所组成的时间轴。如果我们把输入中的一个事件向后延时，在输出中仍然
会有完全相同的表示，只是时间延后了。图像与之类似，卷积产生了一个 2维映射
来表明某些特征在输入中出现的位置。如果我们移动输入中的对象，它的表示也会
在输出中移动同样的量。当处理多个输入位置时，一些作用在邻居像素的函数是很
有用的。例如在处理图像时，在 卷积网络 的第一层进行图像的边缘检测是很有用的。
相同的边缘或多或少地散落在图像的各处，所以应当对整个图像进行 参数共享 。但
在某些情况下，我们并不希望对整幅图进行 参数共享 。例如，在处理已经通过剪裁
而使其居中的人脸图像时，我们可能想要提取不同位置上的不同特征（处理人脸上
部的部分网络需要去搜寻眉毛，处理人脸下部的部分网络就需要去搜寻下巴了） 。
卷积对其他的一些变换并不是天然等变的，例如对于图像的放缩或者旋转变换，
需要其他的一些机制来处理这些变换。
最后，一些不能被传统的由（固定大小的）矩阵乘法定义的神经网络处理的特
殊数据，可能通过卷积神经网络来处理，我们将在第 9.7节中进行讨论。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
288 第九章 卷积网络
图9.6:边缘检测的效率。右边的图像是通过先获得原始图像中的每个像素，然后减去左边相邻像
素的值而形成的。这个操作给出了输入图像中所有垂直方向上的边缘的强度，对目标检测来说是有
用的。两个图像的高度均为 280个像素。输入图像的宽度为 320个像素，而输出图像的宽度为 319
个像素。这个变换可以通过包含两个元素的卷积核来描述，使用卷积需要 3192803 = 267 ;960
次浮点运算（每个输出像素需要两次乘法和一次加法） 。为了用矩阵乘法描述相同的变换，需要一
个包含 320280319280个或者说超过 80亿个元素的矩阵，这使得卷积对于表示这种变换
更有效 40亿倍。直接运行矩阵乘法的算法将执行超过 160亿次浮点运算，这使得卷积在计算上大
约有 60,000倍的效率。当然，矩阵的大多数元素将为零。如果我们只存储矩阵的非零元，则矩阵
乘法和卷积都需要相同数量的浮点运算来计算。矩阵仍然需要包含 2319280 = 178 ;640个元
素。将小的局部区域上的相同线性变换应用到整个输入上，卷积是描述这种变换的极其有效的方
法。照片来源： Paula Goodfellow 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.3池化 289
9.3池化
卷积网络 中一个典型层包含三级（如图 9.7所示） 。在第一级中，这一层并行地计
算多个卷积产生一组线性激活响应。在第二级中，每一个线性激活响应将会通过一个
非线性的激活函数，例如 整流线性 激活函数。这一级有时也被称为 探测级（detector
stage） 。在第三级中，我们使用 池化函数 （pooling function ）来进一步调整这一层
的输出。
Convolutional Layer
Input to layerConvolution stage:Aﬃne transformDetector stage:Nonlinearitye.g., rectiﬁed linearPooling stageNext layer
Input to layersConvolution layer:Aﬃne transform Detector layer: Nonlinearitye.g., rectiﬁed linearPooling layerNext layerComplex layer terminologySimple layer terminology
图9.7:一个典型 卷积神经网络 层的组件。有两组常用的术语用于描述这些层。 (左)在这组术语中，
卷积网络 被视为少量相对复杂的层，每层具有许多 ‘‘级’’。在这组术语中，核张量与网络层之间存
在一一对应关系。在本书中，我们通常使用这组术语。 (右)在这组术语中， 卷积网络 被视为更多
数量的简单层；每一个处理步骤都被认为是一个独立的层。这意味着不是每一 ‘‘层’’都有参数。
池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。
例如，最大池化 （max pooling ）函数 (Zhou and Chellappa ,1988)给出相邻矩形区
域内的最大值。其他常用的 池化函数包括相邻矩形区域内的平均值、 L2范数以及基
于据中心像素距离的加权平均函数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
290 第九章 卷积网络
不管采用什么样的 池化函数，当输入作出少量平移时， 池化能够帮助输入的表
示近似不变（invariant ） 。对于平移的不变性是指当我们对输入进行少量平移时，经
过池化函数后的大多数输出并不会发生改变。图 9.8用了一个例子来说明这是如何实
现的。局部平移不变性是一个很有用的性质，尤其是当我们关心某个特征是否出现
而不关心它出现的具体位置时 。例如，当判定一张图像中是否包含人脸时，我们并
不需要知道眼睛的精确像素位置，我们只需要知道有一只眼睛在脸的左边，有一只
在右边就行了。但在一些其他领域，保存特征的具体位置却很重要。例如当我们想
要寻找一个由两条边相交而成的拐角时，我们就需要很好地保存边的位置来判定它
们是否相交。
0.11.0.21.1.1.0.10.2............
0.30.11.1.0.31.0.21.............DETECTOR STAGEPOOLING STAGE
POOLING STAGE
DETECTOR STAGE
图9.8:最大池化 引入了不变性。 (上)卷积层中间输出的视图。下面一行显示非线性的输出。上面
一行显示 最大池化 的输出，每个 池的宽度为三个像素并且 池化区域的步幅为一个像素。 (下)相同
网络的视图，不过对输入右移了一个像素。下面一行的所有值都发生了改变，但上面一行只有一
半的值发生了改变，这是因为 最大池化 单元只对周围的最大值比较敏感，而不是对精确的位置。
使用池化可以看作是增加了一个无限强的先验：这一层学得的函数必须具有对
少量平移的不变性。当这个假设成立时， 池化可以极大地提高网络的统计效率。
对空间区域进行 池化产生了平移不变性，但当我们对分离参数的卷积的输出进
行池化时，特征能够学得应该对于哪种变换具有不变性（如图 9.9所示） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.3池化 291
Large responsein pooling unitLarge responsein pooling unitLargeresponsein detectorunit 1Largeresponsein detectorunit 3
图9.9:学习不变性的示例。使用分离的参数学得多个特征，再使用 池化单元进行 池化，可以学得
对输入的某些变换的不变性。这里我们展示了用三个学得的过滤器和一个 最大池化 单元可以学得
对旋转变换的不变性。这三个过滤器都旨在检测手写的数字 5。每个过滤器尝试匹配稍微不同方向
的5。当输入中出现 5时，相应的过滤器会匹配它并且在探测单元中引起大的激活。然后，无论哪
个探测单元被激活， 最大池化 单元都具有大的激活。我们在这里演示了网络如何处理两个不同的输
入，这导致两个不同的探测单元被激活，然而对 池化单元的影响大致相同。这个原则在 maxout网
络(Goodfellow et al. ,2013b )和其他卷积网络中更有影响。空间位置上的 最大池化 对于平移是天
然不变的；这种多通道方法只在学习其他变换时是必要的。
因为池化综合了全部邻居的反馈，这使得 池化单元少于探测单元成为可能，我
们可以通过综合 池化区域的 k个像素的统计特征而不是单个像素来实现。图 9.10给
出了一个例子。这种方法提高了网络的计算效率，因为下一层少了约 k倍的输入。
当下一层的参数数目是关于那一层输入大小的函数时（例如当下一层是全连接的基
于矩阵乘法的网络层时） ，这种对于输入规模的减小也可以提高统计效率并且减少对
于参数的存储需求。
在很多任务中， 池化对于处理不同大小的输入具有重要作用。例如我们想对不
同大小的图像进行分类时，分类层的输入必须是固定的大小，而这通常通过调整 池
化区域的偏置大小来实现，这样分类层总是能接收到相同数量的统计特征而不管最
初的输入大小了。例如，最终的 池化层可能会输出四组综合统计特征，每组对应着
图像的一个象限，而与图像的大小无关。
一些理论工作对于在不同情况下应当使用哪种 池化函数给出了一些指导
(Boureau et al. ,2010)。将特征一起动态地 池化也是可行的，例如，对于感兴趣DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
292 第九章 卷积网络
0.11.0.21.0.20.10.10.00.1
图9.10:带有降采样的池化。这里我们使用 最大池化 ，池的宽度为三并且 池之间的步幅为二。这使
得表示的大小减少了一半，减轻了下一层的计算和统计负担。注意到最右边的 池化区域尺寸较小，
但如果我们不想忽略一些探测单元的话就必须包含这个区域。
特征的位置运行聚类算法 (Boureau et al. ,2011)。这种方法对于每幅图像产生一个
不同的池化区域集合。另一种方法是先 学习一个单独的 池化结构，再应用到全部的
图像中 (Jiaet al. ,2012)。
池化可能会使得一些利用自顶向下信息的神经网络结构变得复杂，例如 玻尔兹
曼机和自编码器 。这些问题将在第 三章中当我们遇到这些类型的网络时进一步讨论。
卷积玻尔兹曼机 中的池化出现在第 20.6节。一些可微网络中需要的在 池化单元上进
行的类逆运算将在第 20.10.6节中讨论。
图9.11给出了一些使用卷积和 池化操作的用于分类的完整 卷积网络 结构的例子。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.3池化 293
Input image: 256x256x3Output of convolution + ReLU: 256x256x64Output of pooling with stride 4: 64x64x64Output of convolution + ReLU: 64x64x64Output of pooling with stride 4: 16x16x64Output of reshape to vector:16,384 unitsOutput of matrix multiply: 1,000 unitsOutput of softmax: 1,000 class probabilities
Input image: 256x256x3Output of convolution + ReLU: 256x256x64Output of pooling with stride 4: 64x64x64Output of convolution + ReLU: 64x64x64Output of pooling to 3x3 grid: 3x3x64Output of reshape to vector:576 unitsOutput of matrix multiply: 1,000 unitsOutput of softmax: 1,000 class probabilities
Input image: 256x256x3Output of convolution + ReLU: 256x256x64Output of pooling with stride 4: 64x64x64Output of convolution + ReLU: 64x64x64Output of convolution:16x16x1,000Output of average pooling: 1x1x1,000Output of softmax: 1,000 class probabilities
Output of pooling with stride 4: 16x16x64
图9.11:卷积网络 用于分类的结构示例。本图中使用的具体 步幅和深度并不建议实际使用；它们
被设计得非常浅以适合页面。实际的 卷积网络 还常常涉及大量的分支，不同于这里为简单起见所
使用的链式结构。 (左)处理固定大小的图像的 卷积网络 。在卷积层和 池化层几层交替之后，卷积
特征映射的张量被重新变形以展平空间维度。网络的其余部分是一个普通的前馈网络分类器，如
第六章所述。 (中)处理大小可变的图像的 卷积网络 ，但仍保持全连接的部分。该网络使用具有可
变大小但是数量固定的 池的池化操作，以便向网络的全连接部分提供固定 576个单位大小的向量。
(右)没有任何全连接权重层的 卷积网络 。相对的，最后的卷积层为每个类输出一个特征映射。该
模型可能会用来学习每个类出现在每个空间位置的可能性的映射。将特征映射进行平均得到的单
个值，提供了顶部 softmax 分类器的变量。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
294 第九章 卷积网络
9.4卷积与池化作为一种无限强的先验
回忆一下第 5.2节中先验概率分布 （prior probability distribution ）的概念。这
是一个模型参数的概率分布，它刻画了在我们看到数据之前我们认为什么样的模型
是合理的信念。
先验被认为是强或者弱取决于先验中概率密度的集中程度。弱先验具有较高的
熵值，例如方差很大的 高斯分布 。这样的先验允许数据对于参数的改变具有或多或
少的自由性。强先验具有较低的熵值，例如方差很小的 高斯分布 。这样的先验在决
定参数最终取值时起着更加积极的作用。
一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值，
无论数据对于这些参数的值给出了多大的支持。
我们可以把 卷积网络 类比成全连接网络，但对于这个全连接网络的权重有一个
无限强的先验。这个无限强的先验是说一个 隐藏单元 的权重必须和它邻居的权重相
同，但可以在空间上移动。这个先验也要求除了那些处在 隐藏单元 的小的空间连续
的接受域内的权重以外，其余的权重都为零。总之，我们可以把卷积的使用当作是
对网络中一层的参数引入了一个无限强的 先验概率分布 。这个先验说明了该层应该
学得的函数只包含局部连接关系并且对平移具有等变性。类似的，使用 池化也是一
个无限强的先验：每一个单元都具有对少量平移的不变性。
当然，把 卷积神经网络 当作一个具有无限强先验的全连接网络来实现会导致极
大的计算浪费。但把 卷积神经网络 想成具有无限强先验的全连接网络可以帮助我们
更好地洞察 卷积神经网络 是如何工作的。
其中一个关键的洞察是卷积和 池化可能导致 欠拟合。与任何其他先验类似，卷
积和池化只有当先验的假设合理且正确时才有用。如果一项任务依赖于保存精确
的空间信息，那么在所有的特征上使用 池化将会增大训练误差。一些 卷积网络 结
构(Szegedy et al. ,2014a )为了既获得具有较高不变性的特征又获得当平移不变性不
合理时不会导致 欠拟合的特征，被设计成在一些通道上使用 池化而在另一些通道上
不使用。当一项任务涉及到要对输入中相隔较远的信息进行合并时，那么卷积所利
用的先验可能就不正确了。
另一个关键洞察是当我们比较卷积模型的统计学习表现时，只能以基准中的其
他卷积模型作为比较的对象。其他不使用卷积的模型即使我们把图像中的所有像素
点都置换后依然有可能进行学习。对于许多图像数据集，还有一些分别的基准，有DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.5基本卷积函数的变体 295
些是针对那些具有 置换不变性 （permutation invariant ）并且必须通过学习发现拓
扑结构的模型，还有一些是针对模型设计者将空间关系的知识植入了它们的模型。
9.5基本卷积函数的变体
当在神经网络的上下文中讨论卷积时，我们通常不是特指数学文献中使用的那
种标准的离散卷积运算。实际应用中的函数略有不同。这里我们详细讨论一下这些
差异，并且对神经网络中用到的函数的一些重要性质进行重点说明。
首先，当我们提到神经网络中的卷积时，我们通常是指由多个并行卷积组成的
运算。这是因为具有单个核的卷积只能提取一种类型的特征，尽管它作用在多个空
间位置上。我们通常希望网络的每一层能够在多个位置提取多种类型的特征。
另外，输入通常也不仅仅是实值的网格，而是由一系列观测数据的向量构成的
网格。例如，一幅彩色图像在每一个像素点都会有红绿蓝三种颜色的亮度。在多层
的卷积网络 中，第二层的输入是第一层的输出，通常在每个位置包含多个不同卷积
的输出。当处理图像时，我们通常把卷积的输入输出都看作是 3维的张量，其中一
个索引用于标明不同的通道（例如红绿蓝） ，另外两个索引标明在每个通道上的空间
坐标。软件实现通常使用批处理模式，所以实际上会使用 4维的张量，第四维索引
用于标明批处理中不同的实例，但我们为简明起见这里忽略批处理索引。
因为卷积网络 通常使用多通道的卷积，所以即使使用了核翻转，也不一定保证
网络的线性运算是可交换的。只有当其中的每个运算的输出和输入具有相同的通道
数时，这些多通道的运算才是可交换的。 。
假定我们有一个 4维的核张量 K，它的每一个元素是 Ki;j;k;l，表示输出中处于
通道 i的一个单元和输入中处于通道 j中的一个单元的连接强度，并且在输出单元
和输入单元之间有 k行l列的偏置。假定我们的输入由观测数据 V组成，它的每一
个元素是 Vi;j;k，表示处在通道 i中第 j行第 k列的值。假定我们的输出 Z和输入
V具有相同的形式。如果输出 Z是通过对 K和V进行卷积而不涉及翻转 K得到
的，那么
Zi;j;k=∑
l;m;nVl;j+m 1;k+n 1Ki;l;m;n ; (9.7)
这里对所有的 l，m和n进行求和是对所有（在求和式中）有效的张量索引的值进
行求和。在线性代数中，向量的索引通常从 1开始，这就是上述公式中  1的由来。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
296 第九章 卷积网络
但是像 C或Python这类编程语言索引通常从 0开始，这使得上述公式可以更加简
洁。
我们有时会希望跳过核中的一些位置来降低计算的开销（相应的代价是提取
特征没有先前那么好了） 。我们可以把这一过程看作是对全卷积函数输出的下采样
(downsampling) 。如果我们只想在输出的每个方向上每间隔 s个像素进行采样，那
么我们可以定义一个下采样卷积函数 c使得
Zi;j;k=c(K;V; s)i;j;k=∑
l;m;n[Vl;(j 1)s+m;(k 1)s+n;Ki;l;m;n ]: (9.8)
我们把 s称为下采样卷积的 步幅（stride） 。当然也可以对每个移动方向定义不同的
步幅。图 9.12演示了一个实例。
在任何卷积网络 的实现中都有一个重要性质，那就是能够隐含地对输入 V用零
进行填充 (pad)使得它加宽。如果没有这个性质， 表示的宽度在每一层就会缩减，缩
减的幅度是比核少一个像素这么多。对输入进行零填充允许我们对核的宽度和输出
的大小进行独立的控制。如果没有零填充，我们就被迫面临二选一的局面，要么选
择网络空间宽度的快速缩减，要么选择一个小型的核——这两种情境都会极大得限
制网络的表示能力。图 9.13给出了一个例子。
有三种零填充设定的情况值得注意。第一种是无论怎样都不使用零填充的极端
情况，并且卷积核只允许访问那些图像中能够完全包含整个核的位置。在 MATLAB
的术语中，这称为 有效（valid）卷积。在这种情况下，输出的所有像素都是输入中
相同数量像素的函数，这使得输出像素的表示更加规范。然而，输出的大小在每一
层都会缩减。如果输入的图像宽度是 m，核的宽度是 k，那么输出的宽度就会变成
m k+ 1。如果卷积核非常大的话缩减率会非常显著。因为缩减数大于 0，这限制
了网络中能够包含的卷积层的层数。当层数增加时，网络的空间维度最终会缩减到
11，这种情况下增加的层就不可能进行有意义的卷积了。第二种特殊的情况是只
进行足够的零填充来保持输出和输入具有相同的大小。在 MATLAB 的术语中，这
称为相同（same）卷积。在这种情况下，只要硬件支持，网络就能包含任意多的卷
积层，这是因为卷积运算不改变下一层的结构。 。然而，输入像素中靠近边界的部分
相比于中间部分对于输出像素的影响更小。这可能会导致边界像素存在一定程度的
欠表示。这使得第三种极端情况产生了，在 MATLAB 中称为全（full）卷积。它进
行了足够多的零填充使得每个像素在每个方向上恰好被访问了 k次，最终输出图像
的宽度为 m+k 1。在这种情况下，输出像素中靠近边界的部分相比于中间部分是
更少像素的函数。这将导致学得一个在卷积特征映射的所有位置都表现不错的单核DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.5基本卷积函数的变体 297
x1x1x2x2x3x3s1s1s2s2x4x4x5x5s3s3
x1x1x2x2x3x3z2z2z1z1z3z3x4x4z4z4x5x5z5z5s1s1s2s2s3s3Stridedconvolution
Downsampling
Convolution
图9.12:带有步幅的卷积。在这个例子中，我们的 步幅为二。 (上)在单个操作中实现的 步幅为二的
卷积。 (下)步幅大于一个像素的卷积在数学上等价于单位 步幅的卷积随后 降采样。显然，涉及 降采
样的两步法在计算上是浪费的，因为它计算了许多将被丢弃的值。
更为困难。通常零填充的最优数量（对于测试集的分类正确率）处于 “有效卷积’’和
“相同卷积’’之间的某个位置。
在一些情况下，我们并不是真的想使用卷积，而是想用一些局部连接的网络层
(LeCun ,1986,1989)。在这种情况下，我们的 多层感知机 对应的邻接矩阵是相同的，
但每一个连接都有它自己的权重，用一个 6维的张量 W来表示。 W的索引分别是：
输出的通道 i，输出的行 j和列 k，输入的通道 l，输入的行偏置 m和列偏置 n。局
部连接层的线性部分可以表示为
Zi;j;k=∑
l;m;n[Vl;j+m 1;k+n 1wi;j;k;l;m;n ]: (9.9)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
298 第九章 卷积网络
.........
..................
图9.13:零填充对网络大小的影响。考虑一个 卷积网络 ，每层有一个宽度为六的核。在这个例子
中，我们不使用任何 池化，所以只有卷积操作本身缩小网络的大小。 (上)在这个卷积网络中，我
们不使用任何隐含的零填充。这使得表示在每层缩小五个像素。从十六个像素的输入开始，我们
只能有三个卷积层，并且最后一层不能移动核，所以可以说只有两层是真正的卷积层。可以通过
使用较小的核来减缓收缩速率，但是较小的核表示能力不足，并且在这种结构中一些收缩是不可
避免的。 (下)通过向每层添加五个隐含的零，我们防止了表示随深度收缩。这允许我们设计一个
任意深的卷积网络。
这有时也被称为 非共享卷积 （unshared convolution ） ，因为它和具有一个小核的离
散卷积运算很像，但并不横跨位置来共享参数。图 9.14比较了局部连接、卷积和全连
接的区别。
当我们知道每一个特征都是一小块空间的函数并且相同的特征不会出现在所有
的空间上时，局部连接层是很有用的。例如，如果我们想要辨别一张图片是否是人
脸图像时，我们只需要去寻找嘴是否在图像下半部分即可。
使用那些连接被更进一步限制的卷积或者局部连接层也是有用的，例如，限制DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.5基本卷积函数的变体 299
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
x1x1x2x2s1s1s3s3x5x5s5s5x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
a        ba        ba        ba        ba        a        bc      de     fg      h i  
x4x4x3x3s4s4s2s2
图9.14:局部连接，卷积和全连接的比较。 (上)每一小片（接受域）有两个像素的局部连接层。每
条边用唯一的字母标记，来显示每条边都有自身的权重参数。 (中)核宽度为两个像素的卷积层。
该模型与局部连接层具有完全相同的连接。区别不在于哪些单元相互交互，而在于如何共享参数。
局部连接层没有 参数共享 。正如用于标记每条边的字母重复出现所指示的，卷积层在整个输入上
重复使用相同的两个权重。 (下)全连接层类似于局部连接层，它的每条边都有其自身的参数（在
该图中用字母明确标记的话就太多了） 。然而，它不具有局部连接层的连接受限的特征。
每一个输出的通道 i仅仅是输入通道 l的一部分的函数时。实现这种情况的一种通
用方法是使输出的前 m个通道仅仅连接到输入的前 n个通道，输出的接下来的 m
个通道仅仅连接到输入的接下来的 n个通道，以此类推。图 9.15给出了一个例子。
对少量通道间的连接进行建模允许网络使用更少的参数，这降低了存储的消耗以及
提高了统计效率，并且减少了前向和反向传播所需要的计算量。这些目标的实现并
没有减少 隐藏单元 的数目。
平铺卷积 （tiled convolution ）(Gregor and LeCun ,2010a ;Leet al. ,2010)对卷
积层和局部连接层进行了折衷。这里并不是对 每一个空间位置的权重集合进行学习，
我们学习一组核使得当我们在空间移动时它们可以循环利用。这意味着在近邻的位DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
300 第九章 卷积网络
置上拥有不同的过滤器，就像局部连接层一样，但是对于这些参数的存储需求仅仅
会增长常数倍，这个常数就是核的集合的大小，而不是整个输出的特征映射的大小。
图9.16对局部连接层、 平铺卷积 和标准卷积进行了比较。
为了用代数的方法定义 平铺卷积 ，令K是一个 6维的张量5，其中的两维对应
着输出映射中的不同位置。 K在这里并没有对输出映射中的每一个位置使用单独的
索引，输出的位置在每个方向上在 t个不同的核组成的集合中进行循环。如果 t等
于输出的宽度，这就是局部连接层了。
Zi;j;k=∑
l;m;nVl;j+m 1;k+n 1Ki;l;m;n;j %t+1;k%t+1; (9.10)
这里百分号是取模运算，它的性质包括 t%t= 0;(t+ 1) %t= 1等等。在每一维上使
用不同的 t可以很容易对这个方程进行扩展。
局部连接层与 平铺卷积 层都和最大池化 有一些有趣的关联：这些层的探测单元
都是由不同的过滤器驱动的。如果这些过滤器能够学会探测相同隐含特征的不同变
换形式，那么 最大池化 的单元对于学得的变换就具有不变性（如图 9.9所示） 。卷积
层对于平移具有内置的不变性。
实现卷积网络 时，通常也需要除卷积以外的其他运算。为了实现学习，必须在
给定输出的梯度时能够计算核的梯度。在一些简单情况下，这种运算可以通过卷积
来实现，但在很多我们感兴趣的情况下，包括 步幅大于 1的情况，并不具有这样的
性质。
回忆一下卷积是一种线性运算，所以可以表示成矩阵乘法的形式（如果我们首
先把输入张量变形为一个扁平的向量） 。其中包含的矩阵是关于卷积核的函数。这个
矩阵是稀疏的并且核的每个元素都复制给矩阵的多个元素。这种观点能够帮助我们
导出实现一个 卷积网络 所需的很多其他运算。
通过卷积定义的矩阵转置的乘法就是这样一种运算。这种运算用于在卷积层反
向传播误差的导数，所以它在训练多于一个 隐藏层的卷积网络 时是必要的。如果我们
想要从隐藏层单元重构可视化单元时，同样的运算也是需要的 (Simard et al. ,1992)。
重构可视化单元是本书第 三部分的模型广泛用到的一种运算，这些模型包括 自编码
器、RBM和稀疏编码等等。构建这些模型的卷积化的版本都要用到转置化卷积。类
似核梯度运算，这种输入梯度运算在某些情况下可以用卷积来实现，但在一般情况
下需要用到第三种运算来实现。必须非常小心地来使这种转置运算和 前向传播 过程
5译者注：原文将 K误写成了 k。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.5基本卷积函数的变体 301
相协调。转置运算返回的输出的大小取决于三个方面：零填充的策略、 前向传播 运
算的步幅以及前向传播 的输出映射的大小。在一些情况下，不同大小的输入通过 前
向传播过程能够得到相同大小的输出映射，所以必须明确地告知转置运算原始输入
的大小。
这三种运算——卷积、从输出到权重的反向传播和从输出到输入的反向传播
——对于训练任意深度的前馈 卷积网络 ，以及训练带有（基于卷积的转置的）重构
函数的卷积网络 ，这三种运算都足以计算它们所需的所有梯度。对于完全一般的多
维、多样例情况下的公式，完整的推导可以参考 Goodfellow (2010)。为了直观说明
这些公式是如何起作用的，我们这里给出一个二维单个样例的版本。
假设我们想要训练这样一个 卷积网络 ，它包含 步幅为s的步幅卷积，该卷积的
核为K，作用于多通道的图像 V，定义为 c(K;V; s)，就像式 (9.8)中一样。假设我们
想要最小化某个损失函数 J(V;K)。在前向传播 过程中，我们需要用 c本身来输出
Z，然后 Z传递到网络的其余部分并且被用来计算损失函数 J。在反向传播过程中，
我们会得到一个张量 G满足Gi;j;k=@
@Zi;j;kJ(V;K)。
为了训练网络，我们需要对核中的权重求导。为了实现这个目的，我们可以使
用一个函数
g(G;V; s)i;j;k;l =@
@Ki;j;k;lJ(V;K) =∑
m;nGi;m;nVj;(m 1)s+k;(n 1)s+l: (9.11)
如果这一层不是网络的底层，我们需要对 V求梯度来使得误差进一步反向传播。
我们可以使用如下的函数
h(K;G; s)i;j;k =@
@Vi;j;kJ(V;K) (9.12)
=∑
l;m
s.t.
(l 1)s+m=j∑
n;p
s.t.
(n 1)s+p=k∑
qKq;i;m;pGq;l;n: (9.13)
第十四章描述的 自编码器 网络，是一些被训练成把输入拷贝到输出的前馈网
络。一个简单的例子是 PCA算法，将输入 x拷贝到一个近似的重构值 r，通过函数
W⊤Wx来实现。使用权重矩阵转置的乘法，就像 PCA算法这种，在一般的 自编码
器中是很常见的。为了使这些模型卷积化，我们可以用函数 h来实现卷积运算的转
置。假定我们有和 Z相同形式的隐藏单元 H，并且我们定义一种重构运算
R=h(K;H; s): (9.14)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
302 第九章 卷积网络
为了训练 自编码器 ，我们会得到关于 R的梯度，表示为一个张量 E。为了训练
解码器，我们需要获得对于 K的梯度，这通过 g(H;E; s)来得到。为了训练编码器，
我们需要获得对于 H的梯度，这通过 c(K;E; s)来得到。通过用 c和h对g求微分
也是可行的，但这些运算对于任何标准神经网络上的反向传播算法来说都是不需要
的。
一般来说，在卷积层从输入到输出的变换中我们不仅仅只用线性运算。我们一
般也会在进行非线性运算前，对每个输出加入一些偏置项。这样就产生了如何在偏
置项中共享参数的问题。对于局部连接层，很自然地对每个单元都给定它特有的偏
置，对于 平铺卷积 ，也很自然地用与核一样的平铺模式来共享参数。对于卷积层来
说，通常的做法是在输出的每一个通道上都设置一个偏置，这个偏置在每个卷积映
射的所有位置上共享。然而，如果输入是已知的固定大小，也可以在输出映射的每个
位置学习一个单独的偏置。分离这些偏置可能会稍稍降低模型的统计效率，但同时
也允许模型来校正图像中不同位置的统计差异。例如，当使用隐含的零填充时，图
像边缘的探测单元接收到较少的输入，因此需要较大的偏置。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.5基本卷积函数的变体 303
Input TensorOutput Tensor
Spatial coordinatesChannel coordinates
图9.15:卷积网络 的前两个输出通道只和前两个输入通道相连，随后的两个输出通道只和随后的
两个输入通道相连。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
304 第九章 卷积网络
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5
a        ba        ba        ba        ba       a        bc      de     fg      h i  
x1x1x2x2x3x3s2s2s1s1s3s3x4x4s4s4x5x5s5s5a        bc        da        bc        da        
图9.16:局部连接层、 平铺卷积 和标准卷积的比较。当使用相同大小的核时，这三种方法在单元之
间具有相同的连接。此图是对使用两个像素宽的核的说明。这三种方法之间的区别在于它们如何
共享参数。 (上)局部连接层根本没有共享参数。我们对每个连接使用唯一的字母标记，来表明每
个连接都有它自身的权重。 (中)平铺卷积 有t个不同的核。这里我们说明 t= 2的情况。其中一个
核具有标记为 “a’’和“b’’的边，而另一个具有标记为 “c’’和“d’’的边。每当我们在输出中右移一
个像素后，我们使用一个不同的核。这意味着，与局部连接层类似，输出中的相邻单元具有不同的
参数。与局部连接层不同的是，在我们遍历所有可用的 t个核之后，我们循环回到了第一个核。如
果两个输出单元间隔 t个步长的倍数，则它们共享参数。 (下)传统卷积等效于 t= 1的平铺卷积 。
它只有一个核，并且被应用到各个地方，我们在图中表示为在各处使用具有标记为 “a’’和“b’’的
边的核。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.6结构化输出 305
9.6结构化输出
卷积神经网络 可以用于输出高维的结构化对象，而不仅仅是预测分类任务的类
标签或回归任务的实数值。通常这个对象只是一个张量，由标准卷积层产生。例如，
模型可以产生张量 S，其中 Si;j;k是网络的输入像素 (j; k)属于类 i的概率。这允许
模型标记图像中的每个像素，并绘制沿着单个对象轮廓的精确掩模。
经常出现的一个问题是输出平面可能比输入平面要小，如图 9.13所示。用于
对图像中单个对象分类的常用结构中，网络空间维数的最大减少来源于使用大 步
幅的池化层。为了产生与输入大小相似的输出映射，我们可以避免把 池化放在一起
(Jain et al. ,2007)。另一种策略是单纯地产生一张低分辨率的标签网格 (Pinheiro
and Collobert ,2014,2015)。最后，原则上可以使用具有单位 步幅的池化操作。
对图像逐个像素标记的一种策略是先产生图像标签的原始猜测，然后使用相邻
像素之间的交互来修正该原始猜测。重复这个修正步骤数次对应于在每一步使用相
同的卷积，该卷积在深层网络的最后几层之间共享权重 (Jain et al. ,2007)。这使得在
层之间共享参数的连续的卷积层所执行的一系列运算，形成了一种特殊的 循环神经
网络 (Pinheiro and Collobert ,2014,2015)。图 9.17给出了这样一个循环 卷积网络 的
结构。
一旦对每个像素都进行了预测，我们就可以使用各种方法来进一步处理这些
预测，以便获得图像在区域上的分割 (Briggman et al. ,2009;Turaga et al. ,2010;
Farabet et al. ,2013)。一般的想法是假设大片相连的像素倾向于对应着相同的标签。
图模型可以描述相邻像素间的概率关系。或者， 卷积网络 可以被训练来最大化地近
似图模型的训练目标 (Ning et al. ,2005;Thompson et al. ,2014)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
306 第九章 卷积网络
ˆY(1)ˆY(1)ˆY(2)ˆY(2)ˆY(3)ˆY(3)H(1)H(1)H(2)H(2)H(3)H(3)XXUUUVVVWW
图9.17:用于像素标记的 循环卷积网络 的示例。输入是图像张量 X，它的轴对应图像的行、列和通
道（红，绿，蓝） 。目标是输出标签张量 ^Y，它遵循每个像素的标签的概率分布。该张量的轴对应
图像的行、列和不同类别。 循环网络 通过使用 ^Y的先前估计作为创建新估计的输入，来迭代地改
善其估计，而不是单次输出 ^Y， 。每个更新的估计使用相同的参数，并且估计可以如我们所愿地被
改善任意多次。每一步使用的卷积核张量 U，是用来计算给定输入图像的隐藏表示的。核张量 V
用于产生给定隐藏值时标签的估计。除了第一步之外，核 W都对 ^Y进行卷积来提供隐藏层的输
入。在第一步中，此项由零代替。因为每一步使用相同的参数，所以这是一个 循环网络 的例子，如
第十章所述。
9.7数据类型
卷积网络 使用的数据通常包含多个通道，每个通道是时间上或空间中某一点的
不同观测量。参考表 9.1来了解具有不同维数和通道数的数据类型的例子。
卷积网络 用于视频的例子，可以参考 Chen et al. (2010)。
到目前为止，我们仅讨论了训练和测试数据中的每个样例都有相同的空间维度
的情况。 卷积网络 的一个优点是它们还可以处理具有可变的空间尺度的输入。这些
类型的输入不能用传统的基于矩阵乘法的神经网络来表示。这为 卷积网络 的使用提
供了令人信服的理由，即使当计算开销和过拟合都不是主要问题时。
例如，考虑一组图像的集合，其中每个图像具有不同的高度和宽度。目前还不
清楚如何用固定大小的权重矩阵对这样的输入进行建模。卷积就可以很直接地应用；
核依据输入的大小简单地被使用不同次，并且卷积运算的输出也相应地放缩。卷积
可以被视为矩阵乘法；相同的卷积核为每种大小的输入引入了一个不同大小的 双重
分块循环矩阵 。有时，网络的输出允许和输入一样具有可变的大小，例如如果我们
想要为输入的每个像素分配一个类标签。在这种情况下，不需要进一步的设计工作。
在其他情况下，网络必须产生一些固定大小的输出，例如，如果我们想要为整个图DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.7数据类型 307
单通道 多通道
1维音频波形：卷积的轴对应于时间。
我们将时间离散化并且在每个时
间点测量一次波形的振幅。骨架动画 (skeleton animation) 数
据：计算机渲染的 3D角色动画是
通过随时间调整 ‘‘骨架’’的姿势
而生成的。在每个时间点，角色的
姿势通过骨架中的每个关节的角
度来描述。我们输入到卷积模型
的数据的每个通道，表示一个关
节关于一个轴的角度。
2维已经使用 傅立叶变换 预处理过的
音频数据：我们可以将音频波形
变换成 2维张量，不同的行对应
不同的频率，不同的列对应不同
的时间点。在时间轴上使用卷积
使模型等效于在时间上移动。在
频率轴上使用卷积使得模型等效
于在频率上移动，这使得在不同
八度音阶中播放的相同旋律产生
相同的表示，但处于网络输出中
的不同高度。彩色图像数据：其中一个通道包
含红色像素，另一个包含绿色像
素，最后一个包含蓝色像素。在图
像的水平轴和竖直轴上移动卷积
核，赋予了两个方向上平移等变
性。
3维体积数据：这种数据一般来源于
医学成像技术，例如 CT扫描等。彩色视频数据：其中一个轴对应
着时间，另一个轴对应着视频帧
的高度，最后一个对应着视频帧
的宽度。
表9.1:用于卷积网络 的不同数据格式的示例。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
308 第九章 卷积网络
像指定单个类标签。在这种情况下，我们必须进行一些额外的设计步骤，例如插入
一个池化层，池化区域的大小要与输入的大小成比例，以便保持固定数量的 池化输
出。这种策略的一些例子可以参考图 9.11。
注意，使用卷积处理可变尺寸的输入，仅对输入是因为包含对同种事物的不同
量的观察 (时间上不同长度的记录，空间上不同宽度的观察等 )而导致的尺寸变化这
种情况才有意义。如果输入是因为它可以选择性地包括不同种类的观察而具有可变
尺寸，使用卷积是不合理的。例如，如果我们正在处理大学申请，并且我们的特征
包括成绩等级和标准化测试分数，但不是每个申请人都进行了标准化测试，则使用
相同的权重来对成绩特征和测试分数特征进行卷积是没有意义的。
9.8高效的卷积算法
现代卷积网络 的应用通常需要包含超过百万个单元的网络。利用并行计算资源
的强大实现是很关键的，如第 12.1节中所描述的。然而，在很多情况下，也可以通
过选择适当的卷积算法来加速卷积。
卷积等效于使用 傅立叶变换 将输入与核都转换到频域、执行两个信号的逐点相
乘，再使用傅立叶逆变换转换回时域。对于某些问题的规模，这种算法可能比离散
卷积的朴素实现更快。
当一个 d维的核可以表示成 d个向量（每一维一个向量）的外积时，该核被称
为可分离的 （separable ） 。当核可分离时，朴素的卷积是低效的。它等价于组合 d个
一维卷积，每个卷积使用这些向量中的一个。组合方法显著快于使用它们的外积来
执行一个 d维的卷积。并且核也只要更少的参数来表示成向量。如果核在每一维都
是w个元素宽，那么朴素的多维卷积需要 O(wd)的运行时间和参数存储空间，而可
分离卷积只需要 O(wd)的运行时间和参数存储空间。当然，并不是每个卷积都可
以表示成这种形式。
设计更快的执行卷积或近似卷积，而不损害模型准确性的方法，是一个活跃的
研究领域。甚至仅提高 前向传播 效率的技术也是有用的，因为在商业环境中，通常
部署网络比训练网络还要耗资源。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.9随机或无监督的特征 309
9.9随机或无监督的特征
通常，卷积网络 训练中最昂贵的部分是学习特征。输出层的计算代价通常相对
不高，因为在通过若干层 池化之后作为该层输入的特征的数量较少。当使用梯度下
降执行监督训练时，每步梯度计算需要完整地运行整个网络的前向传播和反向传播。
减少卷积网络 训练成本的一种方式是使用那些不是由 监督方式训练得到的特征。
有三种基本策略可以不通过 监督训练而得到卷积核。其中一种是简单地随机初
始化它们。另一种是手动设计它们，例如设置每个核在一个特定的方向或尺度来检
测边缘。最后，可以使用无监督的标准来学习核。例如， Coates et al. (2011)将k均
值聚类算法应用于小图像块，然后使用每个学得的中心作为卷积核。第 三部分描述
了更多的无监督学习方法。使用无监督的标准来学习特征，允许这些特征的确定与
位于网络结构顶层的分类层相分离。然后只需提取一次全部训练集的特征，构造用
于最后一层的新训练集。假设最后一层类似 逻辑回归 或者 SVM，那么学习最后一层
通常是凸优化问题。
随机过滤器经常在 卷积网络 中表现得出乎意料得好 Jarrett et al. (2009b );Saxe
et al. (2011);Pinto et al. (2011);Cox and Pinto (2011)。Saxe et al. (2011)说明，由
卷积和随后的 池化组成的层，当赋予随机权重时，自然地变得具有频率选择性和平
移不变性。他们认为这提供了一种廉价的方法来选择 卷积网络 的结构：首先通过仅
训练最后一层来评估几个 卷积网络 结构的性能，然后选择最好的结构并使用更昂贵
的方法来训练整个网络。
一个中间方法是学习特征，但是使用那种不需要在每个梯度计算步骤中都进行
完整的前向和反向传播的方法。与多层感知机一样，我们使用 贪心逐层预训练 ，单
独训练第一层，然后一次性地从第一层提取所有特征，之后用那些特征单独训练
第二层，以此类推。第 八章描述了如何实现 监督的贪心逐层预训练 ，第三部分将此
扩展到了无监督的范畴。卷积模型的 贪心逐层预训练 的经典模型是卷积 深度信念网
络(Lee et al. ,2009)。卷积网络 为我们提供了相对于多层感知机更进一步采用预训
练策略的机会。并非一次训练整个卷积层，我们可以训练一小块模型，就像 Coates
et al. (2011)使用 k均值做的那样。然后，我们可以用来自这个小块模型的参数来定
义卷积层的核。这意味着使用无监督学习来训练 卷积网络 并且在训练的过程中完全
不使用卷积 是可能的。使用这种方法，我们可以训练非常大的模型，并且只在推断期
间产生高计算成本 (Ranzato et al. ,2007c ;Jarrett et al. ,2009b ;Kavukcuoglu et al. ,
2010;Coates et al. ,2013)。这种方法大约在 2007到2013年间流行，当时标记的数DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
310 第九章 卷积网络
据集很小，并且计算能力有限。如今，大多数 卷积网络 以纯粹监督的方式训练，在每
次训练迭代中使用通过整个网络的完整的前向和反向传播。
与其他无监督预训练的方法一样，使用这种方法的一些好处仍然难以说清。无
监督预训练可以提供一些相对于 监督训练的正则化，或者它可以简单地允许我们训
练更大的结构，因为它的学习规则降低了计算成本。
9.10卷积网络的神经科学基础
卷积网络 也许是生物学启发人工智能的最为成功的案例。虽然 卷积网络 也经过
许多其他领域的指导，但是神经网络的一些关键设计原则来自于神经科学。
卷积网络 的历史始于神经科学实验，远早于相关计算模型的发展。为了确定关
于哺乳动物视觉系统如何工作的许多最基本的事实，神经生理学家 David Hubel 和
Torsten Wiesel 合作多年 (Hubel and Wiesel ,1959,1962,1968)。他们的成就最终获
得了诺贝尔奖。他们的发现对当代深度学习模型有最大影响的是基于记录猫的单个
神经元的活动。他们观察了猫的脑内神经元如何响应投影在猫前面屏幕上精确位置
的图像。他们的伟大发现是，处于视觉系统较为前面的神经元对非常特定的光模式
（例如精确定向的条纹）反应最强烈，但对其他模式几乎完全没有反应。
他们的工作有助于表征大脑功能的许多方面，这些方面超出了本书的范围。从
深度学习的角度来看，我们可以专注于简化的、草图形式的大脑功能视图。
在这个简化的视图中，我们关注被称为 V1的大脑的一部分，也称为 初级视觉
皮层（primary visual cortex ） 。V1是大脑对视觉输入开始执行显著高级处理的第一
个区域。在该草图视图中，图像是由光到达眼睛并刺激视网膜（眼睛后部的光敏组
织）形成的。视网膜中的神经元对图像执行一些简单的预处理，但是基本不改变它
被表示的方式。然后图像通过视神经和称为 外侧膝状核 的脑部区域。这些解剖区域
的主要作用是仅仅将信号从眼睛传递到位于头后部的 V1。
卷积网络 层被设计为描述 V1的三个性质：
1.V1可以进行空间映射。它实际上具有二维结构来反映视网膜中的图像结构。例
如，到达视网膜下半部的光仅影响 V1相应的一半。 卷积网络 通过用二维映射
定义特征的方式来描述该特性。
2.V1包含许多 简单细胞 （simple cell ） 。简单细胞的活动在某种程度上可以概括DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.10卷积网络的神经科学基础 311
为在一个小的空间位置感受野内的图像的线性函数。 卷积网络 的检测器单元被
设计为模拟简单细胞的这些性质。
3.V1还包括许多 复杂细胞 （complex cell ） 。这些细胞响应类似于由简单细胞检
测的那些特征，但是复杂细胞对于特征的位置微小偏移具有不变性。这启发
了卷积网络 的池化单元。复杂细胞对于照明中的一些变化也是不变的，不能简
单地通过在空间位置上 池化来刻画。这些不变性激发了 卷积网络 中的一些跨通
道池化策略，例如 maxout单元 (Goodfellow et al. ,2013b )。
虽然我们最了解 V1，但是一般认为相同的基本原理也适用于视觉系统的其他区
域。在我们视觉系统的草图视图中，当我们逐渐深入大脑时，遵循 池化的基本探测
策略被反复执行。当我们穿过大脑的多个解剖层时，我们最终找到了响应一些特定
概念的细胞，并且这些细胞对输入的很多种变换都具有不变性。这些细胞被昵称为
‘‘祖母细胞 ’’——这个想法是一个人可能有一个神经元，当看到他祖母的照片时该神
经元被激活，无论祖母是出现在照片的左边或右边，无论照片是她的脸部的特写镜
头还是她的全身照，也无论她处在光亮还是黑暗中，等等。
这些祖母细胞已经被证明确实存在于人脑中，在一个被称为 内侧颞叶 的区域
(Quiroga et al. ,2005)。研究人员测试了单个神经元是否会响应名人的照片。他们发
现了后来被称为 “Halle Berry 神经元 ’’的神经元：由 Halle Berry 的概念激活的单
个神经元。当一个人看到 Halle Berry 的照片， Halle Berry 的图画，甚至包含单词
“Halle Berry’’ 的文本时，这个神经元会触发。当然，这与 Halle Berry 本人无关；其
他神经元会对 Bill Clinton ，Jennifer Aniston 等的出现做出响应。
这些内侧颞叶神经元比现代 卷积网络 更通用一些，这些网络在读取名称时不会
自动联想到识别人或对象。与 卷积网络 的最后一层在特征上最接近的类比是称为 颞
下皮质（IT）的脑区。当查看一个对象时，信息从视网膜经 LGN流到 V1，然后到
V2，V4，之后是 IT。这发生在瞥见对象的前 100ms内。如果允许一个人继续观察对
象更多的时间，那么信息将开始回流，因为大脑使用自上而下的反馈来更新较低级
脑区中的激活。然而，如果我们打断人的注视，并且只观察前 100ms内的大多数前
向激活导致的放电率，那么 IT被证明与 卷积网络 非常相似。 卷积网络 可以预测 IT
放电率，并且在执行对象识别任务时与人类（时间有限的情况）非常类似 (DiCarlo ,
2013)。
话虽如此， 卷积网络 和哺乳动物的视觉系统之间还是有许多区别。这些区别有
一些是计算神经科学家所熟知的，但超出了本书的范围。还有一些区别尚未知晓，因DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
312 第九章 卷积网络
为关于哺乳动物视觉系统如何工作的许多基本问题仍未得到回答。简要列表如下：
•人眼大部分是非常低的分辨率，除了一个被称为 中央凹（fovea）的小块。中
央凹仅观察在手臂长度距离内一块拇指大小的区域。虽然我们觉得我们可以看
到高分辨率的整个场景，但这是由我们的大脑的潜意识部分创建的错觉，因为
它缝合了我们瞥见的若干个小区域。大多数 卷积网络 实际上接收大的全分辨率
的照片作为输入。人类大脑控制几次眼动，称为 扫视（saccade） ，以瞥见场景
中最显眼的或任务相关的部分。将类似的 注意力机制 融入深度学习模型是一
个活跃的研究方向。在深度学习的背景下， 注意力机制 对于自然语言处理是最
成功的，参考第 12.4.5.1节。研究者已经研发了几种具有视觉机制的视觉模型，
但到目前为止还没有成为主导方法 (Larochelle and Hinton ,2010;Denil et al. ,
2012)。
•人类视觉系统集成了许多其他感觉，例如听觉，以及像我们的心情和想法一样
的因素。 卷积网络 迄今为止纯粹是视觉的。
•人类视觉系统不仅仅用于识别对象。它能够理解整个场景，包括许多对象和对
象之间的关系，以及处理我们的身体与世界交互所需的丰富的三维几何信息。
卷积网络 已经应用于这些问题中的一些，但是这些应用还处于起步阶段。
•即使像 V1这样简单的大脑区域也受到来自较高级别的反馈的严重影响。反馈
已经在神经网络模型中被广泛地探索，但还没有被证明提供了引人注目的改进。
•虽然前馈 IT放电频率刻画了与 卷积网络 特征很多相同的信息，但是仍不清楚
中间计算的相似程度。大脑可能使用非常不同的激活和 池化函数。单个神经元
的激活可能不能用单个线性过滤器的响应来很好地表征。最近的 V1模型涉及
对每个神经元的多个二次过滤器 (Rust et al. ,2005)。事实上，我们的 ‘‘简单细
胞’’和‘‘复杂细胞 ’’的草图图片可能并没有区别；简单细胞和复杂细胞可能是
相同种类的细胞，但是它们的 ‘‘参数’’使得它们能够实现从我们所说的 ‘‘简单’’
到‘‘复杂’’的连续的行为。
还值得一提的是，神经科学很少告诉我们该如何 训练卷积网络 。具有跨多个空
间位置的 参数共享 的模型结构，可以追溯到早期关于视觉的联结主义模型 (Marr
and Poggio ,1976)，但是这些模型没有使用现代的反向传播算法和梯度下降。例如，
(Fukushima ,1980)结合了现代 卷积网络 的大多数模型结构设计元素，但依赖于层次
化的无监督聚类算法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.10卷积网络的神经科学基础 313
Lang and Hinton (1988)引入反向传播来训练 时延神经网络 （time delay neural
network ,TDNN） 。使用当代术语来说， TDNN是用于时间序列的一维 卷积网络 。用
于这些模型的反向传播不受任何神经科学观察的启发，并且被一些人认为是生物不
可信的。在基于使用反向传播训练的 TDNN成功之后， LeCun et al. (1989)通过将
相同的训练算法应用于图像的 2维卷积来发展现代 卷积网络 。
到目前为止，我们已经描述了简单细胞对于某些特征是如何呈现粗略的线性和
选择性，复杂细胞是如何更加的非线性，并且对于这些简单细胞特征的某些变换具
有不变性，以及在选择性和不变性之间交替放置的层可以产生对非常特定现象的祖
母细胞。我们还没有精确描述这些单个细胞检测到了什么。在深度非线性网络中，
可能难以理解单个细胞的功能。第一层中的简单细胞相对更容易分析，因为它们的
响应由线性函数驱动。在人工神经网络中，我们可以直接显示卷积核的图像，来查
看卷积层的相应通道是如何响应的。在生物神经网络中，我们不能访问权重本身。
相反，我们在神经元自身中放置一个电极，在动物视网膜前显示几个白噪声图像样
本，并记录这些样本中的每一个是如何导致神经元激活的。然后，我们可以对这些
响应拟合线性模型，以获得近似的神经元权重。这种方法被称为 反向相关 （reverse
correlation ）(Ringach and Shapley ,2004)。
反向相关 向我们表明，大多数的 V1细胞具有由 Gabor函数（Gabor function ）
所描述的权重。 Gabor函数描述在图像中的 2维点处的权重。我们可以认为图像是
2维坐标 I(x; y)的函数。类似地，我们可以认为简单细胞是在图像中的一组位置采
样，这组位置由一组 x坐标X和一组 y坐标Y来定义，并且使用的权重 w(x; y)也
是位置的函数。从这个观点来看，简单细胞对于图像的响应由下式给出
s(I) =∑
x2X∑
y2Yw(x; y)I(x; y): (9.15)
特别地， w(x; y)采用Gabor函数的形式：
w(x; y;;  x; y; f; ϕ; x 0; y0; ) =exp( xx′2 yy′2)cos(fx′+ϕ); (9.16)
其中
x′= (x x0)cos() + (y y0)sin() (9.17)
以及
y′= (x x0)sin() + (y y0)cos(): (9.18)
这里 ;  x; y; f; ϕ; x 0; y0; 都是控制 Gabor函数性质的参数。图 9.18给出
了Gabor函数在不同参数集上的一些例子。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
314 第九章 卷积网络
图9.18:具有各种参数设置的 Gabor函数。白色表示大的正权重，黑色表示大的负权重，背景灰
色对应于零权重。 (左)控制坐标系的参数具有不同值的 Gabor函数，这些参数包括： x0、y0和。
在该网格中的每个 Gabor函数被赋予和它在网格中的位置成比例的 x0和y0的值，并且 被选
择为使得每个 Gabor过滤器对从网格中心辐射出的方向非常敏感。对于其他两幅图， x0、y0和
固定为零。 (中)具有不同高斯比例参数 x和y的Gabor函数。当我们从左到右通过网格时，
Gabor函数被设置为增加宽度（减少 x） ；当我们从上到下通过网格时， Gabor函数被设置为为
增加高度（减少 y） 。对于其他两幅图， 值固定为图像宽度的 1.5倍。(右)具有不同的正弦参数
f和ϕ的Gabor函数。当我们从上到下移动时， f增加；当我们从左到右移动时， ϕ增加。对于
其他两幅图， ϕ固定为 0，f固定为图像宽度的 5倍。
参数 x0; y0和定义坐标系。我们平移和旋转 x和y来得到 x′和y′。具体地，
简单细胞会响应以点 (x0; y0)为中心的图像特征，并且当我们沿着从水平方向旋转 
弧度的线移动时，简单细胞将响应亮度的变化。
作为 x′和y′的函数，函数 w会响应当我们沿着 x′移动时的亮度变化。它有两
个重要的因子：一个是高斯函数，另一个是余弦函数。
高斯因子 exp( xx′2 yy′2)可以被视为阈值项，用于保证简单细胞仅对接
近x′和y′都为零点处的值响应，换句话说，接近细胞接受域的中心。尺度因子 
调整简单细胞响应的总的量级，而 x和y控制接受域消退的速度。
余弦因子 cos(fx′+ϕ)控制简单细胞如何响应延 x‘轴的亮度改变。参数 f控制
余弦的频率， ϕ控制它的相位偏移。
合在一起，简单细胞的这个草图视图意味着，简单细胞对在特定位置处、特定
方向上、特定空间频率的亮度进行响应。当图像中的光波与细胞的权重具有相同的
相位时，简单细胞是最兴奋的。这种情况发生在当图像亮时，它的权重为正，而图
像暗时，它的权重为负。当光波与权重完全异相时，简单细胞被抑制——当图像较DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.10卷积网络的神经科学基础 315
暗时，它的权重为正；较亮时，它的权重为负。
复杂细胞的草图视图是它计算包含两个简单细胞响应的 2维向量的 L2范数：
c(I) =√
s0(I)2+s1(I)2。一个重要的特殊情况是当 s1和s0具有除 ϕ以外都相同的
参数，并且 ϕ被设置为使得 s1与s0相位相差四分之一周期时。在这种情况下， s0和
s1形成象限对（quadrature pair ） 。 当高斯重新加权的图像 I(x; y)exp( xx′2 yy2)
包含具有频率 f、在方向 上、接近 (x0; y0)的高振幅正弦波时，用先前方法定义的
复杂细胞会响应，并且 不管该波的相位偏移 。换句话说，复杂细胞对于图像在方向 
上的微小变换或者翻转图像（用白色代替黑色，反之亦然）具有不变性。
神经科学和机器学习之间最显著的对应关系，是从视觉上比较机器学习模型学
得的特征与使用 V1得到的特征。 Olshausen and Field (1996)说明，一个简单的无
监督学习算法，稀疏编码，学习的特征具有与简单细胞类似的感受野。从那时起，我
们发现，当应用于自然图像时，极其多样的统计学习算法学习类 Gabor函数的特征。
这包括大多数深度学习算法，它们在其第一层中学习这些特征。图 9.19给出了一些
例子。因为如此众多不同的学习算法学习边缘检测器，所以很难仅基于学习算法学
得的特征，来断定哪一个特定的学习算法是 ‘‘正确’’的大脑模型（虽然，当应用于自
然图像时，如果一个算法 不能学得某种检测器时，它能够作为一种否定标志） 。这些
特征是自然图像的统计结构的重要部分，并且可以通过许多不同的统计建模方法来
重新获得。读者可以参考 (Hyvärinen et al. ,2009)来获得自然图像统计领域的综述。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
316 第九章 卷积网络
图9.19:许多机器学习算法在应用于自然图像时，会学习那些用来检测边缘或边缘的特定颜色的特
征。这些特征检测器使人联想到已知存在于初级视觉皮层中的 Gabor函数。(左)通过应用于小图
像块的无监督学习算法（ 尖峰和平板 稀疏编码）学得的权重。 (右)由完全监督的卷积 maxout 网
络的第一层学得的卷积核。相邻的一对过滤器驱动相同的 maxout单元。
9.11卷积网络与深度学习的历史
卷积网络 在深度学习的历史中发挥了重要作用。它们是将研究大脑获得的深刻
理解成功用于机器学习应用的关键例子。它们也是第一个表现良好的深度模型之
一，远远早于任意深度模型被认为是可行的。 卷积网络 也是第一个解决重要商业应
用的神经网络，并且仍然是当今深度学习商业应用的前沿。例如，在 20世纪 90年
代，AT&T的神经网络研究小组开发了一个用于读取支票的 卷积网络 (LeCun et al. ,
2001)。到 90年代末， NEC部署的这个系统已经被用于读取美国 10％以上的支
票。后来，微软部署了若干个基于 卷积网络 的OCR和手写识别系统 (Simard et al. ,
2003)。关于卷积网络 的这种应用和更现代应用的更多细节，参考第 十二章。读者可
以参考 (LeCun et al. ,2010)了解 2010年之前的更为深入的 卷积网络 历史。
卷积网络 也被用作在许多比赛中的取胜手段。当前对深度学习的商业兴趣的热
度始于 Krizhevsky et al. (2012a )赢得了 ImageNet 对象识别挑战，但是在那之前，
卷积网络 也已经被用于赢得前些年影响较小的其他机器学习和计算机视觉竞赛了。
卷积网络 是第一批能使用反向传播有效训练的的深度网络之一。现在仍不完全
清楚为什么 卷积网络 在一般的反向传播网络被认为已经失败时反而成功了。这可能
可以简单地归结为 卷积网络 比全连接网络计算效率更高，因此使用它们运行多个实DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
9.11卷积网络与深度学习的历史 317
验并调整它们的实现和超参数更容易。更大的网络也似乎更容易训练。利用现代硬
件，大型全连接的网络在许多任务上也表现得很合理，即使使用过去那些全连接网
络被认为不能工作得很好的数据集和当时流行的激活函数时，现在也能执行得很好。
心理可能神经网络成功的主要阻碍（实践者没有期望神经网络有效，所以他们没有
认真努力地使用神经网络） 。无论如何，幸运的是 卷积网络 在几十年前就表现良好。
在许多方面，它们为余下的深度学习传递火炬，并为一般的神经网络被接受铺平了
道路。
卷积网络 提供了一种方法来特化神经网络，使其能够处理具有清楚的网格结构
拓扑的数据，以及将这样的模型扩展到非常大的规模。这种方法在二维图像拓扑上
是最成功的。为了处理一维序列数据，我们接下来转向神经网络框架的另一种强大
的特化： 循环神经网络 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十章 序列建模：循环和递归网络
循环神经网络 （recurrent neural network ）或 RNN (Rumelhart et al. ,1986c )
是一类用于处理序列数据的 神经网络 。就像卷积网络 是专门用于处理网格化数据 X
（如一个图像）的 神经网络 ，循环神经网络 是专门用于处理序列 x(1); : : : ; x()的神
经网络。正如卷积网络 可以很容易地扩展到具有很大宽度和高度的图像，以及处理
大小可变的图像， 循环网络 可以扩展到更长的序列（比不基于序列的特化网络长得
多） 。大多数 循环网络 也能处理可变长度的序列。
从多层网络出发到 循环网络 ，我们需要利用上世纪 80年代机器学习 和统计模
型早期思想的优点：在模型的不同部分共享参数。 参数共享 使得模型能够扩展到不
同形式的样本（这里指不同长度的样本）并进行泛化。如果我们在每个时间点都有
一个单独的参数，我们不但不能泛化到训练时没有见过序列长度，也不能在时间上
共享不同序列长度和不同位置的统计强度。当信息的特定部分会在序列内多个位置
出现时，这样的共享尤为重要。例如，考虑这两句话： “I went to Nepal in 2009’’ 和
“In 2009, I went to Nepal.” 如果我们让一个 机器学习 模型读取这两个句子，并提取
叙述者去 Nepal的年份，无论 “2009年’’是作为句子的第六个单词还是第二个单词出
现，我们都希望模型能认出 “2009年’’作为相关资料片段。假设我们要训练一个处
理固定长度句子的 前馈网络 。传统的全连接 前馈网络 会给每个输入特征分配一个单
独的参数，所以需要分别学习句子每个位置的所有语言规则。相比之下， 循环神经网
络在几个时间步内共享相同的权重，不需要分别学习句子每个位置的所有语言规则。
一个相关的想法是在 1维时间序列上使用卷积。这种卷积方法是 时延神经网
络的基础 (Lang and Hinton ,1988;Waibel et al. ,1989;Lang et al. ,1990)。卷积操作
允许网络跨时间共享参数，但是浅层的。卷积的输出是一个序列，其中输出中的每
一项是相邻几项输入的函数。 参数共享 的概念体现在每个 时间步中使用的相同卷积
核。循环神经网络 以不同的方式共享参数。输出的每一项是前一项的函数。输出的
318DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.1展开计算图 319
每一项对先前的输出应用相同的更新规则而产生。这种循环方式导致参数通过很深
的计算图共享。
为简单起见，我们说的 RNN是指在序列上的操作，并且该序列在时刻 t（从
1到）包含向量 x(t)。在实际情况中， 循环网络 通常在序列的 小批量上操作，并
且小批量的每项具有不同序列长度 。我们省略了 小批量索引来简化记号。此外，
时间步索引不必是字面上现实世界中流逝的时间。有时，它仅表示序列中的位置。
RNN也可以应用于跨越两个维度的空间数据（如图像） 。当应用于涉及时间的数据，
并且将整个序列提供给网络之前就能观察到整个序列时，该网络可具有关于时间向
后的连接。
本章将计算图的思想扩展到包括循环。这些周期代表变量自身的值在未来某
一时间步对自身值的影响。这样的 计算图允许我们定义 循环神经网络 。然后，我们
描述许多构建、训练和使用 循环神经网络 的不同方式。
本章将简要介绍 循环神经网络 ， 为获取更多详细信息， 我们建议读者参考 Graves
(2012)的著作。
10.1展开计算图
计算图是形式化一组计算结构的方式，如那些涉及将输入和参数映射到输出和
损失的计算。综合的介绍请参考第 6.5.1节。本节，我们对 展开（unfolding ）递归或
循环计算得到的重复结构进行解释，这些重复结构通常对应于一个事件链。 展开
（unfolding ）这个计算图将导致深度网络结构中的 参数共享 。
例如，考虑动态系统的经典形式：
s(t)=f(s(t 1);); (10.1)
其中 s(t)称为系统的状态。
s在时刻 t的定义需要参考时刻 t 1时同样的定义，因此式 (10.1)是循环的。
对有限时间步 ， 1次应用这个定义可以展开这个图。例如 = 3，我们对
式(10.1)展开，可以得到：
s(3)=f(s(2);) (10.2)
=f(f(s(1););): (10.3)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
320 第十章 序列建模：循环和递归网络
以这种方式重复应用定义， 展开等式，就能得到不涉及循环的表达。现在我们
可以使用传统的有向无环 计算图呈现这样的表达。
式(10.1)和式 (10.3)的展开计算图如图 10.1所示。
s(t 1)s(t 1)s(t)s(t)s(t+1)s(t+1)ffs(...)s(...)s(...)s(...)ffffff
图10.1:将式 (10.1)描述的经典动态系统表示为展开的计算图。每个节点表示在某个时刻 t的状
态，并且函数 f将t处的状态映射到 t+ 1处的状态。所有 时间步都使用相同的参数（用于参数
化f的相同值） 。
作为另一个例子，让我们考虑由外部信号 x(t)驱动的动态系统，
s(t)=f(s(t 1);x(t);); (10.4)
我们可以看到，当前状态包含了整个过去序列的信息。
循环神经网络 可以通过许多不同的方式建立。就像几乎所有函数都可以被认为
是前馈网络 ，本质上任何涉及循环的函数都可以被认为是一个 循环神经网络 。
很多循环神经网络 使用式 (10.5)或类似的公式定义 隐藏单元 的值。为了表明状
态是网络的 隐藏单元 ，我们使用变量 h代表状态重写式 (10.4)：
h(t)=f(h(t 1);x(t);); (10.5)
如图 10.2所示，典型 RNN会增加额外的架构特性，如读取状态信息 h进行预测的
输出层。
ffhhxxh(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)x(t 1)x(t 1)x(t)x(t)x(t+1)x(t+1)h(...)h(...)h(...)h(...)ffUnfoldfffff
图10.2:没有输出的 循环网络 。此循环网络 只处理来自输入 x的信息，将其合并到经过时间向前
传播的状态 h。(左)回路原理图。黑色方块表示单个 时间步的延迟。 (右)同一网络被视为展开的
计算图，其中每个节点现在与一个特定的时间实例相关联。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.1展开计算图 321
当训练循环网络 根据过去预测未来时，网络通常要学会使用 h(t)作为过去序列
（直到 t）与任务相关方面的有损摘要。此摘要一般而言一定是有损的，因为其映射
任意长度的序列 (x(t);x(t 1);x(t 2); : : : ; x(2);x(1))到一固定长度的向量 h(t)。根据不
同的训练 准则，摘要可能选择性地精确保留过去序列的某些方面。例如，如果在统
计语言建模中使用的 RNN，通常给定前一个词预测下一个词，可能没有必要存储时
刻t前输入序列中的所有信息；而仅仅存储足够预测句子其余部分的信息。最苛刻
的情况是我们要求 h(t)足够丰富，并能大致恢复输入序列，如 自编码器 框架（第 十
四章） 。
式(10.5)可以用两种不同的方式绘制。一种方法是为可能在模型的物理实现中
存在的部分赋予一个节点，如生物神经网络。在这个观点下，网络定义了实时操作
的回路，如图 10.2的左侧，其当前状态可以影响其未来的状态。在本章中，我们使用
回路图的黑色方块表明在时刻 t的状态到时刻 t+ 1的状态单个时刻延迟中的相互作
用。另一个绘制 RNN的方法是展开的 计算图，其中每一个组件由许多不同的变量表
示，每个 时间步一个变量，表示在该时间点组件的状态。每个 时间步的每个变量绘
制为计算图的一个独立节点，如图 10.2的右侧。我们所说的 展开是将左图中的回路
映射为右图中包含重复组件的 计算图的操作。目前， 展开图的大小取决于序列长度。
我们可以用一个函数 g(t)代表经 t步展开后的循环：
h(t)=g(t)(x(t);x(t 1);x(t 2); : : : ; x(2);x(1)) (10.6)
=f(h(t 1);x(t);): (10.7)
函数 g(t)将全部的过去序列 (x(t);x(t 1);x(t 2); : : : ; x(2);x(1))作为输入来生成当前状
态，但是展开的循环架构允许我们将 g(t)分解为函数 f的重复应用。因此，展开过
程引入两个主要优点：
1.无论序列的长度，学成的模型始终具有相同的输入大小，因为它指定的是从一
种状态到另一种状态的 转移，而不是在可变长度的历史状态上操作。
2.我们可以在每个 时间步使用相同参数的 相同转移函数 f。
这两个因素使得学习在所有 时间步和所有序列长度上操作单一的模型 f是可能的，
而不需要在所有可能 时间步学习独立的模型 g(t)。学习单一的共享模型允许泛化到
没有见过的序列长度（没有出现在训练集中） ，并且估计模型所需的训练样本远远少
于不带参数共享 的模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
322 第十章 序列建模：循环和递归网络
无论是循环图和 展开图都有其用途。循环图简洁。 展开图能够明确描述其中的
计算流程。 展开图还通过显式的信息流动路径帮助说明信息在时间上向前（计算输
出和损失）和向后（计算 梯度）的思想。
10.2循环神经网络
基于第 10.1节中的图展开和 参数共享 的思想，我们可以设计各种 循环神经网络 。
UUVVWWo(t 1)o(t 1)hhooyyLL
xxo(t)o(t)o(t+1)o(t+1)L(t 1)L(t 1)L(t)L(t)L(t+1)L(t+1)y(t 1)y(t 1)y(t)y(t)y(t+1)y(t+1)
h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)x(t 1)x(t 1)x(t)x(t)x(t+1)x(t+1)WWWWWWWWh(...)h(...)h(...)h(...)VVVVVVUUUUUUUnfold
图10.3:计算循环网络 (将 x值的输入序列映射到输出值 o的对应序列 )训练损失的计算图。损失
L衡量每个 o与相应的训练目标 y的距离。当使用 softmax 输出时，我们假设 o是未归一化的
对数概率。损失 L内部计算 ^y=softmax (o)，并将其与目标 y比较。 RNN输入到隐藏的连接由
权重矩阵 U参数化，隐藏到隐藏的循环连接由权重矩阵 W参数化以及隐藏到输出的连接由权重
矩阵 V参数化。式 (10.8)定义了该模型中的前向传播。 (左)使用循环连接绘制的 RNN和它的损
失。(右)同一网络被视为展开的计算图，其中每个节点现在与一个特定的时间实例相关联。
循环神经网络 中一些重要的设计模式包括以下几种：
1.每个时间步都有输出，并且 隐藏单元 之间有循环连接的 循环网络 ，如图 10.3所
示。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 323
2.每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的 隐藏单元 之间
有循环连接的 循环网络 ，如图 10.4所示。
3.隐藏单元 之间存在循环连接，但读取整个序列后产生单个输出的 循环网络 ，如
图10.5所示。
图10.3是非常具有代表性的例子，我们将会在本章大部分涉及这个例子。
UVWo(t 1)o(t 1)hhooyyLL
xxo(t)o(t)o(t+1)o(t+1)L(t 1)L(t 1)L(t)L(t)L(t+1)L(t+1)y(t 1)y(t 1)y(t)y(t)y(t+1)y(t+1)
h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)x(t 1)x(t 1)x(t)x(t)x(t+1)x(t+1)WWWWo(...)o(...)h(...)h(...)VVVUUUUnfold
图10.4:此类 RNN的唯一循环是从输出到隐藏层的反馈连接。在每个 时间步 t，输入为 xt，隐藏
层激活为 h(t)，输出为 o(t)，目标为 y(t)，损失为 L(t)。(左)回路原理图。 (右)展开的计算图。这样
的RNN没有图 10.3表示的 RNN那样强大（只能表示更小的函数集合） 。图 10.3中的 RNN可以
选择将其想要的关于过去的任何信息放入隐藏表示 h中并且将 h传播到未来。该图中的 RNN被
训练为将特定输出值放入 o中，并且 o是允许传播到未来的唯一信息。此处没有从 h前向传播的
直接连接。之前的 h仅通过产生的预测间接地连接到当前。 o通常缺乏过去的重要信息，除非它
非常高维且内容丰富。这使得该图中的 RNN不那么强大，但是它更容易训练，因为每个 时间步可
以与其他 时间步分离训练，允许训练期间更多的并行化，如第 10.2.1节所述。
任何图灵可计算的函数都可以通过这样一个有限维的 循环网络 计算，在这
个意义上图 10.3和式 (10.8)的循环神经网络 是万能的。 RNN经过若干 时间步后读
取输出，这与由图灵机所用的 时间步是渐近线性的，与输入长度也是渐近线性
的(Siegelmann and Sontag ,1991;Siegelmann ,1995;Siegelmann and Sontag ,1995;DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
324 第十章 序列建模：循环和递归网络
h(t 1)h(t 1)Wh(t)h(t)......x(t 1)x(t 1)x(t)x(t)x(...)x(...)WWUUUh(⌧)h(⌧)x(⌧)x(⌧)WUo(⌧)o(⌧)y(⌧)y(⌧)L(⌧)L(⌧)V......
图10.5:关于时间展开的 循环神经网络 ，在序列结束时具有单个输出。这样的网络可以用于概括序
列并产生用于进一步处理的固定大小的表示。在结束处可能存在目标（如此处所示） ，或者通过更
下游模块的反向传播来获得输出 o(t)上的梯度。
Hyotyniemi ,1996)。由图灵机计算的函数是离散的，所以这些结果都是函数的具体
实现，而不是近似。 RNN作为图灵机使用时，需要一个二进制序列作为输入，其输
出必须离散化以提供二进制输出。利用单个有限大小的特定 RNN计算在此设置下
的所有函数是可能的（ Siegelmann and Sontag (1995)用了 886个单元） 。图灵机的
‘‘输入’’是要计算函数的详细说明 (speciﬁcation) ，所以模拟此图灵机的相同网络足
以应付所有问题。用于证明的理论 RNN可以通过激活和权重（由无限精度的有理
数表示）来模拟无限堆栈。
现在我们研究图 10.3中RNN的前向传播 公式。这个图没有指定 隐藏单元 的激
活函数。我们假设使用双曲正切激活函数。此外，图中没有明确指定何种形式的输
出和损失函数 。我们假定输出是离散的，如用于预测词或字符的 RNN。表示离散变
量的常规方式是把输出 o作为每个离散变量可能值的非标准化对数概率。然后，我
们可以应用 softmax 函数后续处理后，获得标准化后概率的输出向量 ^y。RNN从特
定的初始状态 h(0)开始前向传播 。从 t= 1到t=的每个时间步，我们应用以下DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 325
更新方程：
a(t)= b+Wh(t 1)+Ux(t); (10.8)
h(t)= tanh (a(t)); (10.9)
o(t)= c+Vh(t); (10.10)
^y(t)=softmax (o(t)); (10.11)
其中的参数的 偏置向量 b和 c连同权重矩阵 U、V和 W，分别对应于输入到隐藏、
隐藏到输出和隐藏到隐藏的连接。这个 循环网络 将一个输入序列映射到相同长度的
输出序列。与 x序列配对的 y的总损失就是所有 时间步的损失之和。例如， L(t)为
给定的 x(1); : : : ; x(t)后 y(t)的负对数似然，则
L(
fx(1); : : : ; x()g;fy(1); : : : ; y()g)
(10.12)
=∑
tL(t)(10.13)
= ∑
tlogpmodel(
y(t)jf x(1); : : : ; x(t)g)
; (10.14)
其中 pmodel(
y(t)jf x(1); : : : ; x(t)g)
需要读取模型输出向量 ^y(t)中对应于 y(t)的项。
关于各个参数计算这个 损失函数 的梯度是计算成本很高的操作。 梯度计算涉及执行
一次前向传播 （如在图 10.3展开图中从左到右的传播） ，接着是由右到左的 反向传
播。运行时间是O()，并且不能通过并行化来降低，因为 前向传播 图是固有循序的 ;
每个时间步只能一前一后地计算。 前向传播 中的各个状态必须保存，直到它们 反向
传播中被再次使用，因此内存代价也是 O()。应用于 展开图且代价为O()的反向
传播算法称为 通过时间反向传播 （back-propagation through time ,BPTT） ，将在
第10.2.2节进一步讨论。因此 隐藏单元 之间存在循环的网络非常强大但训练代价也
很大。我们是否有其他选择呢？
10.2.1 导师驱动过程和输出循环网络
仅在一个 时间步的输出和下一个 时间步的隐藏单元 间存在循环连接的网络（示
于图 10.4）确实没有那么强大（因为缺乏隐藏到隐藏的循环连接） 。例如，它不能模
拟通用图灵机。因为这个网络缺少隐藏到隐藏的循环，它要求输出单元捕捉用于预
测未来的关于过去的所有信息。因为输出单元明确地训练成匹配训练集的目标，它
们不太能捕获关于过去输入历史的必要信息，除非用户知道如何描述系统的全部状DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
326 第十章 序列建模：循环和递归网络
态，并将它作为训练目标的一部分。消除隐藏到隐藏循环的优点在于，任何基于比
较时刻 t的预测和时刻 t的训练目标的 损失函数 中的所有 时间步都解耦了。因此训
练可以并行化，即在各时刻 t分别计算 梯度。因为训练集提供输出的理想值，所以
没有必要先计算前一时刻的输出。
由输出反馈到模型而产生循环连接的模型可用 导师驱动过程 （teacher forcing ）
进行训练。训练模型时， 导师驱动过程 不再使用最大似然 准则，而在时刻 t+ 1接收
真实值 y(t)作为输入。我们可以通过检查两个 时间步的序列得知这一点。条件最大
似然准则是
logp(y(1);y(2)jx(1);x(2)) (10.15)
= logp(y(2)jy(1);x(1);x(2)) + logp(y(1)jx(1);x(2)): (10.16)
在这个例子中， 同时给定迄今为止的 x序列和来自训练集的前一 y值，我们可
以看到在时刻 t= 2时，模型被训练为最大化 y(2)的条件概率。因此最大似然在训
练时指定正确反馈，而不是将自己的输出反馈到模型。如图 10.6所示。
我们使用 导师驱动过程 的最初动机是为了在缺乏隐藏到隐藏连接的模型中避
免通过时间反向传播 。只要模型一个 时间步的输出与下一 时间步计算的值存在连接，
导师驱动过程 仍然可以应用到这些存在隐藏到隐藏连接的模型。然而，只要 隐藏单
元成为较早 时间步的函数， BPTT算法是必要的。因此训练某些模型时要同时使
用导师驱动过程 和BPTT。
如果之后网络在 开环 (open-loop) 模式下使用，即网络输出（或输出分布的样
本）反馈作为输入，那么完全使用 导师驱动过程 进行训练的缺点就会出现。在这种
情况下，训练期间该网络看到的输入与测试时看到的会有很大的不同。减轻此问题
的一种方法是同时使用 导师驱动过程 和自由运行的输入进行训练，例如在展开循环
的输出到输入路径上预测几个步骤的正确目标值。通过这种方式，网络可以学会考
虑在训练时没有接触到的输入条件（如自由运行模式下，自身生成自身） ，以及将状
态映射回使网络几步之后生成正确输出的状态。另外一种方式 (Bengio et al. ,2015b )
是通过随意选择生成值或真实的数据值作为输入以减小训练时和测试时看到的输入
之间的差别。这种方法利用了 课程学习 策略，逐步使用更多生成值作为输入。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 327
o(t 1)o(t 1)o(t)o(t)h(t 1)h(t 1)h(t)h(t)x(t 1)x(t 1)x(t)x(t)WVVUUo(t 1)o(t 1)o(t)o(t)L(t 1)L(t 1)L(t)L(t)y(t 1)y(t 1)y(t)y(t)
h(t 1)h(t 1)h(t)h(t)x(t 1)x(t 1)x(t)x(t)WVVUUTrain timeTest time
图10.6:导师驱动过程 的示意图。 导师驱动过程 是一种训练技术，适用于输出与下一 时间步的隐藏
状态存在连接的 RNN。(左)训练时，我们将训练集中 正确的输出 y(t)反馈到 h(t+1)。(右)当模型
部署后，真正的输出通常是未知的。在这种情况下，我们用模型的输出 o(t)近似正确的输出 y(t)，
并反馈回模型。
10.2.2 计算循环神经网络的梯度
计算循环神经网络 的梯度是容易的。我们可以简单地将第 6.5.6节中的推广 反向
传播算法应用于展开的 计算图，而不需要特殊化的算法。由 反向传播 计算得到的 梯
度，并结合任何通用的基于 梯度的技术就可以训练 RNN。
为了获得 BPTT算法行为的一些直观理解，我们举例说明如何通过 BPTT计算
上述RNN公式（式 (10.8)和式 (10.12 )）的梯度。计算图的节点包括参数 U;V;W;b
和 c，以及以 t为索引的节点序列 x(t);h(t);o(t)和L(t)。对于每一个节点 N，我们
需要基于 N后面的节点的 梯度，递归地计算 梯度∇NL。我们从紧接着最终损失的节
点开始递归：
@L
@L(t)= 1: (10.17)
在这个导数中，我们假设输出 o(t)作为 softmax 函数的参数，我们可以从 softmaxDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
328 第十章 序列建模：循环和递归网络
函数可以获得关于输出概率的向量 ^y。我们也假设损失是迄今为止给定了输入后的
真实目标 y(t)的负对数似然。对于所有 i; t，关于时间步 t输出的梯度∇o(t)L如下：
(∇o(t)L)i=@L
@o(t)
i=@L
@L(t)@L(t)
@o(t)
i= ^y(t)
i 1i;y(t): (10.18)
我们从序列的末尾开始，反向进行计算。在最后的 时间步 ,h()只有 o()作为后续
节点，因此这个 梯度很简单：
∇h()L= V⊤∇o()L: (10.19)
然后，我们可以从时刻 t= 1到t= 1反向迭代，通过时间 反向传播 梯度，注意
h(t)(t <  )同时具有 o(t)和 h(t+1)两个后续节点。因此，它的 梯度由下式计算
∇h(t)L=(@h(t+1)
@h(t))⊤
(∇h(t+1)L) +(@o(t)
@h(t))⊤
(∇o(t)L) (10.20)
= W⊤(∇h(t+1)L)diag(
1 (h(t+1))2)
+V⊤(∇o(t)L); (10.21)
其中 diag(
1 (h(t+1))2)
表示包含元素 1 (h(t+1)
i)2的对角矩阵。这是关于时刻 t+ 1
与隐藏单元 i关联的双曲正切的 Jacobian 。
一旦获得了 计算图内部节点的 梯度，我们就可以得到关于参数节点的 梯度。因
为参数在许多 时间步共享，我们必须在表示这些变量的微积分操作时谨慎对待。我
们希望实现的等式使用第 6.5.6节中的 bprop方法计算 计算图中单一边对 梯度的贡
献。然而微积分中的 ∇ Wf算子，计算 W对于 f的贡献时将 计算图中的所有边都考
虑进去了。为了消除这种歧义，我们定义只在 t时刻使用的虚拟变量 W(t)作为 W
的副本。然后，我们可以使用 ∇W(t)表示权重在 时间步 t对梯度的贡献。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 329
使用这个表示，关于剩下参数的 梯度可以由下式给出：
∇ cL=∑
t(@o(t)
@c)⊤
∇o(t)L=∑
t∇o(t)L; (10.22)
∇ bL=∑
t(@h(t)
@b(t))⊤
∇h(t)L=∑
tdiag(
1 (
h(t))2)
∇h(t)L; (10.23)
∇ VL=∑
t∑
i(@L
@o(t)
i)
∇ Vo(t)
i=∑
t(∇o(t)L)h(t)⊤; (10.24)
∇ WL=∑
t∑
i(@L
@h(t)
i)
∇W(t)h(t)
i (10.25)
=∑
tdiag(
1 (
h(t))2)
(∇h(t)L)h(t 1)⊤; (10.26)
∇ UL=∑
t∑
i(@L
@h(t)
i)
∇U(t)h(t)
i (10.27)
=∑
tdiag(
1 (
h(t))2)
(∇h(t)L)x(t)⊤; (10.28)
因为计算图中定义的损失的任何参数都不是训练数据 x(t)的父节点，所以我们不需
要计算关于它的 梯度。
10.2.3 作为有向图模型的循环网络
目前为止，我们接触的 循环网络 例子中损失 L(t)是训练目标 y(t)和输出 o(t)之
间的交叉熵。与前馈网络 类似，原则上 循环网络 几乎可以使用任何损失。但必须根
据任务来选择损失。如 前馈网络 ，我们通常希望将 RNN的输出解释为一个概率分
布，并且我们通常使用与分布相关联的 交叉熵来定义损失。均方误差是与单位高斯
分布的输出相关联的 交叉熵损失，例如 前馈网络 中所使用的。
当我们使用一个预测性对数似然的训练目标，如式 (10.12 )，我们将 RNN训练
为能够根据之前的输入估计下一个序列元素 y(t)的条件分布。这可能意味着，我们
最大化对数似然
logp(y(t)jx(1); : : : ; x(t)); (10.29)
或者，如果模型包括来自一个 时间步的输出到下一个 时间步的连接，
logp(y(t)jx(1); : : : ; x(t);y(1); : : : ; y(t 1)): (10.30)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
330 第十章 序列建模：循环和递归网络
将整个序列 y的联合分布分解为一系列单步的概率预测是捕获关于整个序列完整
联合分布的一种方法。当我们不把过去的 y值反馈给下一步作为预测的条件时，那
么有向图模型 不包含任何从过去 y(i)到当前 y(t)的边。在这种情况下，输出 y与给
定的 x序列是条件独立的。当我们反馈真实的 y值（不是它们的预测值，而是真正
观测到或生成的值）给网络时，那么 有向图模型 包含所有从过去 y(i)到当前 y(t)的
边。
y(1)y(1)y(2)y(2)y(3)y(3)y(4)y(4)y(5)y(5)y(...)y(...)
图10.7:序列 y(1); y(2); : : : ; y(t); : : :的全连接 图模型。给定先前的值，每个过去的观察值 y(i)可
以影响一些 y(t)(t > i )的条件分布。当序列中每个元素的输入和参数的数目越来越多，根据此图
直接参数化 图模型（如式 (10.6)中）可能是非常低效的。 RNN可以通过高效的参数化获得相同的
全连接，如图 10.8所示。
举一个简单的例子，让我们考虑对标量随机变量序列 Y=fy(1); : : : ; y()g建
模的 RNN，也没有额外的输入 x。在时间步 t的输入仅仅是 时间步 t 1的输出。
该RNN定义了关于 y变量的有向图模型 。我们使用链式法则（用于条件概率的
式(3.6)）参数化这些观察值的联合分布：
P(Y) =P(y(1); : : : ; y()) =∏
t=1P(y(t)jy(t 1);y(t 2); : : : ; y(1)); (10.31)
其中当 t= 1时竖杠右侧显然为空。 因此， 根据这样一个模型， 一组值 fy(1); : : : ; y()g
的负对数似然为
L=∑
tL(t); (10.32)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 331
其中
L(t)= logP(y(t)=y(t)jy(t 1); y(t 2); : : : ; y(1)): (10.33)
y(1)y(1)y(2)y(2)y(3)y(3)y(4)y(4)y(5)y(5)y(...)y(...)h(1)h(1)h(2)h(2)h(3)h(3)h(4)h(4)h(5)h(5)h(...)h(...)
图10.8:在RNN图模型中引入状态变量，尽管它是输入的确定性函数，但它有助于我们根据
式(10.5)获得非常高效的参数化。序列中的每个阶段（对于 h(t)和 y(t)）使用相同的结构（每个
节点具有相同数量的输入） ，并且可以与其他阶段共享相同的参数。
图模型中的边表示哪些变量直接依赖于其他变量。许多 图模型的目标是省略不
存在强相互作用的边以实现统计和计算的效率。例如，我们通常可以作 Markov假设，
即图模型应该只包含从fy(t k); : : : ; y(t 1)g到 y(t)的边，而不是包含整个过去历史
的边。然而，在一些情况下，我们认为整个过去的输入会对序列的下一个元素有一
定影响。当我们认为 y(t)的分布可能取决于遥远过去 (在某种程度 )的 y(i)的值，且
无法通过 y(t 1)捕获 y(i)的影响时， RNN将会很有用。
解释 RNN作为图模型的一种方法是将 RNN视为定义一个结构为完全图的 图模
型，且能够表示任何一对 y值之间的直接联系。图 10.7是关于 y值且具有完全图结
构的图模型。该 RNN完全图的解释基于排除并忽略模型中的 隐藏单元 h(t)。
更有趣的是，将 隐藏单元 h(t)视为随机变量，从而产生 RNN的图模型结构1。
在图模型中包括隐藏单元预示 RNN能对观测的联合分布提供非常有效的参数化。
假设我们用表格表示法来表示离散值上任意的联合分布，即对每个值可能的赋值分
配一个单独条目的数组，该条目表示发生该赋值的概率。如果 y可以取 k个不同的
值，表格表示法将有 O(k)个参数。对比 RNN，由于参数共享 ，RNN的参数数目
为O(1)且是序列长度的函数。我们可以调节 RNN的参数数量来控制模型容量，但
不用被迫与序列长度成比例。式 (10.5)展示了所述 RNN通过循环应用相同的函数 f
以及在每个 时间步的相同参数，有效地参数化的变量之间的长期联系。图 10.8说
1给定这些变量的父变量，其条件分布是确定性的。尽管设计具有这样确定性的 隐藏单元 的图模型是很少见的，但
这是完全合理的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
332 第十章 序列建模：循环和递归网络
明了这个 图模型的解释。在 图模型中结合 h(t)节点可以用作过去和未来之间的中间
量，从而将它们解耦。遥远过去的变量 y(i)可以通过其对 h的影响来影响变量 y(t)。
该图的结构表明可以在 时间步使用相同的条件概率分布有效地参数化模型，并且当
观察到全部变量时，可以高效地评估联合分配给所有变量的概率。
即便使用高效参数化的 图模型，某些操作在计算上仍然具有挑战性。例如，难
以预测序列中缺少的值。
循环网络 为减少的参数数目付出的代价是 优化参数可能变得困难。
在循环网络 中使用的 参数共享 的前提是相同参数可用于不同 时间步的假设。也
就是说，假设给定时刻 t的变量后，时刻 t+ 1变量的条件概率分布是 平稳的
（stationary ） ，这意味着之前的 时间步与下个时间步之间的关系并不依赖于 t。原则
上，可以使用 t作为每个 时间步的额外输入，并让学习器在发现任何时间依赖性的
同时，在不同 时间步之间尽可能多地共享。相比在每个 t使用不同的条件概率分布
已经好很多了，但网络将必须在面对新 t时进行推断。
为了完整描述将 RNN作为图模型的观点，我们必须描述如何从模型采样。我们
需要执行的主要操作是简单地从每一 时间步的条件分布采样。然而，这会导致额外
的复杂性。 RNN必须有某种机制来确定序列的长度。这可以通过多种方式实现。
在当输出是从词汇表获取的符号的情况下，我们可以添加一个对应于序列末端
的特殊符号 (Schmidhuber ,2012)。当产生该符号时，采样过程停止。在训练集中，
我们将该符号作为序列的一个额外成员，即紧跟每个训练样本 x()之后。
另一种选择是在模型中引入一个额外的 Bernoulli 输出，表示在每个 时间步决定
继续生成或停止生成。相比向词汇表增加一个额外符号，这种方法更普遍，因为它
适用于任何 RNN，而不仅仅是输出符号序列的 RNN。例如，它可以应用于一个产
生实数序列的 RNN。新的输出单元通常使用 sigmoid单元，并通过 交叉熵训练。在
这种方法中， sigmoid被训练为最大化正确预测的对数似然，即在每个 时间步序列决
定结束或继续。
确定序列长度 的另一种方法是将一个额外的输出添加到模型并预测整数 本
身。模型可以采出 的值，然后采 步有价值的数据。这种方法需要在每个 时间
步的循环更新中增加一个额外输入，使得循环更新知道它是否是靠近所产生序列的
末尾。这种额外的输入可以是 的值，也可以是  t即剩下时间步的数量。如果
没有这个额外的输入， RNN可能会产生突然结束序列，如一个句子在最终完整前结DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.2循环神经网络 333
束。此方法基于分解
P(x(1); : : : ; x()) =P()P(x(1); : : : ; x()j): (10.34)
直接预测 的例子见 Goodfellow et al. (2014d )。
10.2.4 基于上下文的 RNN序列建模
上一节描述了没有输入 x时，关于随机变量序列 y(t)的RNN如何对应于 有向图
模型。当然，如式 (10.8)所示的 RNN包含一个输入序列 x(1);x(2); : : : ; x()。一般情况
下，RNN允许将图模型的观点扩展到不仅代表 y变量的联合分布也能表示给定 x
后y条件分布。如在第 6.2.1.1节的前馈网络 情形中所讨论的，任何代表变量 P(y;)
的模型都能被解释为代表条件分布 P(yj!)的模型，其中 !=。我们能像之前一
样使用 P(yj!)代表分布 P(yjx)来扩展这样的模型，但要令 !是关于 x的函数。
在RNN的情况，这可以通过不同的方式来实现。此处，我们回顾最常见和最明显的
选择。
之前，我们已经讨论了将 t= 1; : : : ; 的向量 x(t)序列作为输入的 RNN。另一
种选择是只使用单个向量 x作为输入。当 x是一个固定大小的向量时，我们可以简
单地将其看作产生 y序列 RNN的额外输入。将额外输入提供到 RNN的一些常见
方法是：
1.在每个时刻作为一个额外输入，或
2.作为初始状态 h(0)，或
3.结合两种方式。
第一个也是最常用的方法如图 10.9所示。输入 x和每个隐藏单元向量 h(t)之间
的相互作用是通过新引入的权重矩阵 R参数化的，这是只包含 y序列的模型所没有
的。同样的乘积 x⊤R在每个时间步作为隐藏单元 的一个额外输入。我们可以认为 x
的选择（确定 x⊤R值） ，是有效地用于每个 隐藏单元 的一个新 偏置参数。权重与输
入保持独立。我们可以认为这种模型采用了非条件模型的 ，并将!代入，其中
!内的偏置参数现在是输入的函数。
RNN可以接收向量序列 x(t)作为输入，而不是仅接收单个向量 x作为输入。
式(10.8)描述的 RNN对应条件分布 P(y(1); : : : ; y()jx(1); : : : ; x())，并在条件独立DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
334 第十章 序列建模：循环和递归网络
o(t 1)o(t 1)o(t)o(t)o(t+1)o(t+1)L(t 1)L(t 1)L(t)L(t)L(t+1)L(t+1)y(t 1)y(t 1)y(t)y(t)y(t+1)y(t+1)
h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)WWWWs(...)s(...)h(...)h(...)VVVUUU
xxy(...)y(...)
RRRRR
图10.9:将固定长度的向量 x映射到序列 Y上分布的 RNN。这类 RNN适用于很多任务如图注，
其中单个图像作为模型的输入，然后产生描述图像的词序列。观察到的输出序列的每个元素 y(t)
同时用作输入（对于当前 时间步）和训练期间的目标（对于前一 时间步） 。
的假设下这个分布分解为
∏
tP(y(t)jx(1); : : : ; x(t)): (10.35)
为去掉条件独立的假设，我们可以在时刻 t的输出到时刻 t+ 1的隐藏单元 添加连
接，如图 10.10所示。该模型就可以代表关于 y序列的任意概率分布。这种给定一个
序列表示另一个序列分布的模型的还是有一个限制，就是这两个序列的长度必须是
相同的。我们将在第 10.4节描述如何消除这种限制。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.3双向 RNN 335
o(t 1)o(t 1)o(t)o(t)o(t+1)o(t+1)L(t 1)L(t 1)L(t)L(t)L(t+1)L(t+1)y(t 1)y(t 1)y(t)y(t)y(t+1)y(t+1)
h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)WWWWh(...)h(...)h(...)h(...)VVVUUUx(t 1)x(t 1)R
x(t)x(t)x(t+1)x(t+1)RR
图10.10:将可变长度的 x值序列映射到相同长度的 y值序列上分布的条件 循环神经网络 。对比
图10.3，此 RNN包含从前一个输出到当前状态的连接。这些连接允许此 RNN对给定 x的序列后
相同长度的 y序列上的任意分布建模。图 10.3的RNN仅能表示在给定 x值的情况下， y值彼此
条件独立的分布。
10.3双向RNN
目前为止我们考虑的所有 循环神经网络 有一个 ‘‘因果’’结构，意味着在时刻 t的
状态只能从过去的序列 x(1); : : : ; x(t 1)以及当前的输入 x(t)捕获信息。我们还讨论
了某些在 y可用时，允许过去的 y值信息影响当前状态的模型。
然而，在许多应用中，我们要输出的 y(t)的预测可能依赖于整个输入序列。例
如，在语音识别中，由于协同发音，当前声音作为音素的正确解释可能取决于未来
几个音素，甚至潜在的可能取决于未来的几个词，因为词与附近的词之间的存在语
义依赖：如果当前的词有两种声学上合理的解释，我们可能要在更远的未来（和过
去）寻找信息区分它们。这在手写识别和许多其他序列到序列学习的任务中也是如
此，将会在下一节中描述。
双向循环神经网络 （或双向 RNN）为满足这种需要而被发明 (Schuster and
Paliwal ,1997)。他们在需要双向信息的应用中非常成功 (Graves ,2012)，如手写DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
336 第十章 序列建模：循环和递归网络
识别 (Graves et al. ,2008;Graves and Schmidhuber ,2009)，语音识别 (Graves and
Schmidhuber ,2005;Graves et al. ,2013)以及生物信息学 (Baldi et al. ,1999)。
顾名思义，双向 RNN结合时间上从序列起点开始移动的 RNN和另一个时间上
从序列末尾开始移动的 RNN。图10.11展示了典型的双向 RNN，其中 h(t)代表通过
时间向前移动的子 RNN的状态， g(t)代表通过时间向后移动的子 RNN的状态。这
允许输出单元 o(t)能够计算同时依赖于过去和未来且对时刻 t的输入值最敏感的表
示，而不必指定 t周围固定大小的窗口（这是 前馈网络 、卷积网络 或具有固定大小
的先行缓存器的常规 RNN所必须要做的） 。
o(t 1)o(t 1)o(t)o(t)o(t+1)o(t+1)L(t 1)L(t 1)L(t)L(t)L(t+1)L(t+1)y(t 1)y(t 1)y(t)y(t)y(t+1)y(t+1)
h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)x(t 1)x(t 1)x(t)x(t)x(t+1)x(t+1)g(t 1)g(t 1)g(t)g(t)g(t+1)g(t+1)
图10.11:典型的双向 循环神经网络 中的计算，意图学习将输入序列 x映射到目标序列 y（在每个
步骤 t具有损失 L(t)） 。循环性 h在时间上向前传播信息（向右） ，而循环性 g在时间上向后传播
信息（向左） 。因此在每个点 t，输出单元 o(t)可以受益于输入 h(t)中关于过去的相关概要以及输
入 g(t)中关于未来的相关概要。
这个想法可以自然地扩展到 2维输入，如图像，由 四个 RNN组成，每一个沿
着四个方向中的一个计算：上、下、左、右。如果 RNN能够学习到承载长期信息，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.4基于编码 -解码的序列到序列架构 337
那在 2维网格每个点 (i; j)的输出 Oi;j就能计算一个能捕捉到大多局部信息但仍依
赖于长期输入的表示。相比 卷积网络 ，应用于图像的 RNN计算成本通常更高，但允
许同一特征图的特征之间存在长期横向的相互作用 (Visin et al. ,2015;Kalchbrenner
et al. ,2015)。实际上，对于这样的 RNN，前向传播 公式可以写成表示使用卷积的
形式，计算自底向上到每一层的输入（在整合横向相互作用的特征图的循环传播之
前） 。
10.4基于编码 -解码的序列到序列架构
我们已经在图 10.5看到 RNN如何将输入序列映射成固定大小的向量，在
图10.9中看到 RNN如何将固定大小的向量映射成一个序列，在图 10.3、图 10.4、
图10.10和图 10.11中看到 RNN如何将一个输入序列映射到等长的输出序列。
本节我们讨论如何训练 RNN，使其将输入序列映射到不一定等长的输出序列。
这在许多场景中都有应用，如语音识别、机器翻译或问答，其中训练集的输入和输
出序列的长度通常不相同（虽然它们的长度可能相关） 。
我们经常将 RNN的输入称为 ‘‘上下文 ’’。我们希望产生此上下文的表示， C。这
个上下文 C可能是一个概括输入序列 X= ( x(1); : : : ; x(nx))的向量或者向量序列。
用于映射可变长度序列到另一可变长度序列最简单的 RNN架构最初由 Cho
et al. (2014a )提出，之后不久由 Sutskever et al. (2014)独立开发，并且第一个使
用这种方法获得翻译的最好结果。前一系统是对另一个机器翻译系统产生的建
议进行评分，而后者使用独立的 循环网络 生成翻译。这些作者分别将该架构称
为编码 -解码或序列到序列架构，如图 10.12所示。这个想法非常简单： （ 1）编码
器（encoder）或读取器 (reader) 或输入 (input) RNN处理输入序列。 编码器输出
上下文 C（通常是最终隐藏状态的简单函数）。 (2)解码器（decoder）或写入器
(writer) 或输出 (output) RNN则以固定长度的向量（如图 10.9）为条件产生输出
序列 Y= ( y(1); : : : ; y(ny))。这种架构对比本章前几节提出的架构的创新之处在于长
度nx和ny可以彼此不同，而之前的架构约束 nx=ny=。在序列到序列的架构
中，两个 RNN共同训练以最大化 logP(y(1); : : : ; y(ny)jx(1); : : : ; x(nx))(关于训练集
中所有 x和 y对的平均 )。编码器 RNN的最后一个状态 hnx通常被当作输入的表
示C并作为解码器 RNN的输入。
如果上下文 C是一个向量，则 编码器 RNN只是在第 10.2.4节描述的向量到序DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
338 第十章 序列建模：循环和递归网络
Encoder…x(1)x(1)x(2)x(2)x(...)x(...)x(nx)x(nx)
Decoder…y(1)y(1)y(2)y(2)y(...)y(...)y(ny)y(ny)CC
图10.12:在给定输入序列 (x(1);x(2); : : : ; x(nx))的情况下学习生成输出序列 (y(1);y(2); : : : ; y(ny))
的编码器 -解码器或序列到序列的 RNN架构的示例。它由读取输入序列的 编码器 RNN以及生成
输出序列（或计算给定输出序列的概率）的 解码器 RNN组成。编码器 RNN的最终隐藏状态用于
计算一般为固定大小的上下文变量 C，C表示输入序列的语义概要并且作为 解码器 RNN的输入。
列RNN。正如我们所见，向量到序列 RNN至少有两种接受输入的方法。输入可以
被提供为 RNN的初始状态，或连接到每个 时间步中的隐藏单元 。这两种方式也可以
结合。
这里并不强制要求 编码器与解码器的隐藏层具有相同的大小。
此架构的一个明显不足是， 编码器 RNN输出的上下文 C的维度太小而难以适
当地概括一个长序列。这种现象由 Bahdanau et al. (2015)在机器翻译中观察到。他
们提出让 C成为可变长度的序列，而不是一个固定大小的向量。此外，他们还引入
了将序列 C的元素和输出序列的元素相关联的 注意力机制 （attention mechanism ） 。
读者可在第 12.4.5.1节了解更多细节。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.5深度循环网络 339
10.5深度循环网络
大多数 RNN中的计算可以分解成三块参数及其相关的变换：
1.从输入到隐藏状态，
2.从前一隐藏状态到下一隐藏状态，以及
3.从隐藏状态到输出。
根据图 10.3中的 RNN架构，这三个块都与单个权重矩阵相关联。换句话说，当网络
被展开时，每个块对应一个浅的变换。能通过深度 MLP内单个层来表示的变换称为
浅变换。通常，这是由学成的仿射变换和一个固定非线性表示组成的变换。
在这些操作中引入深度会有利的吗？实验证据 (Graves ,2013;Pascanu et al. ,
2014a )强烈暗示理应如此。实验证据与我们需要足够的深度以执行所需映射的想
法一致。读者可以参考 Schmidhuber (1996);El Hihi and Bengio (1996)或Jaeger
(2007a )了解更早的关于深度 RNN的研究。
Graves (2013)第一个展示了将 RNN的状态分为多层的显著好处，如
图10.13 (左)。我们可以认为，在图 10.13 (a)所示层次结构中较低的层起到了将原始
输入转化为对更高层的隐藏状态更合适表示的作用。 Pascanu et al. (2014a )更进一步
提出在上述三个块中各使用一个单独的 MLP（可能是深度的） ，如图 10.13 (b)所示。
考虑表示容量，我们建议在这三个步中都分配足够的容量，但增加深度可能会因为
优化困难而损害学习效果。在一般情况下，更容易优化较浅的架构，加入图 10.13 (b)
的额外深度导致从 时间步 t的变量到 时间步 t+ 1的最短路径变得更长。例如，如果
具有单个隐藏层的 MLP被用于状态到状态的转换，那么与图 10.3相比，我们就会
加倍任何两个不同 时间步变量之间最短路径的长度。然而 Pascanu et al. (2014a )认
为，在隐藏到隐藏的路径中引入 跳跃连接 可以缓和这个问题，如图 10.13 (c)所示。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
340 第十章 序列建模：循环和递归网络
hy
xz
(a)(b)(c)xhy
xhy
图10.13:循环神经网络 可以通过许多方式变得更深 (Pascanu et al. ,2014a )。(a)隐藏循环状态可
以被分解为具有层次的组。 (b)可以向输入到隐藏，隐藏到隐藏以及隐藏到输出的部分引入更深的
计算 (如MLP )。这可以延长链接不同 时间步的最短路径。 (c)可以引入 跳跃连接 来缓解路径延长
的效应。
10.6递归神经网络
递归神经网络2代表循环网络 的另一个扩展，它被构造为深的树状结构而不
是RNN的链状结构， 因此是不同类型的 计算图。 递归网络的典型 计算图如图 10.14所
示。递归神经网络由 Pollack (1990)引入，而 Bottou (2011)描述了这类网络的潜在
用途——学习推论。递归网络已成功地应用于输入是 数据结构 的神经网络 (Frasconi
et al. ,1997,1998)，如自然语言处理 (Socher et al. ,2011a ,c,2013a )和计算机视觉
(Socher et al. ,2011b )。
递归网络的一个明显优势是，对于具有相同长度 的序列，深度（通过非线性
操作的组合数量来衡量）可以急剧地从 减小为O(log)，这可能有助于解决 长期
2我们建议不要将 ‘‘递归神经网络 ’’缩写为 “RNN ’’，以免与 “循环神经网络 ’’混淆。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.6递归神经网络 341
依赖。一个悬而未决的问题是如何以最佳的方式构造树。一种选择是使用不依赖于
数据的树结构，如平衡二叉树。在某些应用领域，外部方法可以为选择适当的树结构
提供借鉴。例如，处理自然语言的句子时，用于递归网络的树结构可以被固定为句
子语法分析树的结构（可以由自然语言语法分析程序提供） (Socher et al. ,2011a ,c)。
理想的情况下，人们希望学习器自行发现和推断适合于任意给定输入的树结构，如
(Bottou ,2011)所建议。
x(1)x(1)x(2)x(2)x(3)x(3)VVVyyLL
x(4)x(4)Voo
UWUWUW
图10.14:递归网络将循环网络的链状计算图推广到树状计算图。 可变大小的序列 x(1);x(2); : : : ; x(t)
可以通过固定的参数集合（权重矩阵 U;V;W）映射到固定大小的表示（输出 o） 。该图展示了 监
督学习的情况，其中提供了一些与整个序列相关的目标 y。
递归网络想法的变种存在很多。例如， Frasconi et al. (1997)和Frasconi et al.
(1998)将数据与树结构相关联，并将输入和目标与树的单独节点相关联。由每个节
点执行的计算无须是传统的人工神经计算（所有输入的仿射变换后跟一个单调非线
性） 。例如， Socher et al. (2013a )提出用张量运算和双线性形式，在这之前人们已
经发现当概念是由连续向量（嵌入）表示时，这种方式有利于建模概念之间的联系DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
342 第十章 序列建模：循环和递归网络
(Weston et al. ,2010;Bordes et al. ,2012)。
10.7长期依赖的挑战
学习循环网络 长期依赖 的数学挑战在第 8.2.5节中引入。根本问题是，经过许多
阶段传播后的 梯度倾向于消失（大部分情况）或爆炸（很少，但对优化过程影响很
大） 。即使我们假设 循环网络 是参数稳定的（可存储记忆，且 梯度不爆炸） ，但 长期依
赖的困难来自比短期相互作用指数小的权重（涉及许多 Jacobian 相乘） 。许多资料提
供了更深层次的讨论 (Hochreiter ,1991a ;Doya ,1993;Bengio et al. ,1994a ;Pascanu
et al. ,2013a )。在这一节中，我们会更详细地描述该问题。其余几节介绍克服这个问
题的方法。
循环网络 涉及相同函数的多次组合，每个 时间步一次。这些组合可以导致极端
非线性行为，如图 10.15所示。
 60 40 20 0 20 40 60
Input coordinate 4 3 2 101234Projection of output0
1
2
3
4
5
图10.15:重复组合函数。当组合许多非线性函数（如这里所示的线性 tanh层）时，结果是高度
非线性的，通常大多数值与微小的导数相关联，也有一些具有大导数的值，以及在增加和减小之
间的多次交替。此处，我们绘制从 100维隐藏状态降到单个维度的线性投影，绘制于 y轴上。 x
轴是 100维空间中沿着随机方向的初始状态的坐标。因此，我们可以将该图视为高维函数的线性
截面。曲线显示每个 时间步之后的函数，或者等价地，转换函数被组合一定次数之后。
特别地， 循环神经网络 所使用的函数组合有点像矩阵乘法。我们可以认为，循DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.7长期依赖的挑战 343
环联系
h(t)= W⊤h(t 1)(10.36)
是一个非常简单的、缺少非线性激活函数和输入 x的循环神经网络 。如第 8.2.5节描
述，这种递推关系本质上描述了幂法。它可以被简化为
h(t)= ( Wt)⊤h(0); (10.37)
而当 W符合下列形式的特征分解
W= QQ⊤; (10.38)
其中 Q正交，循环性可进一步简化为
h(t)= Q⊤tQh(0): (10.39)
特征值提升到 t次后，导致幅值不到一的特征值衰减到零，而幅值大于一的就会激
增。任何不与最大特征向量对齐的 h(0)的部分将最终被丢弃。
这个问题是针对 循环网络 的。在标量情况下，想象多次乘一个权重 w。该乘积
wt消失还是爆炸取决于 w的幅值。然而，如果每个时刻使用不同权重 w(t)的非循
环网络，情况就不同了。如果初始状态给定为 1，那么时刻 t的状态可以由∏
tw(t)
给出。假设 w(t)的值是随机生成的，各自独立，且有 0均值 v方差。乘积的方差
就为O(vn)。为了获得某些期望的方差 v，我们可以选择单个方差为 v=np
v权
重。因此，非常深的 前馈网络 通过精心设计的比例可以避免 梯度消失和爆炸问题，
如Sussillo (2014)所主张的。
RNN梯度消失和爆炸问题是由不同研究人员独立发现 (Hochreiter ,1991a ;
Bengio et al. ,1993,1994a )。有人可能会希望通过简单地停留在 梯度不消失或爆炸的
参数空间来避免这个问题。 不幸的是， 为了储存记忆并对小扰动具有鲁棒性， RNN必
须进入参数空间中的 梯度消失区域 (Bengio et al. ,1993,1994a )。具体来说，每当模
型能够表示 长期依赖 时，长期相互作用的 梯度幅值就会变得指数小（相比短期相互
作用的梯度幅值） 。这并不意味着这是不可能学习的，由于 长期依赖 关系的信号很容
易被短期相关性产生的最小波动隐藏，因而学习 长期依赖 可能需要很长的时间。实
践中， Bengio et al. (1994a )的实验表明，当我们增加了需要捕获的依赖关系的跨度，
基于梯度的优化变得越来越困难， SGD在长度仅为 10或20的序列上成功训练传
统RNN的概率迅速变为 0。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
344 第十章 序列建模：循环和递归网络
将循环网络 作为动力系统更深入探讨的资料见 Doya (1993);Bengio et al.
(1994a );Siegelmann and Sontag (1995)及Pascanu et al. (2013b )的回顾。本章的其
余部分将讨论目前已经提出的降低学习 长期依赖 （在某些情况下，允许一个 RNN学
习横跨数百步的依赖）难度的不同方法，但学习 长期依赖 的问题仍是 深度学习 中的
一个主要挑战。
10.8回声状态网络
从 h(t 1)到 h(t)的循环权重映射以及从 x(t)到 h(t)的输入权重映射是 循环网
络中最难学习的参数。研究者 (Jaeger ,2003;Maass et al. ,2002;Jaeger and Haas ,
2004)提出避免这种困难的方法是设定循环 隐藏单元 ，使其能很好地捕捉过去输入
历史，并且 只学习输出权重 。回声状态网络 （echo state network ）或 ESN (Jaeger
and Haas ,2004;Jaeger ,2007b )，以及流体状态机 （liquid state machine ）(Maass
et al. ,2002)分别独立地提出了这种想法。后者是类似的，只不过它使用脉冲神经元
（二值输出）而不是 ESN中的连续 隐藏单元 。ESN和流体状态机 都被称为 储层计算
（reservoir computing ）(Lukoševičius and Jaeger ,2009)，因为隐藏单元 形成了可能
捕获输入历史不同方面的临时特征池。
储层计算 循环网络 类似于核机器，这是思考它们的一种方式：它们将任意长度
的序列（到时刻 t的输入历史）映射为一个长度固定的向量（循环状态 h(t)） ，之后
可以施加一个线性预测算子（通常是一个 线性回归 ）以解决感兴趣的问题。训练 准
则就可以很容易地设计为输出权重的凸函数。例如，如果输出是从 隐藏单元 到输出
目标的线性回归 ，训练准则就是均方误差 ，由于是凸的就可以用简单的学习算法可
靠地解决 (Jaeger ,2003)。
因此，重要的问题是：我们如何设置输入和循环权重才能让一组丰富的历史可
以在循环神经网络 的状态中表示？ 储层计算 研究给出的答案是将 循环网络 视为动态
系统，并设定让动态系统接近稳定边缘的输入和循环权重。
最初的想法是使状态到状态转换函数的 Jacobian 矩阵的特征值接近 1。如
第8.2.5节解释， 循环网络 的一个重要特征就是 Jacobian 矩阵的特征值谱 J(t)=
@s(t)
@s(t 1)。特别重要的是 J(t)的谱半径（spectral radius ） ，定义为特征值的最大绝对
值。
为了解谱半径的影响，可以考虑 反向传播 中Jacobian 矩阵 J不随 t改变的简单DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.8回声状态网络 345
情况。例如当网络是纯线性时，会发生这种情况。假设 J特征值 对应的特征向量
为 v。考虑当我们通过时间向后传播 梯度向量时会发生什么。如果刚开始的 梯度向量
为 g，然后经过 反向传播 的一个步骤后，我们将得到 Jg，n步之后我们会得到 Jng。
现在考虑如果我们向后传播扰动版本的 g会发生什么。如果我们刚开始是 g+v，
一步之后，我们会得到 J(g+v)。n步之后，我们将得到 Jn(g+v)。由此我们可
以看出，由 g开始的反向传播 和由 g+v开始的反向传播 ，n步之后偏离 Jnv。如
果 v选择为 J特征值 对应的一个单位特征向量，那么在每一步乘 Jacobian 矩阵
只是简单地缩放。 反向传播 的两次执行分离的距离为 jjn。当 v对应于最大特征值
jj，初始扰动为 时这个扰动达到可能的最宽分离。
当jj>1，偏差 jjn就会指数增长。当 jj<1，偏差就会变得指数小。
当然，这个例子假定 Jacobian 矩阵在每个 时间步是相同的，即对应于没有非线
性循环网络 。当非线性存在时，非线性的导数将在许多 时间步后接近零，并有助于
防止因过大的 谱半径而导致的爆炸。事实上，关于 回声状态网络 的最近工作提倡使
用远大于 1的谱半径 (Yildiz et al. ,2012;Jaeger ,2012)。
我们已经说过多次，通过反复矩阵乘法的 反向传播 同样适用于没有非线性的正
向传播的网络，其状态为 h(t+1)= h(t)⊤W。
如果线性映射 W⊤在L2范数的测度下总是缩小 h，那么我们说这个映射是 收
缩（contractive ）的。当 谱半径小于一，则从 h(t)到 h(t+1)的映射是 收缩的，因此小
变化在每个 时间步后变得更小。当我们使用有限精度（如 32位整数）来存储状态向
量时，必然会使得网络忘掉过去的信息。
Jacobian 矩阵告诉我们 h(t)一个微小的变化如何向前一步传播，或等价的，
h(t+1)的梯度如何向后一步传播。需要注意的是， W和 J都不需要是对称的（尽管
它们是实方阵） ，因此它们可能有复的特征值和特征向量，其中虚数分量对应于潜
在的振荡行为（如果迭代地应用同一 Jacobian ） 。即使 h(t)或 h(t)中有趣的小变化
在反向传播 中是实值的，它们仍可以用这样的复数基表示。重要的是，当向量乘以矩
阵时，这些复数基的系数幅值（复数的绝对值）会发生什么变化。幅值大于 1的特
征值对应于放大（如果反复应用则指数增长）或收缩（如果反复应用则指数减小） 。
非线性映射情况时， Jacobian 会在每一步任意变化。因此，动态量变得更加复
杂。然而，一个小的初始变化多步之后仍然会变成一个大的变化。纯线性和非线性
情况的一个不同之处在于使用压缩非线性（如 tanh）可以使循环动态量有界。注意，
即使前向传播 动态量有界， 反向传播 的动态量仍然可能无界，例如，当 tanh序列DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
346 第十章 序列建模：循环和递归网络
都在它们状态中间的线性部分，并且由 谱半径大于 1的权重矩阵连接。然而，所有
tanh单元同时位于它们的线性激活点是非常罕见的。
回声状态网络 的策略是简单地固定权重使其具有一定的 谱半径如3，其中信息
通过时间前向传播，但会由于饱和非线性单元（如 tanh）的稳定作用而不会爆炸。
最近，已经有研究表明，用于设置 ESN权重的技术可以用来 初始化完全可训练
的循环网络 的权重（通过时间 反向传播 来训练隐藏到隐藏的循环权重） ，帮助学习 长
期依赖 (Sutskever ,2012;Sutskever et al. ,2013)。在这种设定下，结合第 8.4节中稀
疏初始化的方案，设置 1:2的初始谱半径表现不错。
10.9渗漏单元和其他多时间尺度的策略
处理长期依赖 的一种方法是设计工作在多个时间尺度的模型，使模型的某些部
分在细粒度时间尺度上操作并能处理小细节，而其他部分在粗时间尺度上操作并能
把遥远过去的信息更有效地传递过来。存在多种同时构建粗细时间尺度的策略。这
些策略包括在时间轴增加 跳跃连接 ，“渗漏单元 ’’使用不同时间常数整合信号，并去
除一些用于建模细粒度时间尺度的连接。
10.9.1 时间维度的跳跃连接
增加从遥远过去的变量到目前变量的直接连接是得到粗时间尺度的一种方法。
使用这样 跳跃连接 的想法可以追溯到 Lin et al. (1996)，紧接是向 前馈网络 引入延迟
的想法 (Lang and Hinton ,1988)。在普通的 循环网络 中，循环从时刻 t的单元连接
到时刻 t+ 1单元。构造较长的延迟 循环网络 是可能的 (Bengio et al. ,1991)。
正如我们在第 8.2.5节看到， 梯度可能关于时间步数 呈指数消失或爆炸。 (Lin
et al. ,1996)引入了 d延时的循环连接以减轻这个问题。现在导数指数减小的速度与

d相关而不是 。既然同时存在延迟和单步连接， 梯度仍可能成 t指数爆炸。这允许
学习算法捕获更长的依赖性，但不是所有的 长期依赖 都能在这种方式下良好地表示。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.9渗漏单元和其他多时间尺度的策略 347
10.9.2 渗漏单元和一系列不同时间尺度
获得导数乘积接近 1的另一方式是设置 线性自连接单元，并且这些连接的权重
接近 1。
我们对某些 v值应用更新 (t) (t 1)+ (1 )v(t)累积一个滑动平均值 (t)，
其中 是一个从 (t 1)到(t)线性自连接的例子。当 接近 1时，滑动平均值能记
住过去很长一段时间的信息，而当 接近 0，关于过去的信息被迅速丢弃。线性自连
接的隐藏单元 可以模拟滑动平均的行为。这种 隐藏单元 称为渗漏单元 （leaky unit ） 。
d时间步的跳跃连接 可以确保单元总能被先前的 d个时间步值影响。使用权重
接近 1的线性自连接是确保该单元可以访问过去值的不同方式。线性自连接通过调
节实值 更平滑灵活地调整这种效果，而不是调整整数值的跳跃长度。
这个想法由 Mozer (1992)和El Hihi and Bengio (1996)提出。在 回声状态网
络中，渗漏单元 也被发现很有用 (Jaeger et al. ,2007)。
我们可以通过两种基本策略设置 渗漏单元 使用的时间常数。一种策略是手动将
其固定为常数，例如在初始化时从某些分布采样它们的值。另一种策略是使时间常
数成为自由变量，并学习出来。在不同时间尺度使用这样的 渗漏单元 似乎能帮助学
习长期依赖 (Mozer ,1992;Pascanu et al. ,2013a )。
10.9.3 删除连接
处理长期依赖 另一种方法是在多个时间尺度组织 RNN状态的想法 (El Hihi and
Bengio ,1996)，信息在较慢的时间尺度上更容易长距离流动。
这个想法与之前讨论的时间维度上的 跳跃连接 不同，因为它涉及主动 删除长度
为一的连接并用更长的连接替换它们。以这种方式修改的单元被迫在长时间尺度上
运作。而通过时间 跳跃连接 是添加边。收到这种新连接的单元，可以学习在长时间
尺度上运作，但也可以选择专注于自己其他的短期连接。
强制一组循环单元在不同时间尺度上运作有不同的方式。一种选择是使循环
单元变成 渗漏单元 ，但不同的单元组关联不同的固定时间尺度。这由 Mozer (1992)
提出，并被成功应用于 Pascanu et al. (2013a )。另一种选择是使显式且离散的更新
发生在不同的时间，不同的单元组有不同的频率。这是 El Hihi and Bengio (1996)
和Koutnik et al. (2014)的方法。它在一些基准数据集上表现不错。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
348 第十章 序列建模：循环和递归网络
10.10长短期记忆和其他门控 RNN
本文撰写之时，实际应用中最有效的序列模型称为 门控 RNN（gated RNN ） 。
包括基于 长短期记忆 （long short-term memory ）和基于 门控循环单元 （gated
recurrent unit ）的网络。
像渗漏单元 一样，门控 RNN想法也是基于生成通过时间的路径，其中导数既不
消失也不发生爆炸。 渗漏单元 通过手动选择常量的连接权重或参数化的连接权重来
达到这一目的。 门控 RNN将其推广为在每个 时间步都可能改变的连接权重。
渗漏单元 允许网络在较长持续时间内 积累信息（诸如用于特定特征或类的线
索） 。然而，一旦该信息被使用，让 神经网络 遗忘旧的状态可能是有用的。例如，如
果一个序列是由子序列组成，我们希望 渗漏单元 能在各子序列内积累线索，我们需
要将状态设置为 0以忘记旧状态的的机制。我们希望 神经网络 学会决定何时清除状
态，而不是手动决定。这就是 门控 RNN要做的事。
10.10.1 LSTM
引入自循环的巧妙构思，以产生 梯度长时间持续流动的路径是初始 长短期记忆
（long short-term memory ,LSTM）模型的核心贡献 (Hochreiter and Schmidhuber ,
1997)。其中一个关键扩展是使自循环的权重视上下文而定，而不是固定的 (Gers
et al. ,2000)。门控此自循环（由另一个 隐藏单元 控制）的权重，累积的时间尺度可
以动态地改变。在这种情况下，即使是具有固定参数的 LSTM，累积的时间尺度也
可以因输入序列而改变，因为时间常数是模型本身的输出。 LSTM已经在许多应用
中取得重大成功，如无约束手写识别 (Graves and Schmidhuber ,2009)、语音识别
(Graves et al. ,2013;Graves and Jaitly ,2014)、手写识别 (Graves et al. ,2013)、机
器翻译 (Sutskever et al. ,2014)、为图像生成标题 (Kiros et al. ,2014b ;Vinyals et al. ,
2014b ;Xuet al. ,2015)和解析 (Vinyals et al. ,2014a )。
LSTM块如图 10.16所示。在浅 循环网络 的架构下，相应的 前向传播 公式如下。
更深的架构也被成功应用 (Graves et al. ,2013;Pascanu et al. ,2014a )。LSTM循
环网络除了外部的 RNN循环外，还具有内部的 “LSTM细胞’’循环（自环） ，因
此LSTM不是简单地向输入和循环单元的仿射变换之后施加一个逐元素的非线性。
与普通的 循环网络 类似，每个单元有相同的输入和输出，但也有更多的参数和控制
信息流动的 门控单元系统。最重要的组成部分是状态单元 s(t)
i，与前一节讨论的 渗漏DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.10长短期记忆和其他门控 RNN 349
×inputinput gateforget gateoutput gateoutput
stateself-loop×+×
图10.16: LSTM循环网络 ‘‘细胞’’的框图。细胞彼此循环连接，代替一般 循环网络 中普通的 隐藏
单元。这里使用常规的人工神经元计算输入特征。如果 sigmoid输入门允许，它的值可以累加到状
态。状态单元具有线性自循环，其权重由 遗忘门控制。细胞的输出可以被输出门关闭。所有 门控单
元都具有 sigmoid 非线性，而输入单元可具有任意的压缩非线性。状态单元也可以用作 门控单元
的额外输入。黑色方块表示单个 时间步的延迟。
单元有类似的线性自环。然而，此处自环的权重（或相关联的时间常数）由 遗忘门
（forget gate ）f(t)
i控制（时刻 t和细胞 i） ，由 sigmoid单元将权重设置为 0和1之
间的值：
f(t)
i=(
bf
i+∑
jUf
i;jx(t)
j+∑
jWf
i;jh(t 1)
j)
; (10.40)
其中 x(t)是当前输入向量， ht是当前隐藏层向量， ht包含所有 LSTM细胞的输出。
bf;Uf;Wf分别是偏置、输入权重和 遗忘门的循环权重。因此 LSTM细胞内部状态DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
350 第十章 序列建模：循环和递归网络
以如下方式更新，其中有一个条件的自环权重 f(t)
i：
s(t)
i=f(t)
is(t 1)
i +g(t)
i(
bi+∑
jUi;jx(t)
j+∑
jWi;jh(t 1)
j)
; (10.41)
其中 b;U;W分别是 LSTM细胞中的 偏置、输入权重和 遗忘门的循环权重。 外部输
入门 (external input gate) 单元 g(t)
i以类似遗忘门（使用 sigmoid获得一个 0和1之
间的值）的方式更新，但有自身的参数：
g(t)
i=(
bg
i+∑
jUg
i;jx(t)
j+∑
jWg
i;jh(t 1)
j)
: (10.42)
LSTM细胞的输出 h(t)
i也可以由 输出门 (output gate) q(t)
i关闭（使用 sigmoid单元
作为门控） ：
h(t)
i=tanh(
s(t)
i)
q(t)
i; (10.43)
q(t)
i=(
bo
i+∑
jUo
i;jx(t)
j+∑
jWo
i;jh(t 1)
j)
; (10.44)
其中 bo;Uo;Wo分别是偏置、输入权重和 遗忘门的循环权重。在这些变体中，可以
选择使用细胞状态 s(t)
i作为额外的输入（及其权重） ，输入到第 i个单元的三个门，
如图 10.16所示。这将需要三个额外的参数。
LSTM网络比简单的循环架构更易于学习 长期依赖 ，先是用于测试 长期依
赖学习能力的人工数据集 (Bengio et al. ,1994b ;Hochreiter and Schmidhuber ,1997;
Hochreiter et al. ,2001)，然后是在具有挑战性的序列处理任务上获得最先进的表现
(Graves ,2012,2013;Sutskever et al. ,2014)。LSTM的变体和替代也已经被研究和
使用，这将在下文进行讨论。
10.10.2 其他门控 RNN
LSTM架构中哪些部分是真正必须的？还可以设计哪些其他成功架构允许网络
动态地控制时间尺度和不同单元的遗忘行为？
最近关于 门控 RNN的工作给出了这些问题的某些答案，其单元也被称为 门控循
环单元或GRU (Cho et al. ,2014c ;Chung et al. ,2014,2015a ;Jozefowicz et al. ,2015;
Chrupala et al. ,2015)。与 LSTM的主要区别是，单个 门控单元同时控制遗忘因子DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.11优化长期依赖 351
和更新状态单元的决定。更新公式如下：
h(t)
i=u(t 1)
ih(t 1)
i + (1 u(t 1)
i)(
bi+∑
jUi;jx(t)
j+∑
jWi;jr(t 1)
jh(t 1)
j)
;(10.45)
其中 u代表 ‘‘更新’’门， r表示 ‘‘复位’’门。它们的值就如通常所定义的：
u(t)
i=(
bu
i+∑
jUu
i;jx(t)
j+∑
jWu
i;jh(t)
j)
; (10.46)
和
r(t)
i=(
br
i+∑
jUr
i;jx(t)
j+∑
jWr
i;jh(t)
j)
: (10.47)
复位和更新门能独立地 ‘‘忽略’’状态向量的一部分。更新门像条件渗漏累积器一样可
以线性门控任意维度，从而选择将它复制（在 sigmoid的一个极端）或完全由新的
‘‘目标状态 ’’值（朝向渗漏累积器的收敛方向）替换并完全忽略它（在另一个极端） 。
复位门控制当前状态中哪些部分用于计算下一个目标状态，在过去状态和未来状态
之间引入了附加的非线性效应。
围绕这一主题可以设计更多的变种。例如复位门（或 遗忘门）的输出可以在
多个隐藏单元 间共享。或者，全局门的乘积（覆盖一整组的单元，例如整一层）和
一个局部门（每单元）可用于结合全局控制和局部控制。然而，一些调查发现这
些LSTM和GRU架构的变种，在广泛的任务中难以明显地同时击败这两个原始架
构(Greﬀ et al. ,2015;Jozefowicz et al. ,2015)。Greﬀ et al. (2015)发现其中的关键因
素是遗忘门，而Jozefowicz et al. (2015)发现向 LSTM遗忘门加入 1的偏置(由Gers
et al. (2000)提倡)能让 LSTM变得与已探索的最佳变种一样健壮。
10.11优化长期依赖
我们已经在第 8.2.5节和第 10.7节中描述过在许多 时间步上优化 RNN时发生
的梯度消失和爆炸的问题。
由Martens and Sutskever (2011)提出了一个有趣的想法是，二阶导数可能在一
阶导数消失的同时消失。二阶优化算法可以大致被理解为将一阶导数除以二阶导数
（在更高维数，由 梯度乘以 Hessian的逆） 。如果二阶导数与一阶导数以类似的速率
收缩，那么一阶和二阶导数的比率可保持相对恒定。不幸的是，二阶方法有许多缺DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
352 第十章 序列建模：循环和递归网络
点，包括高的计算成本、需要一个大的 小批量、并且倾向于被吸引到鞍点。 Martens
and Sutskever (2011)发现采用二阶方法的不错结果。之后， Sutskever et al. (2013)
发现使用较简单的方法可以达到类似的结果，例如经过谨慎初始化的 Nesterov 动量
法。更详细的内容参考 Sutskever (2012)。应用于 LSTM时，这两种方法在很大程
度上会被单纯的 SGD（甚至没有动量）取代。这是 机器学习 中一个延续的主题，设
计一个易于优化模型通常比设计出更加强大的优化算法更容易。
10.11.1 截断梯度
如第 8.2.4节讨论，强非线性函数（如由许多 时间步计算的循环网络 ）往往倾向
于非常大或非常小幅度的 梯度。如图 8.3和图 10.17所示，我们可以看到， 目标函数
（作为参数的函数）存在一个伴随 ‘‘悬崖’’的‘‘地形’’：宽且相当平坦区域被 目标函
数变化快的小区域隔开，形成了一种悬崖。
这导致的困难是，当参数 梯度非常大时， 梯度下降的参数更新可以将参数抛出
很远，进入 目标函数 较大的区域，到达当前解所作的努力变成了无用功。 梯度告诉
我们，围绕当前参数的无穷小区域内最速下降的方向。这个无穷小区域之外， 代价
函数可能开始沿曲线背面而上。更新必须被选择为足够小，以避免过分穿越向上的
曲面。我们通常使用衰减速度足够慢的学习率，使连续的步骤具有大致相同的学习
率。适合于一个相对线性的地形部分的步长经常在下一步进入地形中更加弯曲的部
分时变得不适合，会导致上坡运动。
一个简单的解决方案已被从业者使用多年： 截断梯度 （clipping the gradient ） 。
此想法有不同实例 (Mikolov ,2012;Pascanu et al. ,2013a )。一种选择是在参数更新
之前，逐元素地截断小批量产生的参数 梯度 (Mikolov ,2012)。另一种是在参数更新
之前截断梯度 g的范数∥g∥(Pascanu et al. ,2013a )：
if∥g∥> v (10.48)
g gv
∥g∥; (10.49)
其中 v是范数上界， g用来更新参数。因为所有参数（包括不同的参数组，如权重
和偏置）的梯度被单个缩放因子联合重整化，所以后一方法具有的优点是保证了每
个步骤仍然是在 梯度方向上的，但实验表明两种形式类似。虽然参数更新与真实 梯
度具有相同的方向 梯度，经过梯度范数截断，参数更新的向量范数现在变得有界。这
种有界梯度能避免执行 梯度爆炸时的有害一步。事实上，当 梯度大小高于阈值时，即DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.11优化长期依赖 353
w
bJ(w;b)
Without clipping
w
bJ(w;b)
With clipping
图10.17:梯度截断 在有两个参数 w和 b的循环网络 中的效果示例。 梯度截断 可以使梯度下降 在
极陡峭的悬崖附近更合理地执行。这些陡峭的悬崖通常发生在 循环网络 中，位于 循环网络 近似线性
的附近。悬崖在 时间步的数量上呈指数地陡峭，因为对于每个 时间步，权重矩阵都自乘一次。 (左)
没有梯度截断 的梯度下降 越过这个小峡谷的底部，然后从悬崖面接收非常大的梯度。大梯度灾难
性地将参数推到图的轴外。 (右)使用梯度截断 的梯度下降 对悬崖的反应更温和。当它上升到悬崖
面时，步长受到限制，使得它不会被推出靠近解的陡峭区域。经 Pascanu et al. (2013a )许可改编
此图。
使是采取简单的 随机步骤 往往工作得几乎一样好。如果爆炸非常严重， 梯度数值上
为Inf或Nan（无穷大或不是一个数字） ，则可以采取大小为 v的随机一步，通常
会离开数值不稳定的状态。截断每 小批量梯度范数不会改变单个 小批量的梯度方向。
然而，许多 小批量使用范数截断 梯度后的平均值不等同于截断真实 梯度（使用所有
的实例所形成的 梯度）的范数。大导数范数的样本，和像这样的出现在同一 小批量的
样本，其对最终方向的贡献将消失。不像传统 小批量梯度下降，其中真实 梯度的方
向是等于所有 小批量梯度的平均。换句话说，传统的 随机梯度下降 使用梯度的无偏
估计，而与使用范数截断的 梯度下降引入了经验上是有用的启发式 偏置。通过逐元
素截断，更新的方向与真实 梯度或小批量的梯度不再对齐，但是它仍然是一个下降
方向。还有学者提出 (Graves ,2013)（相对于隐藏单元）截断 反向传播 梯度，但没有
公布与这些变种之间的比较 ;我们推测，所有这些方法表现类似。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
354 第十章 序列建模：循环和递归网络
10.11.2 引导信息流的正则化
梯度截断 有助于处理爆炸的 梯度，但它无助于消失的 梯度。为了解决消失的 梯
度问题并更好地捕获 长期依赖 ，我们讨论了如下想法：在展开循环架构的 计算图中，
沿着与弧度相关联的 梯度乘积接近 1的部分创建路径。在第 10.10节中已经讨论过，
实现这一点的一种方法是使用 LSTM以及其他自循环和 门控机制。另一个想法是 正
则化或约束参数，以引导 ‘‘信息流 ’’。特别是即使 损失函数 只对序列尾部的输出作惩
罚，我们也希望 梯度向量∇h(t)L在反向传播 时能维持其幅度。形式上，我们要使
(∇h(t)L)@h(t)
@h(t 1)(10.50)
与
∇h(t)L (10.51)
一样大。在这个目标下， Pascanu et al. (2013a )提出以下正则项：
Ω =∑
t((∇h(t)L)@h(t)
@h(t 1)
∥∇h(t)L∥ 1)2
: (10.52)
计算这一 梯度的正则项可能会出现困难，但 Pascanu et al. (2013a )提出可以将后向
传播向量∇h(t)L考虑为恒值作为近似（为了计算正则化的目的，没有必要通过它们
向后传播） 。使用该正则项的实验表明，如果与标准的启发式截断（处理梯度爆炸）
相结合，该正则项可以显著地增加 RNN可以学习的依赖跨度。 梯度截断 特别重要，
因为它保持了爆炸 梯度边缘的 RNN动态。如果没有 梯度截断 ，梯度爆炸将阻碍学习
的成功。
这种方法的一个主要弱点是，在处理数据冗余的任务时如 语言模型 ，它并不
像LSTM一样有效。
10.12外显记忆
智能需要知识并且可以通过学习获取知识，这已促使大型深度架构的发展。然
而，知识是不同的并且种类繁多。有些知识是隐含的、潜意识的并且难以用语言表
达——比如怎么行走或狗与猫的样子有什么不同。其他知识可以是明确的、可陈述
的以及可以相对简单地使用词语表达——每天常识性的知识，如 ‘‘猫是一种动物 ’’，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.12外显记忆 355
或者为实现自己当前目标所需知道的非常具体的事实，如 ‘‘与销售团队会议在 141
室于下午 3:00开始’’。
神经网络 擅长存储隐性知识，但是他们很难记住事实。被存储在 神经网络 参数
中之前， 随机梯度下降 需要多次提供相同的输入，即使如此，该输入也不会被特
别精确地存储。 Graves et al. (2014)推测这是因为 神经网络 缺乏工作存储 (working
memory) 系统，即类似人类为实现一些目标而明确保存和操作相关信息片段的系统。
这种外显记忆组件将使我们的系统不仅能够快速 ‘‘故意’’地存储和检索具体的事实，
也能利用他们循序推论。 神经网络 处理序列信息的需要，改变了每个步骤向网络注
入输入的方式，长期以来推理能力被认为是重要的，而不是对输入做出自动的、直
观的反应 (Hinton ,1990)。
为了解决这一难题， Weston et al. (2014)引入了记忆网络 （memory network ） ，
其中包括一组可以通过寻址机制来访问的记忆单元。 记忆网络 原本需要监督信号
指示他们如何使用自己的记忆单元。 Graves et al. (2014)引入的神经网络图灵机
（neural Turing machine ） ，不需要明确的监督指示采取哪些行动而能学习从记忆单
元读写任意内容，并通过使用基于内容的软注意机制（ 见 Bahdanau et al. (2015)
和第 12.4.5.1节） ，允许端到端的训练。这种软寻址机制已成为其他允许基于 梯度优
化的模拟算法机制的相关架构的标准 (Sukhbaatar et al. ,2015;Joulin and Mikolov ,
2015;Kumar et al. ,2015a ;Vinyals et al. ,2015a ;Grefenstette et al. ,2015)。
每个记忆单元可以被认为是 LSTM和GRU中记忆单元的扩展。不同的是，网
络输出一个内部状态来选择从哪个单元读取或写入，正如数字计算机读取或写入到
特定地址的内存访问。
产生确切整数地址的函数很难优化。为了缓解这一问题， NTM实际同时从多个
记忆单元写入或读取。读取时，它们采取许多单元的加权平均值。写入时，他们对
多个单元修改不同的数值。用于这些操作的系数被选择为集中在一个小数目的单元，
如通过 softmax 函数产生它们。使用这些具有非零导数的权重允许函数控制访问存
储器，从而能使用梯度下降法优化。关于这些系数的 梯度指示着其中每个参数是应
该增加还是减少，但 梯度通常只在接收大系数的存储器地址上变大。
这些记忆单元通常扩充为包含向量，而不是由 LSTM或GRU存储单元所存
储的单个标量。增加记忆单元大小的原因有两个。原因之一是，我们已经增加了访
问记忆单元的成本。我们为产生用于许多单元的系数付出计算成本，但我们预期这
些系数聚集在周围小数目的单元。通过读取向量值，而不是一个标量，我们可以抵DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
356 第十章 序列建模：循环和递归网络
消部分成本。使用向量值的记忆单元的另一个原因是，它们允许 基于内容的寻址
(content-based addressing) ，其中从一个单元读或写的权重是该单元的函数。如果我
们能够生产符合某些但并非所有元素的模式，向量值单元允许我们检索一个完整向
量值的记忆。这类似于人们能够通过几个歌词回忆起一首歌曲的方式。我们可以认
为基于内容的读取指令是说， ‘‘检索一首副歌歌词中带有 ’我们都住在黄色潜水艇 ’的
歌’’。当我们要检索的对象很大时，基于内容的寻址更为有用——如果歌曲的每一个
字母被存储在单独的记忆单元中，我们将无法通过这种方式找到他们。通过比较， 基
于位置的寻址 (location-based addressing) 不允许引用存储器的内容。我们可以认为
基于位置的读取指令是说 ‘‘检索 347档的歌的歌词 ’’。即使当存储单元很小时，基于
位置的寻址通常也是完全合理的机制。
如果一个存储单元的内容在大多数 时间步上会被复制（不被忘记） ，则它包含的
信息可以在时间上向前传播，随时间向后传播的 梯度也不会消失或爆炸。
Task network,controlling the memoryMemory cellsWritingmechanismReadingmechanism
图10.18:具有外显记忆网络的示意图，具备 神经网络图灵机 的一些关键设计元素。在此图中，我
们将模型的 “表示’’部分（ ‘‘任务网络 ’’，这里是底部的循环网络）与存储事实的模型（记忆单元的
集合）的 ‘‘存储器 ’’部分区分开。任务网络学习 ‘‘控制’’存储器，决定从哪读取以及在哪写入（通
过读取和写入机制，由指向读取和写入地址的粗箭头指示） 。
外显记忆的方法在图 10.18说明，其中我们可以看到与存储器耦接的 ‘‘任务神
经网络 ’’。虽然这一任务神经网络可以是前馈或循环的，但整个系统是一个 循环网
络。任务网络可以选择读取或写入的特定内存地址。外显记忆似乎允许模型学习普DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
10.12外显记忆 357
通RNN或LSTM RNN不能学习的任务。这种优点的一个原因可能是因为信息和 梯
度可以在非常长的持续时间内传播（分别在时间上向前或向后） 。
作为存储器单元的加权平均值 反向传播 的替代，我们可以将存储器寻址系数解
释为概率，并随机从一个单元读取 (Zaremba and Sutskever ,2015)。优化离散决策
的模型需要专门的优化算法，这将在第 20.9.1节中描述。目前为止，训练这些做离散
决策的随机架构，仍比训练进行软判决的确定性算法更难。
无论是软（允许 反向传播 ）或随机硬性的，用于选择一个地址的机制与先前
在机器翻译的背景下引入的 注意力机制 形式相同 (Bahdanau et al. ,2015)，这在
第12.4.5.1节中也有讨论。甚至更早之前， 注意力机制 的想法就被引入了 神经网络 ，
在手写生成的情况下 (Graves ,2013)，有一个被约束为通过序列只向前移动的 注意力
机制。在机器翻译和 记忆网络 的情况下，每个步骤中关注的焦点可以移动到一个完
全不同的地方 (相比之前的步骤 )。
循环神经网络 提供了将 深度学习 扩展到序列数据的一种方法。它们是我们的 深
度学习工具箱中最后一个主要的工具。现在我们的讨论将转移到如何选择和使用这
些工具，以及如何在真实世界的任务中应用这些工具。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十一章 实践方法论
要成功地使用深度学习技术，仅仅知道存在哪些算法和解释他们为何有效的原
理是不够的。一个优秀的机器学习实践者还需要知道如何针对具体应用挑选一个合
适的算法以及如何监控，并根据实验反馈改进机器学习系统。在 机器学习 系统的日
常开发中，实践者需要决定是否收集更多的数据、增加或减少模型 容量、添加或删
除正则化项、改进模型的优化、改进模型的近似推断或调试模型的软件实现。尝试
这些操作都需要大量时间，因此确定正确做法，而不盲目猜测尤为重要的。
本书的大部分内容都是关于不同的 机器学习 模型、训练算法和 目标函数 。这可
能给人一种印象——成为 机器学习 专家的最重要因素是了解各种各样的 机器学习 技
术，并熟悉各种不同的数学。在实践中，正确使用一个普通算法通常比草率地使用一
个不清楚的算法效果更好。正确应用一个算法需要掌握一些相当简单的方法论。本
章的许多建议都来自 Ng(2015)。
我们建议参考以下几个实践设计流程：
•确定目标——使用什么样的 误差度量 ，并为此 误差度量 指定目标值。这些目标
和误差度量 取决于该应用旨在解决的问题。
•尽快建立一个 端到端的 的工作流程，包括估计合适的 性能度量 。
•搭建系统，并确定性能瓶颈。检查哪个部分的性能差于预期，以及是否是因
为过拟合、欠拟合，或者数据或软件缺陷造成的。
•根据具体观察反复地进行增量式的改动，如收集新数据、调整 超参数或改进算
法。
我们将使用街景地址号码 转录系统 (Goodfellow et al. ,2014d )作为一个运行示
例。该应用的目标是将建筑物添加到谷歌地图。街景车拍摄建筑物，并记录与每张
358DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.1性能度量 359
建筑照片相关的 GPS坐标。卷积网络 识别每张照片上的地址号码，由谷歌地图数据
库在正确的位置添加该地址。这个商业应用是一个很好的示例，它的开发流程遵循
我们倡导的设计方法。
我们现在描述这个过程中的每一个步骤。
11.1性能度量
确定目标，即使用什么 误差度量 ，是必要的第一步，因为 误差度量 将指导接下
来的所有工作。同时我们也应该了解大概能得到什么级别的目标性能。
值得注意的是对于大多数应用而言，不可能实现绝对零误差。即使你有无限的
训练数据，并且恢复了真正的 概率分布 ，贝叶斯误差 仍定义了能达到的最小 错误率。
这是因为输入特征可能无法包含输出变量的完整信息，或是因为系统可能本质上是
随机的。当然我们还会受限于有限的训练数据。
训练数据的数量会因为各种原因受到限制。当目标是打造现实世界中最好的产
品或服务时，我们通常需要收集更多的数据，但必须确定进一步减少误差的价值，并
与收集更多数据的成本做权衡。数据收集会耗费时间、金钱，或带来人体痛苦（例
如，收集人体医疗测试数据） 。科研中，目标通常是在某个确定 基准下探讨哪个算法
更好，一般会固定 训练集，不允许收集更多的数据。
如何确定合理的性能期望？在学术界，通常我们可以根据先前公布的 基准结果
来估计预期 错误率。在现实世界中，一个应用的 错误率有必要是安全的、具有成本
效益的或吸引消费者的。一旦你确定了想要达到的 错误率，那么你的设计将由如何
达到这个 错误率来指导。
除了需要考虑 性能度量 之外，另一个需要考虑的是度量的选择。我们有几种不
同的性能度量 ，可以用来度量一个含有 机器学习 组件的完整应用的有效性。这些 性
能度量通常不同于训练模型的 代价函数 。如第 5.1.2节所述，我们通常会度量一个系
统的准确率，或等价地， 错误率。
然而，许多应用需要更高级的度量。
有时，一种错误可能会比另一种错误更严重。例如，垃圾邮件检测系统会有两
种错误：将正常邮件错误地归为垃圾邮件，将垃圾邮件错误地归为正常邮件。阻止
正常消息比允许可疑消息通过糟糕得多。我们希望度量某种形式的总 代价，其中拦DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
360 第十一章 实践方法论
截正常邮件比允许垃圾邮件通过的 代价更高，而不是度量垃圾邮件分类的 错误率。
有时，我们需要训练检测某些罕见事件的二元分类器。例如，我们可能会为一
种罕见疾病设计医疗测试。假设每一百万人中只有一人患病。我们只需要让分类器
一直报告没有患者，就能轻易地在检测任务上实现 99:9999 %的正确率。显然，正确
率很难描述这种系统的性能。解决这个问题的方法是度量 精度（precision ）和召回
率（recall） 。精度是模型报告的检测是正确的比率，而 召回率则是真实事件被检测
到的比率。检测器永远报告没有患者，会得到一个完美的 精度，但召回率为零。而
报告每个人都是患者的检测器会得到一个完美的 召回率，但是精度会等于人群中患
有该病的比例（在我们的例子是 0:0001 %，每一百万人只有一人患病） 。当使用 精
度和召回率时，我们通常会画 PR曲线（PR curve ） ，y轴表示精度，x轴表示召
回率。如果检测到的事件发生了，那么分类器会返回一个较高的得分。例如，我们
将前馈网络 设计为检测一种疾病，估计一个医疗结果由特征 x表示的人患病的概率
为^y=P(y= 1jx)。每当这个得分超过某个阈值时，我们报告检测结果。通过调
整阈值，我们能权衡 精度和召回率。在很多情况下，我们希望用一个数而不是曲线
来概括分类器的性能。要做到这一点，我们可以将 精度 p和召回率 r转换为 F分数
（F-score）
F=2pr
p+r: (11.1)
另一种方法是报告 PR曲线下方的总面积。
在一些应用中， 机器学习 系统可能会拒绝做出判断。如果 机器学习 算法能够估
计所作判断的置信度，这将会非常有用，特别是在错误判断会导致严重危害，而人工
操作员能够偶尔接管的情况下。街景 转录系统 可以作为这种情况的一个示例。这个
任务是识别照片上的地址号码，将照片拍摄地点对应到地图上的地址。如果地图是
不精确的，那么地图的价值会严重下降。因此只在转录正确的情况下添加地址十分
重要。如果 机器学习 系统认为它不太能像人一样正确地转录，那么最好办法当然是
让人来转录照片。当然，只有当 机器学习 系统能够大量降低需要人工操作处理的图
片时，它才是有用的。在这种情况下，一种自然的 性能度量 是覆盖（coverage） 。覆
盖是机器学习 系统能够产生响应的样本所占的比率。我们权衡 覆盖和精度。一个系
统可以通过拒绝处理任意样本的方式来达到 100 %的精度，但是覆盖降到了 0%。对
于街景任务，该项目的目标是达到人类级别的转录 精度，同时保持 95%的覆盖。在
这项任务中，人类级别的性能是 98%的精度。
还有许多其他的 性能度量 。例如，我们可以度量点击率、收集用户满意度调查DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.2默认的基准模型 361
等等。许多专业的应用领域也有特定的标准。
最重要的是首先要确定改进哪个 性能度量 ，然后专心提高 性能度量 。如果没有
明确的目标，那么我们很难判断 机器学习 系统上的改动是否有所改进。
11.2默认的基准模型
确定性能度量 和目标后，任何实际应用的下一步是尽快建立一个合理的 端到端
的系统。本节给出了一些关于在不同情况下使用哪种算法作为第一个 基准方法推荐。
在本节中，我们提供了关于不同情况下使用哪种算法作为第一 基准方法的推荐。值
得注意的是， 深度学习 研究进展迅速，所以本书出版后很快可能会有更好的默认算
法。
根据问题的复杂性，项目开始时可能无需使用 深度学习 。如果只需正确地选择
几个线性权重就可能解决问题，那么项目可以开始于一个简单的统计模型，如 逻辑
回归。
如果问题属于 “AI-完全’’类的，如 对象识别 、语音识别 、机器翻译 等等，那么
项目开始于一个合适的 深度学习 模型，效果会比较好。
首先，根据数据的结构选择一类合适的模型。如果项目是以固定大小的向量作
为输入的 监督学习 ，那么可以使用全连接的 前馈网络 。如果输入有已知的拓扑结构
（例如，输入是图像） ，那么可以使用 卷积网络 。在这些情况下，刚开始可以使用某
些分段线性单元（ ReLU或者其扩展，如 Leaky ReLU 、PReLU和maxout） 。如果输
入或输出是一个序列，可以使用 门控循环网络 （LSTM或GRU） 。
具有衰减 学习率以及动量的SGD是优化算法一个合理的选择（流行的衰减方
法有，衰减到固定最低 学习率的线性衰减、指数衰减，或每次发生验证错误停滞时
将学习率降低 2 10倍，这些衰减方法在不同问题上好坏不一） 。另一个非常合理
的选择是 Adam算法。批标准化 对优化性能有着显著的影响，特别是对 卷积网络 和
具有 sigmoid非线性函数的网络而言。虽然在最初的 基准中忽略批标准化 是合理的，
然而当优化似乎出现问题时，应该立刻使用 批标准化 。
除非训练集包含数千万以及更多的样本，否则项目应该在一开始就包含一些
温和的正则化。提前终止 也被普遍采用。 Dropout 也是一个很容易实现，且兼容很
多模型和训练算法的出色 正则化项 。批标准化 有时也能降低 泛化误差 ，此时可以省
略Dropout 步骤，因为用于标准化变量的统计量估计本身就存在 噪声。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
362 第十一章 实践方法论
如果我们的任务和另一个被广泛研究的任务相似，那么通过复制先前研究中已
知性能良好的模型和算法，可能会得到很好的效果。甚至可以从该任务中复制一个
训练好的模型。例如，通常会使用在 ImageNet 上训练好的 卷积网络 的特征来解决其
他计算机视觉 任务 (Girshick et al. ,2015)。
一个常见问题是项目开始时是否使用 无监督学习 ，我们将在第三部分进一步探
讨这个问题。这个问题和特定领域有关。在某些领域，比如 自然语言处理 ，能够大大
受益于无监督学习 技术，如学习 无监督词嵌入。在其他领域，如 计算机视觉 ，除非是
在半监督的设定下（ 标注样本数量很少） (Kingma et al. ,2014;Rasmus et al. ,2015)，
目前无监督学习 并没有带来益处。如果应用所在环境中， 无监督学习 被认为是很重
要的，那么将其包含在第一个 端到端的 基准中。否则，只有在解决 无监督问题时，才
会第一次尝试时使用 无监督学习 。在发现初始 基准过拟合的时候，我们可以尝试加
入无监督学习 。
11.3决定是否收集更多数据
在建立第一个 端到端的 系统后，就可以度量算法性能并决定如何改进算法。许
多机器学习 新手都忍不住尝试很多不同的算法来进行改进。然而，收集更多的数据
往往比改进学习算法要有用得多。
怎样判断是否要收集更多的数据？首先，确定 训练集上的性能是否可接受。如
果模型在 训练集上的性能就很差，学习算法都不能在 训练集上学习出良好的模型，
那么就没必要收集更多的数据。反之，可以尝试增加更多的网络层或每层增加更多
的隐藏单元 ，以增加模型的规模。此外，也可以尝试调整 学习率等超参数的措施来
改进学习算法。如果更大的模型和仔细调试的优化算法效果不佳，那么问题可能源
自训练数据的 质量。数据可能含太多 噪声，或是可能不包含预测输出所需的正确输
入。这意味着我们需要重新开始，收集更干净的数据或是收集特征更丰富的数据集。
如果训练集上的性能是可接受的，那么我们开始度量 测试集上的性能。如果 测试
集上的性能也是可以接受的，那么就顺利完成了。如果 测试集上的性能比 训练集的要
差得多，那么收集更多的数据是最有效的解决方案之一。这时主要的考虑是收集更
多数据的代价和可行性，其他方法降低 测试误差 的代价和可行性，和增加数据数量
能否显著提升 测试集性能。在拥有百万甚至上亿用户的大型网络公司，收集大型数
据集是可行的，并且这样做的成本可能比其他方法要少很多，所以答案几乎总是收DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.4选择超参数 363
集更多的训练数据。例如，收集大型 标注数据集是解决 对象识别 问题的主要因素之
一。在其他情况下，如医疗应用，收集更多的数据可能代价很高或者不可行。一个可
以替代的简单方法是降低模型大小或是改进 正则化（调整超参数，如权重衰减 系数，
或是加入 正则化策略，如 Dropout） 。如果调整 正则化超参数后，训练集性能和测试
集性能之间的差距还是不可接受，那么收集更多的数据是可取的。
在决定是否收集更多的数据时，也需要确定收集多少数据。如图 5.4所示，绘制
曲线显示 训练集规模和泛化误差 之间的关系是很有帮助的。根据走势延伸曲线，可
以预测还需要多少训练数据来达到一定的性能。通常，加入总数目一小部分的样本
不会对泛化误差 产生显著的影响。因此，建议在对数尺度上考虑 训练集的大小，例
如在后续的实验中倍增样本数目。
如果收集更多的数据是不可行的，那么改进 泛化误差 的唯一方法是改进学习算
法本身。这属于研究领域，并非对应用实践者的建议。
11.4选择超参数
大部分深度学习 算法都有许多 超参数来控制不同方面的算法表现。有些 超参
数会影响算法运行的时间和存储成本。有些 超参数会影响学习到的模型质量，以及
在新输入上推断正确结果的能力。
有两种选择 超参数的基本方法：手动选择和自动选择。手动选择 超参数需要了
解超参数做了些什么，以及 机器学习 模型如何才能取得良好的 泛化。自动选择 超参
数算法大大减少了解这些想法的需要，但它们往往需要更高的计算成本。
11.4.1 手动调整超参数
手动设置 超参数，我们必须了解 超参数、训练误差 、泛化误差 和计算资源（内存
和运行时间）之间的关系。这需要切实了解一个学习算法有效 容量的基础概念，如
第五章所描述的。
手动搜索 超参数的目标通常是最小化受限于运行时间和内存预算的 泛化误差 。
我们不去探讨如何确定各种 超参数对运行时间和内存的影响，因为这高度依赖于平
台。
手动搜索 超参数的主要目标是调整模型的有效 容量以匹配任务的复杂性。有DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
364 第十一章 实践方法论
效容量受限于三个因素：模型的表示 容量、学习算法成功最小化训练模型 代价函数 的
能力以及 代价函数 和训练过程 正则化模型的程度。具有更多网络层，每层有更多 隐
藏单元的模型具有较高的表示能力——能够表示更复杂的函数。然而，如果训练算
法不能找到某个合适的函数来最小化训练 代价，或是正则化项（如权重衰减 ）排除
了这些合适的函数，那么即使模型的表达能力较高，也不能学习出合适的函数。
当泛化误差 以某个超参数为变量，作为函数绘制出来时，通常会表现为 U形曲
线，如图 5.3所示。在某个极端情况下， 超参数对应着低 容量，并且泛化误差 由于训
练误差较大而很高。这便是 欠拟合的情况。另一种极端情况， 超参数对应着高 容量，
并且泛化误差 由于训练误差 和测试误差 之间的差距较大而很高。最优的模型 容量位
于曲线中间的某个位置，能够达到最低可能的 泛化误差 ，由某个中等的 泛化误差 和
某个中等的 训练误差 相加构成。
对于某些 超参数，当超参数数值太大时，会发生 过拟合。例如中间层 隐藏单元 的
数量，增加数量能提高模型的 容量，容易发生 过拟合。对于某些 超参数，当超参数数
值太小时，也会发生 过拟合。例如，最小的 权重衰减 系数允许为零，此时学习算法具
有最大的有效 容量，反而容易 过拟合。
并非每个 超参数都能对应着完整的 U形曲线。很多 超参数是离散的，如中间层
单元数目或是 maxout单元中线性元件的数目，这种情况只能沿曲线探索一些点。有
些超参数是二值的。通常这些 超参数用来指定是否使用学习算法中的一些可选部分，
如预处理步骤减去均值并除以标准差来标准化输入特征。这些 超参数只能探索曲线
上的两点。其他一些 超参数可能会有最小值或最大值，限制其探索曲线的某些部分。
例如，权重衰减 系数最小是零。这意味着，如果 权重衰减 系数为零时模型 欠拟合，那
么我们将无法通过修改 权重衰减 系数探索 过拟合区域。换言之，有些 超参数只能减
少模型容量。
学习率可能是最重要的 超参数。如果你只有时间调整一个 超参数，那就调整 学
习率。相比其他 超参数，它以一种更复杂的方式控制模型的有效 容量——当学习率适
合优化问题时，模型的有效 容量最高，此时 学习率是正确的，既不是特别大也不是
特别小。 学习率关于训练误差 具有 U形曲线，如图 11.1所示。当 学习率过大时， 梯
度下降可能会不经意地增加而非减少 训练误差 。在理想化的二次情况下，如果 学习
率是最佳值的两倍大时，会发生这种情况 (LeCun et al. ,1998a )。当学习率太小，训
练不仅慢，还有可能永久停留在一个很高的 训练误差 。关于这种效应，我们知之甚
少（不会发生于一个凸 损失函数 中） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.4选择超参数 365
10 210 1100
Learning rate (logarithmic scale)012345678Training error
图11.1:训练误差 和学习率之间的典型关系。注意当 学习率大于最优值时误差会有显著的提升。此
图针对固定的训练时间，越小的 学习率有时候可以以一个正比于 学习率减小量的因素来减慢训练
过程。泛化误差 也会得到类似的曲线，由于正则项作用在 学习率过大或过小处比较复杂。由于一个
糟糕的优化从某种程度上说可以避免 过拟合，即使是 训练误差 相同的点也会拥有完全不同的 泛化
误差。
调整学习率外的其他参数时，需要同时监测 训练误差 和测试误差 ，以判断模型
是否过拟合或欠拟合，然后适当调整其 容量。
如果训练集错误率大于目标 错误率，那么只能增加模型 容量以改进模型。如果
没有使用 正则化，并且确信优化算法正确运行，那么有必要添加更多的网络层或 隐
藏单元。然而，令人遗憾的是，这增加了模型的计算代价。
如果测试集错误率大于目标 错误率，那么可以采取两个方法。 测试误差 是训练
误差和测试误差 之间差距与 训练误差 的总和。寻找最佳的 测试误差 需要权衡这些数
值。当训练误差 较小（因此 容量较大） ，测试误差 主要取决于 训练误差 和测试误差 之
间的差距时，通常神经网络效果最好。此时目标是缩小这一差距，使 训练误差 的增
长速率不快于差距减小的速率。要减少这个差距，我们可以改变 正则化超参数，以
减少有效的模型 容量，如添加 Dropout 或权重衰减 策略。通常，最佳性能来自 正则
化得很好的大规模模型，比如使用 Dropout 的神经网络。
大部分超参数可以通过推理其是否增加或减少模型 容量来设置。部分示例如
表11.1所示。
手动调整 超参数时，不要忘记最终目标：提升 测试集性能。加入 正则化只是实现
这个目标的一种方法。只要 训练误差 低，随时都可以通过收集更多的训练数据来减DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
366 第十一章 实践方法论
超参数 容 量何 时
增加原因 注意事项
隐藏单元 数量 增加 增加隐藏单元 数量会增加模
型的表示能力。几乎模型每个操作所需的时
间和内存代价都会随 隐藏单
元数量的增加而增加。
学习率 调至最优 不正确的学习速率，不管是
太高还是太低都会由于优化
失败而导致低有效 容量的模
型。
卷积核宽度 增加 增加卷积核宽度会增加模型
的参数数量。较宽的卷积核导致较窄的输
出尺寸，除非使用隐式零填
充减少此影响，否则会降低
模型容量。较宽的卷积核需
要更多的内存存储参数，并
会增加运行时间，但较窄的
输出会降低内存代价。
隐式零填充 增加 在卷积之前隐式添加零能保
持较大尺寸的 表示。大多数操作的时间和内存代
价会增加。
权重衰减 系数 降低 降低权重衰减 系数使得模型
参数可以自由地变大。
Dropout 比率 降低 较少地丢弃单元可以更多地
让单元彼此 ‘‘协力’’来适应训
练集。
表11.1:各种超参数对模型容量的影响。
少泛化误差 。实践中能够确保学习有效的的暴力方法就是不断提高模型 容量和训练
集的大小，直到解决问题。这种做法增加了训练和推断的计算代价，所以只有在拥
有足够资源时才是可行的。原则上，这种做法可能会因为优化难度提高而失败，但
对于许多问题而言，优化似乎并没有成为一个显著的障碍，当然，前提是选择了合
适的模型。
11.4.2 自动超参数优化算法
理想的学习算法应该是只需要输入一个数据集，就可以输出学习的函数，而不
需要手动调整 超参数。一些流行的学习算法，如 逻辑回归 和支持向量机 ，流行的部DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.4选择超参数 367
分原因是这类算法只有一到两个 超参数需要调整，它们也能表现出不错的性能。有
些情况下，所需调整的 超参数数量较少时，神经网络可以表现出不错的性能；但 超
参数数量有几十甚至更多时，效果会提升得更加明显。当使用者有一个很好的初始
值，例如由在相同类型的应用和架构上具有经验的人确定初始值，或者使用者在相
似问题上具有几个月甚至几年的神经网络 超参数调整经验，那么手动调整 超参数能
有很好的效果。然而，对于很多应用而言，这些起点都不可用。在这些情况下，自动
算法可以找到合适的 超参数。
如果我们仔细想想使用者搜索学习算法合适 超参数的方式，我们会意识到这其
实是一种优化：我们在试图寻找 超参数来优化目标函数 ，例如验证误差，有时还会
有一些约束（如训练时间，内存或识别时间的预算） 。因此，原则上有可能开发出封
装学习算法的 超参数优化 （hyperparameter optimization ）算法，并选择其 超参数，
从而使用者不需要指定学习算法的 超参数。令人遗憾的是， 超参数优化算法往往有
自己的超参数，如学习算法的每个 超参数应该被探索的值的范围。然而，这些次级 超
参数通常很容易选择，这是说，相同的次级 超参数能够很多不同的问题上具有良好
的性能。
11.4.3 网格搜索
当有三个或更少的 超参数时，常见的 超参数搜索方法是 网格搜索 （grid search ） 。
对于每个 超参数，使用者选择一个较小的有限值集去探索。然后，这些 超参数笛卡
尔乘积得到一组组 超参数，网格搜索 使用每组 超参数训练模型。挑选 验证集误差最
小的超参数作为最好的 超参数。如图 11.2所示超参数值的网络。
应该如何选择搜索集合的范围呢？在 超参数是数值（有序）的情况下，每个列
表的最小和最大的元素可以基于先前相似实验的经验保守地挑选出来，以确保最优
解非常可能在所选范围内。通常， 网格搜索 大约会在 对数尺度 （logarithmic scale ）
下挑选合适的值，例如，一个 学习率的取值集合是f0:1;0:01;10 3;10 4;10 5g，或
者隐藏单元 数目的取值集合f50;100;200;500;1000;2000g。
通常重复进行 网格搜索 时，效果会最好。例如，假设我们在集合 f 1;0;1g上网
格搜索超参数 。如果找到的最佳值是 1，那么说明我们低估了最优值 所在的范
围，应该改变搜索格点，例如在集合 f1;2;3g中搜索。如果最佳值是 0，那么我们不
妨通过细化搜索范围以改进估计，在集合 f 0:1;0;0:1g上进行网格搜索 。
网格搜索 带来的一个明显问题是，计算代价会随着 超参数数量呈指数级增长。如DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
368 第十一章 实践方法论
Grid Layout Random LayoutUnimportant parameter
Important parameterUnimportant parameter
Important parameter
Grid Layout Random LayoutUnimportant parameter
Important parameterUnimportant parameter
Important parameter
图11.2:网格搜索 和随机搜索 的比较。为了方便地说明，我们只展示两个 超参数的例子，但是我们
关注的问题中 超参数个数通常会更多。 (左)为了实现 网格搜索 ，我们为每个 超参数提供了一个值
的集合。搜索算法对每一种在这些集合的交叉积中的 超参数组合进行训练。 (右)为了实现 随机搜
索，我们给联合 超参数赋予了一个概率分布。通常 超参数之间是相互独立的。常见的这种分布的选
择是均匀分布或者是对数均匀（从对数均匀分布中抽样，就是对从均匀分布中抽取的样本进行指
数运算）的。然后这些搜索算法从联合的 超参数空间中采样，然后运行每一个样本。 网格搜索 和随
机搜索都运行了 验证集上的误差并返回了最优的解。这个图说明了通常只有一个 超参数对结果有
着重要的影响。在这个例子中，只有水平轴上的 超参数对结果有重要的作用。 网格搜索 将大量的计
算浪费在了指数量级的对结果无影响的 超参数中，相比之下 随机搜索 几乎每次测试都测试了对结
果有影响的每个 超参数的独一无二的值。此图经 Bergstra and Bengio (2011)允许转载。
果有 m个超参数，每个最多取 n个值，那么训练和估计所需的试验数将是 O(nm)。
我们可以并行地进行实验，并且并行要求十分宽松（进行不同搜索的机器之间几乎
没有必要进行通信） 。令人遗憾的是，由于 网格搜索 指数级增长计算代价，即使是并
行，我们也无法提供令人满意的搜索规模。
11.4.4 随机搜索
幸运的是，有一个替代 网格搜索 的方法，并且编程简单，使用更方便，能更快地
收敛到超参数的良好取值： 随机搜索 (Bergstra and Bengio ,2012)。
随机搜索 过程如下。 首先， 我们为每个 超参数定义一个边缘分布， 例如， Bernoulli
分布或范畴分布 （分别对应着二元 超参数或离散超参数） ，或者对数尺度 上的均匀分DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.4选择超参数 369
布（对应着正实值 超参数） 。例如，
log_learning_rate u( 1; 5); (11.2)
learning_rate = 10log_learning_rate; (11.3)
其中， u(a; b)表示区间 (a; b)上均匀采样的样本。 类似地， log_number_of_hidden_units
可以从 u(log(50);log(2000))上采样。
与网格搜索 不同，我们 不需要离散化 超参数的值。这允许我们在一个更大的集
合上进行搜索，而不产生额外的计算代价。实际上，如图 11.2所示，当有几个 超参
数对性能度量 没有显著影响时， 随机搜索 相比于网格搜索 指数级地高效。 Bergstra
and Bengio (2012)进行了详细的研究并发现相比于 网格搜索 ，随机搜索 能够更快地
减小验证集误差（就每个模型运行的试验数而言） 。
与网格搜索 一样，我们通常会重复运行不同版本的 随机搜索 ，以基于前一次运
行的结果改进下一次搜索。
随机搜索 能比网格搜索 更快地找到良好 超参数的原因是，没有浪费的实验，不
像网格搜索 有时会对一个 超参数的两个不同值（给定其他 超参数值不变）给出相同
结果。在 网格搜索 中，其他 超参数将在这两次实验中拥有相同的值，而在 随机搜索 中，
它们通常会具有不同的值。因此，如果这两个值的变化所对应的 验证集误差没有明
显区别的话， 网格搜索 没有必要重复两个等价的实验，而 随机搜索 仍然会对其他 超
参数进行两次独立地探索。
11.4.5 基于模型的超参数优化
超参数搜索问题可以转化为一个优化问题。决策变量是 超参数。优化的 代价是超
参数训练出来的模型在 验证集上的误差。在简化的设定下，可以计算 验证集上可导误
差函数关于 超参数的梯度，然后我们遵循这个梯度更新 (Bengio et al. ,1999;Bengio ,
2000;Maclaurin et al. ,2015)。令人遗憾的是，在大多数实际设定中，这个梯度是
不可用的。这可能是因为其高额的计算代价和存储成本，也可能是因为 验证集误差
在超参数上本质上不可导，例如 超参数是离散值的情况。
为了弥补梯度的缺失，我们可以对 验证集误差建模，然后通过优化该模型来
提出新的 超参数猜想。大部分基于模型的 超参数搜索算法，都是使用贝叶斯回归模
型来估计每个 超参数的验证集误差期望和该期望的不确定性。因此，优化涉及到探
索（探索高度不确定的 超参数，可能带来显著的效果提升，也可能效果很差）和DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
370 第十一章 实践方法论
使用（使用已经确信效果不错的 超参数——通常是先前见过的非常熟悉的 超参数）
之间的权衡。关于 超参数优化的最前沿方法还包括 Spearmint ( Snoek et al. ,2012)，
TPE ( Bergstra et al. ,2011)和SMAC ( Hutter et al. ,2011)。
目前，我们无法明确确定，贝叶斯 超参数优化是否是一个能够实现更好 深度学
习结果或是能够事半功倍的成熟工具。贝叶斯 超参数优化有时表现得像人类专家，
能够在有些问题上取得很好的效果，但有时又会在某些问题上发生灾难性的失误。
看看它是否适用于一个特定的问题是值得尝试的，但目前该方法还不够成熟或可靠。
就像所说的那样， 超参数优化是一个重要的研究领域，通常主要受 深度学习 所需驱
动，但是它不仅能贡献于整个 机器学习 领域，还能贡献于一般的工程学。
大部分超参数优化算法比 随机搜索 更复杂，并且具有一个共同的缺点，在它们
能够从实验中提取任何信息之前，它们需要运行完整的训练实验。相比于人类实践
者手动搜索，考虑实验早期可以收集的信息量，这种方法是相当低效的，因为手动
搜索通常可以很早判断出某组 超参数是否是完全病态的。 Swersky et al. (2014)提出
了一个可以维护多个实验的早期版本算法。在不同的时间点， 超参数优化算法可以
选择开启一个新实验， ‘‘冻结’’正在运行但希望不大的实验，或是 ‘‘解冻’’并恢复早
期被冻结的，但现在根据更多信息后又有希望的实验。
11.5调试策略
当一个机器学习 系统效果不好时，通常很难判断效果不好的原因是算法本身，
还是算法实现错误。由于各种原因， 机器学习 系统很难调试。
在大多数情况下，我们不能提前知道算法的行为。事实上，使用 机器学习 的整
个出发点是，它会发现一些我们自己无法发现的有用行为。如果我们在一个 新的分
类任务上训练一个神经网络，它达到 5%的测试误差 ，我们没法直接知道这是期望
的结果，还是次优的结果。
另一个难点是，大部分 机器学习 模型有多个自适应的部分。如果一个部分失效
了，其他部分仍然可以自适应，并获得大致可接受的性能。例如，假设我们正在训
练多层神经网络，其中参数为权重 W和偏置 b。进一步假设，我们单独手动实现了
每个参数的 梯度下降 规则。而我们在偏置更新时犯了一个错误：
b b ; (11.4)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.5调试策略 371
其中 是学习率。这个错误更新没有使用梯度。它会导致偏置在整个学习中不断变
为负值，对于一个学习算法来说这显然是错误的。然而只是检查模型输出的话，该错
误可能并不是显而易见的。根据输入的分布，权重可能可以自适应地补偿负的偏置。
大部分神经网络的调试策略都是解决这两个难题的一个或两个。我们可以设计
一种足够简单的情况，能够提前得到正确结果，判断模型预测是否与之相符；我们
也可以设计一个测试，独立检查神经网络实现的各个部分。
一些重要的调试检测如下所列。
可视化计算中模型的行为 ：当训练模型检测图像中的对象时，查看一些模型检
测到部分重叠的图像。在训练语音生成模型时，试听一些生成的语音样本。这似乎
是显而易见的，但在实际中很容易只注意量化 性能度量 ，如准确率或对数似然。直
接观察机器学习 模型运行其任务，有助于确定其达到的量化性能数据是否看上去合
理。错误评估模型性能可能是最具破坏性的错误之一，因为它们会使你在系统出问
题时误以为系统运行良好。
可视化最严重的错误 ：大多数模型能够输出运行任务时的某种置信度量。例如，
基于 softmax 函数输出层的分类器给每个类分配一个概率。因此，分配给最有可能
的类的概率给出了模型在其分类决定上的置信估计值。通常，相比于正确预测的概
率最大似然训练会略有高估。但是由于实际上模型的较小概率不太可能对应着正确
的标签，因此它们在一定意义上还是有些用的。通过查看 训练集中很难正确建模的
样本，通常可以发现该数据预处理或者标记方式的问题。例如，街景 转录系统 原本有
个问题是，地址号码检测系统会将图像裁剪得过于紧密，而省略掉了一些数字。然
后转录网络会给这些图像的正确答案分配非常低的概率。将图像排序，确定置信度
最高的错误，显示系统的裁剪有问题。修改检测系统裁剪更宽的图像，从而使整个
系统获得更好的性能，但是转录网络需要能够处理地址号码中位置和范围更大变化
的情况。
根据训练和 测试误差 检测软件 ：我们往往很难确定底层软件是否是正确实现。
训练和测试误差 能够提供一些线索。如果 训练误差 较低，但是 测试误差 较高，那么很
有可能训练过程是在正常运行，但模型由于算法原因 过拟合了。另一种可能是， 测
试误差没有被正确地度量，可能是由于训练后保存模型再重载去度量 测试集时出现
问题，或者是因为测试数据和训练数据预处理的方式不同。如果训练和 测试误差 都
很高，那么很难确定是软件错误，还是由于算法原因模型 欠拟合。这种情况需要进
一步的测试，如下面所述。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
372 第十一章 实践方法论
拟合极小的数据集 ：当训练集上有很大的误差时，我们需要确定问题是真正的 欠
拟合，还是软件错误。通常，即使是小模型也可以保证很好地拟合一个足够小的数
据集。例如，只有一个样本的分类数据可以通过正确设置输出层的偏置来拟合。通
常，如果不能训练一个分类器来正确标注一个单独的样本，或不能训练一个 自编码
器来成功地精准再现一个单独的样本，或不能训练一个生成模型来一致地生成一个
单独的样本，那么很有可能是由于软件错误阻止 训练集上的成功优化。此测试可以
扩展到只有少量样本的小数据集上。
比较反向传播导数和数值导数 ：如果读者正在使用一个需要实现梯度计算的软
件框架，或者在添加一个新操作到求导库中，必须定义它的 bprop方法，那么常见
的错误原因是没能正确地实现梯度表达。验证这些求导正确性的一种方法是比较实
现的自动求导和通过 有限差分 （ﬁnite diﬀerence ）计算的导数。因为
f′(x) = lim
ϵ!0f(x+ϵ) f(x)
ϵ; (11.5)
我们可以使用小的、有限的 ϵ近似导数：
f′(x)f(x+ϵ) f(x)
ϵ: (11.6)
我们可以使用 中心差分 （centered diﬀerence ）提高近似的 准确率：
f′(x)f(x+1
2ϵ) f(x 1
2ϵ)
ϵ: (11.7)
扰动大小 ϵ必须足够大，以确保该扰动不会由于数值计算的有限 精度问题产生舍入
误差。
通常，我们会测试向量值函数 g:Rm!Rn的梯度或 Jacobian 矩阵。令人遗憾
的是，有限差分 只允许我们每次计算一个导数。我们可以使用 有限差分 mn次评估
g的所有偏导数，也可以将该测试应用于一个新函数（在函数 g的输入输出都加上
随机投影） 。例如，我们可以将导数实现的测试用于函数 f(x) = uTg(vx)，其中 u和
v是随机向量。正确计算 f′(x)要求能够正确地通过 g反向传播，但是使用 有限差
分能够高效地计算，因为 f只有一个输入和一个输出。通常，一个好的方法是在多
个 u值和 v值上重复这个测试，可以减少测试忽略了垂直于随机投影的错误的几率。
如果我们可以在复数上进行数值计算，那么使用复数作为函数的输入会有非常
高效的数值方法估算梯度 (Squire and Trapp ,1998)。该方法基于如下观察
f(x+iϵ) =f(x) +iϵf′(x) +O(ϵ2); (11.8)
real(f(x+iϵ)) =f(x) +O(ϵ2);image (f(x+iϵ)
ϵ) =f′(x) +O(ϵ2); (11.9)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.6示例：多位数字识别 373
其中 i=p 1。和上面的实值情况不同，这里不存在消除影响，因为我们对 f在不
同点上计算差分。因此我们可以使用很小的 ϵ，比如 ϵ= 10 150，其中误差 O(ϵ2)对
所有实用目标都是微不足道的。
监控激活函数值和梯度的直方图 ：可视化神经网络在大量训练迭代后（也许是
一个轮）收集到的激活函数值和梯度的统计量往往是有用的。 隐藏单元 的预激活值
可以告诉我们该单元是否饱和，或者它们饱和的频率如何。例如，对于整流器，它
们多久关一次？是否有单元一直关闭？对于双曲正切单元而言，预激活绝对值的平
均值可以告诉我们该单元的饱和程度。在深度网络中，传播梯度的快速增长或快速
消失，可能会阻碍优化过程。最后，比较参数梯度和参数的量级也是有帮助的。正
如(Bottou ,2015)所建议的，我们希望参数在一个 小批量更新中变化的幅度是参数
量值 1%这样的级别，而不是 50%或者 0:001 %（这会导致参数移动得太慢） 。也有
可能是某些参数以良好的步长移动，而另一些停滞。如果数据是稀疏的（比如自然
语言） ，有些参数可能很少更新，检测它们变化时应该记住这一点。
最后，许多 深度学习 算法为每一步产生的结果提供了某种保证。例如，在第三
部分，我们将看到一些使用代数解决优化问题的近似推断算法。通常，这些可以通
过测试它们的每个保证来调试。某些优化算法提供的保证包括， 目标函数 值在算法
的迭代步中不会增加，某些变量的导数在算法的每一步中都是零，所有变量的梯度
在收敛时会变为零。通常，由于舍入误差，这些条件不会在数字计算机上完全成立，
因此调试测试应该包含一些容差参数。
11.6示例：多位数字识别
为了端到端的 说明如何在实践中应用我们的设计方法论，我们从设计 深度学
习组件出发，简单地介绍下街景 转录系统 。显然，整个系统的许多其他组件，如街景
车、数据库设施等等，也是极其重要的。
从机器学习 任务的视角出发，首先这个过程要采集数据。街景车收集原始数据，
然后操作员手动提供标签。转录任务开始前有大量的数据处理工作，包括在转录前
使用其他 机器学习 技术探测房屋号码。
转录项目开始于 性能度量 的选择和对这些度量的期望值。一个重要的总原则是
度量的选择要符合项目的业务目标。因为地图只有是高 准确率时才有用，所以为这
个项目设置高 准确率的要求非常重要。具体地，目标是达到人类水平， 98%的准确DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
374 第十一章 实践方法论
率。这种程度的 准确率并不是总能达到。为了达到这个级别的 准确率，街景转录系
统牺牲了覆盖。因此在保持 准确率 98%的情况下， 覆盖成了这个项目优化的主要 性
能度量。随着卷积网络 的改进，我们能够降低网络拒绝转录输入的置信度阈值，最
终超出了 覆盖 95%的目标。
在选择量化目标后，我们推荐方法的下一步是要快速建立一个合理的 基准系统。
对于视觉任务而言， 基准系统是带有 整流线性单元 的卷积网络 。转录项目开始于一个
这样的模型。当时，使用 卷积网络 输出预测序列并不常见。开始时，我们使用一个尽
可能简单的 基准模型，该模型输出层的第一个实现包含 n个不同的 softmax 单元来
预测 n个字符的序列。我们使用与训练分类任务相同的方式来训练这些 softmax 单
元，独立地训练每个 softmax 单元。
我们建议反复细化这些 基准，并测试每个变化是否都有改进。街景 转录系统 的
第一个变化受激励于 覆盖指标的理论理解和数据结构。具体地，当输出序列的概率
低于某个值 t即p(yjx)< t时，网络拒绝为输入 x分类。最初， p(yjx)的定义是
临时的，简单地将所有 softmax 函数输出乘在一起。这促使我们发展能够真正计算
出合理对数似然的特定输出层和 代价函数 。这种方法使得样本拒绝机制更有效。
此时，覆盖仍低于 90%，但该方法没有明显的理论问题了。因此，我们的方法论
建议综合 训练集和测试集性能，以确定问题是否是 欠拟合或过拟合。在这种情况下，
训练和测试集误差几乎是一样的。事实上，这个项目进行得如此顺利的主要原因是
有数以千万计的 标注样本数据集可用。因为训练和 测试集的误差是如此相似，这表
明要么是这个问题 欠拟合，要么是训练数据的问题。我们推荐的调试策略之一是可
视化模型最糟糕的错误。在这种情况下，这意味着可视化不正确而模型给了最高置
信度的训练集转录结果。结果显示，主要是输入图像裁剪得太紧，有些和地址相关的
数字被裁剪操作除去了。例如，地址 “1849’’的图片可能裁切得太紧，只剩下 “849’’
是可见的。如果我们花费几周时间改进确定裁剪区域的地址号码检测系统的 准确率，
或许也可以解决这个问题。与之不同，项目团队采取了更实际的办法，简单地系统
性扩大裁剪区域的宽度，使其大于地址号码检测系统预测的区域宽度。这种单一改
变将转录系统 的覆盖提高了 10个百分点。
最后，性能提升的最后几个百分点来自调整 超参数。这主要包括在保持一些计
算代价限制的同时加大模型的规模。因为 训练误差 和测试误差 保持几乎相等，所以
明确表明性能不足是由 欠拟合造成的，数据集本身也存在一些问题。
总体来说，转录项目是非常成功的，可以比人工速度更快、代价更低地转录数DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
11.6示例：多位数字识别 375
以亿计的地址。
我们希望本章中介绍的设计原则能带来其他更多类似的成功。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十二章 应用
在本章中，我们将介绍如何使用 深度学习 来解决计算机视觉 、语音识别 、自然
语言处理 以及其他商业领域中的应用。首先我们将讨论在许多最重要的 AI应用中所
需的大规模 神经网络 的实现。接着，我们将回顾 深度学习 已经成功应用的几个特定
领域。尽管 深度学习 的一个目标是设计能够处理各种任务的算法，然而截止目前 深
度学习的应用仍然需要一定程度的特化。例如， 计算机视觉 中的任务对每一个样本
都需要处理大量的输入特征（像素） 。 自然语言处理 任务的每一个输入特征都需要对
大量的可能值（词汇表中的词）建模。
12.1大规模深度学习
深度学习 的基本思想基于 联结主义 ：尽管机器学习 模型中单个生物性的神经元
或者说是单个特征不是智能的，但是大量的神经元或者特征作用在一起往往能够表
现出智能。我们必须着重强调神经元数量必须 很大这个事实。相比 20世纪 80年代，
如今神经网络 的精度以及处理任务的复杂度都有一定提升，其中一个关键的因素就
是网络规模的巨大提升。正如我们在第 1.2.3节中看到的一样，在过去的三十年内，
网络规模是以指数级的速度递增的。然而如今的 人工神经网络 的规模也仅仅和昆虫
的神经系统差不多。
由于规模的大小对于神经网络来说至关重要，因此深度学习需要高性能的硬件
设施和软件实现。
376DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.1大规模深度学习 377
12.1.1 快速的 CPU实现
传统的神经网络 是用单台机器的 CPU来训练的。如今，这种做法通常被视为是
不可取的。现在，我们通常使用 GPU或者许多台机器的 CPU连接在一起进行计
算。在使用这种昂贵配置之前，为论证 CPU无法承担 神经网络 所需的巨大计算量，
研究者们付出了巨大的努力。
描述如何实现高效的数值 CPU代码已经超出了本书的讨论范围，但是我们在
这里还是要强调通过设计一些特定的 CPU上的操作可以大大提升效率。例如，在
2011年，最好的 CPU在训练神经网络 时使用定点运算 能够比浮点运算 跑得更快。
通过调整 定点运算 的实现方式， Vanhoucke et al. (2011)获得了 3倍于一个强 浮点
运算系统的速度。因为各个新型 CPU都有各自不同的特性，所以有时候采用 浮点
运算实现会更快。一条重要的准则就是，通过特殊设计的数值运算，我们可以获得
巨大的回报。除了选择 定点运算 或者浮点运算 以外，其他的策略还包括了如通过优
化数据结构避免高速缓存缺失、使用向量指令等。如果模型规模不会限制模型表现
（不会影响模型精度）时， 机器学习 的研究者们一般忽略这些实现的细节。
12.1.2 GPU 实现
许多现代 神经网络 的实现基于 图形处理器 （Graphics Processing Unit ,GPU） 。
图形处理器 （GPU）最初是为图形应用而开发的专用硬件组件。视频游戏系统的
消费市场刺激了图形处理硬件的发展。它为视频游戏所设计的特性也可以使 神经网
络的计算受益。
视频游戏的渲染要求许多操作能够快速并行地执行。环境和角色模型通过一系
列顶点的 3D坐标确定。为了将大量的 3D坐标转化为 2D显示器上的坐标，显卡必
须并行地对许多顶点执行矩阵乘法与除法。之后，显卡必须并行地在每个像素上执
行诸多计算，来确定每个像素点的颜色。在这两种情况下，计算都是非常简单的，并
且不涉及 CPU通常遇到的复杂的分支运算。例如，同一个刚体内的每个顶点都会乘
上相同的矩阵；也就是说，不需要通过 if语句来判断确定每个顶点需要乘哪个矩
阵。各个计算过程之间也是完全相互独立的，因此能够实现并行操作。计算过程还
涉及处理大量内存缓冲以及描述每一个需要被渲染的对象的纹理（颜色模式）的位
图信息。总的来说，这使显卡设计为拥有高度并行特性以及很高的内存带宽，同时
也付出了一些代价，如相比传统的 CPU更慢的时钟速度以及更弱的处理分支运算DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
378 第十二章 应用
的能力。
与上述的实时图形算法相比， 神经网络 算法所需要的性能特性是相同的。 神经
网络算法通常涉及大量参数、激活值、梯度值的缓冲区，其中每个值在每一次训练迭
代中都要被完全更新。这些缓冲太大，会超出传统的桌面计算机的高速缓存 (cache)，
所以内存带宽通常会成为主要瓶颈。相比 CPU，GPU一个显著的优势是其极高的内
存带宽。 神经网络 的训练算法通常并不涉及大量的分支运算与复杂的控制指令，所
以更适合在 GPU硬件上训练。由于 神经网络 能够被分为多个单独的 ‘‘神经元 ’’，并
且独立于同一层内其他神经元进行处理，所以 神经网络 可以从 GPU的并行特性中
受益匪浅。
GPU硬件最初专为图形任务而设计。随着时间的推移， GPU也变得更灵活，
允许定制的子程序处理转化顶点坐标或者计算像素颜色的任务。原则上， GPU不
要求这些像素值实际基于渲染任务。只要将计算的输出值作为像素值写入缓冲区，
GPU就可以用于科学计算。 Steinkrau et al. (2005)在GPU上实现了一个两层
全连接的 神经网络 ，并获得了相对基于 CPU的基准方法三倍的加速。不久以后，
Chellapilla et al. (2006)也论证了相同的技术可以用来加速 监督卷积网络 的训练。
在通用 GPU发布以后，使用显卡训练 神经网络 的热度开始爆炸性地增长。这
种通用 GPU可以执行任意的代码，而并非仅仅渲染子程序。 NVIDIA 的CUDA
编程语言使得我们可以用一种像 C一样的语言实现任意代码。由于相对简便的编
程模型，强大的并行能力以及巨大的内存带宽， 通用 GPU为我们提供了训练 神经
网络的理想平台。在它发布以后不久，这个平台就迅速被 深度学习 的研究者们所采
纳(Raina et al. ,2009b ;Ciresan et al. ,2010)。
如何在通用 GPU上写高效的代码依然是一个难题。在 GPU上获得良好表现
所需的技术与 CPU上的技术非常不同。比如说，基于 CPU的良好代码通常被设
计为尽可能从高速缓存中读取更多的信息。然而在 GPU中，大多数可写内存位置
并不会被高速缓存，所以计算某个值两次往往会比计算一次然后从内存中读取更
快。GPU代码是天生多线程的，不同线程之间必须仔细协调好。例如，如果能够把
数据级联（coalesced ）起来，那么涉及内存的操作一般会更快。当几个线程同时需
要读/写一个值时，像这样的 级联会作为一次内存操作出现。不同的 GPU可能采用
不同的级联读/写数据的方式。通常来说，如果在 n个线程中，线程 i访问的是第
i+j处的内存，其中 j是2的某个幂的倍数，那么内存操作就易于 级联。具体的设
定在不同的 GPU型号中有所区别。 GPU另一个常见的设定是使一个组中的所有线
程都同时执行同一指令。这意味着 GPU难以执行分支操作。线程被分为一个个称DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.1大规模深度学习 379
作warp的小组。在一个 warp中的每一个线程在每一个循环中执行同一指令，所以
当同一个 warp中的不同线程需要执行不同的指令时，需要使用串行而非并行的方
式。
由于实现高效 GPU代码的困难性，研究人员应该组织好他们的工作流程，避免
对每一个新的模型或算法都编写新的 GPU代码。通常来讲，人们会选择建立一个包
含高效操作（如卷积和矩阵乘法）的软件库解决这个问题，然后再从库中调用所需
要的操作确定模型。例如， 机器学习 库Pylearn2 ( Goodfellow et al. ,2013e )将其所
有的机器学习 算法都通过调用 Theano ( Bergstra et al. ,2010c ;Bastien et al. ,2012a )
和cuda-convnet ( Krizhevsky ,2010)所提供的高性能操作来指定。这种分解方法还
可以简化对多种硬件的支持。例如，同一个 Theano程序可以在 CPU或者 GPU上
运行，而不需要改变调用 Theano的方式。其他库如 Tensorﬂow ( Abadi et al. ,2015)
和Torch ( Collobert et al. ,2011b )也提供了类似的功能。
12.1.3 大规模的分布式实现
在许多情况下，单个机器的计算资源是有限的。因此，我们希望把训练或者推
断的任务分摊到多个机器上进行。
分布式的推断是容易实现的，因为每一个输入的样本都可以在单独的机器上运
行。这也被称为 数据并行 （data parallelism ） 。
同样地， 模型并行 （model parallelism ）也是可行的，其中多个机器共同运行一
个数据点，每一个机器负责模型的一个部分。对于推断和训练，这都是可行的。
在训练过程中， 数据并行 某种程度上来说更加困难对于 随机梯度下降 的单步来
说，我们可以增加 小批量的大小，但是从优化性能的角度来说，我们得到的回报通
常并不会线性增长。使用多个机器并行地计算多个 梯度下降 步骤是一个更好的选择。
不幸的是， 梯度下降 的标准定义完全是一个串行的过程：第 t步的梯度是第 t 1步
所得参数的函数。
这个问题可以使用 异步随机梯度下降 （Asynchoronous Stochastic Gradient
Descent）(Bengio and Bengio ,1996;Recht et al. ,2011)解决。在这个方法中，几个
处理器的核共用存有参数的内存。每一个核在无锁情况下读取这些参数并计算对应
的梯度，然后在无锁状态下更新这些参数。由于一些核把其他的核所更新的参数覆
盖了，因此这种方法减少了每一步 梯度下降 所获得的平均提升。但因为更新步数的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
380 第十二章 应用
速率增加，总体上还是加快了学习过程。 Dean et al. (2012)率先提出了多机器无锁
的梯度下降 方法，其中参数是由 参数服务器 （parameter server ）管理而非存储在共
用的内存中。分布式的异步 梯度下降 方法保留了训练 深度神经网络 的基本策略，并被
工业界很多 机器学习 组所使用 (Chilimbi et al. ,2014;Wu et al. ,2015)。学术界的 深
度学习研究者们通常无法负担那么大规模的分布式学习系统，但是一些研究仍关注
于如何在校园环境中使用相对廉价的硬件系统构造分布式网络 (Coates et al. ,2013)。
12.1.4 模型压缩
在许多商业应用的 机器学习 模型中，一个时间和内存开销较小的推断算法比一
个时间和内存开销较小的训练算法要更为重要。对于那些不需要个性化设计的应用
来说，我们只需要一次性的训练模型，然后它就可以被成千上万的用户使用。在许
多情况下，相比开发者，终端用户的可用资源往往更有限。例如，开发者们可以使
用巨大的计算机集群训练一个 语音识别 的网络，然后将其部署到移动手机上。
减少推断所需开销的一个关键策略是 模型压缩 （model compression ）(Buciluˇ a
et al. ,2006)。模型压缩 的基本思想是用一个更小的模型取代替原始耗时的模型，从
而使得用来存储与评估所需的内存与运行时间更少。
当原始模型的规模很大，且我们需要防止 过拟合时，模型压缩 就可以起到作用。
在许多情况下，拥有最小 泛化误差的模型往往是多个独立训练而成的模型的 集成。
评估所有 n个集成成员的成本很高。有时候，当单个模型很大（例如，如果它使
用Dropout 正则化）时，其 泛化能力也会很好。
这些巨大的模型能够学习到某个函数 f(x)，但选用的参数数量超过了任务所需
的参数数量。只是因为训练样本数是有限的，所以模型的规模才变得必要。只要我
们拟合了这个函数 f(x)，我们就可以通过将 f作用于随机采样点 x来生成有无穷多
训练样本的训练集。然后，我们使用这些样本训练一个新的更小的模型，使其能够
在这些点上拟合 f(x)。为了更加充分地利用了这个新的小模型的 容量，最好从类似
于真实测试数据（之后将提供给模型）的分布中采样 x。这个过程可以通过损坏训
练样本或者从原始训练数据训练的生成模型中采样完成。
此外，我们还可以仅在原始训练数据上训练一个更小的模型，但只是为了复制
模型的其他特征，比如在不正确的类上的后验分布 (Hinton et al. ,2014,2015)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.1大规模深度学习 381
12.1.5 动态结构
一般来说，加速数据处理系统的一种策略是构造一个系统，这个系统用 动态
结构（dynamic structure ）描述图中处理输入的所需计算过程。在给定一个输入的
情况中，数据处理系统可以动态地决定运行神经网络系统的哪一部分。单个神经网
络内部同样也存在 动态结构 ，给定输入信息，决定特征（ 隐藏单元 ）哪一部分用于
计算。这种神经网络中的 动态结构 有时被称为 条件计算 （conditional computation ）
(Bengio et al. ,2013b ,c)。由于模型结构许多部分可能只跟输入的一小部分有关，只
计算那些需要的特征可以起到加速的目的。
动态结构 计算是一种基础的计算机科学方法，广泛应用于软件工程项目。应用
于神经网络的最简单的 动态结构 基于决定神经网络（或者其他 机器学习 模型）中的
哪些子集需要应用于特定的输入。
在分类器中加速推断的可行策略是使用 级联（cascade）的分类器。当目标是检
测罕见对象（或事件）是否存在时，可以应用 级联策略。要确定对象是否存在，我们
必须使用具有高 容量、运行成本高的复杂分类器。然而，因为对象是罕见的，我们通
常可以使用更少的计算拒绝不包含对象的输入。在这些情况下，我们可以训练一序
列分类器。序列中的第一个分类器具有低 容量，训练为具有高 召回率。换句话说，他
们被训练为确保对象存在时，我们不会错误地拒绝输入。最后一个分类器被训练为
具有高精度。在测试时，我们按照顺序运行分类器进行推断，一旦 级联中的任何一
个拒绝它，就选择抛弃。总的来说，这允许我们使用高 容量模型以较高的置信度验
证对象的存在，而不是强制我们为每个样本付出完全推断的成本。有两种不同的方
式可以使得 级联实现高容量。一种方法是使 级联中靠后的成员单独具有高 容量。在
这种情况下，由于系统中的一些个体成员具有高 容量，因此系统作为一个整体显然
也具有高 容量。还可以使用另一种 级联，其中每个单独的模型具有低 容量，但是由
于许多小型模型的组合，整个系统具有高 容量。Viola and Jones (2001)使用级联的
增强决策树实现了适合在手持数字相机中使用的快速并且鲁棒的面部检测器。本质
上，它们的分类器使用滑动窗口方法来定位面部。分类器会检查许多的窗口，如果
这些窗口内不包含面部则被拒绝。 级联的另一个版本使用早期模型来实现一种硬 注
意力机制 ：级联的先遣成员定位对象，并且 级联的后续成员在给定对象位置的情况
下执行进一步处理。例如， Google使用两步 级联从街景视图图像中转换地址编号：
首先使用一个 机器学习 模型查找地址编号，然后使用另一个 机器学习 模型将其转录
(Goodfellow et al. ,2014d )。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
382 第十二章 应用
决策树本身是动态结构 的一个例子，因为树中的每个节点决定应该使用哪个子
树来评估输入。一个结合 深度学习 和动态结构 的简单方法是训练一个 决策树，其中
每个节点使用神经网络做出决策 (Guo and Gelfand ,1992)，虽然这种方法没有实现
加速推断计算的目标。
类似的，我们可以使用称为 选通器（gater）的神经网络来选择在给定当前输入
的情况下将使用几个 专家网络 （expert network ）中的哪一个来计算输出。这个想法
的第一个版本被称为 专家混合体 （mixture of experts ）(Nowlan ,1990;Jacobs et al. ,
1991)，其中选通器为每个专家输出一个概率或权重（通过非线性的 softmax 函数获
得） ，并且最终输出由各个专家输出的加权组合获得。在这种情况下，使用 选通器不
会降低计算成本，但如果每个样本的 选通器选择单个专家，我们就会获得一个特殊
的硬专家混合体 （hard mixture of experts ）(Collobert et al. ,2001,2002)，这可以
加速推断和训练。当 选通器决策的数量很小时，这个策略效果会很好，因为它不是
组合的。但是当我们想要选择不同的单元或参数子集时，不可能使用 ‘‘软开关 ’’，因
为它需要枚举（和计算输出）所有的 选通器配置。为了解决这个问题，许多工作探
索了几种方法来训练组合的 选通器。Bengio et al. (2013c )提出使用 选通器概率梯度
的若干估计器，而 Bacon et al. (2015);Bengio et al. (2015a )使用强化学习 技术（策
略梯度（policy gradient ） ）来学习一种条件的 Dropout 形式（作用于 隐藏单元 块） ，
减少了实际的计算成本，而不会对近似的质量产生负面影响。
另一种动态结构 是开关，其中隐藏单元可以根据具体情况从不同单元接收输
入。这种动态路由方法可以理解为 注意力机制 （attention mechanism ）(Olshausen
et al. ,1993)。目前为止，硬性开关的使用在大规模应用中还没有被证明是有效的。
较为先进的方法一般采用对许多可能的输入使用加权平均，因此不能完全得到 动态
结构所带来的计算益处。先进的 注意力机制 将在第 12.4.5.1节中描述。
使用动态结构化系统的主要障碍是由于系统针对不同输入的不同代码分支导致
的并行度降低。这意味着网络中只有很少的操作可以被描述为对样本 小批量的矩阵
乘法或批量卷积。我们可以写更多的专用子程序，用不同的核对样本做卷积，或者
通过不同的权重列来乘以设计矩阵的每一行。不幸的是，这些专用的子程序难以高
效地实现。由于缺乏高速缓存的一致性， CPU实现会十分缓慢。此外，由于缺乏 级
联的内存操作以及 warp成员使用不同分支时需要串行化操作， GPU的实现也会很
慢。在一些情况下，我们可以通过将样本分成组，并且都采用相同的分支并且同时
处理这些样本组的方式来缓解这些问题。在离线环境中，这是最小化处理固定量样
本所需时间的一项可接受的策略。然而在实时系统中，样本必须连续处理，对工作DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.1大规模深度学习 383
负载进行分区可能会导致负载均衡问题。例如，如果我们分配一台机器处理 级联中
的第一步，另一台机器处理 级联中的最后一步，那么第一台机器将倾向于过载，最
后一个机器倾向于欠载。如果每个机器被分配以实现神经 决策树的不同节点，也会
出现类似的问题。
12.1.6 深度网络的专用硬件实现
自从早期的神经网络研究以来，硬件设计者已经致力于可以加速 神经网络 算法
的训练和 /或推断的专用硬件实现。读者可以查看早期和更近的专用硬件深度网络的
评论 (Lindsey and Lindblad ,1994;Beiu et al. ,2003;Misra and Saha ,2010)。
不同形式的专用硬件 (Graf and Jackel ,1989;Mead and Ismail ,2012;Kim et al. ,
2009;Pham et al. ,2012;Chen et al. ,2014b ,a)的研究已经持续了好几十年，比如 专
用集成电路 （application-speciﬁc integrated circuit ,ASIC）的数字（基于数字的二
进制表示） ，模拟 (Graf and Jackel ,1989;Mead and Ismail ,2012)（基于以电压或电
流表示连续值的物理实现）和混合实现（组合数字和模拟组件） 。近年来更灵活的 现
场可编程门阵列 （ﬁeld programmable gated array ,FPGA）实现（其中电路的具体
细节可以在制造完成后写入芯片）也得到了长足发展。
虽然 CPU和GPU上的软件实现通常使用 32或64位的精度来表示浮点数，但
是长期以来使用较低的精度在更短的时间内完成推断也是可行的 (Holt and Baker ,
1991;Holi and Hwang ,1993;Presley and Haggard ,1994;Simard and Graf ,1994;
Wawrzynek et al. ,1996;Savich et al. ,2007)。这已成为近年来更迫切的问题，因为 深
度学习在工业产品中越来越受欢迎，并且由于更快的硬件产生的巨大影响已经通
过GPU的使用得到了证明。激励当前对深度网络专用硬件研究的另一个因素是单
个CPU或GPU核心的进展速度已经减慢，并且最近计算速度的改进来自于核心的
并行化（无论 CPU还是 GPU） 。这与 20世纪 90年代的情况（上一个神经网络时
代）的不同之处在于， 神经网络 的硬件实现（从开始到芯片可用可能需要两年）跟
不上快速进展和价格低廉的通用 CPU的脚步。因此，在针对诸如手机等低功率设备
开发新的硬件设计，并且想要用于 深度学习 的一般公众应用（例如，具有语音、 计算
机视觉或自然语言功能的设施）等时，研究专用硬件能够进一步推动其发展。
最近对基于 反向传播 神经网络 的低精度实现的工作 (Vanhoucke et al. ,2011;
Courbariaux et al. ,2015;Gupta et al. ,2015)表明， 8和16位之间的精度足以满足
使用或训练基于 反向传播 的深度神经网络 的要求。显而易见的是，在训练期间需要DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
384 第十二章 应用
比在推断时更高的精度，并且数字某些形式的动态定点表示能够减少每个数需要的
存储空间。传统的定点数被限制在了一个固定范围之内（其对应于浮点表示中的给
定指数） 。而动态定点表示在一组数字（例如一个层中的所有权重）之间共享该范
围。使用定点代替浮点表示并且每个数使用较少的比特能够减少执行乘法所需的硬
件表面积、功率需求和计算时间。而乘法已经是使用或训练 反向传播 的现代深度网
络中要求最高的操作。
12.2计算机视觉
一直以来， 计算机视觉 就是深度学习 应用中几个最活跃的研究方向之一。因为
视觉是一个对人类以及许多动物毫不费力，但对计算机却充满挑战的任务 (Ballard
et al. ,1983)。深度学习 中许多流行的标准基准任务包括 对象识别 以及光学字符识别。
计算机视觉 是一个非常广阔的发展领域，其中包括多种多样的处理图片的方式
以及应用方向。 计算机视觉 的应用广泛：从复现人类视觉能力（比如识别人脸）到创
造全新的视觉能力。举个后者的例子，近期一个新的 计算机视觉 应用是从视频中可
视物体的振动中识别相应的声波 (Davis et al. ,2014)。大多数 计算机视觉 领域的深度
学习研究未曾关注过这样一个奇异的应用，它扩展了图像的范围，而不是仅仅关注
于人工智能 中较小的核心目标——复制人类的能力。无论是报告图像中存在哪个物
体，还是给图像中每个对象周围添加注释性的边框，或从图像中转录符号序列，或
给图像中的每个像素标记它所属对象的标识，大多数 计算机视觉 中的深度学习 往往
用于对象识别 或者某种形式的检测。由于 生成模型 已经是深度学习 研究的指导原则，
因此还有大量图像合成工作使用了深度模型。尽管图像合成（ “无中生有 ’’）通常不
包括在计算机视觉 内，但是能够进行图像合成的模型通常用于图像恢复，即修复图
像中的缺陷或从图像中移除对象这样的 计算机视觉 任务。
12.2.1 预处理
由于原始输入往往以 深度学习 架构难以表示的形式出现，许多应用领域需要复
杂精细的预处理。 计算机视觉 通常只需要相对少的这种预处理。图像应该被标准化，
从而使得它们的像素都在相同并且合理的范围内，比如 [0;1]或者 [ 1;1]。将 [0;1]
中的图像与 [0;255]中的图像混合通常会导致失败。将图像格式化为具有相同的比
例严格上说是唯一一种必要的预处理。许多 计算机视觉 架构需要标准尺寸的图像，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.2计算机视觉 385
因此必须裁剪或缩放图像以适应该尺寸。然而，严格地说即使是这种重新调整比例
的操作并不总是必要的。一些卷积模型接受可变大小的输入并动态地调整它们的 池
化区域大小以保持输出大小恒定 (Waibel et al. ,1989)。其他卷积模型具有可变大小
的输出，其尺寸随输入自动缩放，例如对图像中的每个像素进行 去噪或标注的模型
(Hadsell et al. ,2007)。
数据集增强 可以被看作是一种只对训练集做预处理的方式。 数据集增强 是减少
大多数计算机视觉 模型泛化误差的一种极好方法。在测试时可用的一个相关想法是
将同一输入的许多不同版本传给模型（例如，在稍微不同的位置处裁剪的相同图像） ，
并且在模型的不同实例上决定模型的输出。后一个想法可以被理解为集成方法，并
且有助于减少 泛化误差。
其他种类的预处理需要同时应用于训练集和测试集，其目的是将每个样本置于
更规范的形式，以便减少模型需要考虑的变化量。减少数据中的变化量既能够减少 泛
化误差，也能够减小拟合训练集所需模型的大小。更简单的任务可以通过更小的模
型来解决，而更简单的解决方案 泛化能力一般更好。这种类型的预处理通常被设计
为去除输入数据中的某种可变性，这对于人工设计者来说是容易描述的，并且人工
设计者能够保证不受到任务影响。当使用大型数据集和大型模型训练时，这种预处
理通常是不必要的，并且最好只是让模型学习哪些变化性应该保留。例如，用于分
类ImageNet 的AlexNet 系统仅具有一个预处理步骤：对每个像素减去训练样本的
平均值 (Krizhevsky et al. ,2012b )。
12.2.1.1 对比度归一化
在许多任务中，对比度是能够安全移除的最为明显的变化源之一。简单地说，
对比度指的是图像中亮像素和暗像素之间差异的大小。量化图像对比度有许多方式。
在深度学习 中，对比度通常指的是图像或图像区域中像素的 标准差。假设我们有一
个张量表示的图像 X2Rrc3，其中 Xi;j;1表示第 i行第 j列红色的强度， Xi;j;2对
应的是绿色的强度， Xi;j;3对应的是蓝色的强度。然后整个图像的对比度可以表示如
下：
vuut1
3rcr∑
i=1c∑
j=13∑
k=1(Xi;j;k X)2; (12.1)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
386 第十二章 应用
其中 X是整个图片的平均强度，满足
X=1
3rcr∑
i=1c∑
j=13∑
k=1Xi;j;k: (12.2)
全局对比度归一化 （Global contrast normalization ,GCN）旨在通过从每个图
像中减去其平均值，然后重新缩放其使得其像素上的 标准差等于某个常数 s来防止
图像具有变化的对比度。这种方法非常复杂，因为没有缩放因子可以改变零对比度
图像（所有像素都具有相等强度的图像）的对比度。具有非常低但非零对比度的图
像通常几乎没有信息内容。在这种情况下除以真实 标准差通常仅能放大传感器噪声
或压缩伪像。这种现象启发我们引入一个小的正的 正则化参数 来平衡估计的 标准
差。或者，我们至少可以约束分母使其大于等于 ϵ。给定一个输入图像 X，全局对比
度归一化 产生输出图像 X′，定义为
X′
i;j;k=sXi;j;k X
maxfϵ;√
+1
3rc∑r
i=1∑c
j=1∑3
k=1(Xi;j;k X)2g: (12.3)
从大图像中剪切感兴趣的对象所组成的数据集不可能包含任何强度几乎恒定的
图像。在这些情况下，通过设置 = 0来忽略小分母问题是安全的，并且在非常罕
见的情况下为了避免除以 0，通过将 ϵ设置为一个非常小的值比如说 10 8。这也
是Goodfellow et al. (2013c )在CIFAR-10 数据集上所使用的方法。随机剪裁的小图
像更可能具有几乎恒定的强度，使得激进的 正则化更有用。在处理从 CIFAR-10 数
据中随机选择的小区域时， Coates et al. (2011)使用 ϵ= 0; = 10。
尺度参数 s通常可以设置为 1（如 Coates et al. (2011)所采用的） ，或选择使所
有样本上每个像素的 标准差接近 1（如Goodfellow et al. (2013c )所采用的） 。
式(12.3)中的标准差仅仅是对图片 L2范数的重新缩放（假设图像的平均值已经
被移除） 。我们更偏向于根据 标准差而不是 L2范数来定义 GCN，因为标准差包括除
以像素数量这一步，从而基于 标准差的GCN能够使用与图像大小无关的固定的 s。
然而，观察到 L2范数与标准差成比例，这符合我们的直觉。我们可以把 GCN理解
成到球壳的一种映射。图 12.1对此有所说明。这可能是一个有用的属性，因为 神经
网络往往更好地响应空间方向，而不是精确的位置。响应相同方向上的多个距离需
要具有共线权重向量但具有不同偏置的 隐藏单元 。这样的情况对于学习算法来说可
能是困难的。此外，许多浅层的图模型把多个分离的模式表示在一条线上会出现问
题。GCN采用一个样本一个方向1而不是不同的方向和距离来避免这些问题。
1译者：所有样本相似的距离DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.2计算机视觉 387
 1:5 0:0 1:5
x0 1:50:01:5x1Raw input
 1:5 0:0 1:5
x0GCN,= 10 2
 1:5 0:0 1:5
x0GCN,= 0
图12.1: GCN将样本投影到一个球上。 (左)原始的输入数据可能拥有任意的范数。 (中)= 0时
候的 GCN可以完美地将所有的非零样本投影到球上。这里我们令 s= 1，ϵ= 10 8。由于我们
使用的 GCN是基于归一化 标准差而不是 L2范数，所得到的球并不是单位球。 (右) > 0的正则
化GCN将样本投影到球上，但是并没有完全地丢弃其范数中变化。 s和ϵ的取值与之前一样。
与直觉相反的是，存在被称为 sphering 的预处理操作，并且它不同于 GCN。
sphering 并不会使数据位于球形壳上，而是将主成分重新缩放以具有相等方差，
使得 PCA使用的多变量正态分布具有球形等高线。 sphering 通常被称为 白化
（whitening ） 。
全局对比度归一化 常常不能突出我们想要突出的图像特征，例如边缘和角。如
果我们有一个场景，包含了一个大的黑暗区域和一个大的明亮的区域（例如一个城
市广场有一半的区域处于建筑物的阴影之中） ，则 全局对比度归一化 将确保暗区域的
亮度与亮区域的亮度之间存在大的差异。然而，它不能确保暗区内的边缘突出。
这催生了 局部对比度归一化 （local contrast normalization ,LCN）。局部对比
度归一化 确保对比度在每个小窗口上被归一化，而不是作为整体在图像上被归一化。
关于局部对比度归一化 和全局对比度归一化 的比较可以参考图 12.2。
局部对比度归一化 的各种定义都是可行的。在所有情况下，我们可以通过减去邻
近像素的平均值并除以邻近像素的 标准差来修改每个像素。在一些情况下，要计算
以当前要修改的像素为中心的矩形窗口中所有像素的平均值和 标准差 (Pinto et al. ,
2008)。在其他情况下，使用的则是以要修改的像素为中心的高斯权重的加权平均和
加权标准差。在彩色图像的情况下，一些策略单独处理不同的颜色通道，而其他策
略组合来自不同通道的信息以使每个像素归一化 (Sermanet et al. ,2012)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
388 第十二章 应用
Input image GCN LCN
图12.2:全局对比度归一化 和局部对比度归一化 的比较。直观上说， 全局对比度归一化 的效果很巧
妙。它使得所有的图片的尺度都差不多，这减轻了学习算法处理多个尺度的负担。 局部对比度归
一化更多地改变了图像，丢弃了所有相同强度的区域。这使得模型能够只关注于边缘。较好的纹
理区域，如第二行的屋子，可能会由于归一化核的过高带宽而丢失一些细节。
局部对比度归一化 通常可以通过使用可分离卷积（参考第 9.8节）来计算 特征映
射的局部平均值和局部 标准差，然后在不同的 特征映射 上使用逐元素的减法和除法。
局部对比度归一化 是可微分的操作，并且还可以作为一种非线性作用应用于网
络隐藏层，以及应用于输入的预处理操作。
与全局对比度归一化 一样，我们通常需要 正则化局部对比度归一化 来避免出现
除以零的情况。事实上，因为 局部对比度归一化 通常作用于较小的窗口，所以 正则
化更加重要。较小的窗口更可能包含彼此几乎相同的值，因此更可能具有零 标准差。
12.2.2 数据集增强
如第 7.4节中讲到的一样，我们很容易通过增加训练集的额外副本来增加训练
集的大小，进而改进分类器的 泛化能力。这些额外副本可以通过对原始图像进行一
些变化来生成，但是并不改变其类别。 对象识别 这个分类任务特别适合于这种形式
的数据集增强 ，因为类别信息对于许多变换是不变的，而我们可以简单地对输入应
用诸多几何变换。如前所述，分类器可以受益于随机转换或者旋转，某些情况下输
入的翻转可以增强数据集。在专门的 计算机视觉 应用中，存在很多更高级的用以 数
据集增强 的变换。这些方案包括图像中颜色的随机扰动 (Krizhevsky et al. ,2012b )，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.3语音识别 389
以及对输入的非线性几何变形 (LeCun et al. ,2001)。
12.3语音识别
语音识别 任务在于将一段包括了自然语言发音的声学信号投影到对应说话人的
词序列上。令 X= ( x(1);x(2); : : : ; x(T))表示语音的输入向量（传统做法以 20ms为
一帧分割信号） 。许多 语音识别 的系统通过特殊的手工设计方法预处理输入信号，从
而提取特征，但是某些 深度学习 系统 (Jaitly and Hinton ,2011)直接从原始输入中学
习特征。令 y= (y1; y2; : : : ; y N)表示目标的输出序列（通常是一个词或者字符的序
列） 。自动语音识别 （Automatic Speech Recognition ,ASR）任务指的是构造一个函
数f
ASR，使得它能够在给定声学序列 X的情况下计算最有可能的语言序列 y：
f
ASR(X) = arg max
yP(yjX= X); (12.4)
其中 P是给定输入值 X时对应目标 y的真实条件分布。
从20世纪 80年代直到约 2009-2012 年，最先进的 语音识别 系统是隐马尔可夫
模型（Hidden Markov Model ,HMM）和高斯混合模型 （Gaussian Mixture Model ,
GMM）的结合。 GMM对声学特征和 音素（phoneme ）之间的关系建模 (Bahl et al. ,
1987)，HMM对音素序列建模。 GMM -HMM模型将语音信号视作由如下过程生成：
首先，一个 HMM生成了一个 音素的序列以及离散的子 音素状态（比如每一个 音
素的开始，中间，结尾） ，然后 GMM把每一个离散的状态转化为一个简短的声
音信号。尽管直到最近 GMM -HMM一直在 ASR中占据主导地位， 语音识别 仍然
是神经网络 所成功应用的第一个领域。从 20世纪 80年代末期到 90年代初期，大
量语音识别 系统使用了 神经网络 (Bourlard and Wellekens ,1989;Waibel et al. ,1989;
Robinson and Fallside ,1991;Bengio et al. ,1991,1992;Konig et al. ,1996)。当时，基
于神经网络 的ASR的表现和 GMM -HMM系统的表现差不多。比如说， Robinson
and Fallside (1991)在TIMIT数据集 (Garofolo et al. ,1993)（有 39个区分的 音素）
上达到了 26%的音素错误率，这个结果优于或者说是可以与基于 HMM的结果相
比。从那时起， TIMIT成为了音素识别的一个基准数据集，在 语音识别 中的作用就
和MNIST在对象识别 中的作用差不多。然而，由于 语音识别 软件系统中复杂的工
程因素以及在基于 GMM -HMM的系统中已经付出的巨大努力，工业界并没有迫切
转向神经网络 的需求。结果，直到 21世纪 00年代末期，学术界和工业界的研究者
们更多的是用 神经网络 为GMM -HMM系统学习一些额外的特征。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
390 第十二章 应用
之后，随着 更大更深 的模型以及更大的数据集的出现，通过使用 神经网络 代
替GMM来实现将声学特征转化为 音素（或者子 音素状态）的过程可以大大地提高
识别的精度。从 2009年开始， 语音识别 的研究者们将一种 无监督学习 的深度学习 方
法应用于 语音识别 。这种深度学习 方法基于训练一个被称作是 受限玻尔兹曼机 的无
向概率模型，从而对输入数据建模。 受限玻尔兹曼机 将会在第三部分中描述。为了完
成语音识别 任务，无监督的预训练被用来构造一个 深度前馈网络 ，这个神经网络 每
一层都是通过训练 受限玻尔兹曼机 来初始化的。这些网络的输入是从一个固定规格
的输入窗（以当前帧为中心）的谱声学表示抽取，预测了当前帧所对应的 HMM状
态的条件概率。训练一个这样的 神经网络 能够可以显著提高在 TIMIT数据集上的
识别率 (Mohamed et al. ,2009,2012a )，并将音素级别的错误率从大约 26%降到了
20:7%。关于这个模型成功原因的详细分析可以参考 Mohamed et al. (2012b )。对于
基本的电话识别工作流程的一个扩展工作是添加说话人自适应相关特征 (Mohamed
et al. ,2011)的方法，这可以进一步地降低错误率。紧接着的工作则将结构从 音素识
别（TIMIT所主要关注的）转向了大规模词汇语音识别 (Dahl et al. ,2012)，这不仅
包含了识别 音素，还包括了识别大规模词汇的序列。 语音识别 上的深度网络从最初
的使用受限玻尔兹曼机 进行预训练发展到了使用诸如 整流线性单元 和Dropout 这样
的技术 (Zeiler et al. ,2013;Dahl et al. ,2013)。从那时开始，工业界的几个语音研究
组开始寻求与学术圈的研究者之间的合作。 Hinton et al. (2012a )描述了这些合作所
带来的突破性进展，这些技术现在被广泛应用在产品中，比如移动手机端。
随后，当研究组使用了越来越大的带标签的数据集，加入了各种初始化，训练
方法以及调试 深度神经网络 的结构之后，他们发现这种 无监督的预训练方式是没有
必要的，或者说不能带来任何显著的改进。
用语音识别 中词错误率来衡量，在 语音识别 性能上的这些突破是史无前例的
（大约 30%的提高） 。在这之前的长达十年左右的时间内，尽管数据集的规模是随时
间增长的（见 Deng and Yu (2014)的图 2.4） ，但基于 GMM -HMM的系统的传统技
术已经停滞不前了。这也导致了 语音识别 领域快速地转向 深度学习 的研究。在大约
的两年时间内，工业界的大多数的 语音识别 产品都包含了 深度神经网络 ，这种成功
也激发了 ASR领 域对深度学习 算法和结构的一波新的研究浪潮，并且影响至今。
其中的一个创新点是 卷积网络 的应用 (Sainath et al. ,2013)。卷积网络 在时域与
频域上复用了权重，改进了之前的仅在时域上使用重复权值的 时延神经网络 。这种
新的二维的卷积模型并不是将输入的频谱当作一个长的向量，而是当成是一个图像，
其中一个轴对应着时间，另一个轴对应的是谱分量的频率。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 391
完全抛弃 HMM并转向研究 端到端的 深度学习 语音识别 系统是至今仍然活跃的
另一个重要推动。这个领域第一个主要的突破是 Graves et al. (2013)，其中训练了一
个深度的 长短期记忆 循环神经网络 （见第 10.10节） ， 使用了帧－ 音素排列的 MAP推
断，就像 LeCun et al. (2001)以及 CTC框架 (Graves et al. ,2006;Graves ,2012)中
一样。一个深度 循环神经网络 (Graves et al. ,2013)每个时间步的各层都有状态变量，
两种展开图的方式导致两种不同深度：一种是普通的根据层的堆叠衡量的深度，另
一种根据时间 展开衡量的深度。这个工作把 TIMIT数据集上 音素的错误率记录降到
了的新低 17:7%。关于应用于其他领域的深度 循环神经网络 的变种可以参考 Pascanu
et al. (2014a );Chung et al. (2014)。
另一个端到端的 深度学习 语音识别 方向的最新方法是让系统学习如何利用 语音
（phonetic）层级的信息 ‘‘排列”声学（acoustic）层级的信息 (Chorowski et al. ,2014;
Luet al. ,2015)。
12.4自然语言处理
自然语言处理 （Natural Language Processing ）让计算机能够使用人类语言，例
如英语或法语。为了让简单的程序能够高效明确地解析，计算机程序通常读取和发
出特殊化的语言。而自然的语言通常是模糊的，并且可能不遵循形式的描述。 自然
语言处理 中的应用如机器翻译，学习者需要读取一种人类语言的句子，并用另一种
人类语言发出等同的句子。许多 NLP应用程序基于 语言模型 ，语言模型 定义了关于
自然语言中的字、字符或字节序列的概率分布。
与本章讨论的其他应用一样，非常通用的 神经网络 技术可以成功地应用于 自然
语言处理 。然而，为了实现卓越的性能并扩展到大型应用程序，一些领域特定的策略
也很重要。为了构建自然语言的有效模型，通常必须使用专门处理序列数据的技术。
在很多情况下，我们将自然语言视为一系列词，而不是单个字符或字节序列。因为
可能的词总数非常大，基于词的 语言模型 必须在极高维度和稀疏的离散空间上操作。
为使这种空间上的模型在计算和统计意义上都高效，研究者已经开发了几种策略。
12.4.1 n-gram
语言模型 （language model ）定义了自然语言中 标记序列的概率分布。根据模型
的设计， 标记可以是词、字符、甚至是字节。 标记总是离散的实体。最早成功的 语言DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
392 第十二章 应用
模型基于固定长度序列的 标记模型，称为 n-gram。一个 n-gram是一个包含 n个标
记的序列。
基于 n-gram的模型定义一个条件概率——给定前 n 1个标记后的第 n个标
记的条件概率。该模型使用这些条件分布的乘积定义较长序列的概率分布：
P(x1; : : : ; x ) =P(x1; : : : ; x n 1)∏
t=nP(xtjxt n+1; : : : ; x t 1): (12.5)
这个分解可以由概率的链式法则证明。初始序列 P(x1; : : : ; x n 1)的概率分布可以通
过带有较小 n值的不同模型建模。
训练 n-gram模型是简单的，因为 最大似然估计 可以通过简单地统计每个可能
的n-gram在训练集中出现的次数来获得。几十年来，基于 n-gram的模型都是统
计语言模型 的核心模块 (Jelinek and Mercer ,1980;Katz ,1987;Chen and Goodman ,
1999)。
对于小的 n值，模型有特定的名称： n= 1称为一元语法 （unigram） ，n= 2称
为二元语法 （bigram）及 n= 3称为三元语法 （trigram） 。这些名称源于相应数字
的拉丁前缀和希腊后缀 “-gram’’，分别表示所写之物。
通常我们同时训练 n-gram模型和 n 1gram模型。这使得下式可以简单地通
过查找两个存储的概率来计算。
P(xtjxt n+1; : : : ; x t 1) =Pn(xt n+1; : : : ; x t)
Pn 1(xt n+1; : : : ; x t 1)(12.6)
为了在 Pn中精确地再现 推断，我们训练 Pn 1时必须省略每个序列最后一个字符。
举个例子，我们演示三元模型如何计算句子 “THE DOG RAN AWAY .’’的概率。句
子的第一个词不能通过上述条件概率的公式计算，因为句子的开头没有上下文。取
而代之，在句子的开头我们必须使用词的边缘概率。因此我们计算 P3(THE DOG RAN )。
最后，可以使用条件分布 P(AWAYjDOG RAN )（典型情况）来预测最后一个词。将这
与式 (12.6)放在一起，我们得到：
P(THE DOG RAN AWAY ) =P3(THE DOG RAN )P3(DOG RAN AWAY )/P2(DOG RAN ):(12.7)
n-gram模型最大似然的基本限制是，在许多情况下从训练集计数估计得到的
Pn很可能为零（即使元组 (xt n+1; : : : ; x t)可能出现在测试集中） 。这可能会导致
两种不同的灾难性后果。当 Pn 1为零时，该比率是未定义的，因此模型甚至不能DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 393
产生有意义的输出。当 Pn 1非零而 Pn为零时，测试样本的对数似然为  1。为
避免这种灾难性的后果，大多数 n-gram模型采用某种形式的 平滑（smoothing ） 。
平滑技术将概率质量从观察到的元组转移到类似的未观察到的元组。见 Chen and
Goodman (1999)的综述和实验对比。其中一种基本技术基于向所有可能的下一个符
号值添加非零概率质量。这个方法可以被证明是，计数参数具有均匀或 Dirichlet 先
验的贝叶斯 推断。另一个非常流行的想法是包含高阶和低阶 n-gram模型的混合模
型，其中高阶模型提供更多的 容量，而低阶模型尽可能地避免零计数。如果上下文
xt n+k; : : : ; x t 1的频率太小而不能使用高阶模型， 回退方法 (back-oﬀ methods) 就
查找低阶 n-gram。更正式地说，它们通过上下文 xt n+k; : : : ; x t 1估计 xt上的分
布，并增加 k直到找到足够可靠的估计。
经典的 n-gram模型特别容易引起 维数灾难 。因为存在jVjn可能的 n-gram，而
且jVj通常很大。即使有大量训练数据和适当的 n，大多数 n-gram也不会出现在训
练集中。经典 n-gram模型的一种观点是执行最近邻查询。换句话说，它可以被视为
局部非参数预测器，类似于 k-最近邻。这些极端局部预测器面临的统计问题已经在
第5.11.2节中描述过。 语言模型 的问题甚至比普通模型更严重，因为任何两个不同的
词在one-hot向量空间中的距离彼此相同。因此，难以大量利用来自任意 ‘‘邻居’’的
信息——只有重复相同上下文的训练样本对局部泛化有用。为了克服这些问题， 语
言模型必须能够在一个词和其他语义相似的词之间共享知识。
为了提高 n-gram模型的统计效率， 基于类的语言模型 (class-based language
model) ( Brown et al. ,1992;Ney and Kneser ,1993;Niesler et al. ,1998)引入词类别
的概念，然后属于同一类别的词共享词之间的统计强度。这个想法使用了聚类算法，
基于它们与其他词同时出现的频率，将该组词分成集群或类。随后，模型可以在条
件竖杠的右侧使用词类 ID而不是单个词 ID。混合（或回退）词模型和类模型的复
合模型也是可能的。尽管词类提供了在序列之间泛化的方式，但其中一些词被相同
类的另一个替换，导致该 表示丢失了很多信息。
12.4.2 神经语言模型
神经语言模型 （Neural Language Model ,NLM）是一类用来克服 维数灾难 的语
言模型，它使用词的 分布式表示 对自然语言序列建模 (Bengio et al. ,2001b )。不同于
基于类的 n-gram模型，神经语言模型 在能够识别两个相似的词，并且不丧失将每个
词编码为彼此不同的能力。 神经语言模型 共享一个词（及其上下文）和其他类似词DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
394 第十二章 应用
（和上下文之间）的统计强度。模型为每个词学习的 分布式表示 ，允许模型处理具有
类似共同特征的词来实现这种共享。例如，如果词 dog和词 cat映射到具有许多属
性的表示，则包含词 cat的句子可以告知模型对包含词 dog的句子做出预测，反之
亦然。因为这样的属性很多，所以存在许多泛化的方式，可以将信息从每个训练语
句传递到指数数量的语义相关语句。 维数灾难 需要模型泛化到指数多的句子（指数
相对句子长度而言） 。该模型通过将每个训练句子与指数数量的类似句子相关联克服
这个问题。
我们有时将这些词 表示称为词嵌入（word embedding ） 。在这个解释下，我们将
原始符号视为维度等于词表大小的空间中的点。词 表示将这些点嵌入到较低维的特
征空间中。在原始空间中，每个词由一个 one-hot向量表示，因此每对词彼此之间的
欧氏距离都是p
2。在嵌入空间中，经常出现在类似上下文（或共享由模型学习的一
些‘‘特征’’的任何词对）中的词彼此接近。这通常导致具有相似含义的词变得邻近。
图12.3放大了学到的 词嵌入空间的特定区域，我们可以看到语义上相似的词如何映
射到彼此接近的表示。
 34 32 30 28 26 14 13 12 11 10 9 8 7 6
CanadaEuropeOntario
NorthEnglish
CanadianUnionAfricanAfrica
BritishFrance
RussianChina
GermanyFrench
AssemblyEU JapanIraq
SouthEuropean
35:035:536:036:537:037:538:0171819202122
1995199619971998199920002001
200220032004
20052006200720082009
图12.3:从神经机器翻译 模型获得的 词嵌入的二维可视化 (Bahdanau et al. ,2015)。此图在语义相
关词的特定区域放大，它们具有彼此接近的嵌入向量。国家在左图，数字在右图。注意，这些嵌入
是为了可视化才表示为 2维。在实际应用中，嵌入通常具有更高的维度并且可以同时捕获词之间
多种相似性。
其他领域的 神经网络 也可以定义嵌入。例如， 卷积网络 的隐藏层提供 ‘‘图像嵌
入’’。因为自然语言最初不在实值向量空间上，所以 NLP从业者通常对嵌入的这个
想法更感兴趣。隐藏层在表示数据的方式上提供了更质变的戏剧性变化。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 395
使用分布式表示 来改进自然语言处理 模型的基本思想不必局限于 神经网络 。它
还可以用于 图模型，其中分布式表示 是多个潜变量的形式。
12.4.3 高维输出
在许多自然语言应用中，我们通常希望我们的模型产生词（而不是字符）作为
输出的基本单位。对于大词汇表，由于词汇量很大，在词的选择上表示输出分布的计
算成本可能非常高。在许多应用中， V包含数十万词。表示这种分布的朴素方法是
应用一个仿射变换，将隐藏表示转换到输出空间，然后应用 softmax 函数。假设我
们的词汇表 V大小为jVj。因为其输出维数为 jVj，描述该仿射变换线性分量的权重
矩阵非常大。这造成了表示该矩阵的高存储成本，以及与之相乘的高计算成本。因
为softmax 要在所有jVj输出之间归一化，所以在训练时以及测试时执行全矩阵乘
法是必要的——我们不能仅计算与正确输出的权重向量的点积。因此，输出层的高
计算成本在训练期间（计算似然性及其梯度）和测试期间（计算所有或所选词的概
率）都有出现。对于专门的 损失函数 ，可以有效地计算梯度 (Vincent et al. ,2015)，
但是应用于传统 softmax 输出层的标准 交叉熵损失时会出现许多困难。
假设 h是用于预测输出概率 ^y的顶部隐藏层。如果我们使用学到的权重 W和
学到的偏置 b参数化从 h到^y的变换，则仿射 softmax 输出层执行以下计算：
ai=bi+∑
jWijhj8i2f1; : : : ;jVjg; (12.8)
^yi=eai
∑jVj
i′=1eai′: (12.9)
如果 h包含 nh个元素，则上述操作复杂度是 O(jVjnh)。在 nh为数千和jVj数十
万的情况下，这个操作占据了 神经语言模型 的大多数计算。
12.4.3.1 使用短列表
第一个神经语言模型 (Bengio et al. ,2001b ,2003)通过将词汇量限制为 10,000
或20,000来减轻大词汇表上 softmax 的高成本。 Schwenk and Gauvain (2002)和
Schwenk (2007)在这种方法的基础上建立新的方式，将词汇表 V分为最常见词汇
（由神经网络 处理）的 短列表（shortlist）L和较稀有词汇的尾列表 T=VnL（由n-
gram模型处理） 。为了组合这两个预测， 神经网络 还必须预测在上下文 C之后出现DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
396 第十二章 应用
的词位于尾列表的概率。我们可以添加额外的 sigmoid输出单元估计 P(i2TjC)
实现这个预测。额外输出则可以用来估计 V中所有词的概率分布，如下：
P(y=ijC) =1 i2LP(y=ijC; i2L)(1 P(i2TjC))
+ 1i2TP(y=ijC; i2T)P(i2TjC); (12.10)
其中 P(y=ijC; i2L)由神经语言模型 提供 P(y=ijC; i2T)由n-gram模型提
供。稍作修改，这种方法也可以在 神经语言模型 模型的 softmax 层中使用额外的输
出值，而不是单独的 sigmoid单元。
短列表方法的一个明显缺点是， 神经语言模型 的潜在泛化优势仅限于最常用的
词，这大概是最没用的。这个缺点引发了处理高维输出替代方法的探索，如下所述。
12.4.3.2 分层Softmax
减少大词汇表 V上高维输出层计算负担的经典方法 (Goodman ,2001)是分层地
分解概率。jVj因子可以降低到 logjVj一样低，而无需执行与 jVj成比例数量（并且
也与隐藏单元数量 nh成比例）的计算。 Bengio (2002)和Morin and Bengio (2005)
将这种因子分解方法引入 神经语言模型 中。
我们可以认为这种层次结构是先建立词的类别，然后是词类别的类别，然后是
词类别的类别的类别等等。这些嵌套类别构成一棵树，其叶子为词。在平衡树中，
树的深度为 logjVj。选择一个词的概率是由路径（从树根到包含该词叶子的路径）
上的每个节点通向该词分支概率的乘积给出。图 12.4是一个简单的例子。 Mnih and
Hinton (2009)也描述了使用多个路径来识别单个词的方法，以便更好地建模具有多
个含义的词。计算词的概率则涉及在导向该词所有路径上的求和。
为了预测树的每个节点所需的条件概率，我们通常在树的每个节点处使用 逻辑
回归模型，并且为所有这些模型提供与输入相同的上下文 C。因为正确的输出编码
在训练集中，我们可以使用 监督学习 训练逻辑回归 模型。我们通常使用标准 交叉熵损
失，对应于最大化正确判断序列的对数似然。
因为可以高效地计算输出对数似然（低至 logjVj而不是jVj） ，所以也可以高效
地计算梯度。这不仅包括关于输出参数的梯度，而且还包括关于隐藏层激活的梯度。
优化树结构最小化期望的计算数量是可能的，但通常不切实际。给定词的相对
频率，信息理论的工具可以指定如何选择最佳的二进制编码。为此，我们可以构造
树，使得与词相关联的位数量近似等于该词频率的对数。然而在实践中，节省计算通DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 397
(1)(0)
(0,0,0)(0,0,1)(0,1,0)(0,1,1)(1,0,0)(1,0,1)(1,1,0)(1,1,1)(1,1)(1,0)(0,1)(0,0)w0w0w1w1w2w2w3w3w4w4w5w5w6w6w7w7
图12.4:词类别简单层次结构的示意图，其中 8个词 w0; : : : ; w 7组织成三级层次结构。树的叶
子表示实际特定的词。内部节点表示词的组别。任何节点都可以通过二值决策序列（ 0=左， 1=
右）索引，从根到达节点。超类 (0)包含类 (0;0)和(0;1)，其中分别包含词 fw0; w1g和fw2; w3g
的集合，类似地超类 (1)包含类 (1;0)和(1;1)，分别包含词 fw4; w5g和fw6; w7g。如果树充分
平衡，则最大深度（二值决策的数量）与词数 jVj的对数同阶：从 jVj个词中选一个词只需执行
O(logjVj)次操作（从根开始的路径上的每个节点一次操作） 。在该示例中，我们乘三次概率就能
计算词 y的概率，这三次概率与从根到节点 y的路径上每个节点向左或向右的二值决策相关联。
令bi(y)为遍历树移向 y时的第 i个二值决策。对输出 y进行采样的概率可以通过条件概率的链
式法则分解为条件概率的乘积，其中每个节点由这些位的前缀索引。例如，节点 (1;0)对应于前缀
(b0(w4) = 1 ; b1(w4) = 0)，并且 w4的概率可以如下分解：
P(y=w4) =P(b0= 1;b1= 0;b2= 0) (12.11)
=P(b0= 1)P(b1= 0jb0= 1)P(b2= 0jb0= 1;b1= 0): (12.12)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
398 第十二章 应用
常事倍功半，因为输出概率的计算仅是 神经语言模型 中总计算的一部分。例如，假
设有 l个全连接的宽度为 nh的隐藏层。令 nb是识别一个词所需比特数的加权平均
值，其加权由这些词的频率给出。在这个例子中，计算隐藏激活所需的操作数增长
为O(ln2
h)，而输出计算增长为 O(nhnb)。只要 nblnh，我们可以通过收缩 nh比
收缩 nb减少更多的计算量。事实上， nb通常很小。因为词汇表的大小很少超过一
百万而 log2(106)20，所以可以将 nb减小到大约 20，但 nh通常大得多，大约为
103或更大。我们可以定义深度为 2和分支因子为√
jTj的树，而不用仔细优化分支
因子为 2的树。这样的树对应于简单定义一组互斥的词类。基于深度为 2的树的简
单方法可以获得层级策略大部分的计算益处。
一个仍然有点开放的问题是如何最好地定义这些词类，或者如何定义一般的词
层次结构。早期工作使用现有的层次结构 (Morin and Bengio ,2005)，但也可以理想
地与神经语言模型 联合学习层次结构。学习层次结构很困难。对数似然的精确优化
似乎难以解决，因为词层次的选择是离散的，不适于基于梯度的优化。然而，我们
可以使用离散优化来近似地最优化词类的分割。
分层 softmax 的一个重要优点是，它在训练期间和测试期间（如果在测试时我
们想计算特定词的概率）都带来了计算上的好处。
当然即使使用分层 softmax，计算所有jVj个词概率的成本仍是很高的。另一个
重要的操作是在给定上下文中选择最可能的词。不幸的是，树结构不能为这个问题
提供高效精确的解决方案。
缺点是在实践中，分层 softmax倾向于更差的测试结果（相对基于采样的方法） ，
我们将在下文描述。这可能是因为词类选择得不好。
12.4.3.3 重要采样
加速神经语言模型 训练的一种方式是，避免明确地计算所有未出现在下一位置
的词对梯度的贡献。每个不正确的词在此模型下具有低概率。枚举所有这些词的计
算成本可能会很高。相反，我们可以仅采样词的子集。使用式 (12.8)中引入的符号，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 399
梯度可以写成如下形式：
@logP(yjC)
@=@log softmax y(a)
@(12.13)
=@
@logeay
∑
ieai(12.14)
=@
@(ay log∑
ieai) (12.15)
=@ay
@ ∑
iP(y=ijC)@ai
@; (12.16)
其中 a是presoftmax 激活（或得分）向量，每个词对应一个元素。第一项是 正相
(positive phase) 项，推动 ay向上；而第二项是 负相 (negative phase) 项，对于所有
i以权重 P(ijC)推动 ai向下。由于负相项是期望值，我们可以通过 蒙特卡罗 采样
估计。然而，这将需要从模型本身采样。从模型中采样需要对词汇表中所有的 i计
算P(ijC)，这正是我们试图避免的。
我们可以从另一个分布中采样，而不是从模型中采样，这个分布称为 提议分布
（proposal distribution ） （记为 q） ，并通过适当的权重校正从错误分布采样引入的 偏
差(Bengio and Sénécal ,2003;Bengio and Sénécal ,2008)。这是一种称为 重要采样
（Importance Sampling ）的更通用技术的应用，我们将在第 12.4.3.3节中更详细地描
述。不幸的是，即使精确 重要采样 也不一定有效，因为我们需要计算权重 pi/qi，其
中的 pi=P(ijC)只能在计算所有得分 ai后才能计算。这个应用采取的解决方案
称为有偏重要采样 ，其中重要性权重被归一化加和为 1。当对负词 ni进行采样时，
相关联的梯度被加权为：
wi=pni/qni∑N
j=1pnj/qnj: (12.17)
这些权重用于对来自 q的m个负样本给出适当的重要性，以形成负相估计对梯度的
贡献：
jVj∑
i=1P(ijC)@ai
@1
mm∑
i=1wi@ani
@: (12.18)
一元语法 或二元语法 分布与提议分布 q工作得一样好。从数据估计这种分布的参数
是很容易。在估计参数之后，也可以非常高效地从这样的分布采样。
重要采样 （Importance Sampling ）不仅可以加速具有较大 softmax 输出的模
型。更一般地，它可以加速具有大稀疏输出层的训练，其中输出是稀疏向量而不是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
400 第十二章 应用
n选1。其中一个例子是 词袋（bag of words ） 。词袋具有稀疏向量 v，其中 vi表示
词汇表中的词 i存不存在文档中。或者， vi可以指示词 i出现的次数。由于各种原
因，训练产生这种稀疏向量的 机器学习 模型的成本可能很高。在学习的早期，模型
可能不会真的使输出真正稀疏。此外，将输出的每个元素与目标的每个元素进行比
较，可能是描述训练的 损失函数 最自然的方式。这意味着稀疏输出并不一定能带来
计算上的好处，因为模型可以选择使大多数输出非零，并且所有这些非零值需要与
相应的训练目标进行比较（即使训练目标是零） 。 Dauphin et al. (2011)证明可以使
用重要采样 加速这种模型。高效算法最小化 ‘‘正词’’（在目标中非零的那些词）和相
等数量的 ‘‘负词’’的重构损失。负词是被随机选取的，如使用启发式采样更可能被误
解的词。该启发式过采样引入的偏差则可以使用重要性权重校正。
在所有这些情况下，输出层梯度估计的计算复杂度被减少为与负样本数量成比
例，而不是与输出向量的大小成比例。
12.4.3.4 噪声对比估计和排名损失
为减少训练大词汇表的 神经语言模型 的计算成本，研究者也提出了其他基于采
样的方法。早期的例子是 Collobert and Weston (2008a )提出的排名损失，将 神经语
言模型每个词的输出视为一个得分，并试图使正确词的得分 ay比其他词 ai排名更
高。提出的排名损失则是
L=∑
imax(0;1 ay+ai): (12.19)
如果观察到词的得分 ay远超过负词的得分 ai（相差大于 1） ，则第 i项梯度为零。
这个准则的一个问题是它不提供估计的条件概率，条件概率在很多应用中是有用的，
包括语音识别和文本生成（包括诸如翻译的条件文本生成任务） 。
最近用于 神经语言模型 的训练目标是噪声对比估计，将在第 18.6节中介绍。这
种方法已成功应用于 神经语言模型 (Mnih and Teh ,2012;Mnih and Kavukcuoglu ,
2013)。
12.4.4 结合 n-gram和神经语言模型
n-gram模型相对 神经网络 的主要优点是 n-gram模型具有更高的模型 容量（通
过存储非常多的元组的频率） ，并且处理样本只需非常少的计算量（通过查找只匹配DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 401
当前上下文的几个元组） 。 如果我们使用哈希表或树来访问计数， 那么用于 n-gram的
计算量几乎与 容量无关。相比之下，将 神经网络 的参数数目加倍通常也大致加倍计
算时间。当然，避免每次计算时使用所有参数的模型是一个例外。嵌入层每次只索
引单个嵌入，所以我们可以增加词汇量，而不会增加每个样本的计算时间。一些其
他模型，例如平铺 卷积网络 ，可以在减少 参数共享 程度的同时添加参数以保持相同
的计算量。然而，基于矩阵乘法的典型 神经网络 层需要与参数数量成比例的计算量。
因此，增加 容量的一种简单方法是将两种方法结合，由 神经语言模型 和n-
gram语言模型 组成集成 (Bengio et al. ,2001b ,2003)。
对于任何 集成，如果集成成员产生独立的错误，这种技术可以减少测试误差。 集
成学习领域提供了许多方法来组合 集成成员的预测，包括统一加权和在验证集上选
择权重。 Mikolov et al. (2011a )扩展了集成，不是仅包括两个模型，而是包括大量
模型。我们也可以将 神经网络 与最大熵模型配对并联合训练 (Mikolov et al. ,2011b )。
该方法可以被视为训练具有一组额外输入的 神经网络 ，额外输入直接连接到输出并
且不连接到模型的任何其他部分。额外输入是输入上下文中特定 n-gram是否存在
的指示器，因此这些变量是非常高维且非常稀疏的。
模型容量的增加是巨大的（架构的新部分包含高达 jsVjn个参数） ，但是处理输
入所需的额外计算量是很小的（因为额外输入非常稀疏） 。
12.4.5 神经机器翻译
机器翻译以一种自然语言读取句子并产生等同含义的另一种语言的句子。机器
翻译系统通常涉及许多组件。在高层次，一个组件通常会提出许多候选翻译。由于语
言之间的差异，这些翻译中的许多翻译是不符合语法的。例如，许多语言在名词后
放置形容词，因此直接翻译成英语时，它们会产生诸如 “apple red’’ 的短语。提议机
制提出建议翻译的许多变体，理想情况下应包括 “red apple’’ 。翻译系统的第二个组
成部分（ 语言模型 ）评估提议的翻译，并可以评估 “red apple’’ 比“apple red’’ 更好。
最早的机器翻译 神经网络 探索中已经纳入了 编码器和解码器的想法 (Allen 1987;
Chrisman 1991; Forcada and Ñeco 1997) ，而翻译中 神经网络 的第一个大规模有竞
争力的用途是通过 神经语言模型 升级翻译系统的 语言模型 (Schwenk et al. ,2006;
Schwenk ,2010)。之前，大多数机器翻译系统在该组件使用 n-gram模型。机器翻译
中基于 n-gram的模型不仅包括传统的回退 n-gram模型，而且包括 最大熵语言模型
(maximum entropy language models) ，其中给定上下文中常见的词， aﬃne-softmaxDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
402 第十二章 应用
层预测下一个词。
传统语言模型 仅仅报告自然语言句子的概率。因为机器翻译涉及给定输入句子
产生输出句子，所以将自然 语言模型 扩展为条件的是有意义的。如第 6.2.1.1节所述
可以直接地扩展一个模型，该模型定义某些变量的边缘分布，以便在给定上下文
C（C可以是单个变量或变量列表）的情况下定义该变量的条件分布。 Devlin et al.
(2014)在一些统计机器翻译的基准中击败了最先进的技术，他给定源语言中的短语
s1;s2; : : : ; sk后使用 MLP对目标语言的短语 t1;t2; : : : ; tk进行评分。这个 MLP估
计P(t1;t2; : : : ; tkjs1;s2; : : : ; sk)。这个 MLP的估计替代了条件 n-gram模型提供的
估计。
基于 MLP方法的缺点是需要将序列预处理为固定长度。为了使翻译更加灵活，
我们希望模型允许可变的输入长度和输出长度。 RNN具备这种能力。第 10.2.4节描
述了给定某些输入后，关于序列条件分布 RNN的几种构造方法，并且第 10.4节描
述了当输入是序列时如何实现这种条件分布。在所有情况下，一个模型首先读取输
入序列并产生概括输入序列的数据结构。我们称这个概括为 ‘‘上下文 ”C。上下文 C
可以是向量列表，或者向量或张量。读取输入以产生 C的模型可以是 RNN (Cho
et al. ,2014b ;Sutskever et al. ,2014;Jean et al. ,2014)或卷积网络 (Kalchbrenner and
Blunsom ,2013)。另一个模型（通常是 RNN） ，则读取上下文 C并且生成目标语言
的句子。在图 12.5中展示了这种用于机器翻译的 编码器 -解码器框架的总体思想。
为生成以源句为条件的整句，模型必须具有表示整个源句的方式。早期模型只能
表示单个词或短语。从 表示学习 的观点来看，具有相同含义的句子具有类似 表示是有
用的，无论它们是以源语言还是以目标语言书写。研究者首先使用卷积和 RNN的组
合探索该策略 (Kalchbrenner and Blunsom ,2013)。后来的工作介绍了使用 RNN对
所提议的翻译进行打分 (Cho et al. ,2014b )或生成翻译句子 (Sutskever et al. ,2014)。
Jean et al. (2014)将这些模型扩展到更大的词汇表。
12.4.5.1 使用注意力机制并对齐数据片段
使用固定大小的表示概括非常长的句子（例如 60个词）的所有语义细节是非
常困难的。这需要使用足够大的 RNN，并且用足够长时间训练得很好才能实现，如
Cho et al. (2014b )和Sutskever et al. (2014)所表明的。然而，更高效的方法是先
读取整个句子或段落（以获得正在表达的上下文和焦点） ，然后一次翻译一个词，
每次聚焦于输入句子的不同部分来收集产生下一个输出词所需的语义细节。这正DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 403
DecoderOutput object (English sentence)Intermediate, semantic representationSource object (French sentence or image)Encoder
图12.5:编码器 -解码器架构在直观 表示（例如词序列或图像）和语义 表示之间来回映射。使用来
自一种模态数据的 编码器输出（例如从法语句子到捕获句子含义的隐藏 表示的编码器映射）作为
用于另一模态的 解码器输入（如 解码器将捕获句子含义的隐藏 表示映射到英语） ，我们可以训练将
一种模态转换到另一种模态的系统。这个想法已经成功应用于很多领域，不仅仅是机器翻译，还
包括为图像生成标题。
是Bahdanau et al. (2015)第一次引入的想法。图 12.6中展示了 注意力机制 ，其中每
个时间步关注输入序列的特定部分。
我们可以认为基于 注意力机制 的系统有三个组件：
•读取器读取原始数据（例如源语句中的源词）并将其转换为 分布式表示 ，其中
一个特征向量与每个词的位置相关联。
•存储器存储读取器输出的特征向量列表。这可以被理解为包含事实序列的 存储
器，而之后不必以相同的顺序从中检索，也不必访问全部。
•最后一个程序 利用存储器的内容顺序地执行任务，每个 时间步聚焦于某个存储
器元素的内容（或几个，具有不同权重） 。
第三组件可以生成翻译语句。
当用一种语言书写的句子中的词与另一种语言的翻译语句中的相应词对齐时，
可以使对应的 词嵌入相关联。早期的工作表明，我们可以学习将一种语言中的 词
嵌入与另一种语言中的 词嵌入相关联的翻译矩阵 (Kočiský et al. ,2014)，与传统
的基于短语表中频率计数的方法相比，可以产生较低的对齐错误率。更早的工作DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
404 第十二章 应用
↵(t 1)↵(t 1)↵(t)↵(t)↵(t+1)↵(t+1)h(t 1)h(t 1)h(t)h(t)h(t+1)h(t+1)cc
⇥⇥⇥⇥⇥⇥+
图12.6:由Bahdanau et al. (2015)引入的现代 注意力机制 ，本质上是加权平均。 注意力机制 对具
有权重 (t)的特征向量 h(t)进行加权平均形成上下文向量 c。在一些应用中，特征向量 h是神经
网络的隐藏单元 ，但它们也可以是模型的原始输入。权重 (t)由模型本身产生。它们通常是区间
[0;1]中的值，并且旨在仅仅集中在单个 h(t)周围，使得加权平均精确地读取接近一个特定 时间
步的特征向量。权重 (t)通常由模型另一部分发出的相关性得分应用 softmax 函数后产生。 注意
力机制在计算上需要比直接索引期望的 h(t)付出更高的代价，但直接索引不能使用 梯度下降 训练。
基于加权平均的 注意力机制 是平滑、可微的近似，可以使用现有优化算法训练。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.4自然语言处理 405
(Klementiev et al. ,2012)也对跨语言词向量进行了研究。这种方法的存在很多扩展。
例如，允许在更大数据集上训练的更高效的跨语言对齐 (Gouws et al. ,2014)。
12.4.6 历史展望
在对反向传播 的第一次探索中， Rumelhart et al. (1986a )等人提出了 分布式表
示符号的思想，其中符号对应于族成员的身份，而 神经网络 捕获族成员之间的关系，
训练样本形成三元组如（ Colin，Mother，Victoria） 。神经网络 的第一层学习每个族
成员的表示。例如， Colin的特征可能代表 Colin所在的族树，他所在树的分支，他
来自哪一代等等。我们可以将 神经网络 认为是将这些属性关联在一起的计算学习规
则，可以获得期望预测。模型则可以进行预测，例如推断谁是 Colin的母亲。
Deerwester et al. (1990)将符号嵌入的想法扩展到对词的嵌入。这些嵌入使用
SVD学习。之后，嵌入将通过 神经网络 学习。
自然语言处理 的历史是由流行表示（对模型输入不同方式的表示）的变化为
标志的。在早期对符号和词建模的工作之后， 神经网络 在NLP上一些最早的应用
(Miikkulainen and Dyer ,1991;Schmidhuber ,1996)将输入表示为字符序列。
Bengio et al. (2001b )将焦点重新引到对词建模并引入 神经语言模型 ，能产生可
解释的词嵌入。这些神经模型已经从在一小组符号上的定义表示（ 20世纪 80年代）
扩展到现代应用中的数百万字（包括专有名词和拼写错误） 。这种计算扩展的努力导
致了第 12.4.3节中描述的技术发明。
最初，使用词作为 语言模型 的基本单元可以改进语言建模的性能 (Bengio et al. ,
2001b )。而今，新技术不断推动基于字符 (Sutskever et al. ,2011)）和基于词的模型
向前发展，最近的工作 (Gillick et al. ,2015)甚至建模 Unicode 字符的单个字节。
神经语言模型 背后的思想已经扩展到多个 自然语言处理 应用，如解析 (Hender-
son,2003,2004;Collobert ,2011)、词性标注、语义角色标注、分块等，有时使用
共享词嵌入的单一多任务学习架构 (Collobert and Weston ,2008a ;Collobert et al. ,
2011a )。
随着 t-SNE降维算法的发展 (van der Maaten and Hinton ,2008)以及 Joseph
Turian在2009年引入的专用于可视化词嵌入的应用，用于分析 语言模型 嵌入的二
维可视化成为一种流行的工具。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
406 第十二章 应用
12.5其他应用
在本节中，我们介绍 深度学习 一些其他类型的应用，它们与上面讨论的标准对
象识别、语音识别和 自然语言处理 任务不同。本书的第三部分将扩大这个范围，甚
至进一步扩展到仍是目前主要研究领域的任务。
12.5.1 推荐系统
信息技术部门中 机器学习 的主要应用之一是向潜在用户或客户推荐项目。这可
以分为两种主要的应用：在线广告和项目建议（通常这些建议的目的仍然是为了销
售产品） 。两者都依赖于预测用户和项目之间的关联，一旦向该用户展示了广告或推
荐了该产品， 推荐系统 要么预测一些行为的概率（用户购买产品或该行为的一些代
替）或预期增益（其可取决于产品的价值） 。目前，互联网的资金主要来自于各种形
式的在线广告。经济的主要部分依靠网上购物。包括 Amazon 和eBay在内的公司
都使用了 机器学习 （包括深度学习 ）推荐他们的产品。有时，项目不是实际出售的
产品。如选择在社交网络新闻信息流上显示的帖子、推荐观看的电影、推荐笑话、推
荐专家建议、匹配视频游戏的玩家或匹配约会的人。
通常，这种关联问题可以作为 监督学习 问题来处理：给出一些关于项目和关于
用户的信息，预测感兴趣的行为（用户点击广告、输入评级、点击 ‘‘喜欢’’按钮、购
买产品，在产品上花钱、花时间访问产品页面等） 。通常这最终会归结到回归问题
（预测一些条件期望值）或概率分类问题（预测一些离散事件的条件概率） 。
早期推荐系统 的工作依赖于这些预测输入的最小信息：用户 ID和项目 ID。在
这种情况下，唯一的泛化方式依赖于不同用户或不同项目的目标变量值之间的模式
相似性。假设用户 1和用户 2都喜欢项目 A，B和C.由此，我们可以推断出用户
1和用户 2具有类似的口味。如果用户 1喜欢项目 D，那么这可以强烈提示用户 2
也喜欢 D。基于此原理的算法称为 协同过滤 （collaborative ﬁltering ） 。非参数方法
（例如基于估计偏好模式之间相似性的最近邻方法）和参数方法都可能用来解决这个
问题。参数方法通常依赖于为每个用户和每个项目学习 分布式表示 （也称为嵌入） 。
目标变量的双线性预测（例如评级）是一种简单的参数方法，这种方法非常成功，通
常被认为是最先进系统的组成部分。通过用户嵌入和项目嵌入之间的点积（可能需
要使用仅依赖于用户 ID或项目 ID的常数来校正）获得预测。令 ^R是包含我们预
测的矩阵， A矩阵行中是用户嵌入， B矩阵列中具有项目嵌入。令 b和 c是分别包DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.5其他应用 407
含针对每个用户（表示用户平常坏脾气或积极的程度）以及每个项目（表示其大体
受欢迎程度）的 偏置向量。因此，双线性预测如下获得：
^Ru;i=bu+ci+∑
jAu;jBj;i: (12.20)
通常，人们希望最小化预测评级 ^Ru;i和实际评级 ^Ru;i之间的平方误差。当用户嵌入
和项目嵌入首次缩小到低维度（两个或三个）时，它们就可以方便地可视化，或者
可以将用户或项目彼此进行比较（就像 词嵌入） 。获得这些嵌入的一种方式是对实际
目标（例如评级）的矩阵 R进行奇异值分解 。这对应于将 R= UDV′（或归一化
的变体）分解为两个因子的乘积，低秩矩阵 A= UD和 B= V′。SVD的一个问题
是它以任意方式处理缺失条目，如同它们对应于目标值 0。相反，我们希望避免为缺
失条目做出的预测付出任何代价。幸运的是，观察到的评级的平方误差总和也可以
使用基于梯度的优化最小化。 SVD和式 (12.20 )中的双线性预测在 Netﬂix奖竞赛中
（目的是仅基于大量匿名用户的之前评级预测电影的评级）表现得非常好 (Bennett
and Lanning ,2007)。许多机器学习 专家参加了 2006年和 2009年之间的这场比赛。
它提高了使用先进 机器学习 的推荐系统 的研究水平，并改进了 推荐系统 。即使简单
的双线性预测或 SVD本身并没有赢得比赛，但它是大多数竞争对手提出的整体模型
中一个组成部分，包括胜者 (Töscher et al. ,2009;Koren ,2009)。
除了这些具有 分布式表示 的双线性模型之外， 第一次用于 协同过滤 的神经网络 之
一是基于 RBM的无向概率模型 (Salakhutdinov et al. ,2007)。RBM是Netﬂix比
赛获胜方法的一个重要组成部分 (Töscher et al. ,2009;Koren ,2009)。神经网络 社群
中也已经探索了对评级矩阵进行因子分解的更高级变体 (Salakhutdinov and Mnih ,
2008)。
然而，协同过滤 系统有一个基本限制：当引入新项目或新用户时，缺乏评级历
史意味着无法评估其与其他项目或用户的相似性，或者说无法评估新的用户和现有
项目的联系。这被称为冷启动推荐问题。解决冷启动推荐问题的一般方式是引入单
个用户和项目的额外信息。例如，该额外信息可以是用户简要信息或每个项目的特
征。使用这种信息的系统被称为 基于内容的推荐系统 (content-based recommender
system)。从丰富的用户特征或项目特征集到嵌入的映射可以通过 深度学习 架构学习
(Huang et al. ,2013;Elkahky et al. ,2015)。
专用的深度学习 架构，如 卷积网络 已经应用于从丰富内容中提取特征，如提取
用于音乐推荐的音乐音轨 (van den Oörd et al. ,2013)。在该工作中， 卷积网络 将声
学特征作为输入并计算相关歌曲的嵌入。该歌曲嵌入和用户嵌入之间的点积则可以DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
408 第十二章 应用
预测用户是否将收听该歌曲。
12.5.1.1 探索与开发
当向用户推荐时，会产生超出普通 监督学习 范围的问题，并进入 强化学习 的领
域。理论上，许多推荐问题最准确的描述是 contextual bandit (Langford and Zhang ,
2008;Luet al. ,2010)。问题是，当我们使用 推荐系统 收集数据时，我们得到是一个
有偏且不完整的用户偏好观：我们只能看到用户对推荐给他们项目的反应，而不是
其他项目。此外，在某些情况下，我们可能无法获得未向其进行推荐的用户的任何
信息（例如，在广告竞价中，可能是广告的建议价格低于最低价格阈值，或者没有
赢得竞价，因此广告不会显示） 。更重要的是，我们不知道推荐任何其他项目会产生
什么结果。这就像训练一个分类器，为每个训练样本 x挑选一个类别 ^y（通常是基
于模型最高概率的类别） ，然后只能获得该类别正确与否的反馈。显然，每个样本传
达的信息少于监督的情况（其中真实标签 y是可直接访问的） ，因此需要更多的样
本。更糟糕的是，如果我们不够小心，即使收集越来越多的数据，我们得到的系统
可能会继续选择错误的决定，因为正确的决定最初只有很低的概率：直到学习者选
择正确的决定之前，该系统都无法学习正确的决定。这类似于 强化学习 的情况，其
中仅观察到所选动作的奖励。一般来说， 强化学习 会涉及许多动作和许多奖励的序
列。bandit情景是强化学习 的特殊情况，其中学习者仅采取单一动作并接收单个奖
励。bandit问题在学习者知道哪个奖励与哪个动作相关联的时更容易。在一般的 强
化学习场景中，高奖励或低奖励可能是由最近的动作或很久以前的动作引起的。术
语contextual bandit （contextual bandit ）指的是在一些输入变量可以通知决定的
上下文中采取动作的情况。例如，我们至少知道用户身份，并且我们要选择一个项
目。从上下文到动作的映射也称为 策略（policy） 。学习者和数据分布（现在取决于
学习者的动作）之间的反馈循环是 强化学习 和bandit研究的中心问题。
强化学习 需要权衡 探索（exploration ）与开发（exploitation ） 。开发指的是从
目前学到的最好 策略采取动作，也就是我们所知的将获得高奖励的动作。 探索
（exploration ）是指采取行动以获得更多的训练数据。如果我们知道给定上下文 x，
动作 a给予我们 1的奖励，但我们不知道这是否是最好的奖励。我们可能想利用我
们目前的 策略，并继续采取行动 a相对肯定地获得 1的奖励。然而，我们也可能想
通过尝试动作 a′来探索。我们不知道尝试动作 a′会发生什么。我们希望得到 2的
奖励，但有获得 0奖励的风险。无论如何，我们至少获得了一些知识。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.5其他应用 409
探索（exploration ）可以以许多方式实现，从覆盖可能动作的整个空间的随机
动作到基于模型的方法（基于预期回报和模型对该回报不确定性的量来计算动作的
选择） 。
许多因素决定了我们喜欢 探索或开发的程度。最突出的因素之一是我们感兴趣
的时间尺度。如果代理只有短暂的时间积累奖励，那么我们喜欢更多的 开发。如果
代理有很长时间积累奖励，那么我们开始更多的 探索，以便使用更多的知识更有效
地规划未来的动作。
监督学习 在探索或开发之间没有权衡，因为监督信号总是指定哪个输出对于每
个输入是正确的。我们总是知道标签是最好的输出，没有必要尝试不同的输出来确
定是否优于模型当前的输出。
除了权衡 探索和开发之外，强化学习 背景下出现的另一个困难是难以评估和比
较不同的 策略。强化学习 包括学习者和环境之间的相互作用。这个反馈回路意味着
使用固定的测试集输入评估学习者的表现不是直接的。 策略本身确定将看到哪些输
入。Dudik et al. (2011)提出了评估 contextual bandit 的技术。
12.5.2 知识表示、推理和回答
因为使用符号 (Rumelhart et al. ,1986a )和词嵌入 (Deerwester et al. ,1990;
Bengio et al. ,2001b )，深度学习 方法在语言模型 、机器翻译和 自然语言处理 方面非
常成功。这些嵌入表示关于单个词或概念的语义知识。研究前沿是为短语或词和事
实之间的关系开发嵌入。搜索引擎已经使用 机器学习 来实现这一目的，但是要改进
这些更高级的表示还有许多工作要做。
12.5.2.1 知识、联系和回答
一个有趣的研究方向是确定如何训练 分布式表示 才能捕获两个实体之间的 关系
（relation） 。
数学中， 二元关系 是一组有序的对象对。集合中的对具有这种关系，而那些不
在集合中的对则没有。例如，我们可以在实体集 f1;2;3g上定义关系 ‘‘小于’’来定义
有序对的集合 S=f(1;2);(1;3);(2;3)g。一旦这个关系被定义，我们可以像动词一样
使用它。因为 (1;2)2S，我们说 1小于 2。因为 (2;1)̸2S，我们不能说 2小于 1。
当然，彼此相关的实体不必是数字。我们可以定义关系 is_a_type_of 包含如（狗，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
410 第十二章 应用
哺乳动物） 的元组。
在AI的背景下，我们将 关系看作句法上简单且高度结构化的语言。 关系起到动
词的作用，而 关系的两个参数发挥着主体和客体的作用。这些句子是一个三元组 标
记的形式：
(subject ;verb;object ) (12.21)
其值是
(entityi;relation j;entityk): (12.22)
我们还可以定义 属性（attribute ） ，类似于 关系的概念，但只需要一个参数：
(entityi;attribute j): (12.23)
例如，我们可以定义 has_fur 属性，并将其应用于像 狗这样的实体。
许多应用中需要表示 关系和推理。我们如何在 神经网络 中做到这一点？
机器学习 模型当然需要训练数据。我们可以推断非结构化自然语言组成的训练
数据集中实体之间的 关系，也可以使用明确定义 关系的结构化数据库。这些数据库
的共同结构是 关系型数据库 ，它存储这种相同类型的信息，虽然没有格式化为三
元标记的句子。当数据库旨在将日常生活中常识或关于应用领域的专业知识传达
给人工智能 系统时， 我们将这种数据库称为 知识库。知识库包括一般的像 Freebase 、
OpenCyc、WordNet、Wikibase2等等，和专业的知识库，如 GeneOntology3。实体
和关系的表示可以将知识库中的每个三元组作为训练样本来学习，并且以最大化捕
获它们的联合分布为训练目标 (Bordes et al. ,2013a )。
除了训练数据，我们还需定义训练的模型族。一种常见的方法是将 神经语言模
型扩展到模型实体和 关系。神经语言模型 学习提供每个词 分布式表示 的向量。他们还
通过学习这些向量的函数来学习词之间的相互作用，例如哪些词可能出现在词序列
之后。我们可以学习每个关系的嵌入向量将这种方法扩展到实体和 关系。事实上，建
模语言和通过 关系编码建模知识的联系非常接近，研究人员可以 同时使用知识库和
自然语言句子训练这样的实体表示 (Bordes et al. ,2011,2012;Wang et al. ,2014a )，
或组合来自多个 关系型数据库 的数据 (Bordes et al. ,2013b )。可能与这种模型相关
联的特定参数化有许多种。早期关于学习实体间 关系的工作 (Paccanaro and Hinton ,
2分别可以在如下网址获取 :freebase.com ,cyc.com/opencyc ,wordnet.princeton.edu ,wikiba.se
3geneontology.orgDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
12.5其他应用 411
2000)假定高度受限的参数形式（ ‘‘线性关系嵌入 ’’） ，通常对 关系使用与实体形式不
同的表示。例如， Paccanaro and Hinton (2000)和Bordes et al. (2011)用向量表示
实体而矩阵表示 关系，其思想是 关系在实体上相当于运算符。或者，关系可以被认
为是任何其他实体 (Bordes et al. ,2012)，允许我们关于关系作声明，但是更灵活的
是将它们结合在一起并建模联合分布的机制。
这种模型的实际短期应用是 链接预测 （link prediction ） ：预测知识图谱 中缺失
的弧。这是基于旧事实推广新事实的一种形式。目前存在的大多数 知识库都是通过
人力劳动构建的，这往往使 知识库缺失许多并且可能是大多数真正的关系。请查
看Wang et al. (2014b )、Linet al. (2015)和Garcia-Duran et al. (2015)中这样应用
的例子。
我们很难评估 链接预测 任务上模型的性能，因为我们的数据集只有正样本（已
知是真实的事实） 。如果模型提出了不在数据集中的事实，我们不确定模型是犯了错
误还是发现了一个新的以前未知的事实。度量基于测试模型如何将已知真实事实的
留存集合与不太可能为真的其他事实相比较，因此有些不精确。构造感兴趣的负样
本（可能为假的事实）的常见方式是从真实事实开始，并创建该事实的损坏版本，例
如用随机选择的不同实体替换 关系中的一个实体。通用的测试精度（ 10%度量）计
算模型在该事实的所有损坏版本的前 10%中选择 ‘‘正确’’事实的次数。
知识库和分布式表示 的另一个应用是 词义消歧 （word-sense disambiguation ）
(Navigli and Velardi ,2005;Bordes et al. ,2012)，这个任务决定在某些语境中哪个词
的意义是恰当。
最后，知识的 关系结合一个推理过程和对自然语言的理解可以让我们建立一个
一般的问答系统。一般的问答系统必须能处理输入信息并记住重要的事实，并以之
后能检索和推理的方式组织。这仍然是一个困难的开放性问题，只能在受限的 ‘‘玩
具’’环境下解决。目前，记住和检索特定声明性事实的最佳方法是使用显式记忆机
制，如第 10.12节所述。 记忆网络 最开始是被用来解决一个玩具问答任务 (Weston
et al. ,2014)。Kumar et al. (2015b )提出了一种扩展，使用 GRU循环网络 将输入读
入存储器并且在给定存储器的内容后产生回答。
深度学习 已经应用于其他许多应用（除了这里描述的应用以外） ，并且肯定会在
此之后应用于更多的场景。我们不可能全面描述与此主题相关的所有应用。本项调
查尽可能地提供了在本文写作之时的代表性样本
第二部分介绍了涉及 深度学习 的现代实践，包括了所有非常成功的方法。一般DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
412 第十二章 应用
而言，这些方法使用 代价函数 的梯度寻找模型（近似于某些所期望的函数）的参数。
当具有足够的训练数据时，这种方法是非常强大的。我们现在转到第三部分，开始
进入研究领域，旨在使用较少的训练数据或执行更多样的任务。而且相比目前为止
所描述的情况，其中的挑战更困难并且远远没有解决。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第三部分
深度学习研究
413DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
414
本书这一部分描述目前研究社群所追求的、更有远见和更先进的 深度学习 方法。
在本书的前两部分，我们已经展示了如何解决 监督学习 问题，即在给定足够的
映射样本的情况下，学习将一个向量映射到另一个。
我们想要解决的问题并不全都属于这个类别。我们可能希望生成新的样本、或
确定一个点的似然性、或处理缺失值以及利用一组大量的未标记样本或相关任务的
样本。当前应用于工业的最先进技术的缺点是我们的学习算法需要大量的监督数据
才能实现良好的精度。在本书这一部分，我们讨论一些推测性的方法，来减少现有
模型工作所需的标注数据量，并适用于更广泛的任务。实现这些目标通常需要某种
形式的无监督或半监督学习。
许多深度学习 算法被设计为处理 无监督学习 问题，但不像 深度学习 已经在很大
程度上解决了各种任务的 监督学习 问题，没有一个算法能以同样的方式真正解决 无
监督学习 问题。在本书这一部分，我们描述 无监督学习 的现有方法和一些如何在这
一领域取得进展的流行思想。
无监督学习 困难的核心原因是被建模的随机变量的高维度。这带来了两个不同
的挑战：统计挑战和计算挑战。 统计挑战 与泛化相关：我们可能想要区分的配置数
会随着感兴趣的维度数指数增长，并且这快速变得比可能具有的（或者在有限计算
资源下使用的）样本数大得多。与高维分布相关联的 计算挑战 之所以会出现，是因
为用于学习或使用训练模型的许多算法（特别是基于估计显式概率函数的算法）涉
及难处理的计算量，并且随维数呈指数增长。
使用概率模型，这种计算挑战来自执行难解的 推断或归一化分布。
•难解的推断：推断主要在第 十九章讨论。 推断关于捕获 a，b和c上联合分布的
模型，给定其他变量 b的情况下，猜测一些变量 a的可能值。为了计算这样的
条件概率，我们需要对变量 c的值求和，以及计算对 a和c的值求和的归一化
常数。
•难解的归一化常数（ 配分函数 ）：配分函数 主要在第 十八章讨论。归一化概
率函数的常数在 推断（上文）以及学习中出现。许多概率模型涉及这样的归
一化常数。不幸的是，学习这样的模型通常需要相对于模型参数计算 配分函
数对数的梯度。该计算通常与计算 配分函数 本身一样难解。 马尔可夫链蒙特
卡罗（MCMC）（第十七章）通常用于处理 配分函数 。不幸的是，当模型分
布的模式众多且分离良好时， MCMC方法会出现问题，特别是在高维空间中DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
415
（第 17.5节） 。
面对这些难以处理的计算的一种方法是近似它们，如在本书的第三部分中讨论
的，研究者已经提出了许多方法。这里还讨论另一种有趣的方式是通过设计模型，完
全避免这些难以处理的计算，因此不需要这些计算的方法是非常有吸引力的。近年
来，研究者已经提出了数种具有该动机的生成模型。其中第 二十章讨论了各种各样
的现代生成式建模方法。
第三部分对于研究者来说是最重要的，研究者想要了解 深度学习 领域的广度，
并将领域推向真正的 人工智能 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十三章 线性因子模型
许多深度学习的研究前沿均涉及构建输入的概率模型 pmodel (x)。原则上说，给
定任何其他变量的情况下，这样的模型可以使用概率推断来预测其环境中的任何变
量。许多这样的模型还具有 潜变量 h，其中 pmodel (x) =Ehpmodel (xjh)。这些潜变
量提供了表示数据的另一种方式。我们在 深度前馈网络 和循环网络 中已经发现，基
于潜变量的分布式表示继承了 表示学习 的所有优点。
在本章中，我们描述了一些基于 潜变量的最简单的概率模型： 线性因子模型
（linear factor model ） 。这些模型有时被用来作为混合模型的组成模块 (Hinton et al. ,
1995a ;Ghahramani and Hinton ,1996;Roweis et al. ,2002)或者更大的深度概率模
型(Tang et al. ,2012)。同时，也介绍了构建 生成模型 所需的许多基本方法，在此基
础上更先进的深度模型也将得到进一步扩展。
线性因子模型 通过随机线性 解码器函数来定义，该函数通过对 h的线性变换以
及添加噪声来生成 x。
有趣的是，通过这些模型我们能够发现一些符合简单联合分布的解释性因子。
线性解码器的简单性使得它们成为了最早被广泛研究的 潜变量模型。
线性因子模型 描述如下的数据生成过程。首先，我们从一个分布中抽取解释性
因子 h
hp(h); (13.1)
其中 p(h)是一个因子分布，满足 p(h) =∏
ip(hi)，所以易于从中采样。接下来，在
给定因子的情况下，我们对实值的可观察变量进行采样
x= Wh +b+noise; (13.2)
其中噪声通常是对角化的（在维度上是独立的）且服从高斯分布。这在图 13.1有具
416DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.1概率 PCA和因子分析 417
体说明。
h1h1h2h2h3h3x1x1x2x2x3x3x=Wh+b+noisex=Wh+b+noise
图13.1:描述线性因子模型 族的有向图模型 ，其中我们假设观察到的数据向量 x是通过独立的 潜
在因子 h的线性组合再加上一定噪声获得的。不同的模型，比如 概率 PCA，因子分析 或者是 ICA，
都是选择了不同形式的噪声以及先验 p(h)。
13.1概率PCA和因子分析
概率 PCA（probabilistic PCA ） 、因子分析 和其他线性因子模型 是上述等式
（式 (13.1)和式 (13.2)）的特殊情况，并且仅在对观测到 x之前的噪声分布和 潜变量
h先验的选择上有所不同。
在因子分析 （factor analysis ）(Bartholomew ,1987;Basilevsky ,1994)中，潜
变量的先验是一个方差为单位矩阵的 高斯分布
hN (h;0;I); (13.3)
同时，假定在给定 h的条件下观察值 xi是条件独立 （conditionally independent ）
的。具体来说，我们可以假设噪声是从对角协方差矩阵的高斯分布中抽出的， 协方
差矩阵为 =diag(2)，其中2= [2
1; 2
2; : : : ; 2
n]⊤表示一个向量，每个元素表示
一个变量的方差。
因此，潜变量的作用是 捕获不同观测变量 xi之间的依赖关系 。实际上，可以容
易地看出 x服从多维正态分布 ，并满足
xN (x;b;WW⊤+ ): (13.4)
为了将 PCA引入到概率框架中，我们可以对 因子分析 模型作轻微修改，使条件
方差 2
i等于同一个值。在这种情况下， x的协方差简化为 WW⊤+2I，这里的 2DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
418 第十三章 线性因子模型
是一个标量。由此可以得到条件分布，如下：
xN (x;b;WW⊤+2I); (13.5)
或者等价地
x= W h+b+z; (13.6)
其中 zN (z;0;I)是高斯噪声。之后 Tipping and Bishop (1999)提出了一种迭代
的EM算法来估计参数 W和2。
这个概率 PCA（probabilistic PCA ）模型利用了这样一种观察现象：除了一
些微小残余的 重构误差 （reconstruction error ） （至多为 2） ，数据中的大多数变
化可以由 潜变量 h描述。通过 Tipping and Bishop (1999)的研究我们可以发现，当
  !0时，概率 PCA退化为 PCA。在这种情况下，给定 x情况下 h的条件期望等
于将 x b投影到 W的d列所生成的空间上，与 PCA一样。
当  !0时，概率 PCA所定义的密度函数在 d维的 W的列生成空间周围非
常尖锐。这导致模型会为没有在一个超平面附近聚集的数据分配非常低的概率。
13.2独立成分分析
独立成分分析 （independent component analysis ,ICA）是最古老的 表示学习 算
法之一 (Herault and Ans ,1984;Jutten and Herault ,1991;Comon ,1994;Hyvärinen ,
1999;Hyvärinen et al. ,2001;Hinton et al. ,2001;Teh et al. ,2003)。它是一种建模线
性因子的方法，旨在将观察到的信号分离成许多潜在信号，这些潜在信号通过缩放
和叠加可以恢复成观察数据。这些信号是完全独立的，而不是仅仅彼此不相关1。
许多不同的具体方法被称为 ICA。与我们本书中描述的其他 生成模型 最相似
的ICA变种 (Pham et al. ,1992)训练了完全参数化的 生成模型 。潜在因子 h的先验
p(h)，必须由用户提前给出并固定。接着模型确定性地生成 x= Wh。我们可以通过
非线性变化（使用式 (3.47)）来确定 p(x)。然后通过一般的方法比如最大化似然进
行学习。
这种方法的动机是，通过选择一个独立的 p(h)，我们可以尽可能恢复接近独立
的潜在因子。这是一种常用的方法，它并不是用来捕捉高级别的抽象因果因子，而是
1第3.8节讨论了不相关变量和独立变量之间的差异。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.2独立成分分析 419
恢复已经混合在一起的低级别信号。在该设置中，每个训练样本对应一个时刻，每
个xi是一个传感器对混合信号的观察值，并且每个 hi是单个原始信号的一个估计。
例如，我们可能有 n个人同时说话。如果我们在不同位置放置 n个不同的麦克风，
则ICA可以检测每个麦克风的音量变化，并且分离信号，使得每个 hi仅包含一个
人清楚地说话。这通常用于脑电图的神经科学，这种技术可用于记录源自大脑的电
信号。放置在受试者头部上的许多电极传感器用于测量来自身体的多种电信号。实
验者通常仅对来自大脑的信号感兴趣，但是来自受试者心脏和眼睛的信号强到足以
混淆在受试者头皮处的测量结果。信号到达电极，并且混合在一起，因此为了分离
源于心脏与源于大脑的信号，并且将不同脑区域中的信号彼此分离， ICA是必要的。
如前所述， ICA存在许多变种。一些版本在 x的生成中添加一些噪声，而不是
使用确定性的 解码器。大多数方法不使用 最大似然 准则，而是旨在使 h= W 1x的
元素彼此独立。许多准则能够达成这个目标。式 (3.47)需要用到 W的行列式，这可
能是代价很高且数值不稳定的操作。 ICA的一些变种通过将 W约束为正交来避免
这个有问题的操作。
ICA的所有变种均要求 p(h)是非高斯的。这是因为如果 p(h)是具有高斯分量
的独立先验，则 W是不可识别的。对于许多 W值，我们可以在 p(x)上获得相同
的分布。这与其他 线性因子模型 有很大的区别，例如 概率 PCA和因子分析 通常要求
p(h)是高斯的，以便使模型上的许多操作具有 闭式解。在用户明确指定分布的 最大
似然方法中，一个典型的选择是使用 p(hi) =d
dhi(hi)。这些非高斯分布的典型选择
在0附近具有比高斯分布更高的峰值，因此我们也可以看到 独立成分分析 经常用于
学习稀疏特征。
按照我们对 生成模型 这个术语的定义， ICA的许多变种不是 生成模型 。在本书
中，生成模型 可以直接表示 p(x)，也可以认为是从 p(x)中抽取样本。 ICA的许多
变种仅知道如何在 x和 h之间变换，而没有任何表示 p(h)的方式，因此也无法在
p(x)上施加分布。例如，许多 ICA变量旨在增加 h= W 1x的样本峰度，因为高
峰度说明了 p(h)是非高斯的，但这是在没有显式表示 p(h)的情况下完成的。这就
是为什么 ICA多被用作分离信号的分析工具，而不是用于生成数据或估计其密度。
正如 PCA可以推广到第 十四章中描述的非线性 自编码器 ，ICA也可以推广到
非线性生成模型 ，其中我们使用非线性函数 f来生成观测数据。关于非线性 ICA最
初的工作可以参考 Hyvärinen and Pajunen (1999)，它和集成学习 的成功结合可以参
见Roberts and Everson (2001);Lappalainen et al. (2000)。ICA的另一个非线性扩
展是非线性独立成分估计 （nonlinear independent components estimation ,NICE）DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
420 第十三章 线性因子模型
方法 (Dinh et al. ,2014)，这个方法堆叠了一系列可逆变换（在 编码器阶段） ，其特
性是能高效地计算每个变换的 Jacobian 行列式。这使得我们能够精确地计算似然，
并且像 ICA一样， NICE尝试将数据变换到具有因子的边缘分布的空间。由于非线
性编码器的使用，这种方法更可能成功。因为 编码器和一个能进行完美逆变换的 解
码器相关联，所以可以直接从模型生成样本（首先从 p(h)采样，然后使用 解码器） 。
ICA的另一个推广是通过鼓励组内统计依赖关系、抑制组间依赖关系来学习特
征组。当相关单元的组被选为不重叠时，这被称为 独立子空间分析 （independent
subspace analysis ） 。我们还可以向每个 隐藏单元 分配空间坐标，并且空间上相邻的
单元组形成一定程度的重叠。这能够鼓励相邻的单元学习类似的特征。当应用于自
然图像时，这种 地质ICA（topographic ICA ）方法可以学习 Gabor滤波器，从而
使得相邻特征具有相似的方向、位置或频率。在每个区域内出现类似 Gabor函数的
许多不同相位存在抵消作用，使得在小区域上的 池化产生了平移不变性。
13.3慢特征分析
慢特征分析 （slow feature analysis ,SFA）是使用来自时间信号的信息学习不变
特征的线性因子模型 (Wiskott and Sejnowski ,2002)。
慢特征分析 的想法源于所谓的 慢性原则 （slowness principle ） 。其基本思想是，
与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。例如，
在计算机视觉 中，单个像素值可以非常快速地改变。如果斑马从左到右移动穿过图
像并且它的条纹穿过对应的像素时，该像素将迅速从黑色变为白色，并再次恢复成
黑色。通过比较，指示斑马是否在图像中的特征将不发生改变，并且描述斑马位置
的特征将缓慢地改变。因此，我们可能希望将模型 正则化，从而能够学习到那些随
时间变化较为缓慢的特征。
慢性原则 早于慢特征分析 ， 并已被应用于各种模型 (Hinton ,1989;Földiák ,1989;
Mobahi et al. ,2009;Bergstra and Bengio ,2009)。一般来说，我们可以将 慢性原则 应
用于可以使用 梯度下降 训练的任何可微分模型。为了引入 慢性原则 ，我们可以向 代
价函数添加以下项
∑
tL(f(x(t+1)); f(x(t))); (13.7)
其中 是确定慢度 正则化强度的超参数项， t是样本时间序列的索引， f是需要正则DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.3慢特征分析 421
化的特征提取器 ，L是测量 f(x(t))和f(x(t+1))之间的距离的 损失函数 。L的一个
常见选择是 均方误差 。
慢特征分析 是慢性原则 中一个特别高效的应用。由于它被应用于线性 特征提取
器，并且可以通过 闭式解训练，所以它是高效的。像 ICA的一些变种一样， SFA本
身并不是 生成模型 ，只是在输入空间和特征空间之间定义了一个线性映射，但是没
有定义特征空间的先验，因此没有在输入空间上施加分布 p(x)。
SFA算法 (Wiskott and Sejnowski ,2002)先将 f(x;)定义为线性变换，然后求
解如下优化问题
min
Et(f(x(t+1))i f(x(t))i)2(13.8)
并且满足下面的约束：
Etf(x(t))i= 0 (13.9)
以及
Et[f(x(t))2
i] = 1: (13.10)
学习特征具有零均值的约束对于使问题具有唯一解是必要的 ;否则我们可以向所有特
征值添加一个常数，并获得具有相等慢度目标值的不同解。特征具有单位方差的约
束对于防止所有特征趋近于 0的病态解是必要的。与 PCA类似， SFA特征是有序
的，其中学习第一特征是最慢的。要学习多个特征，我们还必须添加约束
8i < j; Et[f(x(t))if(x(t))j] = 0: (13.11)
这要求学习的特征必须彼此线性去相关。没有这个约束，所有学习到的特征将简单
地捕获一个最慢的信号。可以想象使用其他机制，如最小化 重构误差 ，也可以迫使
特征多样化。但是由于 SFA特征的线性，这种去相关机制只能得到一种简单的解。
SFA问题可以通过线性代数软件获得 闭式解。
在运行 SFA之前， SFA通常通过对 x使用非线性的基扩充来学习非线性特征。
例如，通常用 x的二次基扩充来代替原来的 x，得到一个包含所有 xixj的向量。由
此，我们可以通过反复地学习一个线性 SFA特征提取器 ，对其输出应用非线性基扩
展，然后在该扩展之上学习另一个线性 SFA特征提取器 的方式来组合线性 SFA模
块从而学习深度非线性慢 特征提取器 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
422 第十三章 线性因子模型
当在自然场景视频的小块空间部分上训练时，使用二次基扩展的 SFA所学习
到的特征与 V1皮层中那些复杂细胞的特征有许多共同特性 (Berkes and Wiskott ,
2005)。当在计算机渲染的 3D环境内随机运动的视频上训练时，深度 SFA模型能
够学习的特征与大鼠脑中用于导航的神经元学到的特征有许多共同特性 (Franzius
et al. ,2007)。因此从生物学角度上来说 SFA是一个合理的有依据的模型。
SFA的一个主要优点是，即使在深度非线性条件下，它依然能够在理论上预
测SFA能够学习哪些特征。为了做出这样的理论预测，必须知道关于配置空间的环
境动力（例如，在 3D渲染环境中随机运动的例子中，理论分析是从相机位置、速度
的概率分布中入手的） 。已知潜在因子如何改变的情况下，我们能够通过理论分析解
出表达这些因子的最佳函数。在实践中，基于模拟数据的实验上，使用深度 SFA似
乎能够恢复理论预测的函数。相比之下，在其他学习算法中， 代价函数 高度依赖于
特定像素值，使得难以确定模型将学习到什么特征。
深度 SFA也已经被用于学习用在 对象识别 和姿态估计的特征 (Franzius et al. ,
2008)。到目前为止， 慢性原则 尚未成为任何最先进应用的基础。究竟是什么因素限
制了其性能仍有待研究。我们推测，或许慢度先验太过强势，并且，最好添加这样
一个先验使得当前 时间步到下一个 时间步的预测更加容易，而不是加一个先验使得
特征近似为一个常数。对象的位置是一个有用的特征，无论对象的速度是高还是低。
但慢性原则 鼓励模型忽略具有高速度的对象的位置。
13.4稀疏编码
稀疏编码 （sparse coding ）(Olshausen and Field ,1996)是一个线性因子模型 ，
已作为一种 无监督特征学习和特征提取机制得到了广泛研究。严格来说，术语 “稀疏
编码’’是指在该模型中推断 h值的过程，而 ‘‘稀疏建模 ’’是指设计和学习模型的过
程，但是通常这两个概念都可以用术语 “稀疏编码 ’’描述。
像大多数其他 线性因子模型 一样，它使用了线性的 解码器加上噪声的方式获得
一个 x的重构，就像式 (13.2)描述的一样。更具体地说， 稀疏编码 模型通常假设线
性因子有一个各向同性精度为 的高斯噪声：
p(xjh) =N(x;Wh +b;1
I): (13.12)
分布 p(h)通常选取为一个峰值很尖锐且接近 0的分布 (Olshausen and Field ,DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.4稀疏编码 423
1996)。常见的选择包括可分解的 Laplace、Cauchy或者可分解的 Student-t 分布。
例如，以稀疏惩罚系数 为参数的 Laplace先验可以表示为
p(hi) =Laplace (hi; 0;2
) =
4e 1
2jhij; (13.13)
相应的， Student-t 先验分布可以表示为
p(hi)/1
(1 +h2
i
)+1
2: (13.14)
使用最大似然 的方法来训练 稀疏编码 模型是不可行的。相反，为了在给定编码
的情况下更好地重构数据，训练过程在编码数据和训练 解码器之间交替进行。稍后
在第 19.3节中，这种方法将被进一步证明为是解决 最大似然 问题的一种通用的近似
方法。
对于诸如 PCA的模型，我们已经看到使用了预测 h的参数化的 编码器函数，
并且该函数仅包括乘以权重矩阵。 稀疏编码 中的编码器不是参数化的 编码器。相反，
编码器是一个优化算法，在这个优化问题中，我们寻找单个最可能的编码值：
h=f(x) = arg max
hp(hjx): (13.15)
结合式 (13.13 )和式 (13.12 )，我们得到如下的优化问题：
arg max
hp(hjx) (13.16)
= arg max
hlogp(hjx) (13.17)
= arg min
h∥h∥1+∥x Wh∥2
2; (13.18)
其中，我们扔掉了与 h无关的项，并除以一个正的缩放因子来简化表达。
由于在 h上施加 L1范数，这个过程将产生稀疏的 h（详见第 7.1.2节） 。
为了训练模型而不仅仅是进行推断，我们交替迭代关于 h和 W的最小化过程。
在本文中，我们将 视为超参数。我们通常将其设置为 1，因为它在此优化问题的
作用与 类似，没有必要使用两个超参数。原则上，我们还可以将 作为模型的参
数，并学习它。我们在这里已经放弃了一些不依赖于 h但依赖于 的项。要学习 ，
必须包含这些项，否则 将退化为 0。
不是所有的 稀疏编码 方法都显式地构建了一个 p(h)和一个 p(xjh)。通常我们
只是对学习一个带有激活值的特征的字典感兴趣，当特征是由这个推断过程提取时，
这个激活值通常为 0。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
424 第十三章 线性因子模型
如果我们从 Laplace先验中采样 h，h的元素实际上为 0是一个零概率事件。 生
成模型本身并不稀疏，只有 特征提取器 是稀疏的。 Goodfellow et al. (2013f )描述了
不同模型族中的近似推断，如 尖峰和平板 稀疏编码 模型，其中先验的样本通常包含
许多真正的 0。
与非参数 编码器结合的稀疏编码 方法原则上可以比任何特定的参数化 编码器更
好地最小化重构误差和对数先验的组合。另一个优点是 编码器没有泛化误差 。参数
化的编码器必须泛化地学习如何将 x映射到 h。对于与训练数据差异很大的异常
x，所学习的参数化 编码器可能无法找到对应精确重构或稀疏的编码 h。对于稀疏编
码模型的绝大多数形式，推断问题是凸的，优化过程总能找到最优编码（除非出现
退化的情况，例如重复的权重向量） 。显然，稀疏和重构成本仍然可以在不熟悉的点
上升，但这归因于 解码器权重中的 泛化误差 ，而不是 编码器中的泛化误差 。当稀疏
编码用作分类器的 特征提取器 ，而不是使用参数化的函数来预测编码值时，基于优
化的稀疏编码 模型的编码过程中较小的 泛化误差 可以得到更好的 泛化能力。 Coates
and Ng (2011)证明了在 对象识别 任务中稀疏编码 特征比基于参数化的 编码器（线
性-sigmoid自编码器 ）的特征拥有更好的泛化能力。受他们的工作启发， Goodfellow
et al. (2013f )表明一种 稀疏编码 的变体在标签极少（每类 20个或更少标签）的情况
中比相同情况下的其他 特征提取器 拥有更好的 泛化能力。
非参数编码器的主要缺点是在给定 x的情况下需要大量的时间来计算 h，因为
非参数方法需要运行迭代算法。在第 十四章中讲到的参数化 自编码器 方法仅使用固
定数量的层，通常只有一层。另一个缺点是它不直接通过非参数 编码器进行反向传
播，这使得我们很难采用先使用 无监督方式预训练稀疏编码 模型然后使用 监督方式
对其进行 精调的方法。允许近似导数的 稀疏编码 模型的修改版本确实存在但未被广
泛使用 (Bagnell and Bradley ,2009)。
像其他线性因子模型 一样，稀疏编码 经常产生糟糕的样本，如图 13.2所示。即
使当模型能够很好地重构数据并为分类器提供有用的特征时，也会发生这种情况。
这种现象发生的原因是每个单独的特征可以很好地被学习到，但是隐藏编码值的 因
子先验会导致模型包括每个生成样本中所有特征的随机子集。这促使人们开发更深
的模型，可以在其中最深的编码层施加一个非 因子分布，与此同时也在开发一些复
杂的浅度模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.5 PCA的流形解释 425
图13.2:尖峰和平板 稀疏编码 模型上在 MNIST 数据集训练的样例和权重。 (左)这个模型中的样
本和训练样本相差很大。第一眼看来，我们可能认为模型拟合得很差。 (右)这个模型的权重向量
已经学习到了如何表示笔迹，有时候还能写完整的数字。因此这个模型也学习到了有用的特征。问
题在于特征的 因子先验会导致特征子集合随机的组合。一些这样的子集能够合成可识别的 MNIST
集上的数字。这也促进了拥有更强大 潜在编码分布的 生成模型 的发展。此图经 Goodfellow et al.
(2013f )允许转载。
13.5 PCA的流形解释
线性因子模型 ，包括 PCA和因子分析 ，可以理解为学习一个 流形 (Hinton et al. ,
1997)。我们可以将 概率 PCA定义为高概率的薄饼状区域，即一个 高斯分布 ，沿着
某些轴非常窄，就像薄饼沿着其垂直轴非常平坦，但沿着其他轴是细长的，正如薄
饼在其水平轴方向是很宽的一样。图 13.3解释了这种现象。 PCA可以理解为将该薄
饼与更高维空间中的线性 流形对准。这种解释不仅适用于传统 PCA，而且适用于学
习矩阵 W和 V的任何线性 自编码器 ，其目的是使重构的 x尽可能接近于原始的 x。
编码器表示为
h=f(x) = W⊤(x ): (13.19)
编码器计算 h的低维表示。从 自编码器 的角度来看， 解码器负责计算重构：
^x=g(h) = b+Vh: (13.20)
能够最小化 重构误差
E[∥x ^x∥2] (13.21)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
426 第十三章 线性因子模型
图13.3:平坦的高斯能够描述一个低维 流形附近的概率密度。此图表示了 “流形平面’’上‘‘馅饼’’
的上半部分，并且这个平面穿过了馅饼的中心。正交于 流形方向（指向平面外的箭头方向）的方差
非常小，可以被视作是 ‘‘噪声’’，其他方向（平面内的箭头）的方差则很大，对应了 ‘‘信号’’以及
降维数据的坐标系统。
的线性编码器和解码器的选择对应着 V= W，= b=E[x]，W的列形成一组标准
正交基，这组基生成的子空间与 协方差矩阵 C
C=E[(x )(x )⊤] (13.22)
的主特征向量所生成的子空间相同。在 PCA中， W的列是按照对应特征值（其全
部是实数和非负数）幅度大小排序所对应的特征向量。
我们还可以发现 C的特征值 i对应了 x在特征向量 v(i)方向上的方差。如果
x2RD，h2Rd并且满足 d < D，则（给定上述的 ;b;V;W的情况下）最佳的 重
构误差是
minE[∥x ^x∥2] =D∑
i=d+1i: (13.23)
因此，如果 协方差矩阵 的秩为 d，则特征值 d+1到D都为 0，并且重构误差 为0。
此外，我们还可以证明上述解可以通过在给定正交矩阵 W的情况下最大化 h
元素的方差而不是最小化 重构误差 来获得。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
13.5 PCA的流形解释 427
某种程度上说， 线性因子模型 是最简单的 生成模型 和学习数据表示的最简单模
型。许多模型如 线性分类器 和线性回归 模型可以扩展到 深度前馈网络 ，而这些 线性
因子模型 可以扩展到 自编码器 网络和深度概率模型，它们可以执行相同任务但具有
更强大和更灵活的模型族。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十四章 自编码器
自编码器 （autoencoder ）是神经网络 的一种，经过训练后能尝试将输入复制到
输出。自编码器 （autoencoder ）内部有一个 隐藏层 h，可以产生 编码（code）表示
输入。该网络可以看作由两部分组成：一个由函数 h=f(x)表示的编码器和一个生
成重构的解码器 r=g(h)。图 14.1展示了这种架构。如果一个 自编码器 只是简单地
学会将处处设置为 g(f(x)) = x，那么这个 自编码器 就没什么特别的用处。相反，我
们不应该将 自编码器 设计成输入到输出完全相等。这通常需要向 自编码器 强加一些
约束，使它只能近似地复制，并只能复制与训练数据相似的输入。这些约束强制模
型考虑输入数据的哪些部分需要被优先复制，因此它往往能学习到数据的有用特性。
现代自编码器 将编码器和解码器的概念推而广之，将其中的确定函数推广为随
机映射 pencoder (hjx)和pdecoder (xjh)。
数十年间， 自编码器 的想法一直是 神经网络 历史景象的一部分 (LeCun ,1987;
Bourlard and Kamp ,1988;Hinton and Zemel ,1994)。传统自编码器 被用于降维或
特征学习。近年来， 自编码器 与潜变量模型理论的联系将 自编码器 带到了生成式建
模的前沿，我们将在第 二十章揭示更多细节。 自编码器 可以被看作是 前馈网络 的一
个特例，并且可以使用完全相同的技术进行训练，通常使用 小批量梯度下降 法（其
中梯度基于 反向传播 计算） 。不同于一般的 前馈网络 ，自编码器 也可以使用 再循环
（recirculation ）训练 (Hinton and McClelland ,1988)，这种学习算法基于比较原始
输入的激活和 重构输入的激活。相比 反向传播 算法，再循环算法更具生物学意义，但
很少用于 机器学习 应用。
428DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.1欠完备自编码器 429
xxrrhhfg
图14.1:自编码器 的一般结构，通过内部表示或 编码 h将输入 x映射到输出（称为 重构）r。自编
码器具有两个组件： 编码器 f（将 x映射到 h）和解码器 g（将 h映射到 r） 。
14.1欠完备自编码器
将输入复制到输出听起来没什么用，但我们通常不关心 解码器的输出。相反，我
们希望通过训练 自编码器 对输入进行复制而使 h获得有用的特性。
从自编码器 获得有用特征的一种方法是限制 h的维度比 x小，这种 编码维度
小于输入维度的 自编码器 称为欠完备（undercomplete ）自编码器 。学习欠完备的表
示将强制自编码器 捕捉训练数据中最显著的特征。
学习过程可以简单地描述为最小化一个 损失函数
L(x; g(f(x))); (14.1)
其中 L是一个损失函数 ，惩罚 g(f(x))与 x的差异，如 均方误差 。
当解码器是线性的且 L是均方误差 ，欠完备的自编码器 会学习出与 PCA相同
的生成子空间。这种情况下， 自编码器 在训练来执行复制任务的同时学到了训练数
据的主元子空间。
因此，拥有非线性 编码器函数 f和非线性 解码器函数 g的自编码器 能够学习出
更强大的 PCA非线性推广。不幸的是，如果 编码器和解码器被赋予过大的 容量，自
编码器会执行复制任务而捕捉不到任何有关数据分布的有用信息。从理论上说，我们
可以设想这样一个 自编码器 ，它只有一维 编码，但它具有一个非常强大的非线性 编
码器，能够将每个训练数据 x(i)表示为编码 i。而解码器可以学习将这些整数索引
映射回特定训练样本的值。这种特定情形不会在实际情况中发生，但它清楚地说明，
如果自编码器 的容量太大，那训练来执行复制任务的 自编码器 可能无法学习到数据
集的任何有用信息。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
430 第十四章 自编码器
14.2正则自编码器
编码维数小于输入维数的 欠完备自编码器 可以学习数据分布最显著的特征。我
们已经知道，如果赋予这类 自编码器 过大的容量，它就不能学到任何有用的信息。
如果隐藏 编码的维数允许与输入相等，或隐藏 编码维数大于输入的 过完备
（overcomplete ）情况下，会发生类似的问题。在这些情况下，即使是线性 编码器和
线性解码器也可以学会将输入复制到输出，而学不到任何有关数据分布的有用信息。
理想情况下，根据要建模的数据分布的复杂性，选择合适的 编码维数和编码器、
解码器容量，就可以成功训练任意架构的 自编码器 。正则自编码器 提供这样的能力。
正则自编码器 使用的损失函数 可以鼓励模型学习其他特性（除了将输入复制到输
出） ，而不必限制使用浅层的 编码器和解码器以及小的 编码维数来限制模型的 容量。
这些特性包括 稀疏表示、表示的小导数、以及对噪声或输入缺失的鲁棒性。即使模
型容量大到足以学习一个无意义的恒等函数，非线性且 过完备的正则自编码器 仍然
能够从数据中学到一些关于数据分布的有用信息。
除了这里所描述的方法（ 正则化自编码器 最自然的解释） ，几乎任何带有 潜变
量并配有一个 推断过程（计算给定输入的 潜在表示）的 生成模型 ，都可以看作是 自
编码器的一种特殊形式。强调与 自编码器 联系的两个生成式建模方法是 Helmholtz
机(Hinton et al. ,1995b )的衍生模型，如 变分自编码器 （第 20.10.3节）和生成随机
网络（第 20.12节） 。这些变种（或衍生） 自编码器 能够学习出高 容量且过完备的模
型，进而发现输入数据中有用的结构信息，并且也无需对模型进行 正则化。这些编
码显然是有用的，因为这些模型被训练为近似训练数据的概率分布而不是将输入复
制到输出。
14.2.1 稀疏自编码器
稀疏自编码器 简单地在训练时结合 编码层的稀疏惩罚 Ω( h)和重构误差 ：
L(x; g(f(x))) + Ω( h); (14.2)
其中 g(h)是解码器的输出，通常 h是编码器的输出，即 h=f(x)。
稀疏自编码器 一般用来学习特征，以便用于像分类这样的任务。 稀疏正则化的自
编码器必须反映训练数据集的独特统计特征，而不是简单地充当恒等函数。以这种
方式训练，执行附带 稀疏惩罚的复制任务可以得到能学习有用特征的模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.2正则自编码器 431
我们可以简单地将惩罚项 Ω( h)视为加到 前馈网络 的正则项，这个 前馈网络 的
主要任务是将输入复制到输出（ 无监督学习 的目标） ，并尽可能地根据这些 稀疏特征
执行一些 监督学习 任务（根据 监督学习 的目标） 。不像其它正则项如 权重衰减 ——没
有直观的贝叶斯解释。如第 5.6.1节描述， 权重衰减 和其他正则惩罚可以被解释为一
个MAP近似贝叶斯 推断，正则化的惩罚对应于模型参数的先验概率分布。这种观点
认为，正则化的最大似然对应最大化 p(jx)，相当于最大化 logp(xj) + logp()。
logp(xj)即通常的数据似然项，参数的对数先验项 logp()则包含了对特定值
的偏好。这种观点在第 5.6节有所描述。正则 自编码器 不适用这样的解释是因为正则
项取决于数据，因此根据定义上（从文字的正式意义）来说，它不是一个先验。虽
然如此，我们仍可以认为这些正则项隐式地表达了对函数的偏好。
我们可以认为整个 稀疏自编码器 框架是对带有 潜变量的生成模型 的近似最大似
然训练，而不将 稀疏惩罚视为复制任务的 正则化。假如我们有一个带有可见变量 x
和潜变量 h的模型，且具有明确的联合分布 pmodel (x;h) =pmodel (h)pmodel (xjh)。我
们将 pmodel (h)视为模型关于 潜变量的先验分布，表示模型看到 x的信念先验。这与
我们之前使用 ‘‘先验’’的方式不同，之前指分布 p()在我们看到数据前就对模型参
数的先验进行编码。对数似然函数可分解为
logpmodel (x) = log∑
hpmodel (h;x): (14.3)
我们可以认为 自编码器 使用一个高似然值 h的点估计近似这个总和。这类似于 稀疏
编码生成模型 （第 13.4节） ，但 h是参数编码器的输出，而不是从优化结果推断出的
最可能的 h。从这个角度看，我们根据这个选择的 h，最大化如下
logpmodel (h;x) = logpmodel (h) + logpmodel (xjh): (14.4)
logpmodel (h)项能被稀疏诱导。如 Laplace先验，
pmodel (hi) =
2e jhij; (14.5)
对应于绝对值 稀疏惩罚。将对数先验表示为绝对值惩罚，我们得到
Ω( h) =∑
ijhij; (14.6)
 logpmodel (h) =∑
i(jhij  log
2) = Ω( h) +const ; (14.7)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
432 第十四章 自编码器
这里的常数项只跟 有关。通常我们将 视为超参数，因此可以丢弃不影响参数学
习的常数项。其他如 Student-t 先验也能诱导 稀疏性。从稀疏性导致 pmodel (h)学习
成近似最大似然的结果看， 稀疏惩罚完全不是一个正则项。这仅仅影响模型关于 潜
变量的分布。这个观点提供了训练 自编码器 的另一个动机：这是近似训练 生成模型 的
一种途径。这也给出了为什么 自编码器 学到的特征是有用的另一个解释：它们描述
的潜变量可以解释输入。
稀疏自编码器 的早期工作 (Ranzato et al. ,2007a ,2008)探讨了各种形式的 稀
疏性，并提出了 稀疏惩罚和 logZ项（将最大似然应用到无向概率模型 p(x) =1
Z~p(x)
时产生）之间的联系。这个想法是最小化 logZ防止概率模型处处具有高概率，同理
强制稀疏可以防止 自编码器 处处具有低的 重构误差 。这种情况下，这种联系是对通
用机制的直观理解而不是数学上的对应。在数学上更容易解释 稀疏惩罚对应于有向
模型 pmodel (h)pmodel (xjh)中的 logpmodel (h)。
Glorot et al. (2011b )提出了一种在 稀疏（和去噪）自编码器 的 h中实现真正为
零的方式。该想法是使用 整流线性单元 产生编码层。基于将 表示真正推向零（如绝
对值惩罚）的先验，可以间接控制 表示中零的平均数量。
14.2.2 去噪自编码器
除了向代价函数 增加一个惩罚项，我们也可以通过改变 重构误差 项来获得一个
能学到有用信息的 自编码器 。
传统的自编码器 最小化以下目标
L(x; g(f(x))); (14.8)
其中 L是一个损失函数 ，惩罚 g(f(x))与 x的差异，如它们彼此差异的 L2范数。如
果模型被赋予过大的 容量，L仅仅使得 g◦f学成一个恒等函数。
相反，去噪自编码器 （denoising autoencoder ,DAE）最小化
L(x; g(f(~x))); (14.9)
其中 ~x是被某种噪声损坏的 x的副本。因此 去噪自编码器 必须撤消这些损坏，而不
是简单地复制输入。
Alain and Bengio (2013)和Bengio et al. (2013d )指出去噪训练过程强制 f和
g隐式地学习 pdata(x)的结构。因此 去噪自编码器 也是一个通过最小化 重构误差 获DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.3表示能力、层的大小和深度 433
取有用特性的例子。这也是将 过完备、高容量的模型用作 自编码器 的一个例子——
只要小心防止这些模型仅仅学习一个恒等函数。 去噪自编码器 将在第 14.5节给出更
多细节。
14.2.3 惩罚导数作为正则
另一正则化 自编码器 的策略是使用一个类似 稀疏自编码器 中的惩罚项 Ω，
L(x; g(f(x))) + Ω( h;x); (14.10)
但Ω的形式不同：
Ω( h;x) =∑
i∥∇ xhi∥2: (14.11)
这迫使模型学习一个在 x变化小时目标也没有太大变化的函数。因为这个惩罚
只对训练数据适用，它迫使 自编码器 学习可以反映训练数据分布信息的特征。
这样正则化的自编码器 被称为收缩自编码器 （contractive autoencoder ,CAE） 。
这种方法与 去噪自编码器 、流形学习 和概率模型存在一定理论联系。 收缩自编码器 将
在第 14.7节更详细地描述。
14.3表示能力、层的大小和深度
自编码器 通常只有单层的 编码器和解码器，但这不是必然的。实际上深度 编码
器和解码器能提供更多优势。
回忆第 6.4.1节，其中提到加深 前馈网络 有很多优势。这些优势也同样适用于 自
编码器，因为它也属于 前馈网络 。此外， 编码器和解码器各自都是一个 前馈网络 ，因
此这两个部分也能各自从深度结构中获得好处。
万能近似定理 保证至少有一层 隐藏层且隐藏单元 足够多的 前馈神经网络 能以任
意精度近似任意函数（在很大范围里） ，这是非平凡深度（至少有一层 隐藏层）的一
个主要优点。这意味着具有单 隐藏层的自编码器 在数据域内能表示任意近似数据的
恒等函数。但是，从输入到 编码的映射是浅层的。这意味这我们不能任意添加约束，
比如约束 编码稀疏。深度自编码器 （编码器至少包含一层额外 隐藏层）在给定足够
多的隐藏单元 的情况下，能以任意精度近似任何从输入到 编码的映射。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
434 第十四章 自编码器
深度可以指数地降低表示某些函数的计算成本。深度也能指数地减少学习一些
函数所需的训练数据量。读者可以参考第 6.4.1节巩固深度在 前馈网络 中的优势。
实验中，深度 自编码器 能比相应的浅层或线性 自编码器 产生更好的压缩效率
(Hinton and Salakhutdinov ,2006)。
训练深度 自编码器 的普遍策略是训练一堆浅层的 自编码器 来贪心地预训练相应
的深度架构。所以即使最终目标是训练深度 自编码器 ，我们也经常会遇到浅层 自编
码器。
14.4随机编码器和解码器
自编码器 本质上是一个 前馈网络 ，可以使用与传统 前馈网络 相同的损失函数 和
输出单元。
如第 6.2.2.4节中描述，设计 前馈网络 的输出单元和 损失函数 普遍策略是定义一
个输出分布 p(yjx)并最小化负对数似然  logp(yjx)。在这种情况下， y是关于目
标的向量（如类标） 。
在自编码器 中， x既是输入也是目标。然而，我们仍然可以使用与之前相同的架
构。给定一个隐藏 编码 h，我们可以认为 解码器提供了一个条件分布 pmodel (xjh)。
接着我们根据最小化  logpdecoder (xjh)来训练自编码器 。损失函数 的具体形式视
pdecoder的形式而定。就传统的 前馈网络 来说，如果 x是实值的，那么我们通常使用
线性输出单元参数化高斯分布的均值。在这种情况下，负对数似然对应 均方误差 准
则。类似地，二值 x对应于一个 Bernoulli 分布，其参数由 sigmoid输出单元确定
的。而离散的 x对应 softmax 分布，以此类推。在给定 h的情况下，为了便于计算
概率分布，输出变量通常被视为是条件独立的，但一些技术（如混合密度输出）可
以解决输出相关的建模。
为了更彻底地与我们之前了解到的 前馈网络 相区别，我们也可以将 编码函数
(encoding function) f(x)的概念推广为 编码分布 (encoding distribution) pencoder (hj
x)，如图 14.2中所示。
任何潜变量模型 pmodel (h;x)定义一个随机 编码器
pencoder (hjx) =pmodel (hjx) (14.12)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.5去噪自编码器 435
xxrrhhpencoder(h|x)pdecoder(x|h)
图14.2:随机自编码器 的结构，其中 编码器和解码器包括一些噪声注入，而不是简单的函数。这
意味着可以将它们的输出视为来自分布的采样（对于 编码器是pencoder (hjx)，对于解码器是
pdecoder (xjh)） 。
以及一个随机 解码器
pdecoder (xjh) =pmodel (xjh): (14.13)
通常情况下， 编码器和解码器的分布没有必要是与唯一一个联合分布 pmodel (x;h)相
容的条件分布。 Alain et al. (2015)指出，在保证足够的 容量和样本的情况下，将 编
码器和解码器作为去噪自编码器 训练，能使它们渐近地相容。
14.5去噪自编码器
去噪自编码器 （denoising autoencoder ,DAE）是一类接受损坏数据作为输入，
并训练来预测原始未被损坏数据作为输出的 自编码器 。
DAE的训练过程如图 14.3中所示。我们引入一个损坏过程 C(~xjx)，这个条件
分布代表给定数据样本 x产生损坏样本 ~x的概率。 自编码器 则根据以下过程，从训
练数据对 (x;~x)中学习重构分布 (reconstruction distribution) preconstruct (xj~x)：
1.从训练数据中采一个训练样本 x。
2.从C(~xjx= x)采一个损坏样本 ~x。
3.将(x;~x)作为训练样本来估计 自编码器 的重构分布 preconstruct (xj~x) =
pdecoder (xjh)，其中 h是编码器 f(~x)的输出， pdecoder根据解码函数 g(h)定
义。
通常我们可以简单地对负对数似然  logpdecoder (xjh)进行基于梯度法（如 小批DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
436 第十四章 自编码器
量梯度下降 ）的近似最小化。只要 编码器是确定性的， 去噪自编码器 就是一个 前馈
网络，并且可以使用与其他 前馈网络 完全相同的方式进行训练。
˜x˜xLLhhfg
xxC(˜x|x)
图14.3:去噪自编码器 代价函数 的计算图。 去噪自编码器 被训练为从损坏的版本 ~x重构干净数据
点 x。这可以通过最小化损失 L= logpdecoder (xjh=f(~x))实现，其中 ~x是样本 x经过损坏过
程C(~xjx)后得到的损坏版本。通常，分布 pdecoder是因子的分布（平均参数由前馈网络 g给出） 。
因此我们可以认为 DAE是在以下期望下进行 随机梯度下降 ：
 Ex^pdata(x)E~xC(~xjx)logpdecoder (xjh=f(~x)); (14.14)
其中 ^pdata(x)是训练数据的分布。
14.5.1 得分估计
得分匹配 (Hyvärinen ,2005a )是最大似然的代替。它提供了概率分布的一致估
计，促使模型在各个数据点 x上获得与数据分布相同的 得分（score） 。在这种情况
下，得分是一个特定的梯度场：
∇ xlogp(x): (14.15)
我们将在第 18.4节中更详细地讨论 得分匹配 。对于现在讨论的 自编码器 ，理解
学习 logpdata的梯度场是学习 pdata结构的一种方式就足够了。
DAE的训练准则（条件高斯 p(xjh)）能让自编码器 学到能估计数据分布得分
的向量场 (g(f(x)) x)，这是 DAE的一个重要特性。具体如图 14.4所示。
对一类采用高斯噪声和 均方误差 作为重构误差 的特定去噪自编码器 （具有 sig-
moid隐藏单元 和线性重构单元）的 去噪训练过程， 与训练一类特定的被称为 RBM的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.5去噪自编码器 437
x˜xg f˜xC(˜x|x)x
图14.4:去噪自编码器 被训练为将损坏的数据点 ~x映射回原始数据点 x。我们将训练样本 x表示
为位于低维 流形（粗黑线）附近的红叉。我们用灰色圆圈表示等概率的损坏过程 C(~xjx)。灰色箭
头演示了如何将一个训练样本转换为经过此损坏过程的样本。当训练 去噪自编码器 最小化平方误
差∥g(f(~x)) x∥2的平均值时， 重构 g(f(~x))估计Ex;~xpdata (x)C(~xjx)[xj~x]。g(f(~x))对可能产生
~x的原始点 x的质心进行估计，所以向量 g(f(~x)) ~x近似指向 流形上最近的点。因此 自编码器 可
以学习由绿色箭头表示的向量场 g(f(x)) x。该向量场将得分 ∇ xlogpdata(x)估计为一个乘性因
子，即重构误差 均方根的平均。
无向概率模型是等价的 (Vincent ,2011)。这类模型将在第 20.5.1节给出更详细的介
绍；对于现在的讨论，我们只需知道这个模型能显式的给出 pmodel (x;)。当 RBM使
用去噪得分匹配 （denoising score matching ）算法 (Kingma and LeCun ,2010a )训
练时，它的学习算法与训练对应的 去噪自编码器 是等价的。在一个确定的噪声水平
下，正则化的得分匹配 不是一致估计量；相反它会恢复分布的一个模糊版本。然而，
当噪声水平趋向于 0且训练样本数趋向与无穷时，一致性就会恢复。我们将会在
第18.5节更详细地讨论 去噪得分匹配 。
自编码器 和RBM还存在其他联系。在 RBM上应用得分匹配 后，其代价函数 将
等价于重构误差 结合类似 CAE惩罚的正则项 (Swersky et al. ,2011)。Bengio and
Delalleau (2009)指出自编码器 的梯度是对 RBM对比散度 训练的近似。
对于连续的 x，高斯损坏和 重构分布的去噪准则得到的得分估计适用于一般 编DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
438 第十四章 自编码器
码器和解码器的参数化 (Alain and Bengio ,2013)。这意味着一个使用平方误差 准则
∥g(f(~x)) x∥2(14.16)
和噪声方差为 2的损坏
C(~x=~xjx) =N(~x;= x; =2I) (14.17)
的通用编码器 -解码器架构可以用来训练估计 得分。图 14.5展示其中的工作原理。
图14.5:由去噪自编码器 围绕 1维弯曲流形学习的向量场，其中数据集中在 2维空间中。每个箭
头与重构向量减去 自编码器 的输入向量后的向量成比例，并且根据隐式估计的概率分布指向较高
的概率。向量场在估计的密度函数的最大值处（在数据 流形上）和密度函数的最小值处都为零。例
如，螺旋臂形成局部最大值彼此连接的 1维流形。局部最小值出现在两个臂间隙的中间附近。当 重
构误差的范数（由箭头的长度示出）很大时，在箭头的方向上移动可以显著增加概率，并且在低
概率的地方大多也是如此。 自编码器 将这些低概率点映射到较高的概率 重构。在概率最大的情况
下，重构变得更准确，因此箭头会收缩。经 Alain and Bengio (2013)许可转载此图。
一般情况下，不能保证 重构函数 g(f(x))减去输入 x后对应于某个函数的 梯
度，更不用说 得分。这是早期工作 (Vincent ,2011)专用于特定参数化的原因（其中
g(f(x)) x能通过另一个函数的导数获得） 。 Kamyshanska and Memisevic (2015)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.6使用自编码器学习流形 439
通过标识一类特殊的浅层 自编码器 家族，使 g(f(x)) x对应于这个家族所有成员的
一个得分，以此推广 Vincent (2011)的结果。
目前为止我们所讨论的仅限于 去噪自编码器 如何学习表示一个概率分布。更一
般的，我们可能希望使用 自编码器 作为生成模型 ，并从其分布中进行采样。这将在
第20.11节中讨论。
14.5.2 历史展望
采用 MLP去噪的想法可以追溯到 LeCun (1987)和Gallinari et al. (1987)的
工作。 Behnke (2001)也曾使用 循环网络 对图像去噪。在某种意义上， 去噪自编码
器仅仅是被训练 去噪的MLP。然而， “去噪自编码器 ’’的命名指的不仅仅是学习 去
噪，而且可以学到一个好的内部 表示（作为学习 去噪的副效用） 。这个想法提出较
晚(Vincent et al. ,2008b ,2010)。学习到的 表示可以被用来预训练更深的 无监督网络
或监督网络。与 稀疏自编码器 、稀疏编码 、收缩自编码器 等正则化的自编码器 类似，
DAE的动机是允许学习 容量很高的编码器，同时防止在 编码器和解码器学习一个无
用的恒等函数。
在引入现代 DAE之前， Inayoshi and Kurita (2005)探索了其中一些相同的方
法和目标。他们除了在 监督目标的情况下最小化 重构误差 之外，还在监督 MLP的隐
藏层注入噪声，通过引入 重构误差 和注入噪声提升泛化能力。然而，他们的方法基
于线性编码器，因此无法学习到现代 DAE能学习的强大函数族。
14.6使用自编码器学习流形
如第 5.11.3节描述， 自编码器 跟其他很多 机器学习 算法一样，也利用了数据集中
在一个低维 流形或者一小组这样的 流形的思想。其中一些 机器学习 算法仅能学习到
在流形上表现良好但给定不在 流形上的输入会导致异常的函数。 自编码器 进一步借
此想法，旨在学习 流形的结构。
要了解自编码器 如何做到这一点，我们必须介绍 流形的一些重要特性。
流形的一个重要特征是 切平面（tangent plane ）的集合。 d维流形上的一点 x，
切平面由能张成 流形上允许变动的局部方向的 d维基向量给出。如图 14.6所示，这
些局部方向决定了我们能如何微小地变动 x而保持于 流形上。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
440 第十四章 自编码器
图14.6:正切超平面概念的图示。我们在 784维空间中创建了 1维流形。我们使用一张 784像素
的MNIST图像，并通过垂直平移来转换它。垂直平移的量定义沿着 1维流形的坐标，轨迹为通过
图像空间的弯曲路径。该图显示了沿着该 流形的几个点。为了可视化，我们使用 PCA将流形投影
到2维空间中。 n维流形在每个点处都具有 n维切平面。该切平面恰好在该点接触 流形，并且在
该点处平行于 流形表面。它定义了为保持在 流形上可以移动的方向空间。该 1维流形具有单个切
线。我们在图中示出了一个点处的示例切线，其中图像表示该切线方向在图像空间中是怎样的。灰
色像素表示沿着切线移动时不改变的像素，白色像素表示变亮的像素，黑色像素表示变暗的像素。
所有自编码器 的训练过程涉及两种推动力的折衷：
1.学习训练样本 x的表示 h使得 x能通过解码器近似地从 h中恢复。 x是从训
练数据挑出的这一事实很关键，因为这意味着在 自编码器 不需要成功 重构不属
于数据生成分布下的输入。
2.满足约束或正则惩罚。这可以是限制 自编码器 容量的架构约束，也可以是加入DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.6使用自编码器学习流形 441
到重构代价的一个正则项。这些技术一般倾向那些对输入较不敏感的解。
显然，单一的推动力是无用的——从它本身将输入复制到输出是无用的，同样
忽略输入也是没用的。相反，两种推动力结合是有用的，因为它们驱使隐藏的表示
能捕获有关数据分布结构的信息。重要的原则是， 自编码器 必须有能力表示 重构训
练实例所需的变化 。如果该数据生成分布集中靠近一个低维 流形，自编码器 能隐式
产生捕捉这个 流形局部坐标系的表示：仅在 x周围关于 流形的相切变化需要对应于
h=f(x)中的变化。因此， 编码器学习从输入空间 x到表示空间的映射，映射仅对
沿着流形方向的变化敏感，并且对 流形正交方向的变化不敏感。
图14.7中一维的例子说明，我们可以通过构建对数据点周围的输入扰动不敏感
的重构函数，使得 自编码器 恢复流形结构。
x0 x1 x2
x0:00:20:40:60:81:0r(x)Identity
Optimal reconstruction
图14.7:如果自编码器 学习到对数据点附近的小扰动不变的 重构函数，它就能捕获数据的 流形结
构。这里， 流形结构是 0维流形的集合。虚线对角线表示 重构的恒等函数目标。最佳 重构函数会
在存在数据点的任意处穿过恒等函数。图底部的水平箭头表示在输入空间中基于箭头的 r(x) x
重建方向向量，总是指向最近的 “流形’’（1维情况下的单个数据点） 。在数据点周围， 去噪自编
码器明确地尝试将 重构函数 r(x)的导数限制为很小。 收缩自编码器 的编码器执行相同操作。虽然
在数据点周围， r(x)的导数被要求很小，但在数据点之间它可能会很大。数据点之间的空间对应
于流形之间的区域，为将损坏点映射回 流形，重构函数必须具有大的导数。
为了理解 自编码器 可用于流形学习 的原因，我们可以将 自编码器 和其他方法进
行对比。 学习表征 流形最常见的是 流形上（或附近）数据点的 表示（representation ） 。
对于特定的实例，这样的表示也被称为 嵌入。它通常由一个低维向量给出，具有比这
个流形的‘‘外围’’空间更少的维数。有些算法（下面讨论的 非参数流形学习 算法）直DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
442 第十四章 自编码器
接学习每个训练样例的 嵌入，而其他算法学习更一般的映射（有时被称为 编码器或
表示函数） ，将周围空间（输入空间）的任意点映射到它的 嵌入。
流形学习 大多专注于试图捕捉到这些 流形的无监督学习 过程。最初始的学习非
线性流形的机器学习 研究专注基于 最近邻图 （nearest neighbor graph ）的非参数
（non-parametric ）方法。 该图中每个训练样例对应一个节点， 它的边连接近邻点对。 如
图14.8所示，这些方法 (Schölkopf et al. ,1998b ;Roweis and Saul ,2000;Tenenbaum
et al. ,2000;Brand ,2003b ;Belkin and Niyogi ,2003a ;Donoho and Grimes ,2003;
Weinberger and Saul ,2004b ;Hinton and Roweis ,2003;van der Maaten and Hinton ,
2008)将每个节点与张成实例和近邻之间的差向量变化方向的 切平面相关联。
图14.8:非参数流形学习 过程构建的最近邻图，其中节点表示训练样本，有向边指示最近邻关系。
因此，各种过程可以获得与图的邻域相关联的切平面以及将每个训练样本与实值向量位置或 嵌入
（embedding ）相关联的坐标系。我们可以通过插值将这种表示概括为新的样本。只要样本的数量
大到足以覆盖 流形的弯曲和扭转，这些方法工作良好。图片来自 QMUL多角度人脸数据集 (Gong
et al. ,2000)。
全局坐标系则可以通过优化或求解线性系统获得。图 14.9展示了如何通过大量
局部线性的类高斯样平铺（或 ‘‘薄煎饼 ’’，因为高斯块在 切平面方向是扁平的）得到
一个流形。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.6使用自编码器学习流形 443
图14.9:如果每个位置处的切平面（见图 14.6）是已知的，则它们可以平铺后形成全局坐标系或
密度函数。每个局部块可以被认为是局部欧几里德坐标系或者是局部平面高斯或 ‘‘薄饼’’，在与薄
饼正交的方向上具有非常小的方差而在定义坐标系的方向上具有非常大的方差。这些高斯的混合
提供了估计的密度函数，如 流形中的 Parzen窗口算法 (Vincent and Bengio ,2003)或其非局部的
基于神经网络 的变体 (Bengio et al. ,2006c )。
然而， Bengio and Monperrus (2005)指出了这些局部 非参数方法应用于 流形学
习的根本困难：如果 流形不是很光滑（它们有许多波峰、波谷和曲折） ，为覆盖其
中的每一个变化，我们可能需要非常多的训练样本，导致没有能力泛化到没见过的
变化。实际上，这些方法只能通过内插，概括相邻实例之间 流形的形状。不幸的是，
AI问题中涉及的 流形可能具有非常复杂的结构，难以仅从局部插值捕获特征。考虑
图14.6转换所得的 流形样例。如果我们只观察输入向量内的一个坐标 xi，当平移图
像，我们可以观察到当这个坐标遇到波峰或波谷时，图像的亮度也会经历一个波峰
或波谷。换句话说，底层图像模板亮度的模式复杂性决定执行简单的图像变换所产
生的流形的复杂性。这是采用 分布式表示 和深度学习 捕获流形结构的动机。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
444 第十四章 自编码器
14.7收缩自编码器
收缩自编码器 (Rifai et al. ,2011a ,b)在编码 h=f(x)的基础上添加了显式的正
则项，鼓励 f的导数尽可能小：
Ω( h) =@f(x)
@x2
F: (14.18)
惩罚项 Ω( h)为平方 Frobenius 范数（元素平方之和） ，作用于与 编码器的函数相
关偏导数的Jacobian 矩阵。
去噪自编码器 和收缩自编码器 之间存在一定联系： Alain and Bengio (2013)指出
在小高斯噪声的限制下，当 重构函数将 x映射到 r=g(f(x))时，去噪重构误差 与收
缩惩罚项是等价的。换句话说， 去噪自编码器 能抵抗小且有限的输入扰动，而 收缩
自编码器 使特征提取函数能抵抗极小的输入扰动。
分类任务中，基于 Jacobian 的收缩惩罚预训练特征函数 f(x)，将收缩惩罚应
用在 f(x)而不是 g(f(x))可以产生最好的分类精度。如第 14.5.1节所讨论，应用于
f(x)的收缩惩罚与得分匹配 也有紧密的联系。
收缩（contractive ）源于 CAE弯曲空间的方式。具体来说，由于 CAE训练为
抵抗输入扰动，鼓励将输入点邻域映射到输出点处更小的邻域。我们能认为这是将
输入的邻域 收缩到更小的输出邻域。
说得更清楚一点， CAE只在局部 收缩——一个训练样本 x的所有扰动都映射到
f(x)的附近。全局来看，两个不同的点 x和 x′会分别被映射到远离原点的两个点
f(x)和f(x′)。f扩展到数据 流形的中间或远处是合理的（见图 14.7中小例子的情
况） 。 当 Ω( h)惩罚应用于 sigmoid单元时，收缩 Jacobian 的简单方式是令 sigmoid趋
向饱和的 0或1。这鼓励 CAE使用 sigmoid的极值编码输入点，或许可以解释为二
进制编码。它也保证了 CAE可以穿过大部分 sigmoid隐藏单元 能张成的超立方体，
进而扩散其 编码值。
我们可以认为点 x处的 Jacobian 矩阵 J能将非线性 编码器近似为线性算子。这
允许我们更形式地使用 “收缩’’这个词。在线性理论中，当 Jx的范数对于所有单位
x都小于等于 1时， J被称为收缩的。换句话说，如果 J收缩了单位球，他就是 收
缩的。我们可以认为 CAE为鼓励每个局部线性算子具有收缩性，而在每个训练数据
点处将 Frobenius 范数作为 f(x)的局部线性近似的惩罚。
如第 14.6节中描述，正则 自编码器 基于两种相反的推动力学习 流形。在 CAE的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.7收缩自编码器 445
情况下，这两种推动力是 重构误差 和收缩惩罚 Ω( h)。单独的 重构误差 鼓励 CAE学
习一个恒等函数。单独的 收缩惩罚将鼓励 CAE学习关于 x是恒定的特征。这两种
推动力的的折衷产生导数@f(x)
@x大多是微小的 自编码器 。只有少数 隐藏单元 ，对应于
一小部分输入数据的方向，可能有显著的导数。
CAE的目标是学习数据的 流形结构。使 Jx很大的方向 x，会快速改变 h，因
此很可能是近似 流形切平面的方向。 Rifai et al. (2011a ,b)的实验显示训练 CAE会
导致 J中大部分奇异值（幅值）比 1小，因此是收缩的。然而，有些奇异值仍然比
1大，因为 重构误差 的惩罚鼓励 CAE对最大局部变化的方向进行编码。对应于最大
奇异值的方向被解释为 收缩自编码器 学到的切方向。理想情况下，这些切方向应对
应于数据的真实变化。比如，一个应用于图像的 CAE应该能学到显示图像改变的切
向量，如图 14.6图中物体渐渐改变状态。如图 14.10所示，实验获得的奇异向量的可
视化似乎真的对应于输入图象有意义的变换。
Input
pointTangent vectors
Local PCA (no sharing across regions)
Contractive autoencoder
图14.10:通过局部 PCA和收缩自编码器 估计的流形切向量的图示。 流形的位置由来自 CIFAR-10
数据集中狗的输入图像定义。切向量通过输入到代码映射的 Jacobian 矩阵@h
@x的前导奇异向量估
计。虽然局部 PCA和CAE都可以捕获局部切方向，但 CAE能够从有限训练数据形成更准确的
估计，因为它利用了不同位置的参数共享（共享激活的 隐藏单元 子集） 。 CAE切方向通常对应于物
体的移动或改变部分（例如头或腿） 。经 Rifai et al. (2011c )许可转载此图。
收缩自编码器 正则化准则的一个实际问题是，尽管它在单一 隐藏层的自编码
器情况下是容易计算的，但在更深的 自编码器 情况下会变的难以计算。根据 Rifai
et al. (2011a )的策略，分别训练一系列单层的 自编码器 ，并且每个被训练为 重构前
一个自编码器 的隐藏层。这些自编码器 的组合就组成了一个深度 自编码器 。因为每
个层分别训练成局部 收缩，深度自编码器 自然也是 收缩的。这个结果与联合训练深
度模型完整架构（带有关于 Jacobian 的惩罚项）获得的结果是不同的，但它抓住了DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
446 第十四章 自编码器
许多理想的定性特征。
另一个实际问题是，如果我们不对 解码器强加一些约束， 收缩惩罚可能导致无
用的结果。例如， 编码器将输入乘一个小常数 ϵ，解码器将编码除以一个小常数 ϵ。
随着 ϵ趋向于 0，编码器会使收缩惩罚项 Ω( h)趋向于 0而学不到任何关于分布的信
息。同时， 解码器保持完美的 重构。Rifai et al. (2011a )通过绑定 f和g的权重来
防止这种情况。 f和g都是由线性仿射变换后进行逐元素非线性变换的标准 神经网
络层组成，因此将 g的权重矩阵设成 f权重矩阵的转置是很直观的。
14.8预测稀疏分解
预测稀疏分解 （predictive sparse decomposition ,PSD）是稀疏编码 和参数化 自
编码器 (Kavukcuoglu et al. ,2008)的混合模型。参数化 编码器被训练为能预测迭代
推断的输出。 PSD被应用于图片和视频中对象识别的 无监督特征学习 (Kavukcuoglu
et al. ,2009,2010;Jarrett et al. ,2009b ;Farabet et al. ,2011)，在音频中也有所应用
(Henaﬀ et al. ,2011)。这个模型由一个 编码器 f(x)和一个解码器 g(h)组成，并且都
是参数化的。在训练过程中， h由优化算法控制。优化过程是最小化
∥x g(h)∥2+jhj1+∥h f(x)∥2: (14.19)
就像稀疏编码 ，训练算法交替地相对 h和模型的参数最小化上述目标。相对 h最小
化较快，因为 f(x)提供 h的良好初始值以及 损失函数 将 h约束在 f(x)附近。简单
的梯度下降 算法只需 10步左右就能获得理想的 h。
PSD所使用的训练程序不是先训练 稀疏编码 模型，然后训练 f(x)来预测稀疏
编码的特征。 PSD训练过程正则化 解码器，使用 f(x)可以推断出良好 编码的参数。
预测稀疏分解 是学习近似推断 （learned approximate inference ）的一个例子。
在第 19.5节中，这个话题将会进一步展开。第 十九章中展示的工具能让我们了解到，
PSD能够被解释为通过最大化模型的对数似然下界训练有向 稀疏编码 的概率模型。
在PSD的实际应用中，迭代优化仅在训练过程中使用。模型被部署后，参数 编
码器 f用于计算已经习得的特征。相比通过 梯度下降 推断 h，计算 f是很容易的。
因为 f是一个可微带参函数， PSD模型可堆叠，并用于初始化其他训练 准则的深度
网络。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
14.9自编码器的应用 447
14.9自编码器的应用
自编码器 已成功应用于 降维和信息检索 任务。降维是表示学习 和深度学习 的第
一批应用之一。 它是研究 自编码器 早期驱动力之一。 例如， Hinton and Salakhutdinov
(2006)训练了一个栈式 RBM，然后利用它们的权重初始化一个 隐藏层逐渐减小的深
度自编码器 ，终结于 30个单元的瓶颈。生成的 编码比30维的 PCA产生更少的 重
构误差，所学到的表示更容易定性解释，并能联系基础类别，这些类别表现为分离
良好的集群。
低维表示可以提高许多任务的性能，例如分类。小空间的模型消耗更少的内存
和运行时间。据 Salakhutdinov and Hinton (2007b )和Torralba et al. (2008)观察，
许多降维的形式会将语义上相关的样本置于彼此邻近的位置。映射到低维空间所提
供的线索有助于泛化。
相比普通任务， 信息检索 （information retrieval ）从降维中获益更多，此任务
需要找到数据库中类似查询的条目。此任务不仅和其他任务一样从 降维中获得一般
益处，还使某些低维空间中的搜索变得极为高效。特别的，如果我们训练 降维算法生
成一个低维且 二值的编码，那么我们就可以将所有数据库条目在哈希表映射为二值
编码向量。这个哈希表允许我们返回具有相同二值编码的数据库条目作为查询结果
进行信息检索 。我们也可以非常高效地搜索稍有不同条目，只需反转查询编码的各
个位。这种通过 降维和二值化的 信息检索 方法被称为 语义哈希 （semantic hashing ）
(Salakhutdinov and Hinton ,2007b ,2009b )， 已经被用于文本输入 (Salakhutdinov and
Hinton ,2007b ,2009b )和图像 (Torralba et al. ,2008;Weiss et al. ,2008;Krizhevsky
and Hinton ,2011)。
通常在最终层上使用 sigmoid编码函数产生 语义哈希 的二值编码。sigmoid单元
必须被训练为到达饱和，对所有输入值都接近 0或接近 1。能做到这一点的窍门就
是训练时在 sigmoid非线性单元前简单地注入加性噪声。噪声的大小应该随时间增
加。要对抗这种噪音并且保存尽可能多的信息，网络必须加大输入到 sigmoid函数
的幅度，直到饱和。
学习哈希函数的思想已在其他多个方向进一步探讨，包括改变损失训练 表
示的想法，其中所需优化的损失与哈希表中查找附近样本的任务有更直接的联系
(Norouzi and Fleet ,2011)。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十五章 表示学习
在本章中，首先我们会讨论学习表示是什么意思，以及表示的概念如何有助于
深度框架的设计。我们探讨学习算法如何在不同任务中共享统计信息，包括使用 无
监督任务中的信息来完成 监督任务。共享表示有助于处理多模式或多领域，或是将
已学到的知识迁移到样本很少或没有、但任务表示依然存在的任务上。最后，我们
回过头探讨 表示学习 成功的原因，从 分布式表示 (Hinton et al. ,1986)和深度表示的
理论优势，最后会讲到 数据生成过程 潜在假设的更一般概念，特别是观测数据的基
本成因。
很多信息处理任务可能非常容易，也可能非常困难，这取决于信息是如何表示
的。这是一个广泛适用于日常生活、计算机科学及 机器学习 的基本原则。例如，对于
人而言，可以直接使用长除法计算 210除以 6。但如果使用罗马数字表示，这个问
题就没那么直接了。大部分现代人在使用罗马数字计算 CCX除以 VI时，都会将其
转化成阿拉伯数字，从而使用位值系统的长除法。更具体地，我们可以使用合适或
不合适的表示来量化不同操作的渐近运行时间。例如，插入一个数字到有序表中的
正确位置，如果该数列表示为链表，那么所需时间是 O(n)；如果该列表表示为红黑
树，那么只需要 O(logn)的时间。
在机器学习 中，到底是什么因素决定了一种表示比另一种表示更好呢？一般而
言，一个好的表示可以使后续的学习任务更容易。选择什么表示通常取决于后续的
学习任务。
我们可以将 监督学习 训练的前馈网络 视为表示学习 的一种形式。具体地，网络
的最后一层通常是 线性分类器 ，如 softmax 回归分类器。网络的其余部分学习出该
分类器的表示。监督学习训练模型，一般会使得模型的各个 隐藏层（特别是接近顶
层的隐藏层）的表示能够更加容易地完成训练任务。例如，输入特征线性不可分的
类别可能在最后一个 隐藏层变成线性 可分离的 。原则上，最后一层可以是另一种模
448DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.1贪心逐层无监督预训练 449
型，如最近邻分类器 (Salakhutdinov and Hinton ,2007a )。倒数第二层的特征应该根
据最后一层的类型学习不同的性质。
前馈网络 的监督训练并没有给 学成的中间特征明确强加任何条件。其他的 表示
学习算法往往会以某种特定的方式明确设计表示。例如，我们想要学习一种使得密
度估计更容易的表示。具有更多独立性的分布会更容易建模，因此，我们可以设计
鼓励表示向量 h中元素之间相互独立的 目标函数 。就像监督网络，无监督深度学习
算法有一个主要的训练目标，但也额外地学习出了表示。不论该表示是如何得到的，
它都可以用于其他任务。或者，多个任务（有些是 监督的，有些是 无监督的）可以通
过共享的内部表示一起学习。
大多数表示学习 算法都会在尽可能多地保留与输入相关的信息和追求良好的性
质（如独立性）之间作出权衡。
表示学习 特别有趣，因为它提供了进行 无监督学习 和半监督学习 的一种方法。
我们通常会有巨量的 未标注训练数据和相对较少的 标注训练数据。在非常有限的 标
注数据集上 监督学习 通常会导致严重的 过拟合。半监督学习 通过进一步学习 未标
注数据，来解决 过拟合的问题。具体地，我们可以从 未标注数据上学习出很好的表
示，然后用这些表示来解决 监督学习 问题。
人类和动物能够从非常少的 标注样本中学习。我们至今仍不知道这是如何做到
的。有许多假说解释人类的卓越学习能力——例如，大脑可能使用了大量的分类器
或者贝叶斯推断 技术的集成。一种流行的假说是，大脑能够利用 无监督学习 和半监
督学习。利用未标注数据有多种方式。在本章中，我们主要使用的假说是 未标注数
据可以学习出良好的表示。
15.1贪心逐层无监督预训练
无监督学习 在深度神经网络 的复兴上起到了关键的、历史性的作用，它使研究
者首次可以训练不含诸如 卷积或者循环这类特殊结构的深度 监督网络。我们将这一
过程称为 无监督预训练 （unsupervised pretraining ） ，或者更精确地， 贪心逐层无监
督预训练 （greedy layer-wise unsupervised pretraining ） 。此过程是一个任务（ 无监
督学习，尝试获取输入分布的形状）的表示如何有助于另一个任务（具有相同输入
域的监督学习 ）的典型示例。
贪心逐层无监督预训练 依赖于单层 表示学习 算法，例如 RBM、单层自编码器 、DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
450 第十五章 表示学习
稀疏编码 模型或其他学习 潜在表示的模型。每一层使用 无监督学习 预训练，将前一
层的输出作为输入，输出数据的新的表示。这个新的表示的分布（或者是和其他变
量比如要预测类别的关系）有可能是更简单的。如算法 15.1所示的正式表述。
算法15.1贪心逐层无监督预训练 的协定
给定如下：无监督特征学习算法 L，L使用训练集样本并返回 编码器或特征函数 f。
原始输入数据是 X，每行一个样本，并且 f(1)(X)是第一阶段 编码器关于 X的输出。
在执行精调的情况下，我们使用学习者 T，并使用初始函数 f，输入样本 X（以及
在监督精调情况下关联的目标 Y） ，并返回细调好函数。阶段数为 m。
f 恒等函数
~X= X
fork= 1; : : : ; m do
f(k)=L(~X)
f f(k)◦f
~X f(k)(~X)
end for
ifﬁne-tuning then
f T (f;X;Y)
end if
Return f
基于无监督标准的贪心逐层训练过程，早已被用来规避 监督问题中深度神经网
络难以联合训练多层的问题。这种方法至少可以追溯神经认知机 (Fukushima ,1975)。
深度学习的复兴始于 2006年，源于发现这种贪心学习过程能够为多层联合训练过程
找到一个好的初始值，甚至可以成功训练全连接的结构 (Hinton et al. ,2006b ;Hinton
and Salakhutdinov ,2006;Hinton ,2006;Bengio et al. ,2007d ;Ranzato et al. ,2007a )。
在此发现之前，只有深度卷积网络或深度循环网络这类特殊结构的深度网络被认为
是有可能训练的。现在我们知道训练具有全连接的深度结构时，不再需要使用 贪心
逐层无监督预训练 ，但无监督预训练是第一个成功的方法。
贪心逐层无监督预训练 被称为贪心（greedy）的，是因为它是一个 贪心算法
（greedy algorithm ） ，这意味着它独立地优化解决方案的每一个部分，每一步解决一
个部分，而不是联合优化所有部分。它被称为 逐层的（layer-wise ） ，是因为这些独立
的解决方案是网络层。具体地， 贪心逐层无监督预训练 每次处理一层网络，训练第 kDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.1贪心逐层无监督预训练 451
层时保持前面的网络层不变。特别地，低层网络（最先训练的）不会在引入高层网
络后进行调整。它被称为 无监督（unsupervised ）的，是因为每一层用 无监督表示学
习算法训练。然而，它也被称为 预训练（pretraining ） ，是因为它只是在联合训练算
法精调（ﬁne-tune ）所有层之前的第一步。在 监督学习 任务中，它可以被看作是 正
则化项（在一些实验中， 预训练不能降低训练误差，但能降低测试误差）和参数初
始化的一种形式。
通常而言， “预训练 ’’不仅单指 预训练阶段，也指结合 预训练和监督学习 的两阶
段学习过程。 监督学习 阶段可能会使用 预训练阶段得到的顶层特征训练一个简单分
类器，或者可能会对 预训练阶段得到的整个网络进行 监督精调。不管采用什么类型
的监督学习 算法和模型，在大多数情况下，整个训练过程几乎是相同的。虽然 无监
督学习算法的选择将明显影响到细节，但是大多数 无监督预训练 应用都遵循这一基
本方法。
贪心逐层无监督预训练 也能用作其他 无监督学习 算法的初始化，比如深度 自编
码器 (Hinton and Salakhutdinov ,2006)和具有很多 潜变量层的概率模型。这些 模
型包括深度信念网络 (Hinton et al. ,2006b )和深度玻尔兹曼机 (Salakhutdinov and
Hinton ,2009c )。这些深度生成模型 会在第二十章中讨论。
正如第 8.7.4节所探讨的，我们也可以进行 贪心逐层监督预训练。这是建立在
训练浅层模型比 深度模型 更容易的前提下，而该前提似乎在一些情况下已被证
实(Erhan et al. ,2010)。
15.1.1 何时以及为何无监督预训练有效？
在很多分类任务中， 贪心逐层无监督预训练 能够在测试误差 上获得重大提升。
这一观察结果始于 2006年对深度神经网络 的重新关注 (Hinton et al. ,2006b ;Bengio
et al. ,2007d ;Ranzato et al. ,2007a )。然而，在很多其他问题上， 无监督预训练不能
带来改善，甚至还会带来明显的负面影响。 Maet al. (2015)研究了预训练对机器学
习模型在化学活性预测上的影响。结果发现，平均而言 预训练是有轻微负面影响的，
但在有些问题上会有显著帮助。由于 无监督预训练 有时有效，但经常也会带来负面
效果，因此很有必要了解它何时有效以及有效的原因，以确定它是否适合用于特定
的任务。
首先，要注意的是这个讨论大部分都是针对 贪心无监督预训练 而言。还有很多其
他完全不同的方法使用 半监督学习 来训练神经网络 ，比如第 7.13节介绍的 虚拟对抗DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
452 第十五章 表示学习
训练。我们还可以在训练 监督模型 的同时训练 自编码器 或生成模型 。这种单阶段方
法的例子包括 判别 RBM (Larochelle and Bengio ,2008a )和梯形网络 (Rasmus et al. ,
2015)，其中整体目标是两项之和（一个使用 标签，另一个仅仅使用输入） 。
无监督预训练 结合了两种不同的想法。第一，它利用了 深度神经网络 对初始参
数的选择，可以对模型有着显著的 正则化效果（在较小程度上，可以改进优化）的
想法。第二，它利用了更一般的想法——学习 输入分布 有助于学习从 输入到输出的
映射。
这两个想法都涉及到 机器学习 算法中多个未能完全理解的部分之间复杂的相互
作用。
第一个想法，即 深度神经网络 初始参数的选择对其性能具有很强的 正则化效果，
很少有关于这个想法的理解。在 预训练变得流行时，在一个位置初始化模型被认为
会使其接近某一个 局部极小点 ，而不是另一个 局部极小点 。如今，局部极小值 不再被
认为是神经网络 优化中的严重问题。现在我们知道标准的 神经网络 训练过程通常不
会到达任何形式的 临界点。仍然可能的是， 预训练会初始化模型到一个可能不会到
达的位置——例如，某种区域，其中 代价函数 从一个样本点到另一个样本点变化很
大，而小批量只能提供 噪声严重的梯度估计，或是某种区域中的 Hessian矩阵条件
数是病态的， 梯度下降 必须使用非常小的步长。然而，我们很难准确判断 监督学习 期
间预训练参数的哪些部分应该保留。这是现代方法通常同时使用 无监督学习 和监督
学习，而不是依序使用两个学习阶段的原因之一。除了这些复杂的方法可以让 监督
学习阶段保持 无监督学习 阶段提取的信息之外，还有一种简单的方法，固定 特征提
取器的参数，仅仅将 监督学习 作为顶层学成特征的分类器。
另一个想法有更好的理解，即学习算法可以使用 无监督阶段学习的信息，在 监
督学习的阶段表现得更好。其基本想法是对于 无监督任务有用的一些特征对于 监督
学习任务也可能是有用的。例如，如果我们训练汽车和摩托车图像的 生成模型 ，它
需要知道轮子的概念，以及一张图中应该有多少个轮子。如果我们幸运的话， 无监
督阶段学习的轮子表示会适合于 监督学习 。然而我们还未能从数学、理论层面上证
明，因此并不总是能够预测哪种任务能以这种形式从 无监督学习 中受益。这种方法
的许多方面高度依赖于具体使用的模型。例如，如果我们希望在 预训练特征的顶层
添加线性分类器 ，那么（学习到的）特征必须使潜在的类别是线性 可分离的 。这些性
质通常会在 无监督学习 阶段自然发生，但也并非总是如此。这是另一个 监督和无监
督学习同时训练更可取的原因——输出层施加的约束很自然地从一开始就包括在内。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.1贪心逐层无监督预训练 453
从无监督预训练 作为学习一个表示的角度来看，我们可以期望 无监督预训练 在
初始表示较差的情况下更有效。一个重要的例子是 词嵌入。使用 one-hot向量表示
的词并不具有很多信息，因为任意两个不同的 one-hot向量之间的距离（平方 L2距
离都是 2)都是相同的。 学成的词嵌入自然会用它们彼此之间的距离来编码词之间
的相似性。因此， 无监督预训练 在处理单词时特别有用。然而在处理图像时是不太
有用的，可能是因为图像已经在一个很丰富的向量空间中，其中的距离只能提供低
质量的相似性度量。
从无监督预训练 作为正则化项 的角度来看，我们可以期望 无监督预训练 在标
注样本数量非常小时很有帮助。因为 无监督预训练 添加的信息来源于 未标注数据，
所以当未标注样本的数量非常大时，我们也可以期望 无监督预训练 的效果最好。
无监督预训练 的大量未标注样本和少量 标注样本构成的 半监督学习 的优势特别明
显。在 2011年，无监督预训练 赢得了两个国际 迁移学习 比赛 (Mesnil et al. ,2011;
Goodfellow et al. ,2011)。在该情景中，目标任务中 标注样本的数目很少（每类几个
到几十个） 。这些效果也出现在被 Paine et al. (2014)严格控制的实验中。
还可能涉及到一些其他的因素。例如，当我们要学习的函数非常复杂时， 无监
督预训练 可能会非常有用。 无监督学习 不同于权重衰减 这样的正则化项 ，它不偏向
于学习一个简单的函数，而是学习对 无监督学习 任务有用的特征函数。如果真实的
潜在函数是复杂的，并且由 输入分布 的规律塑造，那么 无监督学习 更适合作为 正则
化项。
除了这些注意事项外，我们现在分析一些 无监督预训练 改善性能的成功示例，并
解释这种改进发生的已知原因。 无监督预训练 通常用来改进分类器，并且从减少 测
试集误差的观点来看是很有意思的。然而， 无监督预训练 还有助于分类以外的任务，
并且可以用于改进优化，而不仅仅只是作为 正则化项 。例如，它可以提高 去噪自编
码器的训练和测试 重构误差 (Hinton and Salakhutdinov ,2006)。
Erhan et al. (2010)进行了许多实验来解释 无监督预训练 的几个成功原因。对 训
练误差和测试误差 的改进都可以解释为， 无监督预训练 将参数引入到了其他方法可
能探索不到的区域。 神经网络 训练是非确定性的，并且每次运行都会收敛到不同的
函数。训练可以停止在梯度很小的点；也可以 提前终止 结束训练，以防 过拟合；还可
以停止在梯度很大，但由于诸如随机性或 Hessian矩阵病态条件 等问题难以找到合
适下降方向的点。经过 无监督预训练 的神经网络会一致地停止在一片相同的函数空
间区域，但未经过 预训练的神经网络 会一致地停在另一个区域。图 15.1可视化了这
种现象。经过 预训练的网络到达的区域是较小的，这表明 预训练减少了估计过程的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
454 第十五章 表示学习
方差，这进而又可以降低严重 过拟合的风险。换言之， 无监督预训练 将神经网络 参
数初始化到它们不易逃逸的区域，并且遵循这种初始化的结果更加一致，和没有这
种初始化相比，结果很差的可能性更低。
Erhan et al. (2010)也回答了 何时预训练效果最好——预训练的网络越深， 测试
误差的均值和方差下降得越多。值得注意的是，这些实验是在训练非常深层网络的
现代方法发明和流行（ 整流线性单元 ，Dropout 和批标准化 ）之前进行的，因此对
于无监督预训练 与当前方法的结合，我们所知甚少。
一个重要的问题是 无监督预训练 是如何起到 正则化项 作用的。一个假设是， 预训
练鼓励学习算法发现那些与生成观察数据的潜在原因相关的特征。这也是启发除 无
监督预训练 之外许多其他算法的重要思想，将会在第 15.3节中进一步讨论。
与无监督学习 的其他形式相比， 无监督预训练 的缺点是其使用了两个单独的训
练阶段。很多 正则化技术都具有一个优点，允许用户通过调整单一 超参数的值来控
制正则化的强度。 无监督预训练 没有一种明确的方法来调整 无监督阶段正则化的强
度。相反， 无监督预训练 有许多超参数，但其效果只能之后度量，通常难以提前预
测。当我们同时执行 无监督和监督学习 而不使用 预训练策略时，会有单个 超参数（通
常是附加到 无监督代价的系数）控制 无监督目标正则化监督模型的强度。减少该系
数，总是能够可预测地获得较少 正则化强度。在 无监督预训练 的情况下，没有一种
灵活调整 正则化强度的方式——要么 监督模型初始化为 预训练的参数，要么不是。
具有两个单独的训练阶段的另一个缺点是每个阶段都具有各自的 超参数。第二
阶段的性能通常不能在第一阶段期间预测，因此在第一阶段提出 超参数和第二阶段
根据反馈来更新之间存在较长的延迟。最通用的方法是在 监督阶段使用 验证集上的
误差来挑选 预训练阶段的超参数，如 Larochelle et al. (2009)中讨论的。在实际中，
有些超参数，如预训练迭代的次数，很方便在 预训练阶段设定，通过 无监督目标上
使用提前终止 策略完成。这个策略并不理想，但是在计算上比使用 监督目标代价小
得多。
如今，大部分算法已经不使用 无监督预训练 了，除了在 自然语言处理 领域中单词
作为 one-hot向量的自然表示不能传达相似性信息，并且有非常多的 未标注数据集
可用。在这种情况下， 预训练的优点是可以对一个巨大的 未标注集合（例如用包含数
十亿单词的语料库）进行 预训练，学习良好的表示（通常是单词，但也可以是句子） ，
然后使用该表示或 精调它，使其适合于训练集样本大幅减少的 监督任务。这种方法
由Collobert and Weston (2008b )、Turian et al. (2010)和Collobert et al. (2011a )DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.1贪心逐层无监督预训练 455
−4000 −3000 −2000 −1000 0 1000 2000 3000 4000−1500−1000−500050010001500
With pretraining
Without pretraining
图15.1:在函数空间 （并非参数空间，避免从参数向量到函数的多对一映射）不同神经网络的学
习轨迹的非线性映射的可视化。不同网络采用不同的随机初始化，并且有的使用了 无监督预训练 ，
有的没有。每个点对应着训练过程中一个特定时间的神经网络。经 Erhan et al. (2010)许可改编此
图。函数空间中的坐标是关于每组输入 x和它的一个输出 y的无限维向量。 Erhan et al. (2010)
将很多特定 x的 y连接起来，线性投影到高维空间中。然后他们使用 Isomap (Tenenbaum et al. ,
2000)进行进一步的非线性投影并投到二维空间。颜色表示时间。所有的网络初始化在上图的中心
点附近（对应的函数区域在不多数输入上具有近似 均匀分布 的类别 y） 。随着时间推移，学习将函
数向外移动到预测得更好的点。当使用 预训练时，训练会一致地收敛到同一个区域；而不使用 预
训练时，训练会收敛到另一个不重叠的区域。 Isomap试图维持全局相对距离（体积因此也保持不
变） ，因此使用 预训练的模型对应的较小区域意味着，基于 预训练的估计具有较小的方差。
开创，至今仍在使用。
基于监督学习 的深度学习 技术，通过 Dropout 或批标准化 来正则化，能够在很
多任务上达到人类级别的性能，但仅仅是在极大的 标注数据集上。在中等大小的数
据集（例如 CIFAR-10 和MNIST，每个类大约有 5,000个标注样本）上，这些技术
的效果比 无监督预训练 更好。在极小的数据集，例如 选择性剪接数据集 ，贝叶斯方
法要优于基于 无监督预训练 的方法 (Srivastava ,2013)。由于这些原因， 无监督预训
练已经不如以前流行。然而， 无监督预训练 仍然是深度学习 研究历史上的一个重要
里程碑，并将继续影响当代方法。 预训练的想法已经推广到 监督预训练 （supervised
pretraining ） ，这将在第 8.7.4节中讨论，在 迁移学习 中这是非常常用的方法。 迁移学
习中的监督预训练 流行 (Oquab et al. ,2014;Yosinski et al. ,2014)于在 ImageNet 数
据集上使用 卷积网络 预训练。由于这个原因，实践者们公布了这些网络训练出的参
数，就像自然语言任务公布 预训练的单词向量一样 (Collobert et al. ,2011a ;MikolovDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
456 第十五章 表示学习
et al. ,2013a )。
15.2迁移学习和领域自适应
迁移学习 和领域自适应 指的是利用一个情景（例如，分布 P1）中已经学到的内
容去改善另一个情景（比如分布 P2）中的泛化情况。这点概括了上一节提出的想法，
即在无监督学习 任务和监督学习 任务之间转移表示。
在迁移学习 （transfer learning ）中，学习器必须执行两个或更多个不同的任务，
但是我们假设能够解释 P1变化的许多因素和学习 P2需要抓住的变化相关。这通常
能够在监督学习 中解释，输入是相同的，但是输出不同的性质。例如，我们可能在
第一种情景中学习了一组视觉类别，比如猫和狗，然后在第二种情景中学习一组不
同的视觉类别，比如蚂蚁和黄蜂。如果第一种情景（从 P1采样）中具有非常多的数
据，那么这有助于学习到能够使得从 P2抽取的非常少样本中快速 泛化的表示。许多
视觉类别 共享一些低级概念，比如边缘、视觉形状、几何变化、光照变化的影响等
等。一般而言，当存在对不同情景或任务有用特征时，并且这些特征对应多个情景
出现的潜在因素， 迁移学习 、多任务学习 （第 7.7节）和领域自适应 可以使用 表示学
习来实现。如图 7.2所示，这是具有共享底层和任务相关上层的学习框架。
然而，有时不同任务之间共享的不是输入的语义，而是输出的语义。例如， 语
音识别系统需要在输出层产生有效的句子，但是输入附近的较低层可能需要识别相
同音素或子音素发音的非常不同的版本（这取决于说话人） 。在这样的情况下，共享
神经网络的上层（输出附近）和进行任务特定的预处理是有意义的，如图 15.2所示。
在领域自适应 （domain adaption ）的相关情况下，在每个情景之间任务（和最
优的输入到输出的映射）都是相同的，但是 输入分布 稍有不同。例如，考虑情感分析
的任务，如判断一条评论是表达积极的还是消极的情绪。网上的评论有许多类别。在
书、视频和音乐等媒体内容上训练的顾客评论情感预测器，被用于分析诸如电视机
或智能电话的消费电子产品的评论时， 领域自适应 情景可能会出现。可以想象，存
在一个潜在的函数可以判断任何语句是正面的、中性的还是负面的，但是词汇和风
格可能会因领域而有差异，使得跨域的 泛化训练变得更加困难。简单的 无监督预训
练（去噪自编码器 ）已经能够非常成功地用于 领域自适应 的情感分析 (Glorot et al. ,
2011c )。
一个相关的问题是 概念漂移 （concept drift ） ，我们可以将其视为一种 迁移学习 ，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.2迁移学习和领域自适应 457
Selection switchh(1)h(1)h(2)h(2)h(3)h(3)yyh(shared)h(shared)
x(1)x(1)x(2)x(2)x(3)x(3)
图15.2:多任务学习 或者迁移学习 的架构示例。输出变量 y在所有的任务上具有相同的语义；输
入变量 x在每个任务（或者，比如每个用户）上具有不同的意义（甚至可能具有不同的维度） ，图
上三个任务为 x(1)，x(2)，x(3)。底层结构（决定了选择方向）是面向任务的，上层结构是共享的。
底层结构学习将面向特定任务的输入转化为通用特征。
因为数据分布随时间而逐渐变化。 概念漂移 和迁移学习 都可以被视为 多任务学习 的
特定形式。 “多任务学习 ’’这个术语通常指 监督学习 任务，而更广义的 迁移学习 的概
念也适用于 无监督学习 和强化学习 。
在所有这些情况下，我们的目标是利用第一个 情景下的数据，提取那些在第二
种情景中学习时或直接进行预测时可能有用的信息。 表示学习 的核心思想是相同的
表示可能在两种 情景中都是有用的。两个 情景使用相同的表示，使得表示可以受益
于两个任务的训练数据。
如前所述， 迁移学习 中无监督深度学习 已经在一些 机器学习 比赛中取得了成
功(Mesnil et al. ,2011;Goodfellow et al. ,2011)。这些比赛中的某一个实验配置如
下。首先每个参与者获得一个第一种 情景（来自分布 P1）的数据集，其中含有一些
类别的样本。参与者必须使用这个来学习一个良好的特征空间（将原始输入映射到
某种表示） ，使得当我们将这个 学成变换用于来自迁移 情景（分布 P2）的输入时， 线
性分类器 可以在很少 标注样本上训练、并 泛化得很好。这个比赛中最引人注目的结
果之一是，学习表示的网络架构越深（在第一个 情景P1中的数据使用纯 无监督方式
学习） ，在第二个 情景（迁移） P2的新类别上学习到的曲线就越好。对于深度表示而
言，迁移任务只需要少量 标注样本就能显著地提升 泛化性能。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
458 第十五章 表示学习
迁移学习 的两种极端形式是 一次学习 （one-shot learning ）和零次学习 （zero-
shot learning ） ，有时也被称为 零数据学习 （zero-data learning ） 。只有一个 标注样本
的迁移任务被称为 一次学习 ；没有标注样本的迁移任务被称为 零次学习 。
因为第一阶段学习出的表示就可以清楚地分离出潜在的类别，所以 一次学
习(Fei-Fei et al. ,2006)是可能的。在 迁移学习 阶段，仅需要一个 标注样本来推断表
示空间中聚集在相同点周围许多可能测试样本的 标签。这使得在 学成的表示空间中，
对应于不变性的变化因子已经与其他因子完全分离，在区分某些类别的对象时，我
们可以学习到哪些因素具有决定意义。
考虑一个 零次学习 情景的例子， 学习器已经读取了大量文本，然后要解决 对象
识别的问题。如果文本足够好地描述了对象，那么即使没有看到某对象的图像，也
能识别出该对象的类别。例如，已知猫有四条腿和尖尖的耳朵，那么 学习器可以在
没有见过猫的情况下猜测该图像中是猫。
只有在训练时使用了额外信息， 零数据学习 (Larochelle et al. ,2008)和零次学
习(Palatucci et al. ,2009;Socher et al. ,2013b )才是有可能的。我们可以认为 零数据
学习场景包含三个随机变量：传统输入 x，传统输出或目标 y，以及描述任务的附
加随机变量 T。该模型被训练来估计条件分布 p(yjx; T)，其中 T是我们希望执行
的任务的描述。在我们的例子中，读取猫的文本信息然后识别猫，输出是二元变量
y，y= 1表示 ‘‘是’’，y= 0表示 ‘‘不是’’。任务变量 T表示要回答的问题，例如 ‘‘这
个图像中是否有猫？ ”如果训练集包含和 T在相同空间的 无监督对象样本，我们也
许能够推断未知的 T实例的含义。在我们的例子中，没有提前看到猫的图像而去识
别猫，所以拥有一些 未标注文本数据包含句子诸如 ‘‘猫有四条腿 ’’或‘‘猫有尖耳朵 ’’，
对于学习非常有帮助。
零次学习 要求 T被表示为某种形式的 泛化。例如， T不能仅是指示对象类别
的one-hot编码。通过使用每个类别词的 词嵌入表示， Socher et al. (2013b )提出了对
象类别的 分布式表示 。
我们还可以在 机器翻译 中发现一种类似的现象 (Klementiev et al. ,2012;Mikolov
et al. ,2013b ;Gouws et al. ,2014)：我们已经知道一种语言中的单词，还可以学到单
一语言语料库中词与词之间的关系；另一方面，我们已经翻译了一种语言中的单词
与另一种语言中的单词相关的句子。即使我们可能没有将语言 X中的单词 A翻译
成语言 Y中的单词 B的标注样本，我们也可以 泛化并猜出单词 A的翻译，这是由
于我们已经学习了语言 X和Y单词的分布式表示 ，并且通过两种语言句子的匹配DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.2迁移学习和领域自适应 459
对组成的训练样本，产生了关联于两个空间的链接（可能是双向的） 。如果联合学习
三种成分（两种表示形式和它们之间的关系） ，那么这种迁移将会非常成功。
零次学习 是迁移学习 的一种特殊形式。同样的原理可以解释如何能执行 多模
态学习（multimodal learning ） ，学习两种 模态的表示，和一种 模态中的观察结果 x
与另一种 模态中的观察结果 y组成的对 (x;y)之间的关系（通常是一个联合分布）
(Srivastava and Salakhutdinov ,2012)。通过学习所有的三组参数（从 x到它的表示、
从 y到它的表示，以及两个表示之间的关系） ，一个表示中的概念被锚定在另一个表
示中，反之亦然，从而可以有效地推广到新的对组。这个过程如图 15.3所示。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
460 第十五章 表示学习
hx=fx(x)
xtestytesthy=fy(y)
y space
Relationship between embedded points within one of the domainsMaps between representation spaces fxfyx space
(x,y) pairs in the training setfx: encoder function forxfy: encoder function fory
图15.3:两个域 x和 y之间的迁移学习 能够进行 零次学习 。标注或未标注样本 x可以学习表示函
数fx。同样地，样本 y也可以学习表示函数 fy。上图中 fx和fy旁都有一个向上的箭头，不同
的箭头表示不同的作用函数。并且箭头的类型表示使用了哪一种函数。 hx空间中的相似性度量表
示 x空间中任意点对之间的距离，这种度量方式比直接度量 x空间的距离更好。同样地， hy空间
中的相似性度量表示 y空间中任意点对之间的距离。这两种相似函数都使用带点的双向箭头表示。
标注样本（水平虚线） (x;y)能够学习表示 fx(x)和表示 fy(y)之间的单向或双向映射（实双向箭
头） ，以及这些表示之间如何锚定。 零数据学习 可以通过以下方法实现。像 xtest可以和单词 ytest
关联起来，即使该单词没有像，仅仅是因为单词表示 fy(ytest)和像表示 fx(xtest)可以通过表示空
间的映射彼此关联。这种方法有效的原因是，尽管像和单词没有匹配成队，但是它们各自的特征
向量 fx(xtest)和fy(ytest)互相关联。上图受 Hrant Khachatrian 的建议启发。
15.3半监督解释因果关系
表示学习 的一个重要问题是 ‘‘什么原因能够使一个表示比另一个表示更好？ ”一
种假设是，理想表示中的特征对应到观测数据的 潜在成因 ，特征空间中不同的特征DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.3半监督解释因果关系 461
或方向对应着不同的原因，从而表示能够区分这些原因。这个假设促使我们去寻找
表示 p(x)的更好方法。如果 y是 x的重要成因之一，那么这种表示也可能是计算
p(yjx)的一种良好表示。从 20世纪 90年代以来，这个想法已经指导了大量的 深度
学习研究工作 (Becker and Hinton ,1992;Hinton and Sejnowski ,1999)。关于半监督
学习可以超过纯 监督学习 的其他论点，请读者参考 Chapelle et al. (2006b )的第 1.2
节。
在表示学习 的其他方法中，我们大多关注易于建模的表示——例如，数据稀疏
或是各项之间相互独立的情况。能够清楚地分离出潜在因素的表示可能并不一定易
于建模。然而，该假设促使 半监督学习 使用无监督表示学习 的一个更深层原因是，对
于很多人工智能 任务而言，有两个相随的特点：一旦我们能够获得观察结果基本成
因的解释，那么将会很容易分离出个体属性。具体来说，如果表示向量 h表示观察
值 x的很多潜在因素，并且输出向量 y是最为重要的原因之一，那么从 h预测 y会
很容易。
首先，让我们看看 p(x)的无监督学习 无助于学习 p(yjx)时，半监督学习 为何
失败。例如，考虑一种情况， p(x)是均匀分布的，我们希望学习 f(x) =E[yjx]。显
然，仅仅观察 训练集的值 x不能给我们关于 p(yjx)的任何信息。
接下来，让我们看看 半监督学习 成功的一个简单例子。考虑这样的情况， x来
自一个混合分布，每个 y值具有一个混合分量，如图 15.4所示。如果混合分量很好
地分出来了，那么建模 p(x)可以精确地指出每个分量的位置，每个类一个 标注样本
的训练集足以精确学习 p(yjx)。但是更一般地，什么能将 p(yjx)和p(x)关联在
一起呢？
如果 y与 x的成因之一非常相关，那么 p(x)和p(yjx)也会紧密关联，试图
找到变化 潜在因素的无监督表示学习 可能像半监督学习 一样有用。
假设 y是 x的成因之一，让 h代表所有这些成因。真实的生成过程可以被认为
是根据这个 有向图模型 结构化出来的，其中 h是 x的父节点：
p(h;x) =p(xjh)p(h): (15.1)
因此，数据的边缘概率是
p(x) =Ehp(xjh): (15.2)
从这个直观的观察中，我们得出结论， x最好可能的模型（从广义的观点）是会表示
上述 ‘‘真实’’结构的，其中 h作为潜变量解释 x中可观察的变化。上文讨论的 ‘‘理DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
462 第十五章 表示学习
xp(x)y=1 y=2 y=3
图15.4:混合模型。具有三个混合分量的 x上混合密度示例。混合分量的内在本质是潜在 解释因
子y。因为混合分量（例如，图像数据中的自然对象类别）在统计学上是显著的，所以仅仅使用 未
标注样本无监督建模 p(x)也能揭示 解释因子 y。
想’’的表示学习 应该能够反映出这些 潜在因子。如果 y是其中之一（或是紧密关联
于其中之一） ，那么将很容易从这种表示中预测 y。我们会看到给定 x下 y的条件
分布通过 贝叶斯规则 关联到上式中的分量：
p(yjx) =p(xjy)p(y)
p(x): (15.3)
因此边缘概率 p(x)和条件概率 p(yjx)密切相关，前者的结构信息应该有助于学习
后者。因此，在这些假设情况下， 半监督学习 应该能提高性能。
关于这个事实的一个重要的研究问题是，大多数观察是由极其大量的 潜在成
因形成的。假设 y= hi，但是无监督学习器并不知道是哪一个 hi。对于一个 无监
督学习器暴力求解就是学习一种表示，这种表示能够捕获 所有合理的重要生成因子
hj，并将它们彼此区分开来，因此不管 hi是否关联于 y，从 h预测 y都是容易的。
在实践中，暴力求解是不可行的，因为不可能捕获影响观察的所有或大多数变
化因素。例如，在视觉场景中，表示是否应该对背景中的所有最小对象进行编码？根
据一个有据可查的心理学现象，人们不会察觉到环境中和他们所在进行的任务并不
立刻相关的变化，具体例子可以参考 Simons and Levin (1998)。半监督学习 的一个
重要研究前沿是确定每种情况下要编码 什么。目前，处理大量 潜在原因的两个主要
策略是，同时使用 无监督学习 和监督学习 信号，从而使得模型捕获最相关的变动因
素，或是使用纯 无监督学习 学习更大规模的表示。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.3半监督解释因果关系 463
无监督学习 的另一个思路是选择一个更好的确定哪些 潜在因素最为关键的定义。
之前，自编码器 和生成模型 被训练来优化一个类似于 均方误差 的固定标准。这些固
定标准确定了哪些因素是重要的。例如，图像像素的 均方误差 隐式地指定，一个 潜
在因素只有在其显著地改变大量像素的亮度时，才是重要影响因素。如果我们希望
解决的问题涉及到小对象之间的相互作用，那么这将有可能遇到问题。如图 15.5所
示，在机器人任务中， 自编码器 未能学习到编码小乒乓球。同样是这个机器人，它可
以成功地与更大的对象进行交互（例如棒球， 均方误差 在这种情况下很显著） 。
输入 重构
图15.5:机器人任务上，基于 均方误差 训练的自编码器 不能重构乒乓球。乒乓球的存在及其所有空
间坐标，是生成图像且与机器人任务相关的重要潜在因素。不幸的是， 自编码器 具有有限的容量，
基于均方误差 的训练没能将乒乓球作为显著物体识别出来编码。以上图像由 Chelsea Finn 提供。
还有一些其他的显著性的定义。例如，如果一组像素具有高度可识别的模式，那
么即使该模式不涉及到极端的亮度或暗度，该模式还是会被认为非常显著。实现这
样一种定义显著的方法是使用最近提出的 生成式对抗网络 （generative adversarial
network）(Goodfellow et al. ,2014c )。在这种方法中， 生成模型 被训练来愚弄 前馈分
类器。前馈分类器 尝试将来自 生成模型 的所有样本识别为假的，并将来自 训练集的
所有样本识别为真的。在这个框架中， 前馈网络 能够识别出的任何结构化模式都是
非常显著的。 生成式对抗网络 会在第 20.10.4节中更详细地介绍。为了叙述方便，知
道它能学习出如何决定什么是显著的就可以了。 Lotter et al. (2015)表明，生成人类
头部头像的模型在使用 均方误差 训练时往往会忽视耳朵，但是 对抗式框架学习能够DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
464 第十五章 表示学习
成功地生成耳朵。因为耳朵与周围的皮肤相比不是非常明亮或黑暗，所以根据 均方
误差损失它们不是特别突出，但是它们高度可识别的形状和一致的位置意味着 前馈
网络能够轻易地学习出如何检测它们，从而使得它们在 生成式对抗框架 下是高度突
出的。图 15.6给了一些样例图片。 生成式对抗网络 只是确定应该表示哪些因素的一
小步。我们期望未来的研究能够发现更好的方式来确定表示哪些因素，并且根据任
务来开发表示不同因素的机制。
真实图 MSE 对抗学习
图15.6:预测生成网络是一个学习哪些特征显著的例子。在这个例子中，预测生成网络已被训练成
在特定视角预测人头的 3D模型。 (左)真实情况。这是一张网络应该生成的正确图片。 (中)由具
有均方误差 的预测生成网络生成的图片。因为与相邻皮肤相比，耳朵不会引起亮度的极大差异，所
以它们的显著性不足以让模型学习表示它们。 (右)由具有均方误差 和对抗损失的模型生成的图片。
使用这个 学成的代价函数 ，由于耳朵遵循可预测的模式，因此耳朵是显著重要的。学习哪些原因
对于模型而言是足够重要和相关的，是一个重要的活跃研究领域。以上图片由 Lotter et al. (2015)
提供。
正如 Schölkopf et al. (2012)指出，学习 潜在因素的好处是，如果真实的生成过
程中 x是结果， y是原因，那么建模 p(xjy)对于 p(y)的变化是鲁棒的。如果因果
关系被逆转，这是不对的，因为根据 贝叶斯规则 ，p(xjy)将会对 p(y)的变化十分
敏感。很多时候，我们考虑分布的变化（由于不同领域、时间不稳定性或任务性质
的变化）时， 因果机制是保持不变的 （‘‘宇宙定律不变 ’’） ，而潜在因素的边缘分布是
会变化的。因此，通过学习试图恢复成因向量 h和p(xjh)的生成模型 ，我们可以
期望最后的模型对所有种类的变化有更好的 泛化和鲁棒性。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.4分布式表示 465
15.4分布式表示
分布式表示 的概念（由很多元素组合的表示，这些元素之间可以设置成可分离
的）是表示学习 最重要的工具之一。 分布式表示 非常强大，因为他们能用具有 k个
值的 n个特征去描述 kn个不同的概念。正如我们在本书中看到的，具有多个 隐藏单
元的神经网络 和具有多个 潜变量的概率模型都利用了 分布式表示 的策略。我们现在
再介绍一个观察结果。许多 深度学习 算法基于的假设是， 隐藏单元 能够学习表示出
解释数据的 潜在因果因子 ，就像第 15.3节中讨论的一样。这种方法在 分布式表示 上
是自然的，因为表示空间中的每个方向都对应着一个不同的 潜在配置变量的值。
n维二元向量是一个 分布式表示 的示例，有 2n种配置，每一种都对应输入空间
中的一个不同区域，如图 15.7所示。这可以与 符号表示 相比较，其中输入关联到单
一符号或类别。如果字典中有 n个符号，那么可以想象有 n个特征监测器，每个
特征探测器监测相关类别的存在。在这种情况下，只有表示空间中 n个不同配置才
有可能在输入空间中刻画 n个不同的区域，如图 15.8所示。这样的 符号表示 也被称
为one-hot表示，因为它可以表示成相互排斥的 n维二元向量（其中只有一位是激
活的） 。符号表示 是更广泛的 非分布式表示 类中的一个具体示例，它可以包含很多条
目，但是每个条目没有显著意义的单独控制作用。
以下是基于 非分布式表示 的学习算法的示例：
•聚类算法，包含 k-means算法：每个输入点恰好分配到一个类别。
•k-最近邻算法：给定一个输入，一个或几个模板或原型样本与之关联。在 k >1
的情况下，每个输入都使用多个值来描述，但是它们不能彼此分开控制，因此
这不能算真正的 分布式表示 。
•决策树：给定输入时，只有一个叶节点（和从根到该叶节点路径上的点）是被
激活的。
•高斯混合体 和专家混合体 ：模板（聚类中心）或专家关联一个激活的 程度。和
k-最近邻算法一样，每个输入用多个值表示，但是这些值不能轻易地彼此分开
控制。
•具有高斯核（或其他类似的 局部核）的核机器：尽管每个 “支持向量 ’’或模板
样本的激活程度是连续值，但仍然会出现和 高斯混合体 相同的问题。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
466 第十五章 表示学习
h1h2h3
h=[ 1,1,1]>h=[ 0,1,1]>h=[ 1,0,1]>h=[ 1,1,0]>h=[ 0,1,0]>h=[ 0,0,1]>h=[ 1,0,0]>
图15.7:基于分布式表示 的学习算法如何将输入空间分割成多个区域的图示。这个例子具有二元
变量 h1，h2，h3。每个特征通过为 学成的线性变换设定输出阀值而定义。每个特征将 R2分成两
个半平面。令 h+
i表示输入点 hi= 1的集合； h 
i表示输入点 hi= 0的集合。在这个图示中，每
条线代表着一个 hi的决策边界，对应的箭头指向边界的 h+
i区域。整个表示在这些半平面的每个
相交区域都指定一个唯一值。例如，表示值为 [1;1;1]⊤对应着区域 h+
1\h+
2\h+
3。可以将以上表
示和图 15.8中的非分布式表示 进行比较。在输入维度是 d的一般情况下， 分布式表示 通过半空间
（而不是半平面）的交叉分割 Rd。具有 n个特征的 分布式表示 给O(nd)个不同区域分配唯一的编
码，而具有 n个样本的 最近邻算法只能给 n个不同区域分配唯一的编码。因此， 分布式表示 能够
比非分布式表示 多分配指数级的区域。注意并非所有的 h值都是可取的（这个例子中没有 h= 0） ，
在分布式表示 上的线性分类器 不能向每个相邻区域分配不同的类别标识；甚至深度线性阀值网络
的VC维只有 O(wlogw)（其中 w是权重数目） (Sontag ,1998)。强表示层和弱分类器层的组合
是一个强 正则化项 。试图学习 ‘‘人’’和‘‘非人’’概念的分类器不需要给表示为 ‘‘戴眼镜的女人 ’’和
‘‘没有戴眼镜的男人 ’’的输入分配不同的类别。容量限制鼓励每个分类器关注少数几个 hi，鼓励 h
以线性可分的方式学习表示这些类别。
•基于 n-gram的语言或翻译模型：根据后缀的树结构划分上下文集合（符号序
列） 。例如，一个叶节点可能对应于最后两个单词 w1和w2。树上的每个叶节
点分别估计单独的参数（有些共享也是可能的） 。
对于部分 非分布式 算法而言，有些输出并非是恒定的，而是在相邻区域之间内DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.4分布式表示 467
图15.8:最近邻算法如何将输入空间分成不同区域的图示。 最近邻算法是一个基于 非分布式表示 的
学习算法的示例。不同的 非分布式 算法可以具有不同的几何形状，但是它们通常将输入空间分成
区域，每个区域具有不同的参数 。非分布式 方法的优点是，给定足够的参数，它能够拟合一个 训练
集，而不需要复杂的优化算法。因为它直接为每个区域 独立地设置不同的参数。缺点是， 非分布式
表示的模型只能通过平滑先验来局部地 泛化，因此学习波峰波谷多于样本的复杂函数时，该方法
是不可行的。和 分布式表示 的对比，可以参照图 15.7。
插。参数（或样本）的数量和它们能够定义区域的数量之间仍保持线性关系。
将分布式表示 和符号表示 区分开来的一个重要概念是，由不同概念之间的 共享
属性而产生的 泛化。作为纯符号， ‘‘猫’’和‘‘狗’’之间的距离和任意其他两种符号的
距离一样。然而，如果将它们与有意义的 分布式表示 相关联，那么关于猫的很多特
点可以推广到狗，反之亦然。例如，我们的 分布式表示 可能会包含诸如 ‘‘具有皮毛 ’’
或‘‘腿的数目 ’’这类在 ‘‘猫’’和‘‘狗’’的嵌入上具有相同值的项。正如第 12.4.2节所
讨论的，作用于单词 分布式表示 的神经语言模型比其他直接对单词 one-hot表示进
行操作的模型 泛化得更好。 分布式表示 具有丰富的 相似性空间 ，语义上相近的概念
（或输入）在距离上接近，这是纯粹的 符号表示 所缺少的特点。
在学习算法中使用 分布式表示 何时以及为什么具有统计优势？当一个明显复杂
的结构可以用较少参数紧致地表示时， 分布式表示 具有统计上的优点。一些传统的 非
分布式学习算法仅仅在平滑假设的情况下能够 泛化，也就是说如果 uv，那么学习
到的目标函数 f通常具有 f(u)f(v)的性质。有许多方法来形式化这样一个假设，
但其结果是如果我们有一个样本 (x; y)，并且我们知道 f(x)y，那么我们可以选取
一个估计 ^f近似地满足这些限制，并且当我们移动到附近的输入 x+ϵ时， ^f尽可能
少地发生改变。显然这个假设是非常有用的，但是它会遭受 维数灾难 ：学习出一个DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
468 第十五章 表示学习
能够在很多不同区域上增加或减少很多次的目标函数1，我们可能需要至少和可区分
区域数量一样多的样本。我们可以将每一个区域视为一个类别或符号：通过让每个
符号（或区域）具有单独的自由度，我们可以学习出从符号映射到值的任意 解码器。
然而，这不能推广到新区域的新符号上。
如果我们幸运的话，除了平滑之外，目标函数可能还有一些其他规律。例如，具
有最大池化 的卷积网络 可以在不考虑对象在图像中位置（即使对象的空间变换不对
应输入空间的平滑变换）的情况下识别出对象。
让我们检查 分布式表示 学习算法的一个特殊情况，它通过对输入的线性函数进
行阀值处理来提取二元特征。该表示中的每个二元特征将 Rd分成一对半空间，如
图15.7所示。 n个相应半空间的指数级数量的交集确定了该 分布式表示 学习器能够
区分多少区域。空间 Rd中的 n个超平面的排列组合能够生成多少区间？通过应用
关于超平面交集的一般结果 (Zaslavsky ,1975)，我们发现 (Pascanu et al. ,2014b )这
个二元特征表示能够区分的空间数量是
d∑
j=0(n
j)
=O(nd): (15.4)
因此，我们会发现关于输入大小呈指数级增长，关于 隐藏单元 的数量呈多项式级增
长。
这提供了 分布式表示 泛化能力的一种几何解释： O(nd)个参数（空间 Rd中的 n
个线性阀值特征）能够明确表示输入空间中 O(nd)个不同区域。如果我们没有对数
据做任何假设，并且每个区域使用唯一的符号来表示，每个符号使用单独的参数去
识别Rd中的对应区域，那么指定 O(nd)个区域需要 O(nd)个样本。更一般地， 分
布式表示 的优势还可以体现在我们对 分布式表示 中的每个特征使用非线性的、可能
连续的特征提取器 ，而不是 线性阀值单元 的情况。在这种情况下，如果具有 k个参
数的参数变换可以学习输入空间中的 r个区域（ k≪r） ，并且如果学习这样的表示
有助于关注的任务，那么这种方式会比 非分布式 情景（我们需要 O(r)个样本来获得
相同的特征，将输入空间相关联地划分成 r个区域。 ） 泛化得更好。使用较少的参数
来表示模型意味着我们只需拟合较少的参数，因此只需要更少的训练样本去获得良
好的泛化。
另一个解释基于 分布式表示 的模型泛化能力更好的说法是，尽管能够明确地编
1一般来说，我们可能会想要学习一个函数，这个函数在指数级数量区域的表现都是不同的：在 d-维空间中，为了
区分每一维，至少有两个不同的值。我们想要函数 f区分这 2d个不同的区域，需要 O(2d)量级的训练样本DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.4分布式表示 469
码这么多不同的区域，但它们的 容量仍然是很有限的。例如， 线性阀值单元 神经网
络的VC维仅为 O(wlogw)，其中 w是权重的数目 (Sontag ,1998)。这种限制出现
的原因是，虽然我们可以为表示空间分配非常多的唯一码，但是我们不能完全使用
所有的码空间，也不能使用 线性分类器 学习出从表示空间 h到输出 y的任意函数映
射。因此使用与 线性分类器 相结合的 分布式表示 传达了一种先验信念，待识别的类
在 h代表的潜在因果因子 的函数下是线性可分的。我们通常想要学习类别，例如所
有绿色对象的图像集合，或是所有汽车图像集合，但不会是需要非线性 XOR逻辑
的类别。例如，我们通常不会将数据划分成所有红色汽车和绿色卡车作为一个集合，
所有绿色汽车和红色卡车作为另一个集合。
到目前为止讨论的想法都是抽象的，但是它们可以通过实验验证。 Zhou et al.
(2015)发现，在 ImageNet 和Places基准数据集上训练的深度 卷积网络 中的隐藏单
元学成的特征通常是可以解释的，对应人类自然分配的 标签。在实践中， 隐藏单元 并
不能总是学习出具有简单语言学名称的事物，但有趣的是，这些事物会在那些最好
的计算机视觉 深度网络的顶层附近出现。这些特征的共同之处在于，我们可以设想
学习其中的每个特征不需要知道所有其他特征的所有配置 。Radford et al. (2015)发
现生成模型 可以学习人脸图像的表示，在表示空间中的不同方向捕获不同的 潜在变
差因素。图 15.9展示表示空间中的一个方向对应着该人是男性还是女性，而另一个
方向对应着该人是否戴着眼镜。这些特征都是自动发现的，而非先验固定的。我们
没有必要为 隐藏单元 分类器提供 标签：只要该任务需要这样的特征， 梯度下降 就能
在感兴趣的 目标函数 上自然地学习出语义上有趣的特征。我们可以学习出男性和女
性之间的区别，或者是眼镜的存在与否，而不必通过涵盖所有这些值组合的样本来
表征其他 n 1个特征的所有配置。这种形式的统计可分离性质能够 泛化到训练期
间从未见过的新特征上。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
470 第十五章 表示学习
-
 +
 =
图15.9:生成模型 学到了分布式表示 ，能够从戴眼镜的概念中区分性别的概念。如果我们从一个
戴眼镜的男人的概念表示向量开始，然后减去一个没戴眼镜的男人的概念表示向量，最后加上一
个没戴眼镜的女人的概念表示向量，那么我们会得到一个戴眼镜的女人的概念表示向量。 生成模
型将所有这些表示向量正确地解码为可被识别为正确类别的图像。图片转载许可自 Radford et al.
(2015)。
15.5得益于深度的指数增益
我们已经在第 6.4.1节中看到， 多层感知机 是万能近似器 ，相比于浅层网络，一
些函数能够用指数级小的 深度网络 表示。缩小模型规模能够提高统计效率。在本节
中，我们描述如何将类似结果更一般地应用于其他具有分布式隐藏表示的模型。
在第 15.4节中，我们看到了一个 生成模型 的示例，能够学习人脸图像的 潜在解
释因子，包括性别以及是否佩戴眼镜。完成这个任务的 生成模型 是基于一个 深度神
经网络的。浅层网络例如线性网络不能学习出这些抽象 解释因子 和图像像素之间的
复杂关系。在这个任务和其他 AI任务中，这些因子几乎彼此独立地被抽取，但仍
然对应到有意义输入的因素，很有可能是高度抽象的，并且和输入呈高度非线性的
关系。我们认为这需要 深度分布式表示 ，需要许多非线性组合来获得较高级的特征
（被视为输入的函数）或因子（被视为生成原因） 。
在许多不同 情景中已经证明，非线性和重用特征层次结构的组合来组织计算，可
以使分布式表示 获得指数级加速之外，还可以获得统计效率的指数级提升。许多种
类的只有一个 隐藏层的网络（例如，具有饱和非线性，布尔门，和 /积，或 RBF单
元的网络）都可以被视为 万能近似器 。在给定足够多 隐藏单元 的情况下，这个模型
族是一个 万能近似器 ，可以在任意非零允错级别近似一大类函数（包括所有连续函
数） 。然而， 隐藏单元 所需的数量可能会非常大。关于深层架构表达能力的理论结果
表明，有些函数族可以高效地通过深度 k层的网络架构表示，但是深度不够（深度DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.6提供发现潜在原因的线索 471
为2或k 1）时会需要指数级（相对于输入大小而言）的 隐藏单元 。
在第 6.4.1节中，我们看到确定性 前馈网络 是函数的 万能近似器 。许多具有单
个隐藏层（潜变量）的结构化概率模型 （包括受限玻尔兹曼机 ，深度信念网络 ）是概
率分布的 万能近似器 (Le Roux and Bengio ,2007;Montúfar and Ay ,2011;Montufar
et al. ,2014;Krause et al. ,2013)。
在第 6.4.1节中，我们看到足够深的 前馈网络 会比深度不够的网络具有指数级优
势。这样的结果也能从诸如概率模型的其他模型中获得。 和-积网络（sum-product
network ,SPN）(Poon and Domingos ,2011)是这样的一种概率模型。这些模型使
用多项式回路来计算一组 随机变量 的概率分布 。Delalleau and Bengio (2011)表明存
在一种概率分布 ，对 SPN的最小深度有要求，以避免模型规模呈指数级增长。后来，
Martens and Medabalimi (2014)表明，任意两个有限深度的 SPN之间都会存在显
著差异，并且一些使 SPN易于处理的约束可能会限制其表示能力。
另一个有趣的进展是，一系列和 卷积网络 相关的深度回路 族表达能力的理论结
果，即使让 浅度回路 只去近似 深度回路 计算的函数，也能突出反映 深度回路 的指数
级优势 (Cohen et al. ,2015)。相比之下，以前的理论工作只研究了 浅度回路 必须精
确复制特定函数的情况。
15.6提供发现潜在原因的线索
我们回到最初的问题之一来结束本章：什么原因能够使一个表示比另一个表示
更好？首先在第 15.3节中介绍的一个答案是，一个理想的表示能够区分生成数据变
化的潜在因果因子 ，特别是那些与我们的应用相关的因素。 表示学习 的大多数策略
都会引入一些有助于学习 潜在变差因素 的线索。这些线索可以帮助 学习器将这些观
察到的因素与其他因素分开。 监督学习 提供了非常强的线索：每个观察向量 x的标
签y，它通常直接指定了至少一个 变差因素 。更一般地，为了利用丰富的 未标注数
据，表示学习 会使用关于 潜在因素的其他不太直接的提示。这些提示包含一些我们
（学习算法的设计者）为了引导 学习器而强加的隐式先验信息。诸如 没有免费午餐定
理的这些结果表明， 正则化策略对于获得良好 泛化是很有必要的。当不可能找到一
个普遍良好的 正则化策略时， 深度学习 的一个目标是找到一套相当通用的 正则化策
略，使其能够适用于各种各样的 AI任务（类似于人和动物能够解决的任务） 。
在此，我们提供了一些通用 正则化策略的列表。该列表显然是不详尽的，但是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
472 第十五章 表示学习
给出了一些学习算法是如何发现对应 潜在因素的特征的具体示例。该列表在 Bengio
et al. (2013e )的第 3.1节中提出，这里进行了部分拓展。
•平滑：假设对于单位 d和小量 ϵ有f(x+ϵd)f(x)。这个假设允许 学习器从
训练样本 泛化到输入空间中附近的点。许多 机器学习 算法都利用了这个想法，
但它不能克服 维数灾难 难题。
•线性：很多学习算法假定一些变量之间的关系是线性的。这使得算法能够预测
远离观测数据的点，但有时可能会导致一些极端的预测。大多数简单的学习
算法不会做平滑假设，而会做线性假设。这些假设实际上是不同的，具有很
大权重的线性函数在高维空间中可能不是非常平滑的。参看 Goodfellow et al.
(2014b )了解关于线性假设局限性的进一步讨论。
•多个解释因子 ：许多表示学习 算法受以下假设的启发，数据是由多个 潜在解释
因子生成的， 并且给定每一个因子的状态， 大多数任务都能轻易解决。 第 15.3节
描述了这种观点如何通过 表示学习 来启发半监督学习 的。学习 p(x)的结构要
求学习出一些对建模 p(yjx)同样有用的特征，因为它们都涉及到相同的 潜
在解释因子 。第 15.4节介绍了这种观点如何启发 分布式表示 的使用，表示空间
中分离的方向对应着 分离的变差因素 。
•因果因子 ：该模型认为 学成表示所描述的 变差因素 是观察数据 x的成因，而
并非反过来。正如第 15.3节中讨论的，这对于 半监督学习 是有利的，当 潜在成
因上的分布发生改变，或者我们应用模型到一个新的任务上时， 学成的模型都
会更加鲁棒。
•深度，或者 解释因子 的层次组织 ：高级抽象概念能够通过将简单概念层次化来
定义。从另一个角度来看，深度架构表达了我们认为任务应该由多个程序步骤
完成的观念，其中每一个步骤回溯到先前步骤处理之后的输出。
•任务间共享因素 ：当多个对应到不同变量 yi的任务共享相同的输入 x时，或
者当每个任务关联到全局输入 x的子集或者函数 f(i)(x)时，我们会假设每个
变量 yi关联到来自相关因素 h公共池的不同子集。因为这些子集有重叠，所
以通过共享的中间表示 P(hjx)来学习所有的 P(yijx)能够使任务间共享统
计强度。
•流形：概率质量集中，并且集中区域是局部连通的，且占据很小的体积。在连
续情况下，这些区域可以用比数据所在原始空间低很多维的低维 流形来近似。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
15.6提供发现潜在原因的线索 473
很多机器学习 算法只在这些 流形上有效 (Goodfellow et al. ,2014b )。一些机器
学习算法，特别是 自编码器 ，会试图显式地学习 流形的结构。
•自然聚类 ：很多机器学习 算法假设输入空间中每个连通 流形可以被分配一个单
独的类。数据分布在许多个不连通的 流形上，但相同 流形上数据的类别是相同
的。这个假设激励了各种学习算法，包括 正切传播 、双反向传播 、流形正切分
类器和对抗训练 。
•时间和空间相干性 ：慢特征分析 和相关的算法假设，最重要的 解释因子 随时间
变化很缓慢，或者至少假设预测真实的 潜在解释因子 比预测诸如像素值这类原
始观察会更容易些。读者可以参考第 13.3节，进一步了解这个方法。
•稀疏性：假设大部分特征和大部分输入不相关，如在表示猫的图像时，没有必
要使用象鼻的特征。因此，我们可以强加一个先验，任何可以解释为 ‘‘存在’’
或‘‘不存在 ’’的特征在大多数时间都是不存在的。
•简化因子 依赖：在良好的高级表示中，因子会通过简单的 依赖相互关联。最简
单的可能是边缘独立，即 P(h) =∏
iP(hi)。但是线性 依赖或浅层自编码器 所
能表示的 依赖关系也是合理的假设。这可以从许多物理定律中看出来，并且假
设在学成表示的顶层插入线性预测器或 分解的先验。
表示学习 的概念将许多 深度学习 形式联系在了一起。 前馈网络 和循环网络 ，自
编码器和深度概率模型都在学习和使用表示。学习最佳表示仍然是一个令人兴奋的
研究方向。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十六章 深度学习中的结构化概率模
型
深度学习 为研究者们提供了许多建模方式，用以设计以及描述算法。其中一
种形式是 结构化概率模型 （structured probabilistic model ）的思想。我们曾经在
第3.14节中简要讨论过 结构化概率模型 。此前简要的介绍已经足够使我们充分了解
如何使用 结构化概率模型 作为描述第二部分中某些算法的语言。现在在第三部分，
我们可以看到 结构化概率模型 是许多深度学习 重要研究方向的关键组成部分。作为
讨论这些研究方向的预备知识，本章将更加详细地描述 结构化概率模型 。本章内容
是自洽的，所以在阅读本章之前读者不需要回顾之前的介绍。
结构化概率模型 使用图来描述概率分布中随机变量之间的直接相互作用，从
而描述一个概率分布。在这里我们使用了图论（一系列结点通过一系列边来连接）
中‘‘图’’的概念，由于模型结构是由图定义的，所以这些模型也通常被称为 图模型
（graphical model ） 。
图模型的研究社群是巨大的，并提出过大量的模型、训练算法和推断算法。在本
章中，我们将介绍 图模型中几个核心方法的基本背景，并且重点描述已被证明对 深
度学习社群最有用的观点。如果你已经熟知 图模型，那么你可以跳过本章的绝大部
分。然而，我们相信即使是资深的 图模型方向的研究者也会从本章的最后一节中获
益匪浅，详见第 16.7节，其中我们强调了在 深度学习 算法中使用图模型的独特方式。
相比于其他 图模型研究领域的是， 深度学习 的研究者们通常会使用完全不同的模型
结构、学习算法和推断过程。在本章中，我们将指明这种区别并解释其中的原因。
我们首先介绍了构建大规模概率模型时面临的挑战。之后，我们介绍如何使用一
个图来描述概率分布的结构。尽管这个方法能够帮助我们解决许多挑战和问题，它
本身仍有很多缺陷。 图模型中的一个主要难点就是判断哪些变量之间存在直接的相
474DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.1非结构化建模的挑战 475
互作用关系，也就是对于给定的问题哪一种图结构是最适合的。在第 16.5节中，我们
通过了解 依赖（dependency ） ，简要概括了解决这个难点的两种方法。最后，作为本
章的收尾，我们在第 16.7节中讨论 深度学习 研究者使用 图模型特定方式的独特之处。
16.1非结构化建模的挑战
深度学习 的目标是使得 机器学习 能够解决许多 人工智能 中亟需解决的挑战。这
也意味着它们能够理解具有丰富结构的高维数据。举个例子，我们希望 AI的算法能
够理解自然图片1，表示语音的声音信号和包含许多词和标点的文档。
分类问题可以把这样一个来自高维分布的数据作为输入，然后使用一个类别的
标签来概括它——这个标签可以是照片中是什么物品，一段语音中说的是哪个单词，
也可以是一段文档描述的是哪个话题。这个分类过程丢弃了输入数据中的大部分信
息，然后产生单个值的输出（或者是关于单个输出值的概率分布） 。这个分类器通常
可以忽略输入数据的很多部分。例如，当我们识别一张照片中的一个物体时，我们
通常可以忽略图片的背景。
我们也可以使用概率模型完成许多其他的任务。这些任务通常相比于分类成本
更高。其中的一些任务需要产生多个输出。大部分任务需要对输入数据整个结构的
完整理解，所以并不能舍弃数据的一部分。这些任务包括以下几个：
•估计密度函数 ：给定一个输入 x，机器学习 系统返回一个对数据生成分布的真
实密度函数 p(x)的估计。这只需要一个输出，但它需要完全理解整个输入。即
使向量中只有一个元素不太正常，系统也会给它赋予很低的概率。
•去噪：给定一个受损的或者观察有误的输入数据 ~x，机器学习 系统返回一个对
原始的真实 x的估计。举个例子，有时候 机器学习 系统需要从一张老相片中去
除灰尘或者抓痕。这个系统会产生多个输出值（对应着估计的干净样本 x的每
一个元素） ，并且需要我们有一个对输入的整体理解（因为即使只有一个损坏
的区域，仍然会显示最终估计被损坏） 。
•缺失值的填补 ：给定 x的某些元素作为观察值，模型被要求返回一个 x一些或
者全部未观察值的估计或者概率分布。这个模型返回的也是多个输出。由于这
个模型需要恢复 x的每一个元素，所以它必须理解整个输入。
1自然图片指的是能够在正常的环境下被照相机拍摄的图片，不同于合成的图片，或者一个网页的截图等等。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
476 第十六章 深度学习中的结构化概率模型
•采样：模型从分布 p(x)中抽取新的样本。其应用包括语音合成，即产生一个
听起来很像人说话的声音。这个模型也需要多个输出以及对输入整体的良好建
模。即使样本只有一个从错误分布中产生的元素，那么采样的过程也是错误的。
图16.1中描述了一个使用较小的自然图片的采样任务。
图16.1:自然图片的概率建模。 (上)CIFAR-10 数据集 (Krizhevsky and Hinton ,2009)中的
3232像素的样例图片。 (下)从这个数据集上训练的 结构化概率模型 中抽出的样本。每一个样本
都出现在与其欧式距离最近的训练样本的格点中。这种比较使得我们发现这个模型确实能够生成
新的图片，而不是记住训练样本。为了方便展示，两个集合的图片都经过了微调。图片经 Courville
et al. (2011a )许可转载。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.1非结构化建模的挑战 477
对上千甚至是上百万随机变量的分布建模，无论从计算上还是从统计意义上说，
都是一个极具挑战性的任务。假设我们只想对二值的随机变量建模。这是一个最简
单的例子，但是我们仍然无能为力。对一个只有 3232像素的彩色（ RGB）图片
来说，存在 23072种可能的二值图片。这个数量已经超过了 10800，比宇宙中的原子
总数还要多。
通常意义上讲，如果我们希望对一个包含 n个离散变量并且每个变量都能取 k
个值的 x的分布建模，那么最简单的表示 P(x)的方法需要存储一个可以查询的表
格。这个表格记录了每一种可能值的概率，则需要 kn个参数。
基于下述几个原因，这种方式是不可行的：
•内存：存储参数的开销。 除了极小的 n和k的值，用表格的形式来表示这样
一个分布需要太多的存储空间。
•统计的高效性 ：当模型中的参数个数增加时，使用统计估计器估计这些参数所
需要的训练数据数量也需要相应地增加。因为基于查表的模型拥有天文数字级
别的参数，为了准确地拟合，相应的训练集的大小也是相同级别的。任何这样
的模型都会导致严重的 过拟合，除非我们添加一些额外的假设来联系表格中的
不同元素（正如第 12.4.1节中所举的 回退或者平滑 n-gram模型） 。
•运行时间：推断的开销。 假设我们需要完成这样一个推断的任务，其中我们需
要使用联合分布 P(x)来计算某些其他的分布，比如说边缘分布 P(x1)或者是
条件分布 P(x2jx1)。计算这样的分布需要对整个表格的某些项进行求和操作，
因此这样的操作的运行时间和上述高昂的内存开销是一个级别的。
•运行时间：采样的开销。 类似的，假设我们想要从这样的模型中采样。最简单
的方法就是从均匀分布中采样， uU(0;1)，然后把表格中的元素累加起来，
直到和大于 u，然后返回最后一个加上的元素。最差情况下，这个操作需要读
取整个表格，所以和其他操作一样，它也需要指数级别的时间。
基于表格操作的方法的主要问题是我们显式地对每一种可能的变量子集所产生
的每一种可能类型的相互作用建模。在实际问题中我们遇到的概率分布远比这个简
单。通常，许多变量只是间接地相互作用。
例如，我们想要对接力跑步比赛中一个队伍完成比赛的时间进行建模。假设这
个队伍有三名成员： Alice，Bob和Carol。在比赛开始时， Alice拿着接力棒，开始DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
478 第十六章 深度学习中的结构化概率模型
跑第一段距离。在跑完她的路程以后，她把棒递给了 Bob。然后 Bob开始跑，再把
棒给 Carol，Carol跑最后一棒。我们可以用连续变量来建模他们每个人完成的时间。
因为 Alice第一个跑，所以她的完成时间并不依赖于其他的人。 Bob的完成时间依赖
于Alice的完成时间，因为 Bob只能在 Alice跑完以后才能开始跑。如果 Alice跑得
更快，那么 Bob也会完成得更快。所有其他关系都可以被类似地推出。最后， Carol
的完成时间依赖于她的两个队友。如果 Alice跑得很慢，那么 Bob也会完成得更慢。
结果， Carol将会更晚开始跑步，因此她的完成时间也更有可能要晚。然而，在给定
Bob完成时间的情况下， Carol的完成时间只是 间接地依赖于 Alice的完成时间。如
果我们已经知道了 Bob的完成时间，知道 Alice的完成时间对估计 Carol的完成时
间并无任何帮助。这意味着我们可以通过仅仅两个相互作用来建模这个接力赛。这
两个相互作用分别是 Alice的完成时间对 Bob的完成时间的影响和 Bob的完成时间
对Carol的完成时间的影响。在这个模型中，我们可以忽略第三种间接的相互作用，
即Alice的完成时间对 Carol的完成时间的影响。
结构化概率模型 为随机变量之间的直接作用提供了一个正式的建模框架。这种
方式大大减少了模型的参数个数以致于模型只需要更少的数据来进行有效的估计。
这些更小的模型大大减小了在模型存储、模型推断以及从模型中采样时的计算开销。
16.2使用图描述模型结构
结构化概率模型 使用图（在图论中 ‘‘结点’’是通过 ‘‘边’’来连接的）来表示随机
变量之间的相互作用。每一个结点代表一个随机变量。每一条边代表一个直接相互
作用。这些直接相互作用隐含着其他的间接相互作用，但是只有直接的相互作用会
被显式地建模。
使用图来描述概率分布中相互作用的方法不止一种。在下文中我们会介绍几种
最为流行和有用的方法。 图模型可以被大致分为两类：基于有向无环图的模型和基
于无向图的模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 479
16.2.1 有向模型
有向图模型 （directed graphical model ）是一种 结构化概率模型 ，也被称为 信
念网络（belief network ）或者贝叶斯网络 （Bayesian network ）2(Pearl ,1985)。
之所以命名为 有向图模型 是因为所有的边都是有方向的，即从一个结点指向另
一个结点。这个方向可以通过画一个箭头来表示。箭头所指的方向表示了这个随机
变量的概率分布是由其他变量的概率分布所定义的。画一个从结点 a到结点 b的箭
头表示了我们用一个条件分布来定义 b，而 a是作为这个条件分布符号右边的一个
变量。换句话说， b的概率分布依赖于 a的取值。
我们继续第 16.1节所讲的接力赛的例子，我们假设 Alice的完成时间为 t0，Bob
的完成时间为 t1，Carol的完成时间为 t2。就像我们之前看到的一样， t1的估计是
依赖于 t0的， t2的估计是直接依赖于 t1的，但是仅仅间接地依赖于 t0。我们用一
个有向图模型 来建模这种关系，如图 16.2所示。
t0t0t1t1t2t2AliceBobCarol
图16.2:描述接力赛例子的 有向图模型 。Alice的完成时间 t0影响了 Bob的完成时间 t1，因为
Bob只能在 Alice完成比赛后才开始。类似的， Carol也只会在 Bob完成之后才开始，所以 Bob
的完成时间 t1直接影响了 Carol的完成时间 t2。
正式地说， 变量 x的有向概率模型是通过有向无环图 G（每个结点都是模型中的
随机变量）和一系列 局部条件概率分布 （local conditional probability distribution ）
p(xijPaG(xi))来定义的，其中 PaG(xi)表示结点 xi的所有父结点。 x的概率分布
可以表示为
p(x) =∏
ip(xijPaG(xi)): (16.1)
在之前所述的接力赛的例子中，参考图 16.2，这意味着概率分布可以被表示为
p(t0;t1;t2) =p(t0)p(t1jt0)p(t2jt1): (16.2)
2当我们希望 ‘‘强调’’从网络中计算出的值的 ‘‘推断’’本质，即强调这些值代表的是置信程度大小而不是事件的频
率时， Judea Pearl 建议使用 “贝叶斯网络 ’’这个术语。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
480 第十六章 深度学习中的结构化概率模型
这是我们看到的第一个 结构化概率模型 的实际例子。我们能够检查这样建模的
计算开销，为了验证相比于非结构化建模，结构化建模为什么有那么多的优势。
假设我们采用从第 0分钟到第 10分钟每 6秒一块的方式离散化地表示时间。
这使得 t0，t1和 t2都是一个有 100个取值可能的离散变量。如果我们尝试着用一个
表来表示 p(t0;t1;t2)，那么我们需要存储 999;999个值（ 100个 t0的可能取值 t1
的可能取值100个 t2的可能取值减去 1，由于存在所有的概率之和为 1的限制，
所以其中有 1个值的存储是多余的） 。反之，如果我们用一个表来记录每一种条件概
率分布，那么表中记录 t0的分布需要存储 99个值，给定 t0情况下 t1的分布需要
存储 9900个值，给定 t1情况下 t2的分布也需要存储 9900个值。加起来总共需要
存储 19;899个值。这意味着使用 有向图模型 将参数的个数减少了超过 50倍！
通常意义上说，对每个变量都能取 k个值的 n个变量建模，基于建表的方法需
要的复杂度是 O(kn)，就像我们之前观察到的一样。现在假设我们用一个 有向图模
型来对这些变量建模。如果 m代表图模型的单个条件概率分布中最大的变量数目
（在条件符号的左右皆可） ，那么对这个 有向模型 建表的复杂度大致为 O(km)。只要
我们在设计模型时使其满足 m≪n，那么复杂度就会被大大地减小。
换一句话说，只要图中的每个变量都只有少量的父结点，那么这个分布就可以
用较少的参数来表示。图结构上的一些限制条件，比如说要求这个图为一棵树，也
可以保证一些操作（例如求一小部分变量的边缘或者条件分布）更加地高效。
决定哪些信息需要被包含在图中而哪些不需要是很重要的。如果变量之间可以
被假设为是 条件独立 的，那么这个图可以包含这种简化假设。当然也存在其他类型
的简化图模型的假设。例如，我们可以假设无论 Alice的表现如何， Bob总是跑得
一样快（实际上， Alice的表现很大概率会影响 Bob的表现，这取决于 Bob的性格，
如果在之前的比赛中 Alice跑得特别快，这有可能鼓励 Bob更加努力并取得更好的
成绩，当然这也有可能使得 Bob过分自信或者变得懒惰） 。那么 Alice对Bob的唯
一影响就是在计算 Bob的完成时间时需要加上 Alice的时间。这个假设使得我们所
需要的参数量从 O(k2)降到了 O(k)。然而，值得注意的是在这个假设下 t0和 t1仍
然是直接相关的，因为 t1表示的是 Bob完成时的时间，并不是他跑的总时间。这也
意味着图中会有一个从 t0指向 t1的箭头。 “Bob的个人跑步时间相对于其他因素是
独立的 ’’这个假设无法在 t0，t1，t2的图中被表示出来。反之，我们只能将这个关系
表示在条件分布的定义中。这个条件分布不再是一个大小为 kk 1的分别对应着
t0，t1的表格，而是一个包含了 k 1个参数的略微复杂的公式。 有向图模型 的语法
并不能对我们如何定义条件分布作出任何限制。它只定义了哪些变量可以作为其中DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 481
的参数。
16.2.2 无向模型
有向图模型 为我们提供了一种描述 结构化概率模型 的语言。而另一种常见的语
言则是无向模型 （undirected Model ） ，也被称为 马尔可夫随机场 （Markov random
ﬁeld,MRF）或者是 马尔可夫网络 （Markov network ）(Kindermann ,1980)。就像它
们的名字所说的那样， 无向模型 中所有的边都是没有方向的。
当存在很明显的理由画出每一个指向特定方向的箭头时， 有向模型 显然最适用。
有向模型 中，经常存在我们理解的具有因果关系以及因果关系有明确方向的情况。
接力赛的例子就是一个这样的情况。之前运动员的表现会影响后面运动员的完成时
间，而后面运动员却不会影响前面运动员的完成时间。
然而并不是所有情况的相互作用都有一个明确的方向关系。当相互的作用并没
有本质性的指向，或者是明确的双向相互作用时，使用 无向模型 更加合适。
作为一个这种情况的例子，假设我们希望对三个二值随机变量建模：你是否生
病，你的同事是否生病以及你的室友是否生病。就像在接力赛的例子中所作的简化
假设一样，我们可以在这里做一些关于相互作用的简化假设。假设你的室友和同事
并不认识，所以他们不太可能直接相互传染一些疾病，比如说感冒。这个事件太过
罕见，所以我们不对此事件建模。然而，很有可能其中之一将感冒传染给你，然后
通过你再传染给了另一个人。我们通过对你的同事传染给你以及你传染给你的室友
建模来对这种间接的从你的同事到你的室友的感冒传染建模。
在这种情况下，你传染给你的室友和你的室友传染给你都是非常容易的，所以
模型不存在一个明确的单向箭头。这启发我们使用 无向模型 。其中随机变量对应着
图中的相互作用的结点。与 有向模型 相同的是，如果在 无向模型 中的两个结点通过
一条边相连接，那么对应这些结点的随机变量相互之间是直接作用的。不同于 有向
模型，在无向模型 中的边是没有方向的，并不与一个条件分布相关联。
我们把对应你健康状况的随机变量记作 hy，对应你的室友健康状况的随机变量
记作 hr，你的同事健康的变量记作 hc。图 16.3表示这种关系。
正式地说，一个 无向模型 是一个定义在 无向模型G上的结构化概率模型 。对于
图中的每一个 团3C，一个因子（factor）ϕ(C)(也称为团势能（clique potential ）)，
3图的一个 团是图中结点的一个子集，并且其中的点是全连接的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
482 第十六章 深度学习中的结构化概率模型
hrhrhyhyhchc
图16.3:表示你室友健康状况的 hr、你健康状况的 hy和你同事健康状况的 hc之间如何相互影响
的一个无向图。你和你的室友可能会相互传染感冒，你和你的同事之间也是如此，但是假设你室
友和同事之间相互不认识，他们只能通过你来间接传染。
hy= 0 hy= 1
hc= 0 2 1
hc= 1 1 10
衡量了团中变量每一种可能的联合状态所对应的密切程度。这些 因子都被限制为是
非负的。它们一起定义了 未归一化概率函数 （unnormalized probability function ） ：
~p(x) =∏
C2Gϕ(C): (16.3)
只要所有 团中的结点数都不大，那么我们就能够高效地处理这些 未归一化概率
函数。它包含了这样的思想，密切度越高的状态有越大的概率。然而，不像 贝叶斯网
络，几乎不存在 团定义的结构，所以不能保证把它们乘在一起能够得到一个有效的
概率分布。图 16.4展示了一个从 无向模型 中读取分解信息的例子。
abcdef
图16.4: 这 个 图 说 明 通 过 选 择 适 当 的 ϕ， 函 数 p(a;b;c;d;e;f)可 以 写 作
1
Zϕa;b(a;b)ϕb;c(b;c)ϕa;d(a;d)ϕb;e(b;e)ϕe;f(e;f)。
在你、你的室友和同事之间感冒传染的例子中包含了两个 团。一个团包含了 hy
和 hc。这个团的因子可以通过一个表来定义，可能取到下面的值：
状态为 1代表了健康的状态，相对的状态为 0则表示不好的健康状态（即感染
了感冒） 。你们两个通常都是健康的，所以对应的状态拥有最高的密切程度。两个人
中只有一个人是生病的密切程度是最低的，因为这是一个很罕见的状态。两个人都DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 483
生病的状态（通过一个人来传染给了另一个人）有一个稍高的密切程度，尽管仍然
不及两个人都健康的密切程度。
为了完整地定义这个模型，我们需要对包含 hy和 hr的团定义类似的 因子。
16.2.3 配分函数
尽管这个 未归一化概率函数 处处不为零，我们仍然无法保证它的概率之和或者
积分为 1。为了得到一个有效的概率分布，我们需要使用对应的归一化的概率分布4：
p(x) =1
Z~p(x); (16.4)
其中， Z是使得所有的概率之和或者积分为 1的常数，并且满足：
Z=∫
~p(x)dx: (16.5)
当函数 ϕ固定时，我们可以把 Z当成是一个常数。值得注意的是如果函数 ϕ带有
参数时，那么 Z是这些参数的一个函数。在相关文献中为了节省空间忽略控制 Z的
变量而直接写 Z是一个常用的方式。归一化常数 Z被称作是 配分函数 ，这是一个从
统计物理学中借鉴的术语。
由于 Z通常是由对所有可能的 x状态的联合分布空间求和或者求积分得到的，
它通常是很难计算的。为了获得一个 无向模型 的归一化概率分布，模型的结构和函
数ϕ的定义通常需要设计为有助于高效地计算 Z。在深度学习 中，Z通常是难以处
理的。由于 Z难以精确地计算出，我们只能使用一些近似的方法。这样的近似方法
是第十八章的主要内容。
在设计无向模型 时，我们必须牢记在心的一个要点是设定一些使得 Z不存在
的因子也是有可能的。当模型中的一些变量是连续的，且 ~p在其定义域上的积分发
散时这种情况就会发生。例如，当我们需要对一个单独的标量变量 x2R建模，并
且单个团势能定义为 ϕ(x) =x2时。在这种情况下，
Z=∫
x2dx: (16.6)
由于这个积分是发散的，所以不存在一个对应着这个势能函数 ϕ(x)的概率分布。有
时候 ϕ函数某些参数的选择可以决定相应的概率分布是否能够被定义。例如，对 ϕ
4一个通过归一化 团势能乘积定义的分布也被称作是 吉布斯分布 （Gibbs distribution ）DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
484 第十六章 深度学习中的结构化概率模型
函数 ϕ(x;) =exp( x2)来说，参数 决定了归一化常数 Z是否存在。正的 使
得ϕ函数是一个关于 x的高斯分布，但是非正的参数 则使得 ϕ不可能被归一化。
有向建模和无向建模之间一个重要的区别就是 有向模型 是通过从起始点的概率
分布直接定义的，反之 无向模型 的定义显得更加宽松，通过 ϕ函数转化为概率分布
而定义。这改变了我们处理这些建模问题的直觉。当我们处理 无向模型 时需要牢记
一点，每一个变量的定义域对于一系列给定的 ϕ函数所对应的概率分布有着重要的
影响。举个例子，我们考虑一个 n维向量的随机变量 x以及一个由偏置向量 b参数
化的无向模型 。假设 x的每一个元素对应着一个 团，并且满足 ϕ(i)(xi) = exp(bixi)。
在这种情况下概率分布是怎样的呢？答案是我们无法确定，因为我们并没有指定 x
的定义域。如果 x满足 x2Rn，那么有关归一化常数 Z的积分是发散的，这导
致了对应的概率分布是不存在的。如果 x2f0;1gn，那么 p(x)可以被分解成 n个
独立的分布，并且满足 p(xi= 1) = sigmoid (bi)。如果 x的定义域是 基本单位向量
(f[1;0; : : : ; 0];[0;1; : : : ; 0]; : : : ; [0;0; : : : ; 1]g)的集合，那么 p(x) =softmax (b)，因此
对于 j̸=i，一个较大的 bi的值会降低所有 p(xj= 1)的概率。通常情况下，通过仔
细选择变量的定义域，能够从一个相对简单的 ϕ函数的集合可以获得一个相对复杂
的表达。我们会在第 20.6节中讨论这个想法的实际应用。
16.2.4 基于能量的模型
无向模型 中许多有趣的理论结果都依赖于 8x;~p(x)>0这个假设。使这个条件
满足的一种简单方式是使用 基于能量的模型 （Energy-based model ,EBM） ，其中
~p(x) = exp( E(x)); (16.7)
E(x)被称作是 能量函数 （energy function ） 。对所有的 z，exp(z)都是正的，这保证
了没有一个 能量函数 会使得某一个状态 x的概率为 0。我们可以完全自由地选择那
些能够简化学习过程的 能量函数 。如果我们直接学习各个 团势能，我们需要利用 约
束优化方法来任意地指定一些特定的最小概率值。学习 能量函数 的过程中，我们可
以采用无约束的优化方法5。基于能量的模型 中的概率可以无限趋近于 0但是永远达
不到 0。
服从式 (16.7)形式的任意分布都是 玻尔兹曼分布 （Boltzmann distribution ）
的一个实例。正是基于这个原因，我们把许多 基于能量的模型 称为玻尔兹曼机
5对于某些模型，我们可以仍然使用 约束优化 方法来确保 Z存在。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 485
（Boltzmann Machine ）(Fahlman et al. ,1983;Ackley et al. ,1985;Hinton et al. ,
1984a ;Hinton and Sejnowski ,1986)。关于什么时候称之为 基于能量的模型 ，什么时
候称之为 玻尔兹曼机 不存在一个公认的判别标准。一开始 玻尔兹曼机 这个术语是用
来描述一个只有二值变量的模型，但是如今许多模型，比如 均值-协方差 RBM，也
涉及到了实值变量。虽然 玻尔兹曼机 最初的定义既可以包含 潜变量也可以不包含 潜
变量，但是时至今日 玻尔兹曼机 这个术语通常用于指拥有 潜变量的模型，而没有 潜
变量的玻尔兹曼机 则经常被称为 马尔可夫随机场 或对数线性模型 。
无向模型 中的团对应于未归一化概率函数 中的因子。通过 exp(a+b) =
exp(a)exp(b)，我们发现 无向模型 中的不同 团对应于能量函数 的不同项。换句话说，
基于能量的模型 只是一种特殊的 马尔可夫网络 ：求幂使 能量函数 中的每个项对应
于不同团的一个因子。关于如何从 无向模型 结构中获得 能量函数 形式的示例可以参
考图 16.5。人们可以将 能量函数 中带有多个项的 基于能量的模型 视作是专家之积
（product of expert ）(Hinton ,1999)。能量函数 中的每一项对应的是概率分布中的
一个因子。能量函数 中的每一项都可以看作决定一个特定的软约束是否能够满足的
‘‘专家’’。每个专家只执行一个约束，而这个约束仅仅涉及随机变量的一个低维投影，
但是当其结合概率的乘法时，专家们一同构造了复杂的高维约束。
abcdef
图16.5:这个图说明通过为每个 团选择适当的 能量函数 E(a;b;c;d;e;f)可以写作 E a;b(a;b) +
E b;c(b;c) +E a;d(a;d) +E b;e(b;e) +E e;f(e;f)。值得注意的是，我们令 ϕ等于对应负能量的指数，
可以获得图 16.4中的 ϕ函数，比如， ϕa;b(a;b) = exp( E(a;b))。
基于能量的模型 定义的一部分无法用 机器学习 观点来解释：即式 (16.7)中的 “-’’
符号。这个 “-’’符号可以被包含在 E的定义之中。对于很多 E函数的选择来说，学
习算法可以自由地决定能量的符号。这个负号的存在主要是为了保持 机器学习 文献
和物理学文献之间的兼容性。概率建模的许多研究最初都是由统计物理学家做出的，
其中 E是指实际的、物理概念的能量，没有任何符号。诸如 ‘‘能量’’和“配分函数 ’’
这类术语仍然与这些技术相关联，尽管它们的数学适用性比在物理中更宽。一些 机
器学习研究者（例如， Smolensky (1986)将负能量称为 harmony ）发出了不同的声DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
486 第十六章 深度学习中的结构化概率模型
音，但这些都不是标准惯例。
许多对概率模型进行操作的算法不需要计算 pmodel (x)，而只需要计算
log~pmodel (x)。对于具有 潜变量 h的基于能量的模型 ，这些算法有时会将该量的负数
称为自由能（free energy ） ：
F(x) = log∑
hexp( E(x;h)): (16.8)
在本书中，我们更倾向于更为通用的基于 log~pmodel (x)的定义。
16.2.5 分离和 d-分离
图模型中的边告诉我们哪些变量直接相互作用。我们经常需要知道哪些变量 间
接相互作用。某些间接相互作用可以通过观察其他变量来启用或禁用。更正式地，我
们想知道在给定其他变量子集的值时，哪些变量子集彼此 条件独立 。
在无向模型 中，识别图中的 条件独立 性是非常简单的。在这种情况下，图中隐
含的条件独立 性称为分离（separation ） 。如果图结构显示给定变量集 S的情况下变
量集A与变量集 B无关，那么我们声称给定变量集 S时，变量集 A与另一组变量
集B是分离的。如果连接两个变量 a和 b的连接路径仅涉及未观察变量，那么这些
变量不是 分离的。如果它们之间没有路径，或者所有路径都包含可观测的变量，那
么它们是 分离的。我们认为仅涉及未观察到的变量的路径是 ‘‘活跃’’的，而包括可观
察变量的路径称为 ‘‘非活跃 ’’的。
当我们画图时，我们可以通过加阴影来表示观察到的变量。图 16.6用于描述当
以这种方式绘图时 无向模型 中的活跃和非活跃路径的样子。图 16.7描述了一个从 无
向模型中读取分离信息的例子。
asb
asb
(a) (b)
图16.6: (a)随机变量 a和随机变量 b之间穿过 s的路径是活跃的，因为 s是观察不到的。这意
味着 a，b之间不是 分离的。(b)图中 s用阴影填充，表示它是可观察的。因为 a和 b之间的唯一
路径通过 s，并且这条路径是不活跃的，我们可以得出结论，在给定 s的条件下 a和 b是分离的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 487
abcd
图16.7:从一个无向图中读取 分离性质的一个例子。这里 b用阴影填充，表示它是可观察的。由于
b挡住了从 a到 c的唯一路径，我们说在给定 b的情况下 a和 c是相互分离的。观察值 b同样
挡住了从 a到 d的一条路径，但是它们之间有另一条活跃路径。因此给定 b的情况下 a和 d不
是分离的。
类似的概念适用于 有向模型 ，只是在 有向模型 中，这些概念被称为 d-分离（d-
separation ） 。“d’’代表 “依赖’’的意思。有向图中 d-分离的定义与 无向模型 中分离的
定义相同：如果图结构显示给定变量集 S时，变量集 A与变量集 B无关，那么我们
认为给定变量集 S时，变量集 Ad-分离于变量集 B。
与无向模型 一样，我们可以通过查看图中存在的活跃路径来检查图中隐含的独
立性。如前所述，如果两个变量之间存在活跃路径，则两个变量是依赖的，如果没
有活跃路径，则为 d-分离。在有向网络中，确定路径是否活跃有点复杂。关于在 有向
模型中识别活跃路径的方法可以参考图 16.8。图 16.9是从一个图中读取一些属性的
例子。
尤其重要的是要记住 分离和d-分离只能告诉我们 图中隐含 的条件独立 性。图并
不需要表示所有存在的独立性。进一步的，使用完全图（具有所有可能的边的图）来
表示任何分布总是合法的。事实上，一些分布包含不可能用现有图形符号表示的独
立性。特定环境下的独立 （context-speciﬁc independences ）指的是取决于网络中一
些变量值的独立性。例如，考虑三个二值变量的模型： a，b和 c。假设当 a是0时，
b和 c是独立的，但是当 a是1时， b确定地等于 c。当 a= 1时图模型需要连接 b
和 c的边。但是图不能说明当 a= 0时 b和 c不是独立的。
一般来说，当独立性不存在时，图不会显示独立性。然而，图可能无法编码独立
性。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
488 第十六章 深度学习中的结构化概率模型
asbasbasbasbasb
c(a)(b)
(c)(d)
图16.8:两个随机变量 a，b之间存在的长度为 2的所有种类的活跃路径。 (a)箭头方向从 a指向
b的任何路径，反过来也一样。如果 s可以被观察到，这种路径就是阻塞的。在接力赛的例子中，
我们已经看到过这种类型的路径。 (b)变量 a和 b通过共因 s相连。举个例子，假设 s是一个表
示是否存在飓风的变量， a和 b表示两个相邻气象监控区域的风速。如果我们在 a处观察到很高
的风速，我们可以期望在 b处也观察到高速的风。如果观察到 s，那么这条路径就被阻塞了。如果
我们已经知道存在飓风，那么无论 a处观察到什么，我们都能期望 b处有较高的风速。在 a处观
察到一个低于预期的风速（对飓风而言）并不会改变我们对 b处风速的期望（已知有飓风的情况
下） 。然而，如果 s不被观测到，那么 a和 b是依赖的，即路径是活跃的。 (c)变量 a和 b都是
s的父节点。这称为 V-结构（V-structure ）或者碰撞情况 （the collider case ） 。根据相消解释作
用（explaining away eﬀect ） ，V-结构导致 a和 b是相关的。在这种情况下，当 s被观测到时路径
是活跃的。举个例子，假设 s是一个表示你的同事不在工作的变量。变量 a表示她生病了，而变
量 b表示她在休假。如果你观察到了她不在工作，你可以假设她很有可能是生病了或者是在度假，
但是这两件事同时发生是不太可能的。如果你发现她在休假，那么这个事实足够 解释她的缺席了。
你可以推断她很可能没有生病。 (d)即使 s的任意后代都被观察到， 相消解释作用 也会起作用。举
个例子，假设 c是一个表示你是否收到你同事的报告的一个变量。如果你注意到你还没有收到这
个报告，这会增加你估计的她今天不在工作的概率，这反过来又会增加她今天生病或者度假的概
率。阻塞 V-结构中路径的唯一方法就是共享子节点的后代一个都观察不到。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 489
abcde
图16.9:从这张图中，我们可以发现一些 d-分离的性质。这包括了：
•给定空集的情况下， a和 b是d-分离的。
•给定 c的情况下， a和 e是d-分离的。
•给定 c的情况下， d和 e是d-分离的。
我们还可以发现当我们观察到一些变量时，一些变量不再是 d-分离的：
•给定 c的情况下， a和 b不是 d-分离的。
•给定 d的情况下， a和 b不是 d-分离的。
16.2.6 在有向模型和无向模型中转换
我们经常将特定的 机器学习 模型称为 无向模型 或有向模型 。例如，我们通常将 受
限玻尔兹曼机 称为无向模型 ，而稀疏编码 则被称为 有向模型 。这种措辞的选择可能
有点误导，因为没有概率模型本质上是有向或无向的。但是，一些模型很适合使用
有向图描述，而另一些模型很适合使用 无向模型 描述。
有向模型 和无向模型 都有其优点和缺点。这两种方法都不是明显优越和普遍优
选的。相反，我们根据具体的每个任务来决定使用哪一种模型。这个选择部分取决
于我们希望描述的概率分布。根据哪种方法可以最大程度地捕捉到概率分布中的独
立性，或者哪种方法使用最少的边来描述分布，我们可以决定使用有向建模还是无
向建模。还有其他因素可以影响我们决定使用哪种建模方式。即使在使用单个概率
分布时，我们有时也可以在不同的建模方式之间切换。有时，如果我们观察到变量
的某个子集，或者如果我们希望执行不同的计算任务，换一种建模方式可能更合适。
例如，有向模型 通常提供了一种高效地从模型中抽取样本（在第 16.3节中描述）的
直接方法。而 无向模型 形式通常对于推导 近似推断 过程（我们将在第 十九章中看到，
式(19.56 )强调了无向模型 的作用）是很有用的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
490 第十六章 深度学习中的结构化概率模型
每个概率分布可以由 有向模型 或由无向模型 表示。在最坏的情况下，我们可以
使用 “完全图 ’’来表示任何分布。在 有向模型 的情况下， 完全图是任意有向无环图，
其中我们对随机变量排序，并且每个变量在排序中位于其之前的所有其他变量作为
其图中的祖先。对于 无向模型 ，完全图只是包含所有变量的单个 团。图 16.10给出了
一个实例。
图16.10:完全图的例子， 完全图能够描述任何的概率分布。这里我们展示了一个带有四个随机变
量的例子。 (左)完全无向图。在无向图中， 完全图是唯一的。 (右)一个完全有向图。在有向图中，
并不存在唯一的 完全图。我们选择一种变量的排序，然后对每一个变量，从它本身开始，向每一个
指向顺序在其后面的变量画一条弧。因此存在着关于变量数阶乘数量级的不同种 完全图。在这个
例子中，我们从左到右从上到下地排序变量。
当然，图模型的优势在于图能够包含一些变量不直接相互作用的信息。 完全图并
不是很有用，因为它并不隐含任何独立性。
当我们用图表示概率分布时，我们想要选择一个包含尽可能多独立性的图，但
是并不会假设任何实际上不存在的独立性。
从这个角度来看，一些分布可以使用 有向模型 更高效地表示，而其他分布可以
使用无向模型 更高效地表示。换句话说， 有向模型 可以编码一些 无向模型 所不能编
码的独立性，反之亦然。
有向模型 能够使用一种 无向模型 无法完美表示的特定类型的子结构。这个子结
构被称为 不道德（immorality ） 。这种结构出现在当两个随机变量 a和 b都是第三个
随机变量 c的父结点，并且不存在任一方向上直接连接 a和 b的边时。（ “不道德 ’’
的名字可能看起来很奇怪 ;它在图模型文献中使用源于一个关于未婚父母的笑话。 ）
为了将有向模型 图D转换为无向模型 ，我们需要创建一个新图 U。对于每对变量 x
和 y，如果存在连接D中的 x和 y的有向边（在任一方向上） ，或者如果 x和 y都
是图D中另一个变量 z的父节点，则在U中添加连接 x和 y的无向边。得到的图
U被称为是 道德图（moralized graph ） 。关于一个通过 道德化将有向图模型 转化为无
向模型的例子可以参考图 16.11。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.2使用图描述模型结构 491
h1h1h2h2h3h3
v1v1v2v2v3v3ab
ca
cb
h1h1h2h2h3h3
v1v1v2v2v3v3ab
ca
cb
图16.11:通过构造 道德图将有向模型（上一行）转化为无向模型（下一行）的例子。 (左)只需要
把有向边替换成无向边就可以把这个简单的链转化为一个 道德图。得到的无向模型包含了完全相
同的独立关系和 条件独立 关系。 (中)这个图是在不丢失独立性的情况下是无法转化为无向模型的
最简单的有向模型。这个图包含了单个完整的 不道德结构。因为 a和 b都是 c的父节点，当 c被
观察到时，它们之间通过活跃路径相连。为了捕捉这个 依赖，无向模型必须包含一个含有所有三
个变量的 团。这个团无法编码 a? b这个信息。 (右)一般来说， 道德化的过程会给图添加许多边，
因此丢失了一些隐含的独立性。举个例子，这个 稀疏编码 图需要在每一对 隐藏单元 之间添加 道德
化的边，因此也引入了二次数量级的新的直接 依赖。
同样的， 无向模型 可以包括 有向模型 不能完美表示的子结构。具体来说，如果 U
包含长度大于 3的环（loop） ，则有向图D不能捕获 无向模型U所包含的所有 条件
独立性，除非该 环还包含弦（chord） 。环指的是由无向边连接的变量序列，并且满
足序列中的最后一个变量连接回序列中的第一个变量。 弦是定义环序列中任意两个
非连续变量之间的连接。如果 U具有长度为 4或更大的环，并且这些环没有 弦，我
们必须在将它们转换为 有向模型 之前添加 弦。添加这些 弦会丢弃在U中编码的一些DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
492 第十六章 深度学习中的结构化概率模型
独立信息。通过将 弦添加到U形成的图被称为 弦图（chordal graph ）或者三角形化
图（triangulated graph ） ，因为我们现在可以用更小的、三角的环来描述所有的环。
要从弦图构建有向图D，我们还需要为边指定方向。当这样做时，我们不能在 D中
创建有向循环，否则将无法定义有效的有向概率模型。为 D中的边分配方向的一种
方法是对随机变量排序，然后将每个边从排序较早的节点指向排序稍后的节点。一
个简单的实例可以参考图 16.12。
abdcabdcabdc
图16.12:将一个无向模型转化为一个有向模型。 (左)这个无向模型无法转化为有向模型，因为它
有一个长度为 4且不带有 弦的环。具体说来，这个无向模型包含了两种不同的独立性，并且不存
在一个有向模型可以同时描述这两种性质： a? cj f b;dg和 b? dj f a;cg。(中)为了将无向图
转化为有向图，我们必须通过保证所有长度大于 3的环都有弦来三角形化 图。为了实现这个目标，
我们可以加一条连接 a和 c或者连接 b和 d的边。在这个例子中，我们选择添加一条连接 a和 c
的边。 (右)为了完成转化的过程，我们必须给每条边分配一个方向。执行这个任务时，我们必须
保证不产生任何有向环。避免出现有向环的一种方法是赋予节点一定的顺序，然后将每个边从排
序较早的节点指向排序稍后的节点。在这个例子中，我们根据变量名的字母进行排序。
16.2.7 因子图
因子图（factor graph ）是从无向模型 中抽样的另一种方法，它可以解决标准 无
向模型语法中图表达的模糊性。在 无向模型 中，每个 ϕ函数的范围必须是图中某
个团的子集。我们无法确定每一个 团是否含有一个作用域包含整个 团的因子——比
如说一个包含三个结点的 团可能对应的是一个有三个结点的 因子，也可能对应的是
三个因子并且每个 因子包含了一对结点，这通常会导致模糊性。通过显式地表示每
一个 ϕ函数的作用域， 因子图解决了这种模糊性。具体来说， 因子图是一个包含无向
二分图的 无向模型 的图形化表示。一些节点被绘制为圆形。就像在标准 无向模型 中
一样，这些节点对应于随机变量。其余节点绘制为方块。这些节点对应于 未归一化
概率函数 的因子 ϕ。变量和 因子可以通过无向边连接。当且仅当变量包含在 未归一
化概率函数 的因子中时，变量和 因子在图中存在连接。没有 因子可以连接到图中的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.3从图模型中采样 493
另一个因子，也不能将变量连接到变量。图 16.2.7给出了一个例子来说明 因子图如
何解决无向网络中的模糊性。
abcabcf1f1abcf1f1f2f2f3f3
图16.13:因子图如何解决无向网络中的模糊性的一个例子。 (左)一个包含三个变量（ a、b和 c）
的团组成的无向网络。 (中)对应这个无向模型的 因子图。这个因子图有一个包含三个变量的因子。
(右)对应这个无向模型的另一种有效的 因子图。这个因子图包含了三个因子，每个因子只对应两
个变量。即使它们表示的是同一个无向模型，这个 因子图上进行的表示、推断和学习相比于中图
描述的因子图都要渐近地廉价。
16.3从图模型中采样
图模型同样简化了从模型中采样的过程。
有向图模型 的一个优点是，可以通过一个简单高效的过程从模型所表示的联合
分布中产生样本，这个过程被称为 原始采样 （Ancestral Sampling ） 。
原始采样 的基本思想是将图中的变量 xi使用拓扑排序，使得对于所有 i和j，如
果 xi是 xj的一个父亲结点，则 j大于 i。然后可以按此顺序对变量进行采样。换句
话说，我们可以首先采 x1P(x1)，然后采 x2P(x2jPaG(x2))，以此类推，直到
最后我们从 P(xnjPaG(xn))中采样。只要不难从每个条件分布 xiP(xijPaG(xi))
中采样，那么从整个模型中采样也是容易的。拓扑排序操作保证我们可以按照
式(16.1)中条件分布的顺序依次采样。如果没有拓扑排序，我们可能会在其父节点
可用之前试图对该变量进行抽样。
有些图可能存在多个拓扑排序。 原始采样 可以使用这些拓扑排序中的任何一个。
原始采样 通常非常快（假设从每个条件分布中采样都是很容易的）并且非常简
便。
原始采样 的一个缺点是其仅适用于 有向图模型 。另一个缺点是它并不是每次采DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
494 第十六章 深度学习中的结构化概率模型
样都是条件采样操作。当我们希望从 有向图模型 中变量的子集中采样时，给定一些
其他变量，我们经常要求所有给定的条件变量在顺序图中比要采样的变量的顺序要
早。在这种情况下，我们可以从模型分布指定的局部条件概率分布中采样。否则，我
们需要采样的条件分布是给定观测变量的后验分布。这些后验分布在模型中通常没
有明确指定和参数化。推断这些后验分布的代价可能是很高的。在这种情况下的模
型中，原始采样 不再有效。
不幸的是， 原始采样 仅适用于 有向模型 。我们可以通过将 无向模型 转换为有向
模型来实现从 无向模型 中抽样，但是这通常需要解决棘手的推断问题（要确定新有
向图的根节点上的边缘分布） ，或者需要引入许多边从而会使得到的 有向模型 变得难
以处理。从 无向模型 采样，而不首先将其转换为 有向模型 的做法似乎需要解决循环
依赖的问题。每个变量与每个其他变量相互作用，因此对于采样过程没有明确的起
点。不幸的是，从 无向模型 中抽取样本是一个成本很高的多次迭代的过程。理论上
最简单的方法是 Gibbs采样（Gibbs Sampling ） 。假设我们在一个 n维向量的随机
变量 x上有一个 图模型。我们迭代地访问每个变量 xi，在给定其他变量的条件下从
p(xijx i)中抽样。由于 图模型的分离性质，抽取 xi时我们可以等价地仅对 xi的邻
居条件化。不幸的是，在我们遍历 图模型一次并采样所有 n个变量之后，我们仍然
无法得到一个来自 p(x)的客观样本。相反，我们必须重复该过程并使用它们邻居的
更新值对所有 n个变量重新取样。在多次重复之后，该过程渐近地收敛到正确的目
标分布。我们很难确定样本何时达到所期望分布的足够精确的近似。 无向模型 的采
样技术是一个高级的研究方向，第 十七章将对此进行更详细的讨论。
16.4结构化建模的优势
使用结构化概率模型 的主要优点是它们能够显著降低表示概率分布、学习和推
断的成本。 有向模型 中采样还可以被加速，但是对于 无向模型 情况则较为复杂。选
择不对某些变量的相互作用进行建模是允许所有这些操作使用较少的运行时间和内
存的主要机制。 图模型通过省略某些边来传达信息。在没有边的情况下，模型假设
不对变量间直接的相互作用建模。
结构化概率模型 允许我们明确地将给定的现有知识与知识的学习或者推断分开，
这是一个不容易量化的益处。这使我们的模型更容易开发和调试。我们可以设计、
分析和评估适用于更广范围的图的学习算法和推断算法。同时，我们可以设计能够
捕捉到我们认为数据中存在的重要关系的模型。然后，我们可以组合这些不同的算DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.5学习依赖关系 495
法和结构，并获得不同可能性的笛卡尔乘积。然而，为每种可能的情况设计 端到端
的算法会更加困难。
16.5学习依赖关系
良好的生成模型需要准确地捕获所观察到的或 ‘‘可见’’变量 v上的分布。通常
v的不同元素彼此高度依赖。在 深度学习 中，最常用于建模这些 依赖关系的方法是
引入几个 潜在或‘‘隐藏’’变量 h。然后，该模型可以捕获任何对（变量 vi和 vj间
接依赖可以通过 vi和 h之间直接 依赖和 v和 hj直接依赖捕获)之间的依赖关系。
如果一个良好的关于 v的模型不包含任何 潜变量，那么它在 贝叶斯网络 中的每
个节点需要具有大量父节点或在 马尔可夫网络 中具有非常大的 团。仅仅表示这些高
阶相互作用的成本就很高了，首先从计算角度上考虑，存储在存储器中的参数数量
是团中成员数量的指数级别，接着在统计学意义上，因为这些指数数量的参数需要
大量的数据来准确估计。
当模型旨在描述直接连接的可见变量之间的 依赖关系时，通常不可能连接所有
变量，因此设计 图模型时需要连接那些紧密相关的变量，并忽略其他变量之间的
作用。机器学习 中有一个称为 结构学习 （structure learning ）的领域专门讨论这个
问题。 Koller and Friedman (2009)是一个不错的 结构学习 参考资料。大多数 结构学
习技术基于一种贪婪搜索的形式。它们提出了一种结构，对具有该结构的模型进行
训练，然后给出分数。该分数奖励训练集上的高精度并对模型的复杂度进行惩罚。然
后提出添加或移除少量边的候选结构作为搜索的下一步。搜索向一个预计会增加分
数的新结构发展。
使用潜变量而不是自适应结构避免了离散搜索和多轮训练的需要。可见变量
和潜变量之间的固定结构可以使用可见单元和 隐藏单元 之间的直接作用，从而建模
可见单元之间的间接作用。使用简单的参数学习技术，我们可以学习到一个具有固
定结构的模型，这个模型在边缘分布 p(v)上拥有正确的结构。
潜变量除了发挥本来的作用，即能够高效地描述 p(v)以外，还具有另外的优
势。新变量 h还提供了 v的替代表示。例如，如第 3.9.6节所示， 高斯混合模型 学习
了一个潜变量，这个潜变量对应于输入样本是从哪一个混合体中抽出。这意味着 高
斯混合模型 中的潜变量可以用于做分类。我们可以看到第 十四章中简单的概率模型
如稀疏编码 ，是如何学习可以用作分类器输入特征或者作为 流形上坐标的 潜变量的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
496 第十六章 深度学习中的结构化概率模型
其他模型也可以使用相同的方式，但是更深的模型和具有多种相互作用方式的模型
可以获得更丰富的输入描述。许多方法通过学习 潜变量来完成特征学习。通常，给
定 v和 h，实验观察显示 E[hjv]或 arg maxhp(h;v)都是 v的良好特征映射。
16.6推断和近似推断
解决变量之间如何相互关联的问题是我们使用概率模型的一个主要方式。给定
一组医学测试，我们可以询问患者可能患有什么疾病。在一个 潜变量模型中，我们
可能需要提取能够描述可观察变量 v的特征 E[hjv]。有时我们需要解决这些问题
来执行其他任务。我们经常使用最大似然的准则来训练我们的模型。由于
logp(v) =Ehp(hjv)[logp(h;v) logp(hjv)]; (16.9)
学习过程中，我们经常需要计算 p(hjv)。所有这些都是 推断（inference ）问题的例
子，其中我们必须预测给定其他变量的情况下一些变量的值，或者在给定其他变量
值的情况下预测一些变量的概率分布。
不幸的是，对于大多数有趣的深度模型来说，即使我们使用结构化 图模型来简
化这些推断问题，它们仍然是难以处理的。图结构允许我们用合理数量的参数来表
示复杂的高维分布，但是用于 深度学习 的图并不满足这样的条件，从而难以实现高
效地推断。
我们可以直接看出，计算一般 图模型的边缘概率是 #P-hard 的。复杂性类别
#P是复杂性类别 NP的泛化。 NP中的问题只需确定其中一个问题是否有解决方
案，并找到一个解决方案（如果存在）就可以解决。 #P中的问题需要计算解决方案
的数量。为了构建最坏情况的 图模型，我们可以设想一下我们在 3-SAT问题中定义
二值变量的 图模型。我们可以对这些变量施加均匀分布。然后我们可以为每个子句
添加一个二值 潜变量，来表示每个子句是否成立。然后，我们可以添加另一个 潜变
量，来表示所有子句是否成立。这可以通过构造一个 潜变量的缩减树来完成，树中
的每个结点表示其他两个变量是否成立，从而不需要构造一个大的 团。该树的叶是
每个子句的变量。树的根表示整个问题是否成立。由于子句的均匀分布，缩减树根
结点的边缘分布表示子句有多少比例是成立的。虽然这是一个设计的最坏情况的例
子，NP-hard 图确实会频繁地出现在现实世界的场景中。
这促使我们使用 近似推断 。在深度学习 中，这通常涉及 变分推断 ，其中通过寻
求尽可能接近真实分布的近似分布 q(hjv)来逼近真实分布 p(hjv)。这个技术将在DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.7结构化概率模型的深度学习方法 497
第十九章中深入讨论。
16.7结构化概率模型的深度学习方法
深度学习 从业者通常与其他从事 结构化概率模型 研究的机器学习 研究者使用相
同的基本计算工具。然而，在 深度学习 中，我们通常对如何组合这些工具作出不同
的设计决定，导致总体算法、模型与更传统的 图模型具有非常不同的风格。
深度学习 并不总是涉及特别深的 图模型。在图模型中，我们可以根据 图模型的
图而不是 计算图来定义模型的深度。如果从 潜变量 hi到可观察变量的最短路径是 j
步，我们可以认为 潜变量 hj处于深度 j。我们通常将模型的深度描述为任何这样的
hj的最大深度。这种深度不同于由 计算图定义的深度。用于 深度学习 的许多生成模
型没有潜变量或只有一层 潜变量，但使用深度 计算图来定义模型中的条件分布。
深度学习 基本上总是利用 分布式表示 的思想。即使是用于 深度学习 目的的浅层
模型（例如 预训练浅层模型，稍后将形成深层模型） ，也几乎总是具有单个大的 潜变
量层。深度学习 模型通常具有比可观察变量更多的 潜变量。变量之间复杂的非线性
相互作用通过多个 潜变量的间接连接来实现。
相比之下，传统的 图模型通常包含至少是偶尔观察到的变量，即使一些训练样
本中的许多变量随机地丢失。传统模型大多使用高阶项和 结构学习 来捕获变量之间
复杂的非线性相互作用。如果有 潜变量，它们的数量通常很少。
潜变量的设计方式在 深度学习 中也有所不同。 深度学习 从业者通常不希望 潜变
量提前包含了任何特定的含义——训练算法可以自由地开发对特定数据集建模所需
要的概念。在事后解释 潜变量通常是很困难的，但是可视化技术可以得到它们表示
的一些粗略表征。当 潜变量在传统图模型中使用时，它们通常被赋予一些特定含义
——比如文档的主题、学生的智力、导致患者症状的疾病等。这些模型通常由研究
者解释，并且通常具有更多的理论保证，但是不能扩展到复杂的问题，并且不能像
深度模型一样在许多不同背景中重复使用。
另一个明显的区别是 深度学习 方法中经常使用的连接类型。深度图模型通常具
有大的与其他单元组全连接的单元组，使得两个组之间的相互作用可以由单个矩阵
描述。传统的 图模型具有非常少的连接，并且每个变量的连接选择可以单独设计。
模型结构的设计与推断算法的选择紧密相关。 图模型的传统方法通常旨在保持精确
推断的可解性。当这个约束太强时，我们可以采用一种流行的被称为 环状信念传播DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
498 第十六章 深度学习中的结构化概率模型
（loopy belief propagation ）的近似推断 算法。这两种方法通常在稀疏连接图上都有
很好的效果。相比之下，在 深度学习 中使用的模型倾向于将每个可见单元 vi连接到
非常多的 隐藏单元 hj上，从而使得 h可以获得一个 vi的分布式表示 （也可能是其
他几个可观察变量） 。 分布式表示 具有许多优点，但是从 图模型和计算复杂性的观点
来看，分布式表示 有一个缺点就是很难产生对于精确推断和 环状信念传播 等传统技
术来说足够稀疏的图。结果，大规模 图模型和深度图模型最大的区别之一就是 深度
学习中几乎从来不会使用 环状信念传播 。相反的，许多 深度学习 模型可以设计来加
速Gibbs采样或者变分推断 。此外， 深度学习 模型包含了大量的 潜变量，使得高效
的数值计算代码显得格外重要。除了选择高级推断算法之外，这提供了另外的动机，
用于将结点分组成层，相邻两层之间用一个矩阵来描述相互作用。这要求实现算法
的单个步骤可以实现高效的矩阵乘积运算，或者专门适用于稀疏连接的操作，例如
块对角矩阵乘积或 卷积。
最后，图模型的深度学习 方法的一个主要特征在于对未知量的较高容忍度。与
简化模型直到它的每一个量都可以被精确计算不同的是，我们仅仅直接使用数据运
行或者是训练，以增强模型的能力。我们一般使用边缘分布不能计算的模型，但可
以从中简单地采近似样本。我们经常训练具有难以处理的目标函数的模型，我们甚
至不能在合理的时间内近似，但是如果我们能够高效地获得这样一个函数的梯度估
计，我们仍然能够近似训练模型。深度学习方法通常是找出我们绝对需要的最小量
信息，然后找出如何尽快得到该信息的合理近似。
16.7.1 实例：受限玻尔兹曼机
受限玻尔兹曼机 （Restricted Boltzmann Machine ,RBM）(Smolensky ,1986)或
者簧风琴（harmonium ）是图模型如何用于深度学习的典型例子。 RBM本身不是一
个深层模型。相反，它有一层 潜变量，可用于学习输入的表示。在第 二十章中，我们
将看到 RBM如何被用来构建许多的深层模型。在这里，我们举例展示了 RBM在
许多深度图模型中使用的实践：它的单元被分成很大的组，这种组称作层，层之间
的连接由矩阵描述，连通性相对密集。该模型被设计为能够进行高效的 Gibbs采样，
并且模型设计的重点在于以很高的自由度来学习 潜变量，而潜变量的含义并不是设
计者指定的。之后在第 20.2节，我们将更详细地再次讨论 RBM。
标准的 RBM是具有二值的可见和隐藏单元的 基于能量的模型 。其能量函数 为
E(v;h) = b⊤v c⊤h v⊤Wh; (16.10)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
16.7结构化概率模型的深度学习方法 499
其中 b;c和 W都是无约束、实值的可学习参数。我们可以看到，模型被分成两组
单元： v和 h，它们之间的相互作用由矩阵 W来描述。该模型在图 16.14中以图的
形式描绘。该图能够使我们更清楚地发现，该模型的一个重要方面是在任何两个可
见单元之间或任何两个 隐藏单元 之间没有直接的相互作用（因此称为 ‘‘受限’’，一般
的玻尔兹曼机 可以具有任意连接） 。
h1h1h2h2h3h3v1v1v2v2v3v3h4h4
图16.14:一个画成 马尔可夫网络 形式的 RBM。
对RBM结构的限制产生了良好的属性
p(hjv) =∏
ip(hijv) (16.11)
以及
p(vjh) =∏
ip(vijh): (16.12)
独立的条件分布很容易计算。对于二元的 受限玻尔兹曼机 ，我们可以得到：
p(hi= 1jv) =(
v⊤W:;i+bi)
; (16.13)
p(hi= 0jv) = 1 (
v⊤W:;i+bi)
: (16.14)
结合这些属性可以得到高效的 块吉布斯采样 （block Gibbs Sampling ） ，它在同时采
样所有 h和同时采样所有 v之间交替。 RBM模型通过 Gibbs采样产生的样本展示
在图 16.15中。
由于能量函数 本身只是参数的线性函数，很容易获取 能量函数 的导数。例如，
@
@Wi;jE(v;h) = vihj: (16.15)
这两个属性，高效的 Gibbs采样和导数计算，使训练过程变得非常方便。在第 十
八章中，我们将看到，可以通过计算应用于这种来自模型样本的导数来训练 无向模
型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
500 第十六章 深度学习中的结构化概率模型
图16.15:训练好的 RBM的样本及其权重。 (左)用MNIST 训练模型，然后用 Gibbs采样进行
采样。每一列是一个单独的 Gibbs采样过程。每一行表示另一个 1000步后 Gibbs采样的输出。
连续的样本之间彼此高度相关。 (右)对应的权重向量。将本图结果与图 13.2中描述的 线性因子模
型的样本和权重相比。由于 RBM的先验 p(h)没有限制为 因子，这里的样本表现得好很多。采样
时RBM能够学习到哪些特征需要一起出现。另一方面说， RBM后验 p(hjv)是因子的，而稀疏
编码的后验并不是，所以在特征提取上 稀疏编码 模型表现得更好。其他的模型可以使用非 因子的
p(h)和非因子的p(hjh)。图片经 LISA (2008)允许转载。
训练模型可以得到数据 v的表示 h。我们经常使用 Ehp(hjv)[h]作为一组描述 v
的特征。
总的来说， RBM展示了典型的 图模型深度学习 方法：使用多层 潜变量，并由矩
阵参数化层之间的高效相互作用来完成 表示学习 。
图模型为描述概率模型提供了一种优雅、灵活、清晰的语言。在未来的章节中，
我们将使用这种语言，以其他视角来描述各种各样的深度概率模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十七章 蒙特卡罗方法
随机算法可以粗略地分为两类： Las Vegas 算法和蒙特卡罗 算法。 Las Vegas 算
法总是精确地返回一个正确答案（或者返回算法失败了） 。这类方法通常需要占用随
机量的计算资源（一般指内存或运行时间） 。与此相对的， 蒙特卡罗 方法返回的答案
具有随机大小的错误。花费更多的计算资源（通常包括内存和运行时间）可以减少
这种错误。在任意固定的计算资源下， 蒙特卡罗 算法可以得到一个近似解。
对于机器学习 中的许多问题来说，我们很难得到精确的答案。这类问题很难用
精确的确定性算法如 Las Vegas 算法解决。取而代之的是确定性的近似算法或 蒙特卡
罗近似方法。这两种方法在 机器学习 中都非常普遍。本章主要关注 蒙特卡罗 方法。
17.1采样和蒙特卡罗方法
机器学习 中的许多重要工具都基于从某种分布中采样以及用这些样本对目标量
做一个蒙特卡罗 估计。
17.1.1 为什么需要采样？
有许多原因使我们希望从某个分布中采样。当我们需要以较小的代价近似许多
项的和或某个积分时，采样是一种很灵活的选择。有时候，我们使用它加速一些很
费时却易于处理的求和估计，就像我们使用 小批量对整个训练代价进行 子采样一样。
在其他情况下，我们需要近似一个难以处理的求和或积分，例如估计一个 无向模
型中配分函数 对数的梯度时。在许多其他情况下，抽样实际上是我们的目标，例如
我们想训练一个可以从训练分布采样的模型。
501DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
502 第十七章 蒙特卡罗方法
17.1.2 蒙特卡罗采样的基础
当无法精确计算和或积分（例如，和具有指数数量个项，且无法被精确简化）
时，通常可以使用 蒙特卡罗 采样来近似它。这种想法把和或者积分视作某分布下的
期望，然后 通过估计对应的平均值来近似这个期望 。令
s=∑
xp(x)f(x) =Ep[f(x)] (17.1)
或者
s=∫
p(x)f(x)dx=Ep[f(x)] (17.2)
为我们所需要估计的和或者积分，写成期望的形式， p是一个关于随机变量 x的概
率分布（求和时）或者 概率密度函数 （求积分时） 。
我们可以通过从 p中抽取 n个样本 x(1); : : : ; x(n)来近似 s并得到一个经验平均
值
^sn=1
nn∑
i=1f(x(i)): (17.3)
下面几个性质表明了这种近似的合理性。首先很容易观察到 ^s这个估计是 无偏的，
由于
E[^sn] =1
nn∑
i=1E[f(x(i))] =1
nn∑
i=1s=s: (17.4)
此外，根据 大数定理 （Law of large number ） ，如果样本 x(i)是独立同分布 的，那么
其平均值几乎必然收敛到期望值，即
lim
n  !1^sn=s; (17.5)
只需要满足各个单项的方差 Var[f(x(i))]有界。详细地说，我们考虑当 n增大时 ^sn
的方差。只要满足 Var[f(x(i))]<1，方差 Var[^sn]就会减小并收敛到 0：
Var[^sn] =1
n2n∑
i=1Var[f(x)] (17.6)
=Var[f(x)]
n: (17.7)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.2重要采样 503
这个简单有用的结果启迪我们如何估计 蒙特卡罗 均值中的不确定性，或者等价地说
是蒙特卡罗 估计的期望误差。我们计算了 f(x(i))的经验均值和方差1，然后将估计的
方差除以样本数 n来得到 Var[^sn]的估计。 中心极限定理 （central limit theorem ）
告诉我们 ^sn的分布收敛到以 s为均值以Var[f(x)]
n为方差的 正态分布 。这使得我们可
以利用正态分布 的累积函数 来估计 ^sn的置信区间。
以上的所有结论都依赖于我们可以从基准分布 p(x)中轻易地采样，但是这个
假设并不是一直成立的。当我们无法从 p中采样时，一个备选方案是用第 17.2节讲
到的重要采样 。一种更加通用的方式是构建一个收敛到目标分布的估计序列。这就
是马尔可夫链蒙特卡罗 方法（见第 17.3节） 。
17.2重要采样
如方程 (17.2)所示，在 蒙特卡罗 方法中，对积分（或者和）分解，确定积分中哪
一部分作为概率分布 p(x)以及哪一部分作为被积的函数 f(x)（我们感兴趣的是估
计f(x)在概率分布 p(x)下的期望）是很关键的一步。 p(x)f(x)不存在唯一的分解，
因为它总是可以被写成
p(x)f(x) =q(x)p(x)f(x)
q(x); (17.8)
在这里，我们从 q分布中采样，然后估计pf
q在此分布下的均值。许多情况中，我们
希望在给定 p和f的情况下计算某个期望，这个问题既然是求期望，那么很自然地
p和f是一种分解选择。然而，如果考虑达到某给定精度所需要的样本数量，这个
问题最初的分解选择不是最优的选择。幸运的是，最优的选择 q可以被简单地推导
出来。这种最优的采样函数 q对应所谓的最优 重要采样 。
从式 (17.8)所示的关系中可以发现，任意 蒙特卡罗 估计
^sp=1
nn∑
i=1;x(i)pf(x(i)) (17.9)
可以被转化为一个 重要采样 的估计
^sq=1
nn∑
i=1;x(i)qp(x(i))f(x(i))
q(x(i)): (17.10)
1通常我们会倾向于计算方差的 无偏估计，它由偏差的平方和除以 n 1而非n得到。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
504 第十七章 蒙特卡罗方法
我们可以容易地发现估计的期望与 q分布无关：
Eq[^sq] =Ep[^sp] =s: (17.11)
然而，重要采样 的方差可能对 q的选择非常敏感。这个方差可以表示为
Var[^sq] =Var[p(x)f(x)
q(x)]
/n: (17.12)
方差想要取到最小值， q需要满足
q(x) =p(x)jf(x)j
Z; (17.13)
在这里 Z表示归一化常数，选择适当的 Z使得 q(x)之和或者积分为 1。一个更好
的重要采样 分布会把更多的权重放在被积函数较大的地方。事实上，当 f(x)的正负
符号不变时， Var[^sq] = 0，这意味着当使用最优的 q分布时， 只需要一个样本就足
够了。当然，这仅仅是因为计算 q时已经解决了原问题。所以在实践中这种只需要
采样一个样本的方法往往是无法实现的。
对于重要采样 来说任意 q分布都是可行的（从得到一个期望上正确的值的角度
来说） ， q指的是最优的 q分布（从得到最小方差的角度上考虑） 。从 q中采样往
往是不可行的，但是其他仍然能降低方差的 q的选择还是可行的。
另一种方法是采用 有偏重要采样 （biased importance sampling ） ，这种方法有
一个优势，即不需要归一化的 p或q分布。在处理离散变量时， 有偏重要采样 估计
可以表示为
^sBIS=∑n
i=1p(x(i))
q(x(i))f(x(i))
∑n
i=1p(x(i))
q(x(i))(17.14)
=∑n
i=1p(x(i))
~q(x(i))f(x(i))
∑n
i=1p(x(i))
~q(x(i))(17.15)
=∑n
i=1~p(x(i))
~q(x(i))f(x(i))
∑n
i=1~p(x(i))
~q(x(i)); (17.16)
其中 ~p和~q分别是分布 p和q的未经归一化的形式， x(i)是从分布 q中抽取的样本。
这种估计是有偏的，因为 E[^sBIS]̸=s，只有当 n!1且方程 式 (17.14 )的分母收敛
到1时，等式才渐近地成立。所以这一估计也被称为渐近 无偏的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.3马尔可夫链蒙特卡罗方法 505
一个好的 q分布的选择可以显著地提高 蒙特卡罗 估计的效率，而一个糟糕的 q
分布选择则会使效率更糟糕。我们回过头来看看方程 式 (17.12 )会发现，如果存在一
个q使得p(x)f(x)
q(x)很大， 那么这个估计的方差也会很大。 当 q(x)很小， 而 f(x)和p(x)
都较大并且无法抵消 q时，这种情况会非常明显。 q分布经常会取一些简单常用的分
布使得我们能够从 q分布中容易地采样。当 x是高维数据时， q分布的简单性使得它
很难与 p或者 pjfj相匹配。当 q(x(i))≫p(x(i))jf(x(i))j时，重要采样 采到了很多无
用的样本（很小的数或零相加） 。另一种相对少见的情况是 q(x(i))≪p(x(i))jf(x(i))j，
相应的比值会非常大。正因为后一个事件是很少发生的，这种样本很难被采到，通
常使得对 s的估计出现了典型的 欠估计，很难被整体的 过估计抵消。这样的不均匀
情况在高维数据屡见不鲜，因为在高维度分布中联合分布的动态域可能非常大。
尽管存在上述的风险，但是 重要采样 及其变种在 机器学习 的应用中仍然扮演着
重要的角色，包括 深度学习 算法。例如， 重要采样 被应用于加速训练具有大规模词
表的神经网络 语言模型 的过程中（见第 12.4.3.3节）或者其他有着大量输出结点的 神
经网络中。此外，还可以看到 重要采样 应用于估计 配分函数 （一个概率分布的归一
化常数） ，详见第 18.7节，以及在深度有向图模型比如 变分自编码器 中估计对数似然
（详见第 20.10.3节） 。采用 随机梯度下降 训练模型参数时 重要采样 可以用来改进对 代
价函数梯度的估计，尤其是分类器这样的模型，其中 代价函数 的大部分 代价来自于
少量错误分类的样本。在这种情况下，更加频繁地抽取这些困难的样本可以减小梯
度估计的方差 (Hinton et al. ,2006a )。
17.3马尔可夫链蒙特卡罗方法
在许多实例中，我们希望采用 蒙特卡罗 方法，然而往往又不存在一种简单的方法
可以直接从目标分布 pmodel (x)中精确采样或者一个好的（方差较小的） 重要采样 分
布q(x)。在深度学习中，当分布 pmodel (x)表示成无向模型时，这种情况往往会发生。
在这种情况下，为了从分布 pmodel (x)中近似采样，我们引入了一种称为 马尔可夫链
（Markov Chain ）的数学工具。利用 马尔可夫链 来进行蒙特卡罗 估计的这一类算法被
称为马尔可夫链蒙特卡罗 （Markov Chain Monte Carlo ,MCMC）方法。 Koller and
Friedman (2009)花了大量篇幅来描述 马尔可夫链蒙特卡罗 算法在机器学习 中的应
用。MCMC技术最标准、最一般的的理论保证只适用于那些各状态概率均不为零的
模型。因此，这些技术最方便的使用方法是用于从 基于能量的模型 （Energy-based
model）即 p(x)/ exp( E(x))中采样，见第 16.2.4节。在 EBM的公式表述中，每DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
506 第十七章 蒙特卡罗方法
一个状态所对应的概率都不为零。事实上， MCMC方法可以被广泛地应用在包含 0
概率状态的许多概率分布中。然而，在这种情况下，关于 MCMC方法性能的理论保
证只能依据具体不同类型的分布具体分析证明。在 深度学习 中，我们通常依赖于那
些一般的理论保证，其在所有 基于能量的模型 都能自然成立。
为了解释从 基于能量的模型 中采样困难的原因，我们考虑一个包含两个变量
的EBM的例子，记 p(a;b)为其分布。为了采 a，我们必须先从 p(ajb)中采样；为
了采 b，我们又必须从 p(bja)中采样。这似乎成了棘手的先有鸡还是先有蛋的问题。
有向模型 避免了这一问题因为它的图是有向无环的。为了完成 原始采样 （Ancestral
Sampling ） ，在给定每个变量的所有父结点的条件下，我们根据拓扑顺序采样每一个
变量，这个变量是确定能够被采样的（详见第 16.3节） 。原始采样 定义了一种高效
的、单遍的方法来抽取一个样本。
在EBM中，我们通过使用 马尔可夫链 来采样，从而避免了先有鸡还是先有蛋
的问题。 马尔可夫链 的核心思想是从某个可取任意值的状态 x出发。随着时间的推
移，我们随机地反复更新状态 x。最终 x成为了一个从 p(x)中抽出的（非常接近）
比较一般的样本。在正式的定义中， 马尔可夫链 由一个随机状态 x和一个转移分布
T(x′jx)定义而成， T(x′jx)是一个概率分布，说明了给定状态 x的情况下随机地
转移到 x′的概率。运行一个 马尔可夫链 意味着根据转移分布 T(x′jx)采出的值 x′
来更新状态 x。
为了给出 MCMC方法为何有效的一些理论解释，重参数化这个问题是很有用
的。首先我们关注一些简单的情况，其中随机变量 x有可数个状态。我们将这种状
态简单地记作正整数 x。不同的整数 x的大小对应着原始问题中 x的不同状态。
接下来我们考虑如果并行地运行无穷多个 马尔可夫链 的情况。不同 马尔可夫
链的所有状态都采样自某一个分布 q(t)(x)，在这里 t表示消耗的时间数。开始时，对
每个马尔可夫链 ，我们采用一个分布 q0来任意地初始化 x。之后， q(t)与所有之前
运行的马尔可夫链 有关。我们的目标是 q(t)(x)收敛到 p(x)。
因为我们已经用正整数 x重参数化了这个问题，我们可以用一个向量 v来描述
这个概率分布 q，
q(x=i) =vi: (17.17)
然后我们考虑更新单一的 马尔可夫链 ，从状态 x到新状态 x′。单一状态转移到DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.3马尔可夫链蒙特卡罗方法 507
x′的概率可以表示为
q(t+1)(x′) =∑
xq(t)(x)T(x′jx): (17.18)
根据状态为整数的参数化设定，我们可以将转移算子 T表示成一个矩阵 A。矩
阵 A的定义如下：
Ai;j=T(x′=ijx=j): (17.19)
使用这一定义，我们可以改写式 (17.18 )。不同于之前使用 q和T来理解单个状态的
更新，我们现在可以使用 v和 A来描述当我们更新时（并行运行的）不同 马尔可夫
链上整个分布是如何变化的：
v(t)= Av(t 1): (17.20)
重复地使用 马尔可夫链 更新相当于重复地与矩阵 A相乘。换言之，我们可以认为这
一过程就是关于 A的幂乘：
v(t)= Atv(0): (17.21)
矩阵 A有一种特殊的结构，因为它的每一列都代表一个概率分布。这样的矩阵
被称为随机矩阵 （Stochastic Matrix ） 。如果对于任意状态 x到任意其他状态 x′存在
一个 t使得转移概率不为 0，那么 Perron-Frobenius 定理 (Perron ,1907;Frobenius ,
1908)可以保证这个矩阵的最大特征值是实数且大小为 1。我们可以看到所有的特征
值随着时间呈现指数变化：
v(t)= ( Vdiag()V 1)tv(0)= Vdiag()tV 1v(0): (17.22)
这个过程导致了所有不等于 1的特征值都衰减到 0。在一些额外的较为宽松的假
设下，我们可以保证矩阵 A只有一个对应特征值为 1的特征向量。所以这个过程
收敛到平稳分布 （Stationary Distribution ） ，有时也被称为 均衡分布 （Equilibrium
Distribution ） 。收敛时，我们得到
v′= Av= v; (17.23)
这个条件也适用于收敛之后的每一步。这就是特征向量方程。作为收敛的稳定点， v
一定是特征值为 1所对应的特征向量。这个条件保证收敛到了 平稳分布 以后，再重DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
508 第十七章 蒙特卡罗方法
复转移采样过程不会改变所有不同 马尔可夫链 上状态的 分布（尽管转移算子自然而
然地会改变每个单独的状态） 。
如果我们正确地选择了转移算子 T，那么最终的 平稳分布 q将会等于我们所希
望采样的分布 p。我们会将第 17.4节介绍如何选择 T。
可数状态 马尔可夫链 的大多数性质可以被推广到连续状态的 马尔可夫链 中。在
这种情况下，一些研究者把这种 马尔可夫链 称为哈里斯链 （Harris Chain ） ，但是我
们将这两种情况都称为 马尔可夫链 。通常在一些宽松的条件下，一个带有转移算子
T的马尔可夫链 都会收敛到一个不动点，这个不动点可以写成如下形式：
q′(x′) =ExqT(x′jx); (17.24)
这个方程的离散版本就相当于重新改写方程 式 (17.23 )。当 x是离散值时，这个期
望对应着求和，而当 x是连续值时，这个期望对应的是积分。
无论状态是连续的还是离散的，所有的 马尔可夫链 方法都包括了重复、随机地
更新直到最后状态开始从 均衡分布 中采样。运行 马尔可夫链 直到它达到 均衡分布 的
过程通常被称为 马尔可夫链 的磨合（Burning-in ）过程。在 马尔可夫链 达到均衡分
布之后，我们可以从 均衡分布 中抽取一个无限多数量的样本序列。这些样本服从同
一分布，但是两个连续的样本之间会高度相关。所以一个有限的序列无法完全表
达均衡分布 。一种解决这个问题的方法是每隔 n个样本返回一个样本，从而使得我
们对于均衡分布 的统计量的估计不会被 MCMC方法的样本之间的相关性所干扰。所
以马尔可夫链 的计算代价很高，主要源于达到 均衡分布 前需要磨合的时间以及在达
到均衡分布 之后从一个样本转移到另一个足够无关的样本所需要的时间。如果我们
想要得到完全独立的样本，那么我们可以同时并行地运行多个 马尔可夫链 。这种方
法使用了额外的并行计算来减少时延。使用一条 马尔可夫链 来生成所有样本的策略
和（使用多条 马尔可夫链 ）每条马尔可夫链 只产生一个样本的策略是两种极端。深
度学习的从业者们通常选取的 马尔可夫链 的数目和 小批量中的样本数相近，然后从
这些固定的 马尔可夫链 集合中抽取所需要的样本。 马尔可夫链 的数目通常选为 100。
另一个难点是我们无法预先知道 马尔可夫链 需要运行多少步才能到达 均衡分布 。
这段时间通常被称为 混合时间 （Mixing Time ） 。检测一个 马尔可夫链 是否达到平衡
是很困难的。我们并没有足够完善的理论来解决这个问题。理论只能保证 马尔可夫
链会最终收敛，但是无法保证其他。如果我们从矩阵 A作用在概率向量 v上的角度
来分析马尔可夫链 ，那么我们可以发现当 At除了单个 1以外的特征值都趋于 0时，
马尔可夫链 混合成功（收敛到了 均衡分布 ） 。这也意味着矩阵 A的第二大特征值决DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.4 GIBBS 采样 509
定了马尔可夫链 的混合时间 。然而，在实践中，我们通常不能真的将 马尔可夫链 表示
成矩阵的形式。我们的概率模型所能够达到的状态是变量数的指数级别，所以表达
v，A或者 A的特征值是不现实的。由于以上在内的诸多阻碍，我们通常无法知道 马
尔可夫链 是否已经混合成功。作为替代，我们只能运行一定量时间 马尔可夫链 直到
我们粗略估计这段时间是足够的，然后使用启发式的方法来判断 马尔可夫链 是否混
合成功。这些启发性的算法包括了手动检查样本或者衡量前后样本之间的相关性。
17.4 Gibbs 采样
目前为止我们已经了解了如何通过反复更新 x   x′T(x′jx)从一个分布
q(x)中采样。然而我们还没有介绍过如何确定 q(x)是否是一个有效的分布。本书
中将会描述两种基本的方法。第一种方法是从已经学习到的分布 pmodel中推导出
T，下文描述了如何从 基于能量的模型 中采样。第二种方法是直接用参数描述 T，然
后学习这些参数，其 平稳分布 隐式地定义了我们所感兴趣的模型 pmodel。我们将在
第20.12节和第 20.13节中讨论第二种方法的例子。
在深度学习 中，我们通常使用 马尔可夫链 从定义为 基于能量的模型 的分布
pmodel (x)中采样。在这种情况下，我们希望 马尔可夫链 的q(x)分布就是 pmodel (x)。
为了得到所期望的 q(x)分布，我们必须选取合适的 T(x′jx)。
Gibbs采样（Gibbs Sampling ）是一种概念简单而又有效的方法。它构造一个
从pmodel (x)中采样的 马尔可夫链 ，其中在 基于能量的模型 中从 T(x′jx)采样是通
过选择一个变量 xi，然后从 pmodel中该点关于在无向图 G（定义了 基于能量的模
型结构）中邻接点的条件分布中采样。只要一些变量在给定相邻变量时是条件独立
的，那么这些变量就可以被同时采样。正如在第 16.7.1节中看到的 RBM示例一样，
RBM中所有的 隐藏单元 可以被同时采样，因为在给定所有可见单元的条件下它们相
互条件独立。同样地，所有的可见单元也可以被同时采样，因为在给定所有 隐藏单
元的情况下它们相互条件独立。以这种方式同时更新许多变量的 Gibbs采样通常被
称为块吉布斯采样 （block Gibbs Sampling ） 。
设计从 pmodel中采样的 马尔可夫链 还存在其他备选方法。比如说， Metropolis-
Hastings 算法在其他领域中广泛使用。不过在 深度学习 的无向模型 中，我们主要使
用Gibbs采样，很少使用其他方法。改进采样技巧也是一个潜在的研究热点。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
510 第十七章 蒙特卡罗方法
17.5不同的峰值之间的混合挑战
使用 MCMC方法的主要难点在于 马尔可夫链 的混合（Mixing）通常不理想。在
理想情况下，从设计好的 马尔可夫链 中采出的连续样本之间是完全独立的，而且在
x空间中， 马尔可夫链 会按概率大小访问许多不同区域。
然而， MCMC方法采出的样本可能会具有很强的相关性，尤其是在高维的情况
下。我们把这种现象称为慢 混合甚至混合失败。具有缓慢 混合的MCMC方法可以被
视为对能量函数 无意地执行类似于带噪声的 梯度下降 的操作，或者说等价于相对于
链的状态（被采样的随机变量）依据概率进行噪声爬坡。（在 马尔可夫链 的状态空
间中）从 x(t 1)到 x(t)该链倾向于选取很小的步长，其中能量 E(x(t))通常低于或
者近似等于能量 E(x(t 1))，倾向于向较低能量的区域移动。当从可能性较小的状态
（比来自 p(x)的典型样本拥有更高的能量）开始时，链趋向于逐渐减少状态的能量，
并且仅仅偶尔移动到另一个 峰值。一旦该链已经找到低能量的区域（例如，如果变量
是图像中的像素，则低能量的区域可以是同一对象所对应图像的一个连通的 流形） ，
我们称之为 峰值，链将倾向于围绕着这个 峰值游走（按某一种形式随机游走） 。它
时不时会走出该 峰值，但是结果通常会返回该 峰值或者（如果找到一条离开的路线）
移向另一个 峰值。问题是对于很多有趣的分布来说成功的离开路线很少，所以 马尔
可夫链将在一个 峰值附近抽取远超过需求的样本。
当我们考虑 Gibbs采样算法（见第 17.4节）时，这种现象格外明显。在这种情
况下，我们考虑在一定步数内从一个 峰值移动到一个临近 峰值的概率。决定这个概
率的是两个 峰值之间的 ‘‘能量障碍 ’’的形状。隔着一个巨大 ‘‘能量障碍 ”（低概率
的区域）的两个 峰值之间的转移概率是（随着能量障碍的高度）指数下降的，如
图17.1所示。当目标分布有多个高概率 峰值并且被低概率区域所分割，尤其当 Gibbs
采样的每一步都只是更新变量的一小部分而这一小部分变量又严重依赖其他的变量
时，就会产生问题。
举一个简单的例子，考虑两个变量 a，b的基于能量的模型 ，这两个变量都是二
值的，取值 +1或者 1。如果对某个较大的正数 w，E(a;b) = wab，那么这个模
型传达了一个强烈的信息， a和 b有相同的符号。当 a= 1时用 Gibbs采样更新 b。
给定 b时的条件分布满足 p(b= 1ja= 1) = (w)。如果 w的值很大， sigmoid函
数趋近于饱和，那么 b也取到 1的概率趋近于 1。同理，如果 a= 1，那么 b取
到 1的概率也趋于 1。根据模型 pmodel (a;b)，两个变量取一样的符号的概率几乎相
等。根据 pmodel (ajb)，两个变量应该有相同的符号。这也意味着 Gibbs采样很难会DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.5不同的峰值之间的混合挑战 511
图17.1:对于三种分布使用 Gibbs采样所产生的路径，所有的分布 马尔可夫链 初始值都设为 峰
值。(左)一个带有两个独立变量的 多维正态分布 。由于变量之间是相互独立的， Gibbs采样混合得
很好。 (中)变量之间存在高度相关性的一个 多维正态分布 。变量之间的相关性使得 马尔可夫链 很
难混合。因为每一个变量的更新需要相对其他变量求条件分布，相关性减慢了 马尔可夫链 远离初
始点的速度。 (右)峰值之间间距很大且不在轴上对齐的混合高斯分布。 Gibbs采样混合得很慢，因
为每次更新仅仅一个变量很难跨越不同的 峰值。
改变这些变量的符号。
在更实际的问题中，这种挑战更加艰巨因为在实际问题中我们不能仅仅关注在
两个峰值之间的转移，更要关注在多个 峰值之间的转移。如果由于 峰值之间混合困
难，而导致某几个这样的转移难以完成，那么得到一些可靠的覆盖大部分 峰值的样
本集合的计算代价是很高的，同时 马尔可夫链 收敛到它的 平稳分布 的过程也会非常
缓慢。
通过寻找一些高度依赖变量的组以及分块同时更新块（组）中的变量，这个问
题有时候是可以被解决的。然而不幸的是，当依赖关系很复杂时，从这些组中采样
的过程从计算角度上说是难以处理的。归根结底， 马尔可夫链 最初就是被提出来解
决这个问题，即从大量变量中采样的问题。
在定义了一个联合分布 pmodel (x;h)的潜变量模型中，我们经常通过交替地从
pmodel (xjh)和pmodel (hjx)中采样来达到抽 x的目的。从快速 混合的角度上说，我
们更希望 pmodel (hjx)有很大的熵。然而，从学习一个 h的有用表示的角度上考虑，
我们还是希望 h能够包含 x的足够信息从而能够较完整地重构它，这意味 h和 x
要有非常高的互信息。这两个目标是相互矛盾的。我们经常学习到能够将 x精确地DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
512 第十七章 蒙特卡罗方法
编码为 h的生成模型 ，但是无法很好 混合。这种情况在 玻尔兹曼机 中经常出现，一
个玻尔兹曼机 学到的分布越尖锐，该分布的 马尔可夫链 采样越难 混合得好。这个问
题在图 17.2中有所描述。
图17.2:深度概率模型中一个 混合缓慢问题的例证。每张图都是按照从左到右从上到下的顺序的。
(左)Gibbs采样从MNIST 数据集训练成的 深度玻尔兹曼机 中采出的连续样本。这些连续的样本
之间非常相似。由于 Gibbs采样作用于一个深度图模型，相似度更多地是基于语义而非原始视觉
特征。但是对于吉布斯链来说从分布的一个 峰值转移到另一个仍然是很困难的，比如说改变数字。
(右)从生成式对抗网络 中抽出的连续原始样本。因为 原始采样 生成的样本之间互相独立，所以不
存在混合问题。译者注：原书此处左右搞反了。
当感兴趣的分布对于每个类具有单独的 流形结构时，所有这些问题都
使MCMC方法变得不那么有用：分布集中在许多 峰值周围，并且这些 峰值由大量高
能量区域分割。我们在许多分类问题中遇到的是这种类型的分布，由于 峰值之间混
合缓慢，它将使得 MCMC方法非常缓慢地收敛。
17.5.1 不同峰值之间通过回火来混合
当一个分布有一些陡峭的峰并且被低概率区域包围时，很难在分布的不同 峰
值之间混合。一些加速 混合的方法是基于构造一个概率分布替代目标分布，这个概
率分布的 峰值没有那么高， 峰值周围的低谷也没有那么低。 基于能量的模型 为这个
想法提供一种简单的做法。目前为止，我们一直将 基于能量的模型 描述为定义一个
概率分布：
p(x)/ exp( E(x)): (17.25)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
17.5不同的峰值之间的混合挑战 513
基于能量的模型 可以通过添加一个额外的控制 峰值尖锐程度的参数 来加强：
p(x)/ exp( E(x)): (17.26)
参数可以被理解为 温度（temperature ）的倒数，反映了 基于能量的模型 的统计物
理学起源。当 温度趋近于 0时，趋近于无穷大，此时的 基于能量的模型 是确定性
的。当温度趋近于无穷大时， 趋近于零， 基于能量的模型 （对离散的 x）成了均匀
分布。
通常情况下，在 = 1时训练一个模型。但我们也可以利用其他 温度，尤其是
 < 1的情况。 回火（tempering ）作为一种通用的策略，它通过从  < 1模型中采
样来实现在 p1的不同峰值之间快速 混合。
基于回火转移 （tempered transition ）(Neal,1994)的马尔可夫链 临时从高 温
度的分布中采样使其在不同 峰值之间混合，然后继续从单位 温度的分布中采样。这
些技巧被应用在一些模型比如 RBM中(Salakhutdinov ,2010)。另一种方法是利用 并
行回火（parallel tempering ）(Iba,2001)。其中马尔可夫链 并行地模拟许多不同 温
度的不同状态。最高 温度的状态混合较慢，相比之下最低 温度的状态，即 温度为1
时，采出了精确的样本。转移算子包括了两个 温度之间的随机跳转，所以一个高 温
度状态分布槽中的样本有足够大的概率跳转到低 温度分布的槽中。这个方法也被应
用到了 RBM中(Desjardins et al. ,2010a ;Cho et al. ,2010a )。尽管回火这种方法前
景可期，现今它仍然无法让我们在采样复杂的 基于能量的模型 中更进一步。一个可
能的原因是在 临界温度 （critical temperatures ）时温度转移算子必须设置得非常慢
（因为温度需要逐渐下降）来确保 回火的有效性。
17.5.2 深度也许会有助于混合
当我们从 潜变量模型 p(h;x)中采样时，我们可以发现如果 p(hjx)将 x编码
得非常好，那么从 p(xjh)中采样时，并不会太大地改变 x，那么混合结果会很糟
糕。解决这个问题的一种方法是使得 h成为一种将 x编码为 h的深度表示，从而使
得马尔可夫链 在 h空间中更容易 混合。在许多 表示学习 算法如自编码器 和RBM中，
h的边缘分布相比于 x上的原始数据分布，通常表现为更加均匀、更趋近于 单峰值。
或许可以说，这是因为利用了所有可用的表示空间并尽量减小 重构误差 。因为当训
练集上的不同样本之间在 h空间能够被非常容易地区分时，我们也会很容易地最
小化重构误差 。Bengio et al. (2013a )观察到这样的现象，堆叠越深的 正则化自编码DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
514 第十七章 蒙特卡罗方法
器或者 RBM，顶端 h空间的边缘分布越趋向于均匀和发散，而且不同 峰值（比如
说实验中的类别）所对应区域之间的间距也会越小。在高层空间中训练 RBM会使
得Gibbs采样在峰值间混合得更快。然而，如何利用这种观察到的现象来辅助训练
深度生成模型 或者从中采样仍然有待探索。
尽管存在 混合的难点， 蒙特卡罗 技术仍然是一个有用的工具，通常也是最好的
可用工具。事实上，在遇到难以处理的 无向模型 中的配分函数 时，蒙特卡罗 方法仍
然是最主要的工具，这将在下一章详细阐述。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十八章 直面配分函数
在第 16.2.2节中，我们看到许多概率模型（通常是 无向图模型 ）由一个未归一
化的概率分布 ~p(x; )定义。我们必须通过除以 配分函数 Z()来归一化 ~p，以获得
一个有效的 概率分布 ：
p(x;) =1
Z()~p(x;): (18.1)
配分函数 是未归一化概率所有状态的积分（对于连续变量）或求和（对于离散变量） ：
∫
~p(x)dx (18.2)
或者∑
x~p(x): (18.3)
对于很多有趣的模型而言，以上积分或求和难以计算。
正如我们将在第 二十章看到的，有些 深度学习 模型被设计成具有一个易于处理
的归一化常数，或被设计成能够在不涉及计算 p(x)的情况下使用。然而，其他一些
模型会直接面对难以计算的 配分函数 的挑战。在本章中，我们会介绍用于训练和评
估那些具有难以处理的 配分函数 的模型的技术。
18.1对数似然梯度
通过最大似然 学习无向模型 特别困难的原因在于 配分函数 依赖于参数。对数似
然相对于参数的梯度具有一项对应于 配分函数 的梯度：
∇logp(x;) =∇log~p(x;) ∇logZ(): (18.4)
515DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
516 第十八章 直面配分函数
这是机器学习中非常著名的 正相（positive phase ）和负相（negative phase ）的
分解。
对于大多数感兴趣的 无向模型 而言，负相是困难的。没有 潜变量或潜变量之间
很少相互作用的模型通常会有一个易于计算的 正相。RBM的隐藏单元 在给定可见单
元的情况下彼此条件独立，是一个典型的具有简单 正相和困难负相的模型。 正相计
算困难， 潜变量之间具有复杂相互作用的情况将主要在第 十九章中讨论。本章主要
探讨负相计算中的难点。
让我们进一步分析 logZ的梯度：
∇logZ (18.5)
=∇Z
Z(18.6)
=∇∑
x~p(x)
Z(18.7)
=∑
x∇~p(x)
Z: (18.8)
对于保证所有的 x都有 p(x)>0的模型，我们可以用 exp(log~p(x))代替 ~p(x)：
∑
x∇exp(log~p(x))
Z(18.9)
=∑
xexp(log~p(x))∇log~p(x)
Z(18.10)
=∑
x~p(x)∇log~p(x)
Z(18.11)
=∑
xp(x)∇log~p(x) (18.12)
=Exp(x)∇log~p(x): (18.13)
上述推导对离散的 x进行求和，对连续的 x进行积分也可以得到类似结果。在
连续版本的推导中，使用在积分符号内取微分的 莱布尼兹法则 可以得到等式
∇∫
~p(x)dx=∫
∇~p(x)dx: (18.14)
该等式只适用于 ~p和∇~p(x)上的一些特定规范条件。在测度论术语中，这些条件
是：(1)对每一个而言，未归一化分布 ~p必须是 x的勒贝格可积 函数。 (2)对于所DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.2随机最大似然和对比散度 517
有的和几乎所有 x，梯度∇~p(x)必须存在。 (3)对于所有的和几乎所有的 x，
必须存在一个可积函数 R(x)使得 max ij@
@i~p(x)jR(x)。幸运的是，大多数感兴趣
的机器学习 模型都具有这些性质。
等式
∇logZ=Exp(x)∇log~p(x) (18.15)
是使用各种 蒙特卡罗 方法近似最大化（具有难计算 配分函数 模型的）似然的基础。
蒙特卡罗 方法为学习 无向模型 提供了直观的框架， 我们能够在其中考虑 正相和负
相。在正相中，我们增大从数据中采样得到的 log~p(x)。在负相中，我们通过降低从
模型分布中采样的 log~p(x)来降低配分函数 。
在深度学习 文献中，经常会看到用 能量函数 （式 (16.7)）来参数化 log~p。在这
种情况下， 正相可以解释为压低训练样本的能量， 负相可以解释为提高模型抽出的
样本的能量，如图 18.1所示。
18.2随机最大似然和对比散度
实现式 (18.15 )的一个朴素方法是，每次需要计算梯度时， 磨合随机初始化的一
组马尔可夫链 。当使用 随机梯度下降 进行学习时，这意味着 马尔可夫链 必须在每次
梯度步骤中 磨合。这种方法引导下的训练过程如算法 18.1所示。内循环中 磨合马尔
可夫链的计算代价过高，导致这个过程在实际中是不可行的，但是这个过程是其他
更加实际的近似算法的基础。
我们可以将最大化似然的 MCMC方法视为在两种力之间平衡，一种力拉高数据
出现时的模型分布，一种拉低模型采样出现时的模型分布。图 18.1展示了这个过程。
这两种力分别对应最大化 log~p和最小化 logZ。对于负相会有一些近似方法。这些
近似都可以被理解为使 负相更容易计算，但是也可能将其推向错误的位置。
因为负相涉及到从模型分布中抽样，所以我们可以认为它在找模型信任度很高
的点。因为 负相减少了这些点的概率，它们一般被认为代表了模型不正确的信念。在
文献中，它们经常被称为 ‘‘幻觉’’或‘‘幻想粒子 ’’。事实上， 负相已经被作为人类和其
他动物做梦的一种可能解释 (Crick and Mitchison ,1983)。这个想法是说，大脑维持
着世界的概率模型，并且在醒着经历真实事件时会遵循 log~p的梯度，在睡觉时会遵
循 log~p的负梯度最小化 logZ，其经历的样本采样自当前的模型。这个视角解释了
具有正相和负相的大多数算法，但是它还没有被神经科学实验证明是正确的。在 机DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
518 第十八章 直面配分函数
算法18.1一种朴素的 MCMC算法，使用梯度上升最大化具有难以计算 配分函数 的
对数似然。
设步长 ϵ为一个小正数。
设吉布斯步数 k大到足以允许 磨合。在小图像集上训练一个 RBM大致设为 100。
while不收敛 do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量。
g 1
m∑m
i=1∇log~p(x(i);).
初始化 m个样本f~x(1); : : : ; ~x(m)g为随机值（例如，从均匀或正态分布中采，或
大致与模型边缘分布匹配的分布） 。
fori= 1tokdo
forj= 1tomdo
~x(j) gibbs_update (~x(j)):
end for
end for
g g 1
m∑m
i=1∇log~p(~x(i);):
 +ϵg:
end while
器学习模型中，通常有必要同时使用 正相和负相，而不是按不同时间阶段分为清醒
和REM睡眠时期。正如我们将在第 19.5节中看到的，一些其他 机器学习 算法出于
其他原因从模型分布中采样，这些算法也能提供睡觉做梦的解释。
这样理解学习 正相和负相的作用之后，我们设计了一个比算法 18.1计算代价更
低的替代算法。简单的 MCMC算法的计算成本主要来自每一步的随机初始化 磨合马
尔可夫链 。一个自然的解决方法是初始化 马尔可夫链 为一个非常接近模型分布的分
布，从而大大减少 磨合步骤。
对比散度 （CD，或者是具有 k个Gibbs步骤的 CD-k）算法在每个步骤中初始
化马尔可夫链 为采样自数据分布中的样本 (Hinton ,2000,2010)，如算法 18.2所示。
从数据分布中获取样本是计算代价最小的，因为它们已经在数据集中了。初始时，数
据分布并不接近模型分布，因此 负相不是非常准确。幸运的是， 正相仍然可以准确
地增加数据的模型概率。进行 正相阶段一段时间之后，模型分布会更接近于数据分
布，并且 负相开始变得准确。
当然， CD仍然是真实 负相的一个近似。 CD未能定性地实现真实 负相的主要原DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.2随机最大似然和对比散度 519
xp(x)The positive phase
pmodel (x)
pdata(x)
xp(x)The negative phase
pmodel (x)
pdata(x)
图18.1:算法 18.1角度的 “正相’’和“负相’’。(左)在正相中，我们从数据分布中采样，然后推高
它们未归一化的概率。这意味着概率越高的数据点未归一化的概率被推高得越多。 (右)在负相中，
我们从模型分布中采样，然后压低它们未归一化的概率。这与 正相的倾向相反，给未归一化的概
率处处添加了一个大常数。当数据分布和模型分布相等时， 正相推高数据点和 负相压低数据点的
机会相等。此时，不再有任何的梯度（期望上说） ，训练也必须停止。
因是，它不能抑制远离真实训练样本的高概率区域。这些区域在模型上具有高概率，
但是在数据生成区域上具有低概率，被称为 虚假模态 （spurious modes ） 。图 18.2解
释了这种现象发生的原因。基本上，除非 k非常大，模型分布中远离数据分布的 峰
值不会被使用训练数据初始化的 马尔可夫链 访问到。
Carreira-Perpiñan and Hinton (2005)实验上证明 CD估计偏向于 RBM和完全
可见的玻尔兹曼机 ，因为它会收敛到与 最大似然估计 不同的点。他们认为，由于偏
差较小， CD可以作为一种计算代价低的方式来初始化模型，之后可以通过计算代价
高的 MCMC方法进行 精调。Bengio and Delalleau (2009)表明， CD可以被理解为去
掉了正确 MCMC梯度更新中的最小项，这解释了偏差的由来。
在训练诸如 RBM的浅层网络时 CD是很有用的。反过来，这些可以堆叠起来初
始化更深的模型，如 DBN或DBM。但是 CD并不直接有助于训练更深的模型。这是
因为在给定可见单元样本的情况下，很难获得 隐藏单元 的样本。由于 隐藏单元 不包
括在数据中，所以使用训练点初始化无法解决这个问题。即使我们使用数据初始化
可见单元，我们仍然需要 磨合在给定这些可见单元的 隐藏单元 条件分布上采样的 马
尔可夫链 。
CD算法可以被理解为惩罚某类模型，这类模型的 马尔可夫链 会快速改变来自数DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
520 第十八章 直面配分函数
算法18.2对比散度 算法，使用梯度上升作为优化过程。
设步长 ϵ为一个小正数。
设吉布斯步数 k大到足以让从 pdata初始化并从 p(x;)采样的马尔可夫链 混合。
在小图像集上训练一个 RBM大致设为 1-20。
while不收敛 do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量。
g 1
m∑m
i=1∇log~p(x(i);):
fori= 1tomdo
~x(i) x(i):
end for
fori= 1tokdo
forj= 1tomdo
~x(j) gibbs_update (~x(j)):
end for
end for
g g 1
m∑m
i=1∇log~p(~x(i);):
 +ϵg:
end while
据的输入。这意味着使用 CD训练从某种程度上说类似于训练 自编码器 。即使 CD估
计比一些其他训练方法具有更大偏差，但是它有助于 预训练之后会堆叠起来的浅层
模型。这是因为堆栈中最早的模型会受激励复制更多的信息到其 潜变量，使其可用
于随后的模型。这应该更多地被认为是 CD训练中经常可利用的副产品，而不是主要
的设计优势。
Sutskever and Tieleman (2010)表明， CD的更新方向不是任何函数的梯度。这
使得 CD可能存在永久循环的情况，但在实践中这并不是一个严重的问题。
另一个解决 CD中许多问题的不同策略是，在每个梯度步骤中初始化 马尔可夫
链为先前梯度步骤的状态值。这个方法首先被应用数学和统计学社群发现，命名
为随机最大似然 （SML）(Younes ,1998)，后来又在 深度学习 社群中以名称 持续性对
比散度（PCD，或者每个更新中具有 k个Gibbs步骤的 PCD -k）独立地被重新发
现(Tieleman ,2008)。具体可以参考算法 18.3。这种方法的基本思想是，只要随机梯
度算法得到的步长很小，那么前一步骤的模型将类似于当前步骤的模型。因此，来DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.2随机最大似然和对比散度 521
xp(x)pmodel (x)
pdata(x)
图18.2:一个虚假模态 。说明对比散度 （算法 18.2）的负相为何无法抑制 虚假模态 的例子。一个 虚
假模态指的是一个在模型分布中出现数据分布中却不存在的模式。由于 对比散度 从数据点中初始
化它的马尔可夫链 然后仅仅运行了几步 马尔可夫链 ，不太可能到达模型中离数据点较远的模式。这
意味着从模型中采样时，我们有时候会得到一些与数据并不相似的样本。这也意味着由于在这些
模式上浪费了一些概率质量，模型很难把较高的概率质量集中于正确的模式上。出于可视化的目
的，这个图使用了某种程度上说更加简单的距离的概念——在 R的数轴上 虚假模态 与正确的模式
有很大的距离。这对应着基于局部移动 R上的单个变量 x的马尔可夫链 。对于大部分深度概率模
型来说， 马尔可夫链 是基于 Gibbs采样的，并且对于单个变量产生非局部的移动但是无法同时移
动所有的变量。对于这些问题来说，考虑编辑距离比欧式距离通常更好。然而，高维空间的编辑距
离很难在二维空间作图展示。
自先前模型分布的样本将非常接近来自当前模型分布的客观样本，用这些样本初始
化的马尔可夫链 将不需要花费很多时间来完成 混合。
因为每个 马尔可夫链 在整个学习过程中不断更新，而不是在每个梯度步骤中重
新开始，马尔可夫链 可以自由探索很远， 以找到模型的所有 峰值。 因此， SML比CD更
不容易形成具有 虚假模态 的模型。此外，因为可以存储所有采样变量的状态，无论
是可见的还是 潜在的，SML为隐藏单元 和可见单元都提供了初始值。 CD只能为可
见单元提供初始化，因此 深度模型 需要进行 磨合步骤。 SML能够高效地训练 深度模
型。Marlin et al. (2010)将SML与本章中提出的许多其他标准方法进行比较。他们
发现， SML在RBM上得到了最佳的测试集对数似然，并且如果 RBM的隐藏单元 被
用作 SVM分类器的特征，那么 SML会得到最好的分类精度。
在k太小或 ϵ太大时，随机梯度算法移动模型的速率比 马尔可夫链 在迭代步
中混合更快，此时 SML容易变得不准确。不幸的是，这些值的容许范围高度依赖DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
522 第十八章 直面配分函数
算法18.3随机最大似然 /持续性对比散度 算法，使用梯度上升作为优化过程。
设步长 ϵ为一个小正数。
设吉布斯步数 k大到足以让从 p(x;+ϵg)采样的马尔可夫链 磨合（从采自 p(x;)
的样本开始） 。在小图像集上训练一个 RBM大致设为 1，对于更复杂的模型如 深度
玻尔兹曼机 可能要设为 5到50。
初始化 m个样本f~x(1); : : : ; ~x(m)g为随机值（例如，从均匀或正态分布中采，或大
致与模型边缘分布匹配的分布） 。
while不收敛 do
从训练集中采包含 m个样本fx(1); : : : ; x(m)g的小批量。
g 1
m∑m
i=1∇log~p(x(i);):
fori= 1tokdo
forj= 1tomdo
~x(j) gibbs_update (~x(j)):
end for
end for
g g 1
m∑m
i=1∇log~p(~x(i);):
 +ϵg:
end while
于具体问题。现在还没有方法能够正式地测试 马尔可夫链 是否能够在迭代步骤之间
成功混合。主观地，如果对于 Gibbs步骤数目而言 学习率太大的话，那么梯度步骤
中负相采样的方差会比不同 马尔可夫链 中负相采样的方差更大。例如，一个 MNIST
模型在一个步骤中只采样得到了 7。然后学习过程将会极大降低 7对应的峰值，在
下一个步骤中，模型可能会只采样得到 9。
从使用 SML训练的模型中评估采样必须非常小心。在模型训练完之后，有必要
从一个随机起点初始化的新 马尔可夫链 抽取样本。用于训练的连续负相链中的样本
受到了模型最近几个版本的影响，会使模型看起来具有比其实际更大的 容量。
Berglund and Raiko (2013)进行了实验来检验由 CD和SML进行梯度估计带来
的偏差和方差。结果证明 CD比基于精确采样的 估计具有更低的方差。而 SML有更
高的方差。 CD方差低的原因是，其在 正相和负相中使用了相同的训练点。如果从不
同的训练点来初始化 负相，那么方差会比基于精确采样的 估计的方差更大。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.3伪似然 523
所有基于 MCMC从模型中抽取样本的方法在原则上几乎可以与 MCMC的任何
变体一起使用。这意味着诸如 SML这样的技术可以使用第 十七章中描述的任何增
强MCMC的技术（例如 并行回火 ）来加以改进 (Desjardins et al. ,2010b ;Cho et al. ,
2010b )。
一种在学习期间加速 混合的方法是，不改变 蒙特卡罗 采样技术，而是改变模型的
参数化和 代价函数 。快速持续性对比散度 （fast persistent contrastive divergence ） ，
或者 FPCD (Tieleman and Hinton ,2009)使用如下表达式去替换传统模型的参数 
=(slow)+(fast): (18.16)
现在的参数是以前的两倍多，将其逐个相加以定义原始模型的参数。快速复制参数
可以使用更大的 学习率来训练，从而使其快速响应学习的 负相，并促使 马尔可夫链 探
索新的区域。这能够使 马尔可夫链 快速混合，尽管这种效应只会发生在学习期间快
速权重可以自由改变的时候。通常，在短时间地将快速权重设为大值并保持足够长
时间，使 马尔可夫链 改变峰值之后，我们会对快速权重使用显著的 权重衰减 ，促使
它们收敛到较小的值。
本节介绍的基于 MCMC的方法的一个关键优点是它们提供了 logZ梯度的估
计，因此我们可以从本质上将问题分解为 log~p和 logZ两块。然后我们可以使用任
何其他的方法来处理 log~p(x)，只需将我们的 负相梯度加到其他方法的梯度中。特别
地，这意味着 正相可以使用那些仅提供 ~p下限的方法。然而，本章介绍处理 logZ的
大多数其他方法都和基于边界的 正相方法是不兼容的。
18.3伪似然
蒙特卡罗 近似配分函数 及其梯度需要直接处理 配分函数 。有些其他方法通过训
练不需要计算 配分函数 的模型来绕开这个问题。这些方法大多数都基于以下观察：
无向概率模型中很容易计算概率的比率。这是因为 配分函数 同时出现在比率的分子
和分母中，互相抵消：
p(x)
p(y)=1
Z~p(x)
1
Z~p(y)=~p(x)
~p(y): (18.17)
伪似然正是基于 条件概率 可以采用这种基于比率的形式，因此可以在没有 配分
函数的情况下进行计算。假设我们将 x分为 a，b和 c，其中 a包含我们想要的条DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
524 第十八章 直面配分函数
件分布的变量， b包含我们想要条件化的变量， c包含除此之外的变量：
p(ajb) =p(a;b)
p(b)=p(a;b)∑
a;cp(a;b;c)=~p(a;b)∑
a;c~p(a;b;c): (18.18)
以上计算需要边缘化 a，假设 a和 c包含的变量并不多，那么这将是非常高效的操
作。在极端情况下， a可以是单个变量， c可以为空，那么该计算仅需要估计与单
个随机变量 值一样多的 ~p。
不幸的是，为了计算对数似然，我们需要边缘化很多变量。如果总共有 n个变
量，那么我们必须边缘化 n 1个变量。根据概率的 链式法则 ，我们有
logp(x) = logp(x1) + logp(x2jx1) ++logp(xnjx1:n−1): (18.19)
在这种情况下， 我们已经使 a尽可能小， 但是 c可以大到 x2:n。 如果我们简单地将 c移
到 b中以减少计算代价，那么会发生什么呢？这便产生了 伪似然（pseudolikelihood ）
(Besag ,1975)目标函数 ，给定所有其他特征 x i，预测特征 xi的值：
n∑
i=1logp(xijx i): (18.20)
如果每个 随机变量 有k个不同的值，那么计算 ~p需要 kn次估计，而计算 配
分函数需要 kn次估计。
这看起来似乎是一个没有道理的策略，但可以证明最大化 伪似然的估计是渐近
一致的 (Mase ,1995)。当然，在数据集不趋近于大采样极限的情况下， 伪似然可能表
现出与最大似然估计 不同的结果。
我们可以使用 广义伪似然估计 （generalized pseudolikelihood estimator ）来权
衡计算复杂度和最大似然表现的偏差 (Huang and Ogata ,2002)。广义伪似然估计 使
用m个不同的集合 S(i)，i= 1; : : : ; m作为变量的指标出现在条件棒的左侧。在
m= 1和S(1)= 1; : : : ; n的极端情况下， 广义伪似然估计 会变为对数似然。在 m=n
和S(i)=fig的极端情况下， 广义伪似然 会恢复为 伪似然。广义伪似然估计 目标函
数如下所示
m∑
i=1logp(xS(i)jx S(i)): (18.21)
基于伪似然的方法的性能在很大程度上取决于模型是如何使用的。对于完全联
合分布 p(x)模型的任务（例如密度估计和采样） ， 伪似然通常效果不好。对于在训DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.4得分匹配和比率匹配 525
练期间只需要使用条件分布的任务而言，它的效果比最大似然更好，例如填充少量
的缺失值。如果数据具有规则结构，使得 S索引集可以被设计为表现最重要的相关
性质，同时略去相关性可忽略的变量，那么 广义伪似然 策略将会非常有效。例如，在
自然图像中，空间中相隔很远的像素也具有弱相关性，因此 广义伪似然 可以应用于
每个S集是小的局部空间窗口的情况。
伪似然估计的一个弱点是它不能与仅在 ~p(x)上提供下界的其他近似一起使用，
例如第十九章中介绍的 变分推断 。这是因为 ~p出现在了分母中。分母的下界仅提供
了整个表达式的上界，然而最大化上界没有什么意义。这使得我们难以将 伪似然方
法应用于诸如 深度玻尔兹曼机 的深度模型 ，因为变分方法是近似边缘化互相作用的
多层隐藏变量 的主要方法之一。尽管如此， 伪似然仍然可以用在 深度学习 中，它可
以用于单层模型，或使用不基于下界的近似推断方法的 深度模型 中。
伪似然比SML在每个梯度步骤中的计算代价要大得多，这是由于其对所有条
件进行显式计算。但是，如果每个样本只计算一个随机选择的条件，那么 广义伪
似然和类似标准仍然可以很好地运行，从而使计算代价降低到和 SML差不多的程
度(Goodfellow et al. ,2013d )。
虽然伪似然估计没有显式地最小化 logZ，但是我们仍然认为它具有类似 负相的
效果。每个条件分布的分母会使得学习算法降低所有仅具有一个变量不同于训练样
本的状态的概率。
读者可以参考 Marlin and de Freitas (2011)了解伪似然渐近效率的理论分析， 。
18.4得分匹配和比率匹配
得分匹配 (Hyvärinen ,2005b )提供了另一种训练模型而不需要估计 Z或其导数
的一致性方法。对数密度关于参数的导数 ∇ xlogp(x)，被称为其 得分（score） ，得分
匹配这个名称正是来自这样的术语。 得分匹配 采用的策略是，最小化模型对数密度
和数据对数密度关于输入的导数之间的平方差期望：
L(x;) =1
2∥∇ xlogpmodel (x;) ∇ xlogpdata(x)∥2
2; (18.22)
J() =1
2Epdata(x)L(x;); (18.23)
= min
J(): (18.24)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
526 第十八章 直面配分函数
该目标函数 避免了微分 配分函数 Z带来的难题，因为 Z不是 x的函数，所以
∇ xZ= 0。最初， 得分匹配 似乎有一个新的困难：计算数据分布的 得分需要知道生成
训练数据的真实分布 pdata。幸运的是，最小化 L(x;)的期望等价于最小化下式的
期望
~L(x;) =n∑
j=1(
@2
@x2
jlogpmodel (x;) +1
2(@
@xjlogpmodel (x;))2)
; (18.25)
其中 n是 x的维度。
因为得分匹配 需要关于 x的导数，所以它不适用于具有离散数据的模型，但是
模型中的 潜变量可以是离散的。
类似于伪似然，得分匹配 只有在我们能够直接估计 log~p(x)及其导数的时候才
有效。它与对 log~p(x)仅提供下界的方法不兼容，因为 得分匹配 需要 log~p(x)的导
数和二阶导数，而下限不能传达关于导数的任何信息。这意味着 得分匹配 不能应用
于隐藏单元 之间具有复杂相互作用的模型估计，例如 稀疏编码 模型或深度玻尔兹曼
机。虽然得分匹配 可以用于 预训练较大模型的第一个 隐藏层，但是它没有被用于预
训练较大模型的较深层网络。这可能是因为这些模型的 隐藏层通常包含一些离散变
量。
虽然得分匹配 没有明确显示具有 负相信息，但是它可以被视为使用特定类型 马
尔可夫链 的对比散度 的变种 (Hyvärinen ,2007a )。在这种情况下， 马尔可夫链 并没有
采用 Gibbs采样，而是采用一种由梯度引导局部更新的不同方法。当局部更新的大
小接近于零时， 得分匹配 等价于具有这种 马尔可夫链 的对比散度 。
Lyu(2009)将得分匹配 推广到离散的情况（但是推导有误，后由 Marlin et al.
(2010)修正） 。 Marlin et al. (2010)发现，广义得分匹配 （generalized score match-
ing，GSM）在许多样本观测概率为 0的高维离散空间中不起作用。
一种更成功地将 得分匹配 的基本想法扩展到离散数据的方法是 比率匹配 （ratio
matching ）(Hyvärinen ,2007b )。比率匹配 特别适用于二值数据。 比率匹配 最小化以
下目标函数 在样本上的均值：
L(RM)(x;) =n∑
j=1(
1
1 +pmodel (x;)
pmodel (f(x);j;))2
: (18.26)
其中 f(x; j)返回 j处位值取反的 x。比率匹配 使用了与 伪似然估计相同的策略来绕
开配分函数 ：配分函数 会在两个概率的比率中抵消掉。 Marlin et al. (2010)发现，训DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.5去噪得分匹配 527
练模型给测试集图像 去噪时，比率匹配 的效果要优于 SML、伪似然和GSM。
类似于伪似然估计，比率匹配 对每个数据点都需要 n个~p的估计，因此每次更
新的计算代价大约比 SML的计算代价高出 n倍。
与伪似然估计一样，我们可以认为 比率匹配 减小了所有只有一个变量不同于训
练样本的状态的概率。由于 比率匹配 特别适用于二值数据，这意味着在与数据的 汉
明距离为1内的所有状态上， 比率匹配 都是有效的。
比率匹配 还可以作为处理高维稀疏数据（例如词计数向量）的基础。这类稀疏
数据对基于 MCMC的方法提出了挑战，因为以密集格式表示数据是非常消耗计算资
源的，而只有在模型学会表示数据分布的稀疏性之后， MCMC采样才会产生稀疏值。
Dauphin and Bengio (2013)设计了比率匹配 的无偏随机近似来解决这个问题。该近
似只估计随机选择的目标子集，不需要模型生成完整的样本。
读者可以参考 Marlin and de Freitas (2011)了解比率匹配 渐近效率的理论分
析， 。
18.5去噪得分匹配
某些情况下，我们希望拟合以下分布来 正则化得分匹配
psmoothed (x) =∫
pdata(y)q(xjy)dy (18.27)
而不是拟合真实分布 pdata。分布 q(xjy)是一个损坏过程，通常在形成 x的过程中
会向 y中添加少量 噪声。
去噪得分匹配 非常有用，因为在实践中，通常我们不能获取真实的 pdata，而只
能得到其样本确定的 经验分布 。给定足够 容量，任何一致估计都会使 pmodel成为一
组以训练点为中心的 Dirac分布。考虑在第 5.4.5节介绍的渐近一致性上的 损失，通
过q来平滑有助于缓解这个问题。 Kingma and LeCun (2010b )介绍了平滑分布 q为
正态分布 噪声的正则化得分匹配 。
回顾第 14.5.1节，有一些 自编码器 训练算法等价于 得分匹配 或去噪得分匹配 。因
此，这些 自编码器 训练算法也是解决 配分函数 问题的一种方式。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
528 第十八章 直面配分函数
18.6噪声对比估计
具有难求解的 配分函数 的大多数模型估计都没有估计 配分函数 。SML和CD只
估计对数 配分函数 的梯度，而不是估计 配分函数 本身。得分匹配 和伪似然避免了和 配
分函数相关的计算。
噪声对比估计 （noise-contrastive estimation ，NCE）(Gutmann and Hyvari-
nen,2010)采取了一种不同的策略。在这种方法中，模型估计的 概率分布 被明确表示
为
logpmodel (x) = log~pmodel (x;) +c; (18.28)
其中 c是 logZ()的近似。 噪声对比估计 过程将 c视为另一参数，使用相同的算
法同时估计和c，而不是仅仅估计 ， 。因此，所得到的 logpmodel (x)可能并不完
全对应有效的 概率分布 ，但随着 c估计的改进，它将变得越来越接近有效值1。
这种方法不可能使用最大似然作为估计的标准。最大似然标准可以设置 c为任
意大的值，而不是设置 c以创建一个有效的 概率分布 。
NCE将估计 p(x)的无监督学习 问题转化为学习一个概率二元分类器，其中一
个类别对应模型生成的数据。该 监督学习 问题中的 最大似然估计 定义了原始问题的
渐近一致估计。
具体地说，我们引入第二个分布， 噪声分布 （noise distribution ）pnoise(x)。噪
声分布应该易于估计和从中采样。我们现在可以构造一个联合 x和新二值变量 y的
模型。在新的联合模型中，我们指定
pjoint(y= 1) =1
2; (18.29)
pjoint(xjy= 1) = pmodel (x); (18.30)
和
pjoint(xjy= 0) = pnoise(x): (18.31)
换言之， y是一个决定我们从模型还是从 噪声分布 中生成 x的开关变量。
我们可以在训练数据上构造一个类似的联合模型。在这种情况下，开关变量决定
是从数据还是从噪声分布中抽取 x。正式地， ptrain(y= 1) =1
2，ptrain(xjy= 1) =
pdata(x)，和 ptrain(xjy= 0) = pnoise(x)。
1NCE也适用于具有易于处理的，不需要引入额外参数 c的配分函数 的问题。它已经是最令人感兴趣的，估计具
有复杂配分函数 模型的方法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.6噪声对比估计 529
现在我们可以应用标准的最大似然学习拟合 pjoint到ptrain的监督学习问题：
; c= arg max
;cEx;yptrain logpjoint(yjx): (18.32)
分布 pjoint本质上是将 逻辑回归 模型应用于模型和 噪声分布 之间的对数概率之
差：
pjoint(y= 1jx) =pmodel (x)
pmodel (x) +pnoise(x)(18.33)
=1
1 +pnoise (x)
pmodel (x)(18.34)
=1
1 + exp(
logpnoise (x)
pmodel (x)) (18.35)
=(
 logpnoise(x)
pmodel (x))
(18.36)
=(logpmodel (x) logpnoise(x)): (18.37)
因此，只要 log~pmodel易于反向传播 ，并且如上所述， pnoise应易于估计（以便
评估 pjoint）和采样（以生成训练数据） ，那么 NCE就易于使用。
NCE能够非常成功地应用于 随机变量 较少的问题，但即使 随机变量 有很多可以
取的值时，它也很有效。例如，它已经成功地应用于给定单词上下文建模单词的条
件分布 (Mnih and Kavukcuoglu ,2013)。虽然单词可以采样自一个很大的词汇表，但
是只能采样一个单词。
当NCE应用于具有许多 随机变量 的问题时，其效率会变得较低。当 逻辑回归 分
类器发现某个变量的取值不大可能时，它会拒绝这个 噪声样本。这意味着在 pmodel
学习了基本的边缘统计之后，学习进程会大大减慢。想象一个使用非结构化高斯 噪
声作为 pnoise来学习面部图像的模型。如果 pmodel学会了眼睛，就算没有学习任何
其他面部特征，比如嘴，它也会拒绝几乎所有的非结构化 噪声样本。
噪声分布 pnoise必须是易于估计和采样的约束可能是过于严格的限制。当 pnoise
比较简单时，大多数采样可能与数据有着明显不同，而不会迫使 pmodel进行显著改
进。
类似于得分匹配 和伪似然，如果 ~p只有下界，那么 NCE不会有效。这样的下界
能够用于构建 pjoint(y= 1jx)的下界，但是它只能用于构建 pjoint(y= 0jx)（出现DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
530 第十八章 直面配分函数
在一半的 NCE对象中）的上界。同样地， pnoise的下界也没有用，因为它只提供了
pjoint(y= 1jx)的上界。
在每个梯度步骤之前，模型分布被复制来定义新的 噪声分布 时，NCE定义了一
个被称为 自对比估计 （self-contrastive estimation ）的过程，其梯度期望等价于最大
似然的梯度期望 (Goodfellow ,2014)。特殊情况的 NCE（噪声采样由模型生成）表
明最大似然可以被解释为使模型不断学习以将现实与自身发展的信念区分的过程，
而噪声对比估计 通过让模型区分现实和固定的基准（ 噪声模型） ，我们降低了计算成
本。
在训练样本和生成样本（使用模型能量函数定义分类器）之间进行分类以得
到模型的梯度的方法，已经在更早的时候以各种形式提出来 (Welling et al. ,2003b ;
Bengio ,2009)。
噪声对比估计 是基于良好 生成模型 应该能够区分数据和 噪声的想法。一个密切
相关的想法是，良好的 生成模型 能够生成分类器无法将其与数据区分的样本。这个
想法诞生了 生成式对抗网络 （第 20.10.4节） 。
18.7估计配分函数
尽管本章中的大部分内容都在避免计算与 无向图模型 相关的难以计算的 配分函
数Z()，但在本节中我们将会讨论几种直接估计 配分函数 的方法。
估计配分函数 可能会很重要，当我们希望计算数据的归一化似然时，我们会需
要它。在 评估模型，监控训练性能，和比较模型时，这通常是很重要的。
例如，假设我们有两个模型： 概率分布 为pA(x;A) =1
ZA~pA(x;A)的模型MA
和概率分布 为pB(x;B) =1
ZB~pB(x;B)的模型MB。比较模型的常用方法是评估
和比较两个模型分配给 独立同分布 测试数据集的似然。假设测试集含 m个样本
fx(1); : : : ; x(m)g。如果∏
ipA(x(i);A)>∏
ipB(x(i);B)，或等价地，如果
∑
ilogpA(x(i);A) ∑
ilogpB(x(i);B)>0; (18.38)
那么我们说MA是一个比MB更好的模型（或者，至少可以说，它在测试集上是
一个更好的模型） ，这是指它有一个更好的测试对数似然。不幸的是，测试这个条件
是否成立需要知道 配分函数 。式 (18.38 )看起来需要估计模型分配给每个点的对数概
率，因而需要估计 配分函数 。我们可以通过将式 (18.38 )重新转化为另一种形式来简DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.7估计配分函数 531
化情况，在该形式中我们只需要知道两个模型的 配分函数 的比率：
∑
ilogpA(x(i);A) ∑
ilogpB(x(i);B) =∑
i(
log~pA(x(i);A)
~pB(x(i);B))
 mlogZ(A)
Z(B):
(18.39)
因此，我们可以在不知道任一模型的 配分函数 ，而只知道它们比率的情况下，判断
模型MA是否比模型MB更优。正如我们将很快看到的，在两个模型相似的情况
下，我们可以使用 重要采样 来估计比率。
然而，如果我们想要计算测试数据在 MA或MB上的真实概率，我们需要计
算配分函数 的真实值。如果我们知道两个 配分函数 的比率， r=Z(B)
Z(A)，并且我们知
道两者中一个的实际值，比如说 Z(A)，那么我们可以计算另一个的值：
Z(B) =rZ(A) =Z(B)
Z(A)Z(A): (18.40)
一种估计 配分函数 的简单方法是使用 蒙特卡罗 方法，例如简单 重要采样 。以下
用连续变量积分来表示该方法，也可以替换积分为求和，很容易将其应用到离散变
量的情况。我们使用 提议分布 p0(x) =1
Z0~p0(x)，其在配分函数 Z0和未归一化分布
~p0(x)上易于采样和估计。
Z1=∫
~p1(x)dx (18.41)
=∫p0(x)
p0(x)~p1(x)dx (18.42)
=Z0∫
p0(x)~p1(x)
~p0(x)dx (18.43)
^Z1=Z0
KK∑
k=1~p1(x(k))
~p0(x(k))s.t.:x(k)p0 (18.44)
在最后一行，我们使用 蒙特卡罗 估计，使用从 p0(x)中抽取的采样计算积分 ^Z1，
然后用未归一化的 ~p1和提议分布 p0的比率对每个采样加权。
这种方法使得我们可以估计 配分函数 之间的比率：
1
KK∑
k=1~p1(x(k))
~p0(x(k))s.t.:x(k)p0: (18.45)
然后该值可以直接比较式 (18.39 )中的两个模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
532 第十八章 直面配分函数
如果分布 p0接近 p1，那么式 (18.44 )能够有效地估计 配分函数 (Minka ,2005)。
不幸的是，大多数时候 p1都很复杂（通常是 多峰值的） ，并且定义在高维空间中。
很难找到一个易求解的 p0，既能易于评估，又能充分接近 p1以保持高质量的近似。
如果 p0和p1不接近，那么 p0的大多数采样将在 p1中具有较低的概率，从而在
式(18.44 )的求和中产生（相对的）可忽略的贡献。
如果求和中只有少数几个具有显著权重的样本，那么将会由于高方差而导致估
计的效果很差。这可以通过估计 ^Z1的方差来定量地理解：
^Var(
^Z1)
=Z0
K2K∑
k=1(~p1(x(k))
~p0(x(k)) ^Z1)2
: (18.46)
当重要性权重~p1(x(k))
~p0(x(k))存在显著偏差时，上式的值是最大的。
我们现在关注两个解决高维空间复杂分布上估计 配分函数 的方法： 退火重要采
样和桥式采样 。两者都始于上面介绍的简单 重要采样 方法，并且都试图通过引入 缩
小p0和p1之间差距的中间分布，来解决 p0远离 p1的问题。
18.7.1 退火重要采样
在DKL(p0∥p1)很大的情况下（即 p0和p1之间几乎没有重叠） ，一种称为 退火
重要采样 （annealed importance sampling ，AIS）的方法试图通过引入中间分
布来缩小这种差距 (Jarzynski ,1997;Neal,2001)。考虑分布序列 p0; : : : ; p n，其中
0 =0<  1<< n 1< n= 1，分布序列中的第一个和最后一个分别是 p0和
p1。
这种方法使我们能够估计定义在高维空间多峰分布（例如训练 RBM时定义
的分布）上的 配分函数 。我们从一个已知 配分函数 的简单模型（例如，权重为零
的RBM）开始，估计两个模型 配分函数 之间的比率。该比率的估计基于许多个相似
分布的比率估计，例如在零和学习到的权重之间插值一组权重不同的 RBM。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.7估计配分函数 533
现在我们可以将比率Z1
Z0写作
Z1
Z0=Z1
Z0Z1
Z1: : :Zn 1
Zn 1(18.47)
=Z1
Z0Z2
Z1: : :Zn 1
Zn 2Z1
Zn 1(18.48)
=n 1∏
j=0Zj+1
Zj: (18.49)
如果对于所有的 0jn 1，分布 pj和pj+1足够接近，那么我们能够使用简
单的重要采样 来估计每个因子Zj+1
Zj，然后使用这些得到Z1
Z0的估计。
这些中间分布是从哪里来的呢？正如最先的 提议分布 p0是一种设计选择，分布
序列 p1: : : p n 1也是如此。也就是说，它们可以被特别设计为特定的问题领域。中
间分布的一个通用和流行选择是使用目标分布 p1的加权几何平均，起始分布（其 配
分函数是已知的）为 p0：
pj/pj
1p1 j
0: (18.50)
为了从这些中间分布中采样，我们定义了一组 马尔可夫链 转移函数 Tj(x′jx)，
定义了给定 x转移到 x′的条件概率分布 。转移算子 Tj(x′jx)定义如下，保持
pj(x)不变：
pj(x) =∫
pj(x′)Tj(xjx′)dx′: (18.51)
这些转移可以被构造为任何 马尔可夫链蒙特卡罗 方法（例如， Metropolis-Hastings ，
Gibbs） ，包括涉及多次遍历所有 随机变量 或其他迭代的方法。
然后， AIS采样方法从 p0开始生成样本，并使用转移算子从中间分布顺序地生
成采样，直到我们得到目标分布 p1的采样：
•对于 k= 1: : : K
–采样 x(k)
1p0(x)
–采样 x(k)
2T1(x(k)
2jx(k)
1)
–: : :
–采样 x(k)
n 1Tn 2(x(k)
n 1jx(k)
n 2)
–采样 x(k)
nTn 1(x(k)
njx(k)
n 1)
•结束DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
534 第十八章 直面配分函数
对于采样 k，通过连接式 (18.49 )给出的中间分布之间的重要性权重，我们可以
导出目标重要性权重：
w(k)=~p1(x(k)
1)
~p0(x(k)
1)~p2(x(k)
2)
~p1(x(k)
2): : :~p1(x(k)
1)
~pn 1(x(k)
n): (18.52)
为了避免诸如 上溢的数值问题，最佳方法可能是通过加法或减法计算 logw(k)，而不
是通过概率乘法和除法计算 w(k)。
利用由此定义的采样过程和式 (18.52 )中给出的重要性权重， 配分函数 的比率估
计如下所示：
Z1
Z01
KK∑
k=1w(k)(18.53)
为了验证该过程定义的 重要采样 方案是否有效，我们可以展示 (Neal,
2001)AIS过程对应着扩展状态空间上的简单 重要采样 ，其中数据点采样自乘
积空间 [x1; : : : ; xn 1;x1]。为此，我们将扩展空间上的分布定义为
~p(x1; : : : ; xn 1;x1) (18.54)
=~p1(x1)~Tn 1(xn 1jx1)~Tn 2(xn 2jxn 1): : :~T1(x1jx2); (18.55)
其中 ~Ta是由 Ta定义的转移算子的逆（应用 贝叶斯规则 ） ：
~Ta(x′jx) =pa(x′)
pa(x)Ta(xjx′) =~pa(x′)
~pa(x)Ta(xjx′): (18.56)
将以上代入到式 (18.55 )给出的扩展状态空间上的联合分布中，我们得到：
~p(x1; : : : ; xn 1;x1) (18.57)
=~p1(x1)~pn 1(xn 1)
~pn 1(x1)Tn 1(x1jxn 1)n 2∏
i=1~pi(xi)
~pi(xi+1)Ti(xi+1jxi) (18.58)
=~p1(x1)
~pn 1(x1)Tn 1(x1jxn 1)~p1(x1)n 2∏
i=1~pi+1(xi+1)
~pi(xi+1)Ti(xi+1jxi): (18.59)
通过上面给定的采样方案，现在我们可以从扩展样本上的联合 提议分布 q上生成采
样，联合分布如下
q(x1; : : : ; xn 1;x1) =p0(x1)T1(x2jx1): : : T n 1(x1jxn 1): (18.60)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
18.7估计配分函数 535
式(18.59 )给出了扩展空间上的联合分布。将 q(x1; : : : ; xn 1;x1)作为扩展状态空间
上的提议分布 （我们会从中抽样） ，重要性权重如下
w(k)=~p(x1; : : : ; xn 1;x1)
q(x1; : : : ; xn 1;x1)=~p1(x(k)
1)
~pn 1(x(k)
n 1): : :~p2(x(k)
2)
~p1(x(k)
1)~p1(x(k)
1)
~p0(x(k)
0): (18.61)
这些权重和 AIS上的权重相同。因此，我们可以将 AIS解释为应用于扩展状态上的
简单重要采样 ，其有效性直接来源于 重要采样 的有效性。
退火重要采样 首先由 Jarzynski (1997)发现，然后由 Neal (2001)再次独立发现。
目前它是估计无向概率模型的 配分函数 的最常用方法。其原因可能与一篇有影响力
的论文 (Salakhutdinov and Murray ,2008)有关，该论文并没有讨论该方法相对于其
他方法的优点，而是介绍了将其应用于估计 受限玻尔兹曼机 和深度信念网络 的配分
函数。
关于 AIS估计性质（例如，方差和效率）的讨论，请参看 Neal (2001)。
18.7.2 桥式采样
类似于 AIS，桥式采样 (Bennett ,1976)是另一种处理 重要采样 缺点的方法。并
非将一系列中间分布连接在一起， 桥式采样 依赖于单个分布 p（被称为桥） ，在已
知配分函数 的分布 p0和分布 p1（我们试图估计其 配分函数 Z1）之间插值。
桥式采样 估计比率 Z1/Z0：~p0和~p之间重要性权重期望与 ~p1和~p之间重要
性权重的比率，
Z1
Z0K∑
k=1~p(x(k)
0)
~p0(x(k)
0)/K∑
k=1~p(x(k)
1)
~p1(x(k)
1): (18.62)
如果仔细选择 桥式采样 p，使其与 p0和p1都有很大重合的话，那么 桥式采样 能够
允许两个分布（或更正式地， DKL(p0∥p1)）之间有较大差距（相对标准 重要采样 而
言） 。
可以表明，最优的 桥式采样 是p(opt)
(x)/~p0(x)~p1(x)
r~p0(x)+~p1(x)，其中 r=Z1/Z0。这似乎
是一个不可行的解决方案，因为它似乎需要我们估计数值 Z1/Z0。然而，可以从粗
糙的 r开始估计，然后使用得到的 桥式采样 逐步迭代以改进估计 (Neal,2005)。也就
是说，我们会迭代地重新估计比率，并使用每次迭代更新 r的值。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
536 第十八章 直面配分函数
链接重要采样 AIS和桥式采样 各有优点。如果 DKL(p0∥p1)不太大（由于 p0和p1
足够接近）的话，那么 桥式采样 能比 AIS更高效地估计 配分函数 比率。然而，如果
对于单个分布 p而言，两个分布相距太远难以桥接差距，那么 AIS至少可以使用许
多潜在中间分布来跨越 p0和p1之间的差距。 Neal (2005)展示链接重要采样 方法如
何利用桥式采样 的优点，桥接 AIS中使用的中间分布，并且显著改进了整个 配分函
数的估计。
在训练期间估计 配分函数 虽然 AIS已经被认为是用于估计许多无向模型 配分函
数的标准方法，但是它在计算上代价很高，以致其在训练期间仍然不很实用。研究
者探索了一些在训练过程中估计 配分函数 的替代方法。
使用桥式采样 、短链 AIS和并行回火 的组合， Desjardins et al. (2011)设计了一
种在训练过程中追踪 RBM配分函数 的方法。该策略的基础是，在 并行回火 方法操作
的每个温度下， RBM配分函数 的独立估计会一直保持。作者将相邻链（来自 并行回
火）的配分函数 比率的桥式采样 估计和跨越时间的 AIS估计组合起来，提出一个在
每次迭代学习时估计 配分函数 的（且方差较小的）方法。
本章中描述的工具提供了许多不同的方法，以解决难处理的 配分函数 问题，但
是在训练和使用 生成模型 时，可能会存在一些其他问题。其中最重要的是我们接下
来会遇到的难以推断的问题。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第十九章 近似推断
许多概率模型很难训练的原因是很难进行推断。在 深度学习 中，通常我们有一
系列可见变量 v和一系列 潜变量 h。推断困难通常是指难以计算 p(hjv)或其期望。
而这样的操作在一些诸如最大似然学习的任务中往往是必需的。
许多仅含一个 隐藏层的简单图模型会定义成易于计算 p(hjv)或其期望的形式，
例如受限玻尔兹曼机 和概率 PCA。不幸的是，大多数具有多层 隐藏变量 的图模型的
后验分布都很难处理。对于这些模型而言，精确推断算法需要指数量级的运行时间。
即使一些只有单层的模型，如 稀疏编码 ，也存在着这样的问题。
在本章中，我们将会介绍几个用来解决这些难以处理的推断问题的技巧。稍后，
在第二十章中，我们还将描述如何将这些技巧应用到训练其他方法难以奏效的概率
模型中，如 深度信念网络 、深度玻尔兹曼机 。
在深度学习 中难以处理的推断问题通常源于结构化图模型中 潜变量之间的相互
作用。读者可以参考图 19.1的几个例子。这些相互作用可能是 无向模型 的直接相互
作用，也可能是 有向模型 中同一个可见变量的共同祖先之间的 “相消解释 ’’作用。
537DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
538 第十九章 近似推断
图19.1:深度学习 中难以处理的推断问题通常是由于结构化图模型中 潜变量的相互作用。这些
相互作用产生于一个 潜变量与另一个 潜变量或者当 V-结构的子节点可观察时与更长的激活路径
相连。 (左)一个隐藏单元 存在连接的 半受限波尔兹曼机 （semi-restricted Boltzmann Machine ）
(Osindero and Hinton ,2008)。由于存在大量 潜变量的团，潜变量的直接连接使得后验分布难以处
理。(中)一个深度玻尔兹曼机 ，被分层从而使得不存在层内连接，由于层之间的连接其后验分布仍
然难以处理。 (右)当可见变量可观察时这个有向模型的 潜变量之间存在相互作用，因为每两个 潜
变量都是共父。即使拥有上图中的某一种结构，一些概率模型依然能够获得易于处理的关于 潜变
量的后验分布。如果我们选择条件概率分布来引入相对于图结构描述的额外的独立性这种情况也
是可能出现的。举个例子， 概率 PCA的图结构如右图所示，然而由于其条件分布的特殊性质（带
有相互正交基向量的线性高斯条件分布）依然能够进行简单的推断。
19.1把推断视作优化问题
精确推断问题可以描述为一个优化问题，有许多方法正是由此解决了推断的困
难。通过近似这样一个潜在的优化问题，我们往往可以推导出 近似推断 算法。
为了构造这样一个优化问题，假设我们有一个包含可见变量 v和潜变量 h的概
率模型。我们希望计算观察数据的对数概率 logp(v;)。有时候如果边缘化消去 h的
操作很费时，我们会难以计算 logp(v;)。作为替代，我们可以计算一个 logp(v;)
的下界L(v;; q)。这个下界被称为 证据下界 （evidence lower bound ,ELBO） 。这个
下界的另一个常用名称是负 变分自由能 （variational free energy ） 。具体地，这个 证
据下界是这样定义的：
L(v;; q) = logp(v;) DKL(q(hjv)∥p(hjv;)); (19.1)
其中 q是关于 h的一个任意概率分布。
因为 logp(v)和L(v;; q)之间的距离是由 KL散度来衡量的，且 KL散度总是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.1把推断视作优化问题 539
非负的，我们可以发现 L总是小于等于所求的对数概率。当且仅当分布 q完全相等
于p(hjv)时取到等号。
令人吃惊的是，对于某些分布 q，计算L可以变得相当简单。通过简单的代数
运算我们可以把L重写成一个更加简单的形式：
L(v;; q) = logp(v;) DKL(q(hjv)∥p(hjv;)) (19.2)
=logp(v;) Ehqlogq(hjv)
p(hjv)(19.3)
=logp(v;) Ehqlogq(hjv)
p(h;v;)
p(v;)(19.4)
=logp(v;) Ehq[logq(hjv) logp(h;v;) + logp(v;)] (19.5)
= Ehq[logq(hjv) logp(h;v;)]: (19.6)
这也给出了 证据下界 的标准定义：
L(v;; q) =Ehq[logp(h;v)] +H(q): (19.7)
对于一个较好的分布 q的选择来说，L是容易计算的。对任意分布 q的选择来
说，L提供了似然函数的一个下界。越好地近似 p(hjv)的分布 q(hjv)，得到的下
界就越紧，换言之，就是与 logp(v)更加接近。当 q(hjv) =p(hjv)时，这个近似
是完美的，也意味着 L(v;; q) = logp(v;)。
因此我们可以将推断问题看作是找一个分布 q使得L最大的过程。精确推断能
够在包含分布 p(hjv)的函数族中搜索一个函数，完美地最大化 L。在本章中，我们
将会讲到如何通过近似优化寻找分布 q的方法来推导出不同形式的 近似推断 。我们
可以通过限定分布 q的形式或者使用并不彻底的优化方法来使得优化的过程更加高
效（却更粗略） ，但是优化的结果是不完美的，不求彻底地最大化 L，而只要显著地
提升L。
无论我们选择什么样的分布 q，L始终是一个下界。我们可以通过选择一个更简
单抑或更复杂的计算过程来得到对应的更松抑或更紧的下界。通过一个不彻底的优
化过程或者将分布 q做很强的限定（并且使用一个彻底的优化过程）我们可以获得
一个很差的分布 q，但是降低了计算开销。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
540 第十九章 近似推断
19.2期望最大化
我们介绍的第一个最大化下界 L的算法是 期望最大化 （expectation maximiza-
tion,EM）算法。在 潜变量模型中，这是一个非常常见的训练算法。在这里我们描
述Neal and Hinton (1999)所提出的 EM算法。与大多数我们在本章中介绍的其他
算法不同的是， EM并不是一个 近似推断 算法，而是一种能够学到近似后验的算法。
EM算法由交替迭代，直到收敛的两步运算组成：
•E步（expectation step ）:令(0)表示在这一步开始时的参数值。对任何我们
想要训练的（对所有的或者 小批量数据均成立）索引为 i的训练样本 v(i)，令
q(h(i)jv) =p(h(i)jv(i);(0))。通过这个定义，我们认为 q在当前参数(0)下
定义。如果我们改变 ，那么 p(hjv;)将会相应地变化，但是 q(hjv)还是
不变并且等于 p(hjv;(0))。
•M步（maximization step ） ：使用选择的优化算法完全地或者部分地关于 最
大化
∑
iL(v(i);; q): (19.8)
这可以被看作通过 坐标上升 算法来最大化L。在第一步中，我们更新分布 q来
最大化L，而在另一步中，我们更新 来最大化L。
基于潜变量模型的随机梯度上升 可以被看作是一个 EM算法的特例，其中 M
步包括了单次梯度操作。 EM算法的其他变种可以实现多次梯度操作。对一些模型
族来说， M步甚至可以通过推出解析解直接完成，不同于其他方法，在给定当前 q
的情况下直接求出最优解。
尽管E步采用的是精确推断，我们仍然可以将 EM算法视作是某种程度上的 近
似推断。具体地说， M步假设一个分布 q可以被所有的 值分享。当 M步越来越
远离 E步中的(0)时，这将会导致L和真实的 logp(v)之间出现差距。幸运的是，
在进入下一个循环时， E步把这种差距又降到了 0。
EM算法还包含一些不同的见解。首先，它包含了学习过程的一个基本框架，就
是我们通过更新模型参数来提高整个数据集的似然，其中缺失变量的值是通过后验
分布来估计的。这种特定的性质并不是 EM算法独有的。例如，使用 梯度下降 来最
大化对数似然函数的方法也有相同的性质。计算对数似然函数的梯度需要对 隐藏单DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.3最大后验推断和稀疏编码 541
元的后验分布求期望。 EM算法另一个关键的性质是当我们移动到另一个 时候，
我们仍然可以使用旧的分布 q。在传统 机器学习 中，这种特有的性质在推导大 M
步更新时候得到了广泛的应用。在 深度学习 中，大多数模型太过于复杂以致于在最
优大 M步更新中很难得到一个简单的解。所以 EM算法的第二个特质，更多为其所
独有，较少被使用。
19.3最大后验推断和稀疏编码
我们通常使用 推断（inference ）这个术语来指代给定一些其他变量的情况下计
算某些变量概率分布的过程。当训练带有 潜变量的概率模型时，我们通常关注于计
算p(hjv)。另一种可选的推断形式是计算一个缺失变量的最可能值来代替在所有可
能值的完整分布上的推断。在 潜变量模型中，这意味着计算
h= arg max
hp(hjv): (19.9)
这被称作 最大后验 （Maximum A Posteriori ）推断，简称 MAP推断。
MAP推断并不被视作是一种 近似推断 ，它只是精确地计算了最有可能的一个
h。然而，如果我们希望设计一个最大化 L(v;h; q)的学习过程，那么把 MAP推断
视作是输出一个 q值的学习过程是很有帮助的。在这种情况下，我们可以将 MAP推
断视作是 近似推断 ，因为它并不能提供一个最优的 q。
我们回过头来看看第 19.1节中所描述的精确推断，它指的是关于一个在无限制
的概率分布族中的分布 q使用精确的优化算法来最大化
L(v;; q) =Ehq[logp(h;v)] +H(q): (19.10)
我们通过限定分布 q属于某个分布族，能够使得 MAP推断成为一种形式的 近似推
断。具体地说，我们令分布 q满足一个 Dirac分布：
q(hjv) =(h ): (19.11)
这也意味着现在我们可以通过 来完全控制分布 q。通过将L中不随变化的项
丢弃，我们只需解决一个优化问题：
= arg max
logp(h=;v); (19.12)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
542 第十九章 近似推断
这等价于 MAP推断问题
h= arg max
hp(hjv): (19.13)
因此我们能够证明一种类似于 EM算法的学习算法，其中我们轮流迭代两步，
一步是用 MAP推断估计出 h，另一步是更新 来增大 logp(h;v)。从 EM算法角
度看，这也是对L的一种形式的 坐标上升 ，交替迭代时通过推断来优化关于 q的L
以及通过参数更新来优化关于 的L。作为一个整体，这个算法的正确性可以得到
保证，因为L是 logp(v)的下界。在 MAP推断中，这个保证是无效的，因为 Dirac
分布的熵的微分趋近于负无穷，使得这个界会无限地松。然而，人为加入一些 的
噪声会使得这个界又有了意义。
MAP推断作为 特征提取器 以及一种学习机制被广泛地应用在了 深度学习 中。它
主要用于 稀疏编码 模型中。
我们回过头来看第 13.4节中的稀疏编码 ，稀疏编码 是一种在 隐藏单元 上加上了
诱导稀疏性的先验知识的 线性因子模型 。一个常用的选择是可分解的 Laplace先验，
表示为
p(hi) =
2exp( jhij): (19.14)
可见的节点是由一个线性变化加上噪声生成的：
p(vjh) =N(v;Wh +b;  1I): (19.15)
分布 p(hjv)难以计算，甚至难以表达。每一对 hi，hj变量都是 v的母节点。
这也意味着当 v可被观察时， 图模型包含了一条连接 hi和hj的活跃路径。因此
p(hjv)中所有的 隐藏单元 都包含在了一个巨大的 团中。如果是高斯模型，那么这些
相互作用关系可以通过协方差矩阵来高效地建模。然而稀疏型先验使得这些相互作
用关系并不服从高斯分布。
分布 p(xjh)的难处理性导致了对数似然及其梯度也很难得到。因此我们不能
使用精确的 最大似然估计 来进行学习。取而代之的是，我们通过 MAP推断以及最
大化由以 h为中心的 Dirac分布所定义而成的 ELBO来学习模型参数。
如果我们将训练集中所有的向量 h拼成矩阵 H，并将所有的向量 v拼起来组成
矩阵 V，那么稀疏编码 问题意味着最小化
J(H;W) =∑
i;jjHi;jj+∑
i;j(
V HW⊤)2
i;j: (19.16)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 543
为了避免如极端小的 H和极端大的 W这样的病态的解，大多数 稀疏编码 的应用包
含了权重衰减 或者对 H列范数的限制。
我们可以通过交替迭代，分别关于 H和 W最小化 J的方式来最小化 J。两个
子问题都是凸的。事实上，关于 W的最小化问题就是一个 线性回归 问题。然而关于
这两个变量同时最小化 J的问题通常并不是凸的。
关于 H的最小化问题需要某些特别设计的算法，例如特征符号搜索方法 (Lee
et al. ,2007)。
19.4变分推断和变分学习
我们已经说明过了为什么 证据下界L(v;; q)是 logp(v;)的一个下界、如何将
推断看作是关于分布 q最大化L的过程以及如何将学习看作是关于参数 最大化L
的过程。我们也讲到了 EM算法在给定了分布 q的条件下能够进行 大学习步骤 ，而
基于 MAP推断的学习算法则是学习一个 p(hjv)的点估计而非推断整个完整的分
布。在这里我们介绍一些变分学习中更加通用的算法。
变分学习的核心思想就是我们在一个关于 q的有约束的分布族上最大化 L。选
择这个分布族时应该考虑到计算 Eqlogp(h;v)的难易度。一个典型的方法就是添加
分布 q如何分解的假设。
一种常用的变分学习的方法是加入一些限制使得 q是一个因子分布：
q(hjv) =∏
iq(hijv): (19.17)
这被称为 均值场（mean-ﬁeld ）方法。更一般地说，我们可以通过选择分布 q的形
式来选择任何 图模型的结构，通过选择变量之间的相互作用来灵活地决定近似程度
的大小。这种完全通用的 图模型方法被称为 结构化变分推断 （structured variational
inference ）(Saul and Jordan ,1996)。
变分方法的优点是我们不需要为分布 q设定一个特定的参数化形式。我们设定
它如何分解，之后通过解决优化问题来找出在这些分解限制下最优的概率分布。对
离散型潜变量来说，这意味着我们使用传统的优化技巧来优化描述分布 q的有限个
变量。对连续型 潜变量来说，这意味着我们使用一个被称为 变分法的数学分支工具
来解决函数空间上的优化问题。然后决定哪一个函数来表示分布 q。变分法是‘‘变分
学习’’或者 ‘‘变分推断 ’’这些名字的来因，尽管当 潜变量是离散时 变分法并没有用武DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
544 第十九章 近似推断
之地。当遇到连续型 潜变量时，变分法不需要过多地人工选择模型，是一种很有用
的工具。我们只需要设定分布 q如何分解，而不需要去猜测一个特定的能够精确近
似原后验分布的分布 q。
因为L(v;; q)被定义成 logp(v;) DKL(q(hjv)∥p(hjv;))，我们可以认为
关于 q最大化L的问题等价于（关于 q）最小化 DKL(q(hjv)∥p(hjv))。在这种
情况下，我们要用 q来拟合 p。然而，与以前方法不同，我们使用 KL散度的相
反方向来拟合一个近似。当我们使用 最大似然估计 来用模型拟合数据时，我们最小
化DKL(pdata∥pmodel )。如图 3.6所示，这意味着 最大似然 鼓励模型在每一个数据达
到高概率的地方达到高概率，而基于优化的推断则鼓励了 q在每一个真实后验分
布概率低的地方概率较小。这两种基于 KL散度的方法都有各自的优点与缺点。选
择哪一种方法取决于在具体每一个应用中哪一种性质更受偏好。在基于优化的推断
问题中，从计算角度考虑，我们选择使用 DKL(q(hjv)∥p(hjv))。具体地说，计算
DKL(q(hjv)∥p(hjv))涉及到了计算分布 q下的期望。所以通过将分布 q设计得较
为简单，我们可以简化求所需要的期望的计算过程。 KL散度的相反方向需要计算真
实后验分布下的期望。因为真实后验分布的形式是由模型的选择决定的，所以我们
不能设计出一种能够精确计算 DKL(p(hjv)∥q(hjv))的开销较小的方法。
19.4.1 离散型潜变量
关于离散型 潜变量的变分推断相对来说比较直接。我们定义一个分布 q，通常
分布 q的每个因子都由一些离散状态的可查询表格定义。在最简单的情况中， h
是二值的并且我们做了 均值场假定，分布 q可以根据每一个 hi分解。在这种情况
下，我们可以用一个向量 ^h来参数化分布 q，^h的每一个元素都代表一个概率，即
q(hi= 1jv) =^hi。
在确定了如何表示分布 q以后，我们只需要优化它的参数。在离散型 潜变量模
型中，这是一个标准的优化问题。基本上分布 q的选择可以通过任何优化算法解决，
比如梯度下降 算法。
因为它在许多学习算法的内循环中出现，所以这个优化问题必须可以很快求解。
为了追求速度，我们通常使用特殊设计的优化算法。这些算法通常能够在极少的循
环内解决一些小而简单的问题。一个常见的选择是使用 不动点方程 ，换句话说，就
是解关于 ^hi的方程
@
@^hiL= 0: (19.18)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 545
我们反复地更新 ^h不同的元素直到满足收敛准则。
为了具体化这些描述，我们接下来会讲如何将变分推断应用到 二值稀疏编码
（binary sparse coding ）模型（这里我们所描述的模型是 Henniges et al. (2010)提出
的，但是我们采用了传统、通用的 均值场方法，而原文作者采用了一种特殊设计的
算法）中。数学推导过程非常详细，为希望完全了解我们描述过的变分推断和变分
学习高级概念描述的读者所准备。而对于并不计划推导或者实现变分学习算法的读
者来说，可以放心跳过，直接阅读下一节，这并不会遗漏新的高级概念。建议那些
从事二值稀疏编码 研究的读者可以重新看一下第 3.10节中描述的一些经常在概率模
型中出现的有用的函数性质。我们在推导过程中随意地使用了这些性质，并没有特
别强调它们。
在二值稀疏编码 模型中，输入 v2Rn，是由模型通过添加高斯噪声到 m个或
有或无的不同成分的和而生成的。每一个成分可以是开或者关的，对应着 隐藏单
元 h2f0;1gm:
p(hi= 1) = (bi); (19.19)
p(vjh) =N(v;Wh; 1); (19.20)
其中 b是一个可以学习的 偏置集合， W是一个可以学习的权值矩阵， 是一个可以
学习的对角精度矩阵。
使用最大似然 来训练这样一个模型需要对参数进行求导。我们考虑对其中一DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
546 第十九章 近似推断
个偏置进行求导的过程：
@
@bilogp(v) (19.21)
=@
@bip(v)
p(v)(19.22)
=@
@bi∑
hp(h;v)
p(v)(19.23)
=@
@bi∑
hp(h)p(vjh)
p(v)(19.24)
=∑
hp(vjh)@
@bip(h)
p(v)(19.25)
=∑
hp(hjv)@
@bip(h)
p(h)(19.26)
=Ehp(hjv)@
@bilogp(h): (19.27)
这需要计算 p(hjv)下的期望。不幸的是， p(hjv)是一个很复杂的分布。关于
p(h;v)和p(hjv)的图结构可以参考图 19.2。隐藏单元 的后验分布对应的是关于 隐
藏单元的完全图，所以相对于暴力算法， 变量消去 算法并不能有助于提高计算期望
的效率。
h1h1h2h2h3h3v1v1v2v2v3v3h4h4h1h1h2h2h3h3h4h4
图19.2:包含四个 隐藏单元 的二值稀疏编码 的图结构。 (左)p(h;v)的图结构。要注意边是有向的，
每两个隐藏单元 都是每个可见单元的 共父。(右)p(h;v)的图结构。为了解释 共父之间的活跃路径，
后验分布所有 隐藏单元 之间都有边。
取而代之的是，我们可以应用变分推断和变分学习来解决这个难点。
我们可以做一个 均值场近似：
q(hjv) =∏
iq(hijv): (19.28)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 547
二值稀疏编码 中的潜变量是二值的，所以为了表示可分解的 q我们假设对 m
个Bernoulli 分布 q(hijv)建模。表示 Bernoulli 分布的一种很自然的方法是使用一
个概率向量 ^h，满足 q(hijv) =^hi。为了避免计算中的误差，比如说计算 log^hi时，
我们对 ^hi添加一个约束，即 ^hi不等于 0或者 1。
我们将会看到变分推断方程理论上永远不会赋予 ^hi0或者 1。然而在软件实现
过程中，机器的舍入误差会导致 0或者 1的值。在 二值稀疏编码 的软件实现中，我
们希望使用一个没有限制的变分参数向量 z以及通过关系 ^h=(z)来获得 h。因此
通过使用等式 log(zi) = ( zi)来建立 sigmoid函数和 softplus函数的关系，我们
可以放心地在计算机上计算 log^hi。
在开始二值稀疏编码 模型中变分学习的推导时，我们首先说明了 均值场近似的
使用可以使得学习过程更加简单。
证据下界 可以表示为
L(v;; q) (19.29)
=Ehq[logp(h;v)] +H(q) (19.30)
=Ehq[logp(h) + logp(vjh) logq(hjv)] (19.31)
=Ehq[m∑
i=1logp(hi) +n∑
i=1logp(vijh) m∑
i=1logq(hijv)]
(19.32)
=m∑
i=1[
^hi(log(bi) log^hi) + (1 ^hi)(log( bi) log(1 ^hi))]
(19.33)
+Ehq[n∑
i=1log√
i
2exp( i
2(vi Wi;:h)2)]
(19.34)
=m∑
i=1[
^hi(log(bi) log^hi) + (1 ^hi)(log( bi) log(1 ^hi))]
(19.35)
+1
2n∑
i=1[
logi
2 i(
v2
i 2viWi;:^h+∑
j[
W2
i;j^hj+∑
k̸=jWi;jWi;k^hj^hk])]
:
(19.36)
尽管这些方程从美学观点来看有些不尽如人意。他们展示了 L可以被表示为少量简
单的代数运算。因此 证据下界L是易于处理的。我们可以把 L看作是难以处理的对
数似然函数的一个替代。
原则上说，我们可以使用关于 v和 h的梯度上升 。这会成为一个推断和学习算DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
548 第十九章 近似推断
法的完美组合。但是，由于两个原因，我们往往不这么做。第一点，对每一个 v我们
需要存储 ^h。我们通常更加偏向于那些不需要为每一个样本都准备内存的算法。如
果我们需要为每一个样本都存储一个动态更新的向量，使得算法很难处理上亿的样
本。第二个原因就是为了能够识别 v的内容，我们希望能够有能力快速提取特征 ^h。
在实际应用场景中，我们需要在有限时间内计算出 ^h。
由于以上两个原因，我们通常不会采用 梯度下降 来计算均值场参数 ^h。取而代
之的是，我们使用 不动点方程 来快速估计。
不动点方程 的核心思想是我们寻找一个关于 h的局部极大点 ，满足
∇ hL(v;;^h) = 0。我们无法同时高效地计算所有 ^h的元素。然而，我们可以
解决单个变量的问题：
@
@^hiL(v;;^h) = 0 : (19.37)
我们可以迭代地将这个解应用到 i= 1; : : : ; m，然后重复这个循环直到我们满足
了收敛准则。常见的收敛准则包含了当整个循环所改进的 L不超过预设的 容差量时
停止，或者是循环中改变的 ^h不超过某个值时停止。
在很多不同的模型中，迭代的 均值场不动点方程 是一种能够提供快速变分推断
的通用算法。为了使它更加具体，我们详细地讲一下如何推导出 二值稀疏编码 模型
的更新过程。
首先， 我们给出了对 ^hi的导数表达式。 为了得到这个表达式， 我们将式 (19.36 )代DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 549
入到式 (19.37 )的左边：
@
@^hiL(v;;^h) (19.38)
=@
@^hi[m∑
j=1[
^hj(log(bj) log^hj) + (1 ^hj)(log( bj) log(1 ^hj))]
(19.39)
+1
2n∑
j=1[
logj
2 j(
v2
j 2vjWj;:^h+∑
k[
W2
j;k^hk+∑
l̸=kWj;kWj;l^hk^hl])]]
(19.40)
=log(bi) log^hi 1 + log(1 ^hi) + 1 log( bi) (19.41)
+n∑
j=1[
j(
vjWj;i 1
2W2
j;i ∑
k̸=iWj;kWj;i^hk)]
(19.42)
=bi log^hi+log(1 ^hi) + v⊤W:;i 1
2W⊤
:;iW:;i ∑
j̸=iW⊤
:;jW:;i^hj:(19.43)
为了应用固定点更新的推断规则，我们通过令式 (19.43 )等于 0来解 ^hi：
^hi=(
bi+v⊤W:;i 1
2W⊤
:;iW:;i ∑
j̸=iW⊤
:;jW:;i^hj)
: (19.44)
此时，我们可以发现 图模型中的推断和 循环神经网络 之间存在着紧密的联系。
具体地说， 均值场不动点方程 定义了一个 循环神经网络 。这个神经网络的任务就是
完成推断。我们已经从模型描述的角度介绍了如何推导这个网络，但是直接训练这
个推断网络也是可行的。有关这种思路的一些想法在第 二十章中有所描述。
在二值稀疏编码 模型中，我们可以发现式 (19.44 )中描述的 循环网络 连接包含
了根据相邻 隐藏单元 变化值来反复更新当前 隐藏单元 的操作。输入层通常给 隐藏单
元发送一个固定的信息 v⊤W，然而隐藏单元 不断地更新互相传送的信息。具体地
说，当 ^hi和^hj两个单元的权重向量平行时，它们会互相抑制。这也是一种形式的
竞争——两个解释输入的 隐藏单元 之间，只有一个解释得更好的才被允许继续保持
活跃。在 二值稀疏编码 的后验分布中， 均值场近似试图捕获到更多的 相消解释 相互
作用，从而产生了这种竞争。事实上， 相消解释 效应会产生一个 多峰值的后验分布，
以致于如果我们从后验分布中采样，一些样本在一个单元是活跃的，其他的样本在
另一个单元活跃，只有很少的样本能够两者都处于活跃状态。不幸的是， 相消解释 作DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
550 第十九章 近似推断
用无法通过 均值场中因子分布 q来建模，因此建模时 均值场近似只能选择一个 峰值。
这个现象的一个例子可以参考图 3.6。
我们将式 (19.44 )重写成等价的形式来揭示一些深层的含义：
^hi=(
bi+(
v ∑
j̸=iW:;j^hj)⊤
W:;i 1
2W⊤
:;iW:;i)
: (19.45)
在这种新的形式中，我们可以将 v ∑
j̸=iW:;j^hj看作是输入，而不是 v。因此，我
们可以把第 i个单元视作给定其他单元编码时给 v中的剩余误差编码。由此我们可
以将稀疏编码 视作是一个迭代的 自编码器 ，将输入反复地编码解码，试图在每一轮
迭代后都能修复重构中的误差。
在这个例子中，我们已经推导出了每一次更新单个结点的更新规则。如果能够
同时更新更多的结点，那会更令人满意。某些 图模型，比如深度玻尔兹曼机 ，我们
可以同时解出 ^h中的许多元素。不幸的是， 二值稀疏编码 并不适用这种块更新。取
而代之的是，我们使用一种被称为 衰减（damping ）的启发式技巧来实现块更新。
在衰减方法中，对 ^h中的每一个元素我们都可以解出最优值，然后对于所有的值都
在这个方向上移动一小步。这个方法不能保证每一步都能增加 L，但是对于许多模
型都很有效。关于在 信息传输 算法中如何选择同步程度以及使用 衰减策略可以参考
Koller and Friedman (2009)。
19.4.2 变分法
在继续介绍变分学习之前，我们有必要简单地介绍一种变分学习中重要的数学
工具：变分法（calculus of variations ） 。
许多机器学习 的技巧是基于寻找一个输入向量 2Rn来最小化函数 J()，
使得它取到最小值。这个步骤可以利用多元微积分以及线性代数的知识找到满足
∇J() = 0的临界点来完成。在某些情况下，我们希望能够解一个函数 f(x)，比如
当我们希望找到一些随机变量的 概率密度函数 时。正是 变分法能够让我们完成这个
目标。
函数 f的函数被称为 泛函（functional ）J[f]。正如我们许多情况下对一个函
数求关于以向量的元素为变量的 偏导数一样，我们可以使用 泛函导数 （functional
derivative ） ，即在任意特定的 x值，对一个 泛函 J[f]求关于函数 f(x)的导数，这
也被称为 变分导数 （variational derivative ） 。泛函 J的关于函数 f在点 x处的泛函DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 551
导数被记作
f(x)J。
完整正式的 泛函导数 的推导不在本书的范围之内。对于我们的目标而言，了解
可微分函数 f(x)以及带有连续导数的可微分函数 g(y;x)就足够了：

f(x)∫
g(f(x);x)dx=@
@yg(f(x);x): (19.46)
为了使上述等式更加直观，我们可以把 f(x)看作是一个有着无穷不可数多元素的向
量，由一个实数向量 x表示。在这里（看作是一个不完全的介绍） ，这种关系式中描
述的泛函导数 和向量2Rn的导数相同：
@
@i∑
jg(j; j) =@
@ig(i; i): (19.47)
在其他机器学习 文献中的许多结果则使用了更为通用的 欧拉-拉格朗日方程 （Euler-
Lagrange Equation ） ，它能够使得 g不仅依赖于 f的导数而且也依赖于 f的值。但
是在本书中我们不需要这个通用版本。
为了关于一个向量优化某个函数，我们求出了这个函数关于这个向量的梯度，
然后找这个梯度中每一个元素都为 0的点。类似地，我们可以通过寻找一个函数使
得泛函导数 的每个点都等于 0从而来优化一个 泛函。
下面介绍一个该过程如何运行的例子，我们考虑寻找一个定义在 x2R上的有
最大微分熵的概率密度函数 。我们回过头来看一下一个概率分布 p(x)的熵，定义如
下：
H[p] = Exlogp(x): (19.48)
对于连续的值，这个期望可以被看作一个积分：
H[p] = ∫
p(x)logp(x)dx: (19.49)
我们不能简单地仅仅关于函数 p(x)最大化 H[p]，因为那样的话结果可能不是一
个概率分布。为了解决这个问题，我们需要使用一个 拉格朗日乘子 来添加一个分布
p(x)积分值为 1的约束。同样地，当方差增大时，熵也会无限制地增加。因此，寻
找哪一个分布有最大熵这个问题是没有意义的。但是，在给定固定的方差 2时，我
们可以寻找一个最大熵的分布。最后，这个问题还是 欠定的，因为在不改变熵的条
件下一个分布可以被随意地改变。为了获得一个唯一的解，我们再加一个约束：分DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
552 第十九章 近似推断
布的均值必须为 。那么这个问题的拉格朗日 泛函如下：
L[p] =1(∫
p(x)dx 1)
+2(E[x] ) +3(E[(x )2] 2) +H[p](19.50)
=∫(
1p(x) +2p(x)x+3p(x)(x )2 p(x)logp(x))
dx 1 2 23:
(19.51)
为了关于 p最小化拉格朗日乘子 ，我们令 泛函导数 等于 0：
8x;
p(x)L=1+2x+3(x )2 1 logp(x) = 0 : (19.52)
这个条件告诉我们 p(x)的泛函形式。通过代数运算重组上述方程，我们可以得
到
p(x) = exp(
1+2x+3(x )2 1)
: (19.53)
我们并没有直接假设 p(x)取这种形式，而是通过最小化 泛函从理论上得到了这
个p(x)的表达式。为了解决这个最小化问题，我们需要选择 的值来确保所有的约
束都能够满足。我们有很大的自由去选择 。因为只要满足约束，拉格朗日关于 这
个变量的梯度就为 0。为了满足所有的约束，我们可以令 1= 1 logp
2,2= 0,
3= 1
22，从而得到
p(x) =N(x;; 2): (19.54)
这也是当我们不知道真实的分布时总是使用 正态分布 的一个原因。因为 正态分布 拥
有最大的熵，我们通过这个假定来保证了最小可能量的结构。
当寻找熵的拉格朗日 泛函的临界点并且给定一个固定的方差时，我们只能找到
一个对应最大熵的 临界点。那最小化熵的 概率密度函数 是什么样的呢？为什么我们
无法发现对应着 极小点的第二个 临界点呢？原因是没有一个特定的函数能够达到最
小的熵值。当函数把越多的概率密度加到 x=+和x= 两个点上，越少的
概率密度到其他点上时，它们的熵值会减少，而方差却不变。然而任何把所有的权
重都放在这两点的函数的积分都不为 1，不是一个有效的概率分布。所以不存在一
个最小熵的 概率密度函数 ，就像不存在一个最小的正实数一样。然而，我们发现存
在一个收敛的概率分布的序列，收敛到权重都在两个点上。这种情况能够退化为混
合Dirac分布。因为 Dirac分布并不是一个单独的 概率密度函数 ，所以 Dirac分布或DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.4变分推断和变分学习 553
者混合 Dirac分布并不能对应函数空间的一个点。所以对我们来说，当寻找一个 泛
函导数为0的函数空间的点时，这些分布是不可见的。这就是这种方法的局限之处。
诸如 Dirac分布这样的分布可以通过其他方法被找到，比如可以先猜测一个解，然后
证明它是满足条件的。
19.4.3 连续型潜变量
当我们的 图模型包含连续型 潜变量时，我们仍然可以通过最大化 L进行变分推
断和变分学习。然而，我们需要使用 变分法来实现关于 q(hjv)最大化L。
在大多数情况下，研究者并不需要解决任何 变分法的问题。取而代之的是， 均
值场固定点迭代更新有一个通用的方程。如果我们做了 均值场近似：
q(hjv) =∏
iq(hijv); (19.55)
并且对任何的 j̸=i固定 q(hjjv)，那么只需要满足分布 p中任何联合分布变量的
概率值不为 0，我们就可以通过归一化下面这个未归一的分布
~q(hijv) = exp(
Eh iq(h ijv)log~p(v;h))
(19.56)
来得到最优的 q(hijv)。在这个方程中计算期望就能得到正确的 q(hijv)的表达式。
我们只有在希望提出一种新形式的变分学习算法时才需要使用 变分法来直接推导 q
的函数形式。式 (19.56 )给出了适用于任何概率模型的 均值场近似。
式(19.56 )是一个不动点方程 ，对每一个 i它都被迭代地反复使用直到收敛。然
而，它还包含着更多的信息。它还包含了最优解取到的 泛函形式，无论我们是否能
够通过不动点方程 来解出它。这意味着我们可以利用方程中的 泛函形式，把其中一
些值当成参数，然后通过任何我们想用的优化算法来解决这个问题。
我们拿一个简单的概率模型作为例子，其中 潜变量满足 h2R2，可见变量只有
一个 v。假设 p(h) =N(h; 0;I)以及 p(vjh) =N(v;w⊤h; 1)，我们可以积掉 h来简
化这个模型，结果是关于 v的高斯分布 。这个模型本身并不有趣。只是为了说明 变
分法如何应用在概率建模之中，我们才构造了这个模型。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
554 第十九章 近似推断
忽略归一化常数时，真实的后验分布如下：
p(hjv) (19.57)
/p(h;v) (19.58)
=p(h1)p(h2)p(vjh) (19.59)
/exp(
 1
2[h2
1+h2
2+ (v h1w1 h2w2)2])
(19.60)
=exp(
 1
2[h2
1+h2
2+v2+h2
1w2
1+h2
2w2
2 2vh1w1 2vh2w2+ 2h1w1h2w2])
:
(19.61)
在上式中，我们发现由于带有 h1; h2乘积项的存在，真实的后验并不能关于 h1; h2
分解。
应用式 (19.56 )，我们可以得到
~q(h1jv) (19.62)
=exp(
Eh2q(h2jv)log~p(v;h))
(19.63)
=exp(
 1
2Eh2q(h2jv)[h2
1+h2
2+v2+h2
1w2
1+h2
2w2
2 (19.64)
 2vh1w1 2vh2w2+ 2h1w1h2w2])
: (19.65)
从这里，我们可以发现其中我们只需要从 q(h2jv)中获得两个有效值： Eh2q(hjv)[h2]
和Eh2q(hjv)[h2
2]。把这两项记作⟨h2⟩和⟨h2
2⟩，我们可以得到：
~q(h1jv) = exp( 1
2[h2
1+⟨h2
2⟩+v2+h2
1w2
1+⟨h2
2⟩w2
2 (19.66)
 2vh1w1 2v⟨h2⟩w2+ 2h1w1⟨h2⟩w2]): (19.67)
从这里，我们可以发现 ~q的泛函形式满足 高斯分布 。因此，我们可以得到
q(hjv) =N(h;; 1)，其中和对角的是变分参数，我们可以使用任何方法
来优化它。有必要再强调一下，我们并没有假设 q是一个高斯分布 ，这个高斯的形
式是使用 变分法来关于分布 q最大化L而推导出来的。在不同的模型上应用相同的
方法可能会得到不同 泛函形式的分布 q。
当然，上述模型只是为了说明情况的一个简单例子。 深度学习 中关于变分学习
中连续型变量的实际应用可以参考 Goodfellow et al. (2013f )。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.5学成近似推断 555
19.4.4 学习和推断之间的相互作用
在学习算法中使用 近似推断 会影响学习的过程，反过来学习的过程也会影响推
断算法的准确性。
具体来说，训练算法倾向于朝使得 近似推断 算法中的近似假设变得更加真实的
方向来适应模型。当训练参数时，变分学习增加
Ehqlogp(v;h): (19.68)
对于一个特定的 v，对于 q(hjv)中概率很大的 h它增加了 p(hjv)；对于 q(hjv)
中概率很小的 h它减小了 p(hjv)。
这种行为使得我们做的近似假设变得合理。如果我们用 单峰值近似后验来训练
模型，那么所得具有真实后验的模型会比我们使用精确推断训练模型获得的模型更
接近单峰值。
因此，估计变分近似对模型的破坏程度是很困难的。存在几种估计 logp(v)的方
式。通常我们在训练模型之后估计 logp(v;)，然后发现它和L(v;; q)的差距是很
小的。从这里我们可以得出结论，对于特定的从学习过程中获得的 来说，变分近似
是很准确的。然而我们无法直接得到变分近似普遍很准确或者变分近似几乎不会对
学习过程产生任何负面影响这样的结论。为了准确衡量变分近似带来的危害，我们
需要知道= maxlogp(v;)。L(v;; q) logp(v;)和 logp(v;)≪ logp(v;)
同时成立是有可能的。如果存在 max qL(v;; q)≪ logp(v;)，即在点处后验
分布太过复杂使得 q分布族无法准确描述，那么学习过程永远无法到达 。这样的
一类问题是很难发现的，因为只有在我们有一个能够找到 的超级学习算法时，才
能确定地进行上述的比较。
19.5学成近似推断
我们已经看到了推断可以被视作一个增加函数 L值的优化过程。显式地通
过迭代方法（比如 不动点方程 或者基于梯度的优化算法）来进行优化的过程通常
是代价很高且耗时巨大的。通过学习一个近似推断，许多推断算法避免了这种
代价。具体地说，我们可以将优化过程视作将一个输入 v投影到一个近似分布
q= arg max qL(v; q)的一个函数 f。一旦我们将多步的迭代优化过程看作是一个函
数，我们可以用一个近似函数为 ^f(v;)的神经网络 来近似它。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
556 第十九章 近似推断
19.5.1 醒眠算法
训练一个可以用 v来推断 h的模型的一个主要难点在于我们没有一个 监督训
练集来训练模型。给定一个 v，我们无法获知一个合适的 h。从 v到 h的映射依赖
于模型族的选择，并且在学习过程中随着 的改变而变化。 醒眠（wake sleep ）算
法(Hinton et al. ,1995b ;Frey et al. ,1996)通过从模型分布中抽取 v和 h的样本来
解决这个问题。例如，在 有向模型 中，这可以通过执行从 h开始并在 v结束的原始
采样来高效地完成。然后这个推断网络可以被训练来执行反向的映射：预测哪一个
h产生了当前的 v。这种方法的主要缺点是我们将只能在那些在当前模型上有较高概
率的 v值上训练推断网络。在学习早期，模型分布与数据分布偏差较大，因此推断
网络将不具有在类似数据的样本上学习的机会。
在第 18.2节中，我们看到睡眠做梦在人类和动物中作用的一个可能解释是，做
梦可以提供 蒙特卡罗 训练算法用于近似 无向模型 中对数配分函数 负梯度的 负相样本。
生物做梦的另一个可能解释是它提供来自 p(h;v)的样本，这可以用于训练推断网络
在给定 v的情况下预测 h。在某些意义上，这种解释比 配分函数 的解释更令人满意。
如果蒙特卡罗 算法仅使用梯度的 正相运行几个步骤，然后仅对梯度的 负相运行几个
步骤，那么结果通常不会很好。人类和动物通常连续清醒几个小时，然后连续睡着
几个小时。这个时间表如何支持 无向模型 的蒙特卡罗 训练尚不清楚。然而，基于最
大化L的学习算法可以通过长时间调整改进 q和长期调整来实现。如果生物做梦
的作用是训练网络来预测 q，那么这解释了动物如何能够保持清醒几个小时（它们
清醒的时间越长， L和 logp(v)之间的差距越大，但是 L仍然是下限）并且睡眠几
个小时（ 生成模型 本身在睡眠期间不被修改） ，而不损害它们的内部模型。当然，这
些想法纯粹是猜测性的，没有任何确定的证据表明做梦实现了这些目标之一。做梦
也可以通过从动物的过渡模型（用来训练动物策略）采样合成经验来服务于 强化学
习而不是概率建模。也许睡眠可以服务于一些 机器学习 社区尚未发现的其他目的。
19.5.2 学成推断的其他形式
这种学成近似推断 策略已经被应用到了其他模型中。 Salakhutdinov and
Larochelle (2010)证明了在 学成推断网络中的单遍传递相比于在 深度玻尔兹曼机 中
的迭代均值场不动点方程 能够得到更快的推断。其训练过程基于运行推断网络，然
后运行一步 均值场来改进其估计，并训练推断网络来输出这个更精细的估计以代替
其原始估计。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
19.5学成近似推断 557
我们已经在第 14.8节中看到，预测性的稀疏分解模型训练一个浅层 编码器网络，
从而预测输入的 稀疏编码 。这可以被看作是 自编码器 和稀疏编码 之间的混合。为模型
设计概率语义是可能的，其中 编码器可以被视为执行 学成近似 MAP推断。由于其浅
层的编码器，PSD不能实现我们在 均值场推断中看到的单元之间的那种竞争。然而，
该问题可以通过训练深度 编码器实现学成近似推断 来补救，如 ISTA技术 (Gregor
and LeCun ,2010b )。
近来学成近似推断 已经成为了 变分自编码器 形式的生成模型 中的主要方法之一
(Kingma and Welling ,2014a ;Rezende et al. ,2014)。在这种优美的方法中，不需要
为推断网络构造显式的目标。反之，推断网络仅仅被用来定义 L，然后调整推断网
络的参数来增大L。我们将在第 20.10.3节中详细介绍这种模型。
我们可以使用 近似推断 来训练和使用很多不同的模型。其中许多模型将在下一
章中描述。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
第二十章 深度生成模型
在本章中，我们介绍几种具体的 生成模型 ，这些模型可以使用第 十六章至第十
九章中出现的技术构建和训练。所有这些模型在某种程度上都代表了多个变量的概
率分布。有些模型允许显式地计算概率分布函数。其他模型则不允许直接评估概率
分布函数，但支持隐式获取分布知识的操作，如从分布中采样。这些模型中的一部
分使用第 十六章中的图模型语言，从图和 因子的角度描述为 结构化概率模型 。其他
的不能简单地从因子角度描述，但仍然代表概率分布。
20.1玻尔兹曼机
玻尔兹曼机 最初作为一种广义的 “联结主义 ’’引入，用来学习二值向量上的任意
概率分布 (Fahlman et al. ,1983;Ackley et al. ,1985;Hinton et al. ,1984b ;Hinton and
Sejnowski ,1986)。玻尔兹曼机 的变体（包含其他类型的变量）早已超过了原始 玻尔
兹曼机的流行程度。在本节中，我们简要介绍二值 玻尔兹曼机 并讨论训练模型和进
行推断时出现的问题。
我们在 d维二值随机向量 x2f0;1gd上定义玻尔兹曼机 。玻尔兹曼机 是一种基
于能量的模型 （第 16.2.4节） ，意味着我们可以使用 能量函数 定义联合概率分布 ：
P(x) =exp( E(x))
Z; (20.1)
其中 E(x)是能量函数 ，Z是确保∑
xP(x) = 1的配分函数 。玻尔兹曼机 的能量函
数如下给出：
E(x) = x⊤Ux b⊤x; (20.2)
其中 U是模型参数的 ‘‘权重’’矩阵， b是偏置向量。
558DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.1玻尔兹曼机 559
在一般设定下，给定一组训练样本，每个样本都是 n维的。式 (20.1)描述了观
察到的变量的 联合概率分布 。虽然这种情况显然可行，但它限制了观察到的变量和
权重矩阵描述的变量之间相互作用的类型。具体来说，这意味着一个单元的概率由
其他单元值的 线性模型 （逻辑回归 ）给出。
当不是所有变量都能被观察到时， 玻尔兹曼机 变得更强大。在这种情况下， 潜变
量类似于多层感知机 中的隐藏单元 ，并模拟可见单元之间的高阶交互。正如添加 隐
藏单元将逻辑回归 转换为 MLP，导致 MLP成为函数的 万能近似器 ，具有隐藏单
元的玻尔兹曼机 不再局限于建模变量之间的线性关系。相反， 玻尔兹曼机 变成了离
散变量上 概率质量函数 的万能近似器 (Le Roux and Bengio ,2008)。
正式地，我们将单元 x分解为两个子集：可见单元 v和潜在（或隐藏）单元 h。
能量函数 变为
E(v;h) = v⊤Rv v⊤Wh h⊤Sh b⊤v c⊤h: (20.3)
玻尔兹曼机 的学习 玻尔兹曼机 的学习算法通常基于最大似然。所有 玻尔兹曼机 都
具有难以处理的 配分函数 ，因此最大似然梯度必须使用第 十八章中的技术来近似。
玻尔兹曼机 有一个有趣的性质，当基于最大似然的学习规则训练时，连接两个单
元的特定权重的更新仅取决于这两个单元在不同分布下收集的统计信息： Pmodel (v)
和^Pdata(v)Pmodel (hjv)。网络的其余部分参与 塑造这些统计信息，但权重可以在完
全不知道网络其余部分或这些统计信息如何产生的情况下更新。这意味着学习规则
是‘‘局部’’的，这使得 玻尔兹曼机 的学习似乎在某种程度上是生物学合理的。我们
可以设想每个神经元都是 玻尔兹曼机 中随机变量的情况，那么连接两个随机变量的
轴突和树突只能通过观察与它们物理上实际接触细胞的激发模式来学习。特别地，
正相期间，经常同时激活的两个单元之间的连接会被加强。这是 Hebbian 学习规则
(Hebb ,1949)的一个例子， 经常总结为好记的短语—— “ﬁre together, wire together’’ 。
Hebbian 学习规则是生物系统学习中最古老的假设性解释之一，直至今天仍然有重
大意义 (Giudice et al. ,2009)。
不仅仅使用局部统计信息的其他学习算法似乎需要假设更多的学习机制。例如，
对于大脑在 多层感知机 中实现的 反向传播 ，似乎需要维持一个辅助通信的网络，并
借此向后传输梯度信息。已经有学者 (Hinton ,2007a ;Bengio ,2015)提出生物学上可
行（和近似）的 反向传播 实现方案，但仍然有待验证， Bengio (2015)还将梯度的 反
向传播关联到类似于 玻尔兹曼机 （但具有连续 潜变量）的能量模型中的 推断。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
560 第二十章 深度生成模型
从生物学的角度看， 玻尔兹曼机 学习中的 负相阶段有点难以解释。正如第 18.2节
所主张的，人类在睡眠时做梦可能是一种形式的 负相采样。尽管这个想法更多的只
是猜测。
20.2受限玻尔兹曼机
受限玻尔兹曼机 以簧风琴（harmonium ）之名 (Smolensky ,1986)面世之后，成
为了深度概率模型中最常见的组件之一。我们之前在第 16.7.1节简要介绍了 RBM。
在这里我们回顾以前的内容并探讨更多的细节。 RBM是包含一层可观察变量和单
层潜变量的无向概率 图模型。RBM可以堆叠起来（一个在另一个的顶部）形成更深
的模型。图 20.1展示了一些例子。特别地，图 20.1a显示 RBM本身的图结构。它是
一个二分图，观察层或 潜层中的任何单元之间不允许存在连接。
我们从二值版本的 受限玻尔兹曼机 开始，但如我们之后所见，这还可以扩展为
其他类型的可见和 隐藏单元 。
更正式地说，令观察层由一组 nv个二值随机变量组成，我们统称为向量 v。我
们将 nh个二值随机变量的 潜在或隐藏层记为 h。
就像普通的 玻尔兹曼机 ，受限玻尔兹曼机 也是基于能量的模型 ，其联合概率分
布由能量函数 指定：
P(v= v;h= h) =1
Zexp( E(v;h)): (20.4)
RBM的能量函数 由下给出
E(v;h) = b⊤v c⊤h v⊤Wh; (20.5)
其中 Z是被称为 配分函数 的归一化常数：
Z=∑
v∑
hexpf E(v;h)g (20.6)
从配分函数 Z的定义显而易见，计算 Z的朴素方法（对所有状态进行穷举求和）计
算上可能是难以处理的，除非有巧妙设计的算法可以利用概率分布中的规则来更快
地计算 Z。在受限玻尔兹曼机 的情况下， Long and Servedio (2010)正式证明 配分函
数Z是难解的。难解的 配分函数 Z意味着归一化 联合概率分布 P(v)也难以评估。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.2受限玻尔兹曼机 561
h1h1h2h2h3h3v1v1v2v2v3v3h4h4
h(1)1h(1)1h(1)2h(1)2h(1)3h(1)3v1v1v2v2v3v3h(2)1h(2)1h(2)2h(2)2h(2)3h(2)3h(1)4h(1)4
(a) (b)
h(1)1h(1)1h(1)2h(1)2h(1)3h(1)3v1v1v2v2v3v3h(2)1h(2)1h(2)2h(2)2h(2)3h(2)3h(1)4h(1)4
(c)
图20.1:可以用受限玻尔兹曼机 构建的模型示例。 (a)受限玻尔兹曼机 本身是基于二分图的无向 图
模型，在图的一部分具有可见单元，另一部分具有 隐藏单元 。可见单元之间没有连接， 隐藏单元 之
间也没有任何连接。通常每个可见单元连接到每个 隐藏单元 ，但也可以构造稀疏连接的 RBM，如
卷积 RBM。(b)深度信念网络 是涉及有向和无向连接的混合 图模型。与 RBM一样，它也没有层内
连接。然而， DBN具有多个 隐藏层，因此隐藏单元 之间的连接在分开的层中。 深度信念网络 所需
的所有局部条件概率分布都直接复制 RBM的局部条件概率分布。或者，我们也可以用完全无向
图表示深度信念网络 ，但是它需要层内连接来捕获父节点间的依赖关系。 (c)深度玻尔兹曼机 是具
有几层潜变量的无向图模型。与 RBM和DBN一样， DBM也缺少层内连接。 DBM与RBM的
联系不如 DBN紧密。当从 RBM堆栈初始化 DBM时，有必要对 RBM的参数稍作修改。某些
种类的 DBM可以直接训练，而不用先训练一组 RBM。
20.2.1 条件分布
虽然 P(v)难解，但 RBM的二分图结构具有非常特殊的性质，其条件分布
P(hjv)和P(vjh)是因子的，并且计算和采样是相对简单的。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
562 第二十章 深度生成模型
从联合分布中导出条件分布是直观的：
P(hjv) =P(h;v)
P(v)(20.7)
=1
P(v)1
Zexp{
b⊤v+c⊤h+v⊤Wh}
(20.8)
=1
Z′exp{
c⊤h+v⊤Wh}
(20.9)
=1
Z′exp{nh∑
j=1c⊤
jhj+j=1∑
nhv⊤W:;jhj}
(20.10)
=1
Z′nh∏
j=1exp{
c⊤
jhj+v⊤W:;jhj}
: (20.11)
由于我们相对可见单元 v计算条件概率，相对于分布 P(hjv)我们可以将它们视为
常数。条件分布 P(hjv)因子相乘的本质，我们可以将向量 h上的联合概率写成单
独元素 hj上（未归一化）分布的乘积。现在原问题变成了对单个二值 hj上的分布
进行归一化的简单问题。
P(hj= 1jv) =~P(hj= 1jv)
~P(hj= 0jv) +~P(hj= 1jv)(20.12)
=expfcj+v⊤W:;jg
expf0g+expfcj+v⊤W:;jg(20.13)
=(cj+v⊤W:;j): (20.14)
现在我们可以将关于 隐藏层的完全条件分布表达为 因子形式：
P(hjv) =nh∏
j=1(
(2h 1)⊙(c+W⊤v))
j: (20.15)
类似的推导将显示我们感兴趣的另一条件分布， P(vjh)也是因子形式的分布：
P(vjh) =nv∏
i=1(
(2v 1)⊙(b+Wh))
i: (20.16)
20.2.2 训练受限玻尔兹曼机
因为 RBM允许高效计算 ~P(v)的估计和微分，并且还允许高效地（以 块吉布
斯采样的形式）进行 MCMC采样，所以我们很容易使用第 十八章中训练具有难以计DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.3深度信念网络 563
算配分函数 的模型的技术来训练 RBM。这包括 CD、SML（PCD） 、比率匹配 等。
与深度学习中使用的其他 无向模型 相比， RBM可以相对直接地训练，因为我们可以
以闭解形式计算 P(hjv)。其他一些深度模型，如 深度玻尔兹曼机 ，同时具备难处理
的配分函数 和难以推断的难题。
20.3深度信念网络
深度信念网络 （deep belief network ,DBN）是第一批成功应用深度架构训练的
非卷积模型之一 (Hinton et al. ,2006a ;Hinton ,2007b )。2006年深度信念网络 的引入
开始了当前深度学习的复兴。在引入 深度信念网络 之前，深度模型被认为太难以优
化。具有凸 目标函数 的核机器引领了研究前沿。 深度信念网络 在MNIST数据集上表
现超过内核化支持向量机，以此证明深度架构是能够成功的 (Hinton et al. ,2006a )。
尽管现在与其他无监督或生成学习算法相比， 深度信念网络 大多已经失去了青睐并
很少使用，但它们在深度学习历史中的重要作用仍应该得到承认。
深度信念网络 是具有若干 潜变量层的生成模型 。潜变量通常是二值的，而可见
单元可以是二值或实数。尽管构造连接比较稀疏的 DBN是可能的，但在一般的模型
中，每层的每个单元连接到每个相邻层中的每个单元（没有层内连接） 。顶部两层之
间的连接是无向的。而所有其他层之间的连接是有向的，箭头指向最接近数据的层。
见图 20.1b的例子。
具有 l个隐藏层的DBN包含 l个权重矩阵： W(1); : : : ; W(l)。同时也包含 l+ 1
个偏置向量： b(0); : : : ; b(l)，其中 b(0)是可见层的 偏置。DBN表示的概率分布由下式
给出：
P(h(l);h(l 1))/exp(
b(l)⊤h(l)+b(l 1)⊤h(l 1)+h(l 1)⊤W(l)h(l))
; (20.17)
P(h(k)
i= 1jh(k+1)) =(
b(k)
i+W(k+1)⊤
:;i h(k+1))
8i;8k21; : : : ; l 2; (20.18)
P(vi= 1jh(1)) =(
b(0)
i+W(1)⊤
:;i h(1))
8i: (20.19)
在实值可见单元的情况下，替换
vN(
v;b(0)+W(1)⊤h(1); 1)
(20.20)
为便于处理， 为对角形式。至少在理论上，推广到其他指数族的可见单元是直观
的。只有一个 隐藏层的DBN只是一个 RBM。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
564 第二十章 深度生成模型
为了从 DBN中生成样本，我们先在顶部的两个 隐藏层上运行几个 Gibbs采
样步骤。这个阶段主要从 RBM（由顶部两个 隐藏层定义）中采一个样本。然后，我
们可以对模型的其余部分使用单次 原始采样 ，以从可见单元绘制样本。
深度信念网络 引发许多与 有向模型 和无向模型 同时相关的问题。
由于每个有向层内的 相消解释 效应，并且由于无向连接的两个 隐藏层之间的相
互作用， 深度信念网络 中的推断是难解的。评估或最大化对数似然的标准 证据下界 也
是难以处理的，因为 证据下界 基于大小等于网络宽度的 团的期望。
评估或最大化对数似然，不仅需要面对边缘化 潜变量时难以处理的 推断问题，而
且还需要处理顶部两层 无向模型 内难处理的 配分函数 问题。
为训练深度信念网络 ，我们可以先使用 对比散度 或随机最大似然 方法训
练RBM以最大化 Evpdata logp(v)。RBM的参数定义了 DBN第一层的参数。
然后，第二个 RBM训练为近似最大化
EvpdataEh(1)p(1)(h(1)jv)logp(2)(h(1)); (20.21)
其中 p(1)是第一个 RBM表示的概率分布， p(2)是第二个 RBM表示的概率分布。
换句话说，第二个 RBM被训练为模拟由第一个 RBM的隐藏单元 采样定义的分布，
而第一个 RBM由数据驱动。这个过程能无限重复，从而向 DBN添加任意多层，其
中每个新的 RBM对前一个 RBM的样本建模。每个 RBM定义 DBN的另一层。这
个过程可以被视为提高数据在 DBN下似然概率的变分下界 (Hinton et al. ,2006a )。
在大多数应用中，对 DBN进行贪心逐层训练后，不需要再花功夫对其进行联合
训练。然而，使用 醒眠算法对其进行生成 精调是可能的。
训练好的 DBN可以直接用作 生成模型 ，但是 DBN的大多数兴趣来自于它们改
进分类模型的能力。我们可以从 DBN获取权重，并使用它们定义 MLP：
h(1)=(
b(1)+v⊤W(1))
; (20.22)
h(l)=(
b(l)
i+h(l 1)⊤W(l))
8l22; : : : ; m: (20.23)
利用 DBN的生成训练后获得的权重和 偏置初始化该 MLP之后，我们可以训练
该MLP来执行分类任务。这种 MLP的额外训练是判别性 精调的示例。
与第十九章中从基本原理导出的许多 推断方程相比，这种特定选择的 MLP有
些随意。这个 MLP是一个启发式选择，似乎在实践中效果不错，并在文献中一贯使
用。许多近似 推断技术是由它们在一些约束下，并在对数似然上找到最大 紧变分下DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 565
界的能力所驱动的。我们可以使用 DBN中MLP定义的隐藏单元 的期望，构造对数
似然的变分下界，但这对于 隐藏单元 上的任何概率分布都是如此，并没有理由相信
该MLP提供了一个特别的紧界。特别地， MLP忽略了 DBN图模型中许多重要的
相互作用。 MLP将信息从可见单元向上传播到最深的 隐藏单元 ，但不向下或侧向传
播任何信息。 DBN图模型解释了同一层内所有 隐藏单元 之间的相互作用以及层之间
的自顶向下的相互作用。
虽然 DBN的对数似然是难处理的，但它可以使用 AIS近似 (Salakhutdinov and
Murray ,2008)。通过近似，可以评估其作为 生成模型 的质量。
术语 “深度信念网络 ’’通常不正确地用于指代任意种类的 深度神经网络 ，甚至没
有潜变量意义的网络。这个术语应特指最深层中具有无向连接，而在所有其他连续
层之间存在向下有向连接的模型。
这个术语也可能导致一些混乱，因为术语 ‘‘信念网络 ’’有时指纯粹的 有向模
型，而深度信念网络 包含一个无向层。 深度信念网络 也与动态贝叶斯网络（ dynamic
Bayesian networks ）(Dean and Kanazawa ,1989)共享首字母缩写 DBN，动态贝叶
斯网络表示 马尔可夫链 的贝叶斯网络 。
20.4深度玻尔兹曼机
深度玻尔兹曼机 （Deep Boltzmann Machine ,DBM）(Salakhutdinov and Hin-
ton,2009a )是另一种深度 生成模型 。与深度信念网络 （DBN）不同的是，它是一
个完全无向的模型。与 RBM不同的是， DBM有几层潜变量（RBM只有一层） 。
但是像 RBM一样，每一层内的每个变量是相互独立的，并条件于相邻层中的变
量。见图 20.2中的图结构。 深度玻尔兹曼机 已经被应用于各种任务，包括文档建模
(Srivastava et al. ,2013)。
与RBM和DBN一样， DBM通常仅包含二值单元（正如我们为简化模型的演
示而假设的） ，但很容易就能扩展到实值可见单元。
DBM是基于能量的模型 ，这意味着模型变量的 联合概率分布 由能量函数 E参
数化。在一个 深度玻尔兹曼机 包含一个可见层 v和三个隐藏层 h(1);h(2)和 h(3)的情
况下，联合概率由下式给出：
P(v;h(1);h(2);h(3)) =1
Z()exp(
 E(v;h(1);h(2);h(3);))
: (20.24)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
566 第二十章 深度生成模型
h(1)1h(1)1h(1)2h(1)2h(1)3h(1)3v1v1v2v2v3v3h(2)1h(2)1h(2)2h(2)2h(2)3h(2)3h(1)4h(1)4
图20.2:具有一个可见层（底部）和两个 隐藏层的深度玻尔兹曼机 的图模型。仅在相邻层的单元之
间存在连接。没有层内连接。
为简化表示，下式省略了 偏置参数。 DBM能量函数 定义如下：
E(v;h(1);h(2);h(3);) = v⊤W(1)h(1) h(1)⊤W(2)h(2) h(2)⊤W(3)h(3):(20.25)
与RBM的能量函数 （式 (20.5)）相比， DBM能量函数 以权重矩阵（ W(2)和
W(3)）的形式表示 隐藏单元 （潜变量）之间的连接。正如我们将看到的，这些连接
对模型行为以及我们如何在模型中进行 推断都有重要的影响。
h(1)1h(1)1h(1)2h(1)2h(1)3h(1)3v1v1v2v2h(2)1h(2)1h(2)2h(2)2h(2)3h(2)3h(3)1h(3)1h(3)2h(3)2
v1v2h(2)1h(2)1h(2)2h(2)2h(2)3h(2)3h(1)1h(1)1h(1)2h(1)2h(1)3h(1)3h(3)1h(3)1h(3)2h(3)2
图20.3:深度玻尔兹曼机 ，重新排列后显示为二分图结构。
与全连接的 玻尔兹曼机 （每个单元连接到其他每个单元）相比， DBM提供了类DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 567
似于 RBM的一些优点。
具体来说，如图 20.3所示， DBM的层可以组织成一个二分图，其中奇数层在一
侧，偶数层在另一侧。容易发现，当我们条件于偶数层中的变量时，奇数层中的变
量变得条件独立。当然，当我们条件于奇数层中的变量时，偶数层中的变量也会变
得条件独立。
DBM的二分图结构意味着我们可以应用之前用于 RBM条件分布的相同式子
来确定 DBM中的条件分布。在给定相邻层值的情况下，层内的单元彼此条件独立，
因此二值变量的分布可以由 Bernoulli 参数（描述每个单元的激活概率）完全描述。
在具有两个 隐藏层的示例中，激活概率由下式给出：
P(vi= 1jh(1)) =(
W(1)
i;:h(1))
; (20.26)
P(h(1)
i= 1jv;h(2)) =(
v⊤W(1)
:;i+W(2)
i;:h(2))
; (20.27)
和
P(h(2)
k= 1jh(1)) =(
h(1)⊤W(2)
:;k)
: (20.28)
二分图结构使 Gibbs采样能在深度玻尔兹曼机 中高效采样。 Gibbs采样的方法
是一次只更新一个变量。 RBM允许所有可见单元以一个块的方式更新，而所有 隐藏
单元在另一个块上更新。我们可以简单地假设具有 l层的 DBM需要 l+ 1次更新，
每次迭代更新由某层单元组成的块。然而，我们可以仅在两次迭代中更新所有单元。
Gibbs采样可以将更新分成两个块，一块包括所有偶数层（包括可见层） ，另一个
包括所有奇数层。由于 DBM二分连接模式，给定偶数层，关于奇数层的分布是 因
子的，因此可以作为块同时且独立地采样。类似地，给定奇数层，可以同时且独立
地将偶数层作为块进行采样。高效采样对使用 随机最大似然 算法的训练尤其重要。
20.4.1 有趣的性质
深度玻尔兹曼机 具有许多有趣的性质。
DBM在DBN之后开发。与 DBN相比， DBM的后验分布 P(hjv)更简单。
有点违反直觉的是，这种后验分布的简单性允许更加丰富的后验近似。在 DBN的
情况下，我们使用启发式的近似 推断过程进行分类，其中我们可以通过 MLP（使
用sigmoid激活函数并且权重与原始 DBN相同）中的向上传播猜测 隐藏单元 合理
的均匀场期望值。 任何分布 Q(h)可用于获得对数似然的变分下界。因此这种启发DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
568 第二十章 深度生成模型
式的过程让我们能够获得这样的下界。但是，该界没有以任何方式显式优化，所以
该界可能是远远不紧的。特别地， Q的启发式估计忽略了相同层内 隐藏单元 之间的
相互作用以及更深层中 隐藏单元 对更接近输入的 隐藏单元 自顶向下的反馈影响。因
为DBN中基于启发式 MLP的推断过程不能考虑这些相互作用，所以得到的 Q想
必远不是最优的。 DBM中，在给定其他层的情况下，层内的所有 隐藏单元 都是条件
独立的。这种层内相互作用的缺失使得通过 不动点方程 优化变分下界并找到真正最
佳的均匀场期望（在一些数值容差内）变得可能的。
使用适当的 均匀场允许 DBM的近似推断过程捕获自顶向下反馈相互作用的影
响。这从神经科学的角度来看是有趣的，因为根据已知，人脑使用许多自上而下的反
馈连接。由于这个性质， DBM已被用作真实神经科学现象的计算模型 (Series et al. ,
2010;Reichert et al. ,2011)。
DBM一个不理想的特性是从中采样是相对困难的。 DBN只需要在其顶部的一
对层中使用 MCMC采样。其他层仅在采样过程末尾涉及，并且只需在一个高效的 原
始采样过程。要从 DBM生成样本，必须在所有层中使用 MCMC，并且模型的每一
层都参与每个 马尔可夫链 转移。
20.4.2 DBM均匀场推断
给定相邻层，一个 DBM层上的条件分布是 因子的。在有两个 隐藏层的DBM的
示例中，这些分布是 P(vjh(1)); P(h(1)jv;h(2))和P(h(2)jh(1))。因为层之间的相
互作用， 所有隐藏层上的分布通常不是 因子的。在有两个 隐藏层的示例中，由于 h(1)
和 h(2)之间的交互权重 W(2)使得这些变量相互依赖， P(h(1)jv;h(2))不是因子的。
与DBN的情况一样，我们还是要找出近似 DBM后验分布的方法。然而，
与DBN不同， DBM在其隐藏单元 上的后验分布（复杂的）很容易用变分近似来近
似（如第 19.4节所讨论） ，具体是一个 均匀场近似。均匀场近似是变分 推断的简单形
式，其中我们将近似分布限制为完全 因子的分布。在 DBM的情况下， 均匀场方程
捕获层之间的双向相互作用。在本节中，我们推导出由 Salakhutdinov and Hinton
(2009a )最初引入的迭代近似 推断过程。
在推断的变分近似中，我们通过一些相当简单的分布族近似特定目标分布——
在这里指给定可见单元时 隐藏单元 的后验分布。在 均匀场近似的情况下，近似族是 隐
藏单元条件独立的分布集合。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 569
我们现在为具有两个 隐藏层的示例推导 均匀场方法。令 Q(h(1);h(2)jv)为
P(h(1);h(2)jv)的近似。 均匀场假设意味着
Q(h(1);h(2)jv) =∏
jQ(h(1)
jjv)∏
kQ(h(2)
kjv): (20.29)
均匀场近似试图找到这个分布族中最适合真实后验 P(h(1);h(2)jv)的成员。重
要的是，每次我们使用 v的新值时，必须再次运行 推断过程以找到不同的分布 Q。
我们可以设想很多方法来衡量 Q(hjv)与P(hjv)的拟合程度。 均匀场方法是
最小化
KL(QjjP) =∑
hQ(h(1);h(2)jv)log(Q(h(1);h(2)jv)
P(h(1);h(2)jv))
: (20.30)
一般来说，除了要保证独立性假设，我们不必提供参数形式的近似分布。变分
近似过程通常能够恢复近似分布的函数形式。然而，在二值 隐藏单元 （我们在这里
推导的情况）的 均匀场假设的情况下，不会由于预先固定模型的参数而损失一般性。
我们将 Q作为 Bernoulli 分布的乘积进行参数化，即我们将 h(1)每个元素的
概率与一个参数相关联。具体来说，对于每个 j，^h(1)
j=Q(h(1)
j= 1jv)，其中
^h(1)
j2[0;1]。另外，对于每个 k，^h(2)
k=Q(h(2)
k= 1jv)，其中 ^h(2)
k2[0;1]。因此，我
们有以下近似后验：
Q(h(1);h(2)jv) =∏
jQ(h(1)
jjv)∏
kQ(h(2)
kjv) (20.31)
=∏
j(^h(1)
j)h(1)
j(1 ^h(1)
j)(1 h(1)
j)∏
k(^h(2)
k)h(2)
k(1 ^h(2)
k)(1 h(2)
k):
(20.32)
当然，对于具有更多层的 DBM，近似后验的参数化可以通过明显的方式扩展，即利
用图的二分结构，遵循 Gibbs采样相同的调度，同时更新所有偶数层，然后同时更
新所有奇数层。
现在我们已经指定了近似分布 Q的函数族，但仍然需要指定用于选择该函数族
中最适合 P的成员的过程。最直接的方法是使用式 (19.56 )指定的均匀场方程。这些
方程是通过求解变分下界导数为零的位置而导出。他们以抽象的方式描述如何优化
任意模型的变分下界（只需对 Q求期望） 。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
570 第二十章 深度生成模型
应用这些一般的方程，我们得到以下更新规则（再次忽略 偏置项） ：
h(1)
j=(∑
iviW(1)
i;j+∑
k′W(2)
j;k′^h(2)
k′)
;8j; (20.33)
^h(2)
k=(∑
j′W(2)
j′;k^h(1)
j′)
;8k: (20.34)
在该方程组的不动点处，我们具有变分下界 L(Q)的局部最大值。因此，这些不动点
更新方程定义了迭代算法，其中我们交替更新 h(1)
j（使用式 (20.33 )）和 h(2)
k（使
用式 (20.34 )） 。对于诸如 MNIST的小问题，少至 10次迭代就足以找到用于学习的
近似正相梯度，而 50次通常足以获得要用于高精度分类的单个特定样本的高质量表
示。将近似变分 推断扩展到更深的 DBM是直观的。
20.4.3 DBM的参数学习
DBM中的学习必须面对难解 配分函数 的挑战（使用第 十八章中的技术） ，以及
难解后验分布的挑战（使用第 十九章中的技术） 。
如第 20.4.2节中所描述的，变分 推断允许构建近似难处理的 P(hjv)的分布
Q(hjv)。然后通过最大化 L(v; Q;)（难处理的对数似然的变分下界 logP(v;)）
学习。
对于具有两个 隐藏层的深度玻尔兹曼机 ，L由下式给出
L(Q;) =∑
i∑
j′viW(1)
i;j′^h(1)
j′+∑
j′∑
k′^h(1)
j′W(2)
j′;k′^h(2)
k′ logZ() +H(Q):(20.35)
该表达式仍然包含对数 配分函数 logZ()。由于深度玻尔兹曼机 包含受限玻尔兹曼
机作为组件，用于计算 受限玻尔兹曼机 的配分函数 和采样的困难同样适用于 深度玻
尔兹曼机 。这意味着评估 玻尔兹曼机 的概率质量函数 需要近似方法，如 退火重要采
样。同样，训练模型需要近似对数 配分函数 的梯度。见第 十八章对这些方法的一般
性描述。 DBM通常使用 随机最大似然 训练。第 十八章中描述的许多其他技术都不适
用。诸如 伪似然的技术需要评估非归一化概率的能力，而不是仅仅获得它们的变分
下界。对于 深度玻尔兹曼机 ，对比散度 是缓慢的，因为它们不能在给定可见单元时
对隐藏单元 进行高效采样——反而，每当需要新的 负相样本时， 对比散度 将需要磨
合一条马尔可夫链 。
非变分版本的 随机最大似然 算法已经在第 18.2节讨论过。算法 20.1给出了应用DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 571
于DBM的变分随机最大似然 算法。回想一下，我们描述的是 DBM的简化变体（缺
少偏置参数） ;很容易推广到包含 偏置参数的情况。
20.4.4 逐层预训练
不幸的是，随机初始化后使用 随机最大似然 训练（如上所述）的 DBM通常导致
失败。在一些情况下，模型不能学习如何充分地表示分布。在其他情况下， DBM可
以很好地表示分布，但是没有比仅使用 RBM获得更高的似然。除第一层之外，所
有层都具有非常小权重的 DBM与RBM表示大致相同的分布。
如第 20.4.5节所述，目前已经开发了允许联合训练的各种技术。然而，克
服DBM的联合训练问题最初和最流行的方法是 贪心逐层预训练 。在该方法中，
DBM的每一层被单独视为 RBM，进行训练。第一层被训练为对输入数据进行建模。
每个后续 RBM被训练为对来自前一 RBM后验分布的样本进行建模。在以这种方
式训练了所有 RBM之后，它们可以被组合成 DBM。然后可以用 PCD训练 DBM。
通常， PCD训练将仅使模型的参数、由数据上的对数似然衡量的性能、或区分输入
的能力发生微小的变化。见图 20.4展示的训练过程。
这种贪心逐层训练 过程不仅仅是 坐标上升 。因为我们在每个步骤优化参数的一
个子集，它与 坐标上升 具有一些传递相似性。这两种方法是不同的，因为 贪心逐层
训练过程中，我们在每个步骤都使用了不同的 目标函数 。
DBM的贪心逐层预训练 与DBN的贪心逐层预训练 不同。 每个单独的 RBM的参
数可以直接复制到相应的 DBN。在DBM的情况下， RBM的参数在包含到 DBM中
之前必须修改。 RBM栈的中间层仅使用自底向上的输入进行训练，但在栈组合
形成 DBM后，该层将同时具有自底向上和自顶向下的输入。为了解释这种效应，
Salakhutdinov and Hinton (2009a )提倡在将其插入 DBM之前，将所有 RBM（顶
部和底部 RBM除外）的权重除 2。另外，必须使用每个可见单元的两个 ‘‘副本’’来
训练底部 RBM，并且两个副本之间的权重约束为相等。这意味着在向上传播时，权
重能有效地加倍。类似地，顶部 RBM应当使用最顶层的两个副本来训练。
为了使用 深度玻尔兹曼机 获得最好结果， 我们需要修改标准的 SML算法， 即在联
合PCD训练步骤的 负相期间使用少量的 均匀场 (Salakhutdinov and Hinton ,2009a )。
具体来说，应当相对于其中所有单元彼此独立的 均匀场分布来计算能量梯度的期望。
这个均匀场分布的参数应该通过运行一次 均匀场不动点方程 获得。 Goodfellow et al.
(2013d )比较了在 负相中使用和不使用部分 均匀场的中心化 DBM的性能。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
572 第二十章 深度生成模型
算法20.1用于训练具有两个 隐藏层的DBM的变分随机最大似然 算法
设步长 ϵ为一个小正数
设定吉布斯步数 k，大到足以让 p(v;h(1);h(2);+ϵ∆)的马尔可夫链 能磨合（从
来自 p(v;h(1);h(2);)的样本开始） 。
初始化三个矩阵， ~V,~H(1)和~H(2)每个都将 m行设为随机值（例如， 来自 Bernoulli
分布，边缘分布大致与模型匹配） 。
while没有收敛（学习循环） do
从训练数据采包含 m个样本的 小批量，并将它们排列为设计矩阵 V的行。
初始化矩阵 ^H(1)和^H(2)，使其大致符合模型的边缘分布。
while没有收敛（ 均匀场推断循环） do
^H(1) sigmoid(
VW(1)+^H(2)W(2)⊤)
.
^H(2) sigmoid(
^H(1)W(2))
.
end while
∆W(1) 1
mV⊤^H(1)
∆W(2) 1
m^H(1)⊤^H(2)
forl= 1tok（Gibbs采样）do
Gibbs block 1:
8i; j;~Vi;j采自P(~Vi;j= 1) = sigmoid(
W(1)
j;:(
~H(1)
i;:)⊤)
.
8i; j;~H(2)
i;j采自P(~H(2)
i;j= 1) = sigmoid(
~H(1)
i;:W(2)
:;j)
.
Gibbs block 2:
8i; j;~H(1)
i;j采自P(~H(1)
i;j= 1) = sigmoid(
~Vi;:W(1)
:;j+~H(2)
i;:W(2)⊤
j;:)
.
end for
∆W(1) ∆W(1) 1
mV⊤~H(1)
∆W(2) ∆W(2) 1
m~H(1)⊤~H(2)
W(1) W(1)+ϵ∆W(1)（这是大概的描述，实践中使用的算法更高效，如具有
衰减学习率的动量）
W(2) W(2)+ϵ∆W(2)
end whileDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 573
d)a)b)
c)
图20.4:用于分类 MNIST数据集的 深度玻尔兹曼机 训练过程 (Salakhutdinov and Hinton ,2009a ;
Srivastava et al. ,2014)。(a)使用CD近似最大化 logP(v)来训练 RBM。(b)训练第二个 RBM，使
用CD-k近似最大化 logP(h(1);y)来建模 h(1)和目标类 y，其中 h(1)采自第一个 RBM条件于数
据的后验。在学习期间将 k从1增加到 20。(c)将两个 RBM组合为 DBM。使用 k= 5的随机最
大似然训练，近似最大化 logP(v;y)。(d)将 y从模型中删除。定义新的一组特征 h(1)和 h(2)，可
在缺少 y的模型中运行 均匀场推断后获得。使用这些特征作为 MLP的输入，其结构与 均匀场的额
外轮相同，并且具有用于估计 y的额外输出层。初始化 MLP的权重与 DBM的权重相同。使用 随机
梯度下降 和Dropout 训练MLP近似最大化 logP(yjv)。图来自 Goodfellow et al. (2013d )。
20.4.5 联合训练深度玻尔兹曼机
经典 DBM需要贪心无监督预训练 ，并且为了更好的分类，需要在它们提取
的隐藏特征之上，使用独立的基于 MLP的分类器。这种方法有一些不理想的性
质。因为我们不能在训练第一个 RBM时评估完整 DBM的属性，所以在训练期间
难以跟踪性能。因此，直到相当晚的训练过程，我们都很难知道我们的超参数表DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
574 第二十章 深度生成模型
现如何。 DBM的软件实现需要很多不同的模块，如用于单个 RBM的CD训练、
完整 DBM的PCD训练以及基于 反向传播 的MLP训练。最后， 玻尔兹曼机 顶部
的MLP失去了玻尔兹曼机 概率模型的许多优点，例如当某些输入值丢失时仍能够
进行推断的优点。
主要有两种方法可以处理 深度玻尔兹曼机 的联合训练问题。第一个是 中心化深
度玻尔兹曼机 (centered deep Boltzmann machine) ( Montavon and Muller ,2012)，通
过重参数化 模型使其在开始学习过程时 代价函数 的Hessian具有更好的条件数。这
个模型不用经过 贪心逐层预训练 阶段就能训练。这个模型在测试集上获得出色的
对数似然，并能产生高质量的样本。不幸的是，作为分类器，它仍然不能与适当 正
则化的MLP竞争。联合训练 深度玻尔兹曼机 的第二种方式是使用 多预测深度玻尔
兹曼机（multi-prediction deep Boltzmann machine ,MP-DBM ）(Goodfellow et al. ,
2013d )。该模型的训练 准则允许反向传播 算法，以避免使用 MCMC估计梯度的问
题。不幸的是，新的 准则不会导致良好的似然性或样本，但是相比 MCMC方法，它
确实会导致更好的分类性能和良好的 推断缺失输入的能力。
如果我们回到 玻尔兹曼机 的一般观点，即包括一组权重矩阵 U和偏置 b的单元
x，玻尔兹曼机 中心化技巧是最容易描述的。回顾式 (20.2)，能量函数 由下式给出
E(x) = x⊤Ux b⊤x: (20.36)
在权重矩阵 U中使用不同的稀疏模式，我们可以实现不同架构的 玻尔兹曼机 ，
如RBM或具有不同层数的 DBM。将 x分割成可见和 隐藏单元 并将 U中不相互作
用的单元的归零可以实现这些架构。中心化 玻尔兹曼机 引入了一个向量 ，并从所
有状态中减去：
E′(x;U;b) = (x )⊤U(x ) (x )⊤b: (20.37)
通常在开始训练时固定为一个超参数。当模型初始化时，通常选择为 x 0。
这种重参数化 不改变模型可表示的概率分布的集合，但它确实改变了应用于似然
的随机梯度下降 的动态。具体来说，在许多情况下，这种 重参数化 导致更好条件数
的Hessian矩阵。 Melchior et al. (2013)通过实验证实了 Hessian矩阵条件数的改
善，并观察到中心化技巧等价于另一个 玻尔兹曼机 学习技术—— 增强梯度 (enhanced
gradient) ( Cho et al. ,2011)。即使在困难的情况下，例如训练多层的 深度玻尔兹曼
机，Hessian矩阵条件数的改善也能使学习成功。
联合训练 深度玻尔兹曼机 的另一种方法是 多预测深度玻尔兹曼机 （MP-DBM ） ，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.4深度玻尔兹曼机 575
它将均匀场方程视为定义一系列用于近似求解每个可能 推断问题的循环网络 (Good-
fellow et al. ,2013d )。模型被训练为使每个 循环网络 获得对相应 推断问题的准确答
案，而不是训练模型来最大化似然。训练过程如图 20.5所示。它包括随机采一个训
练样本、随机采样 推断网络的输入子集，然后训练 推断网络来预测剩余单元的值。
这种用于近似 推断，通过计算图进行反向传播 的一般原理已经应用于其他模
型(Stoyanov et al. ,2011;Brakel et al. ,2013)。在这些模型和 MP-DBM 中，最终 损
失不是似然的下界。相反，最终 损失通常基于近似 推断网络对缺失值施加的近似条
件分布。这意味着这些模型的训练有些启发式。如果我们检查由 MP-DBM 学习出来
的玻尔兹曼机 表示 p(v)，在 Gibbs采样产生较差样本的意义下，它倾向于有些缺陷。
通过推断图的反向传播 有两个主要优点。首先，它以模型真正使用的方式训练
模型——使用近似 推断。这意味着在 MP-DBM 中，进行如填充缺失的输入或执行
分类（尽管存在缺失的输入）的近似 推断比在原始 DBM中更准确。原始 DBM不
会自己做出准确的分类器 ;使用原始 DBM的最佳分类结果是基于 DBM提取的特
征训练独立的分类器，而不是通过使用 DBM中的推断来计算关于类标签的分布。
MP-DBM 中的均匀场推断作为分类器，不需要进行特殊修改就获得良好的表现。通
过近似推断反向传播 的另一个优点是 反向传播 计算损失的精确梯度。对于优化而言，
比SML训练中具有偏差和方差的近似梯度更好。这可能解释了为什么 MP-DBM 可
以联合训练，而 DBM需要贪心逐层预训练 。近似推断图反向传播 的缺点是它不提
供一种优化对数似然的方法，而提供 广义伪似然 的启发式近似。
MP-DBM 启发了对 NADE框架的扩展 NADE- k(Raiko et al. ,2014)，我们将
在第 20.10.10节中描述。
MP-DBM 与Dropout 有一定联系。 Dropout 在许多不同的 计算图之间共享相
同的参数，每个图之间的差异是包括还是排除每个单元。 MP-DBM 还在许多 计算
图之间共享参数。在 MP-DBM 的情况下，图之间的差异是每个输入单元是否被观
察到。当没有观察到单元时， MP-DBM 不会像 Dropout 那样将其完全删除。相反，
MP-DBM 将其视为要 推断的潜变量。我们可以想象将 Dropout 应用到 MP-DBM ，
即额外去除一些单元而不是将它们变为 潜变量。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
576 第二十章 深度生成模型
图20.5:深度玻尔兹曼机 多预测训练过程的示意图。每一行指示相同训练步骤内 小批量中的不同
样本。每列表示 均匀场推断过程中的 时间步。对于每个样本，我们对数据变量的子集进行采样，作
为推断过程的输入。这些变量以黑色阴影表示条件。然后我们运行 均匀场推断过程，箭头指示过
程中的哪些变量会影响其他变量。在实际应用中，我们将 均匀场展开为几个步骤。在此示意图中，
我们只展开为两个步骤。虚线箭头表示获得更多步骤需要如何展开该过程。未用作 推断过程输入
的数据变量成为目标，以灰色阴影表示。我们可以将每个样本的 推断过程视为 循环网络 。为了使
其在给定输入后能产生正确的目标，我们使用 梯度下降 和反向传播 训练这些 循环网络 。这可以训
练MP-DBM 均匀场过程产生准确的估计。图改编自 Goodfellow et al. (2013d )。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.5实值数据上的玻尔兹曼机 577
20.5实值数据上的玻尔兹曼机
虽然玻尔兹曼机 最初是为二值数据而开发的，但是许多应用，例如图像和音频
建模似乎需要表示实值上概率分布的能力。在一些情况下，我们可以将区间 [0;1]中
的实值数据视为表示二值变量的期望。例如， Hinton (2000)将训练集中灰度图像的
像素值视为定义 [0;1]间的概率值。每个像素定义二值变量为 1的概率，并且二值像
素的采样都彼此独立。这是评估灰度图像数据集上二值模型的常见过程。然而，这
种方法理论上并不特别令人满意，并且以这种方式独立采样的二值图像具有噪声表
象。在本节中，我们介绍概率密度定义在实值数据上的 玻尔兹曼机 。
20.5.1 Gaussian-Bernoulli RBM
受限玻尔兹曼机 可以用于许多指数族的条件分布 (Welling et al. ,2005)。其中，
最常见的是具有二值 隐藏单元 和实值可见单元的 RBM，其中可见单元上的条件分布
是高斯分布 （均值为 隐藏单元 的函数） 。
有很多方法可以参数化 Gaussian-Bernoulli RBM 。首先，我们可以选择协方差
矩阵或精度矩阵来参数化 高斯分布 。这里，我们介绍选择精度矩阵的情况。我们可
以通过简单的修改获得协方差的形式。我们希望条件分布为
p(vjh) =N(v;Wh; 1): (20.38)
通过扩展未归一化的对数条件分布可以找到需要添加到 能量函数 中的项：
logN(v;Wh; 1) = 1
2(v Wh)⊤(v Wh) +f(): (20.39)
此处 f封装所有的参数，但不包括模型中的随机变量。因为 f的唯一作用是归
一化分布，并且我们选择的任何可作为 配分函数 的能量函数 都能起到这个作用，所
以我们可以忽略 f。
如果我们在 能量函数 中包含式 (20.39 )中涉及 v的所有项（其符号被翻转） ，并
且不添加任何其他涉及 v的项，那么我们的 能量函数 就能表示想要的条件分布
p(vjh)。
其他条件分布比较自由，如 p(hjv)。注意式 (20.39 )包含一项
1
2h⊤W⊤Wh: (20.40)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
578 第二十章 深度生成模型
因为该项包含 hihj项，它不能被全部包括在内。这些对应于 隐藏单元 之间的边。如
果我们包括这些项，我们将得到一个 线性因子模型 ，而不是 受限玻尔兹曼机 。当设
计我们的 玻尔兹曼机 时，我们简单地省略这些 hihj交叉项。省略这些项不改变条件
分布 p(vjh)，因此式 (20.39 )仍满足。然而，我们仍然可以选择是否包括仅涉及单个
hi的项。如果我们假设精度矩阵是对角的，就能发现对于每个 隐藏单元 hi，我们有
一项
1
2hi∑
jjW2
j;i: (20.41)
在上面，我们使用了 h2
i=hi的事实（因为 hi2f0;1g） 。如果我们在 能量函数 中包
含此项（符号被翻转） ，则当该单元的权重较大且以高精度连接到可见单元时， 偏
置hi将自然被关闭。是否包括该 偏置项不影响模型可以表示的分布族（假设我们包
括隐藏单元 的偏置参数） ，但是它确实会影响模型的学习动态。包括该项可以帮助 隐
藏单元（即使权重在幅度上快速增加时）保持合理激活。
因此，在 Gaussian-Bernoulli RBM 上定义能量函数 的一种方式：
E(v;h) =1
2v⊤(⊙v) (v⊙)⊤Wh b⊤h; (20.42)
但我们还可以添加额外的项或者通过方差而不是精度参数化能量。
在这个推导中，我们没有在可见单元上添加 偏置项，但添加这样的 偏置是容易
的。Gaussian-Bernoulli RBM 参数化一个最终变化的来源是如何处理精度矩阵的选
择。它可以被固定为常数（可能基于数据的边缘精度估计）或学习出来。它也可以
是标量乘以单位矩阵，或者是一个对角矩阵。在此情况下，由于一些操作需要对矩
阵求逆，我们通常不允许非对角的精度矩阵，因为高斯分布的一些操作需要对矩阵 求
逆，一个对角矩阵可以非常容易地被 求逆。在接下来的章节中，我们将看到其他形式
的玻尔兹曼机 ，它们允许对协方差结构建模，并使用各种技术避免对精度矩阵 求逆。
20.5.2 条件协方差的无向模型
虽然高斯 RBM已成为实值数据的标准能量模型， Ranzato et al. (2010a )认为高
斯RBM感应偏置不能很好地适合某些类型的实值数据中存在的统计变化，特别是
自然图像。问题在于自然图像中的许多信息内容嵌入于像素之间的协方差而不是
原始像素值中。换句话说，图像中的大多数有用信息在于像素之间的关系，而不是
其绝对值。由于 高斯 RBM仅对给定 隐藏单元 的输入条件均值建模，所以它不能捕DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.5实值数据上的玻尔兹曼机 579
获条件协方差信息。为了回应这些评论，已经有学者提出了替代模型，设法更好地
考虑实值数据的协方差。这些模型包括 均值和协方差 RBM（mean and covariance
RBM ,mcRBM）1、学生 t分布均值乘积 （mean product of Student t-distribution ,
mPoT）模型和 尖峰和平板 RBM（spike and slab RBM ,ssRBM） 。
均值和协方差 RBM mcRBM 使用隐藏单元 独立地编码所有可观察单元的条件均
值和协方差。 mcRBM 的隐藏层分为两组单元：均值单元和协方差单元。建模条件
均值的那组单元是简单的 高斯 RBM。另一半是 协方差 RBM（covariance RBM ,
cRBM）(Ranzato et al. ,2010a )，对条件协方差的结构进行建模（如下所述） 。
具体来说， 在二值均值的单元 h(m)和二值协方差单元 h(c)的情况下， mcRBM 模
型被定义为两个 能量函数 的组合：
Emc(x;h(m);h(c)) =Em(x;h(m)) +Ec(x;h(c)); (20.43)
其中 Em为标准的 Gaussian-Bernoulli RBM 能量函数2，
Em(x;h(m)) =1
2x⊤x ∑
jx⊤W:;jh(m)
j ∑
jb(m)
jh(m)
j; (20.44)
Ec是cRBM建模条件协方差信息的 能量函数 ：
Ec(x;h(c)) =1
2∑
jh(c)
j(
x⊤r(j))2 ∑
jb(c)
jh(c)
j: (20.45)
参数 r(j)与h(c)
j关联的协方差权重向量对应， b(c)是一个协方差 偏置向量。组合后
的能量函数 定义联合分布，
pmc(x;h(m);h(c)) =1
Zexp{
 Emc(x;h(m);h(c))}
; (20.46)
以及给定 h(m)和 h(c)后，关于观察数据相应的条件分布（为一个多元 高斯分布 ） ：
pmc(xjh(m);h(c)) =N(
x;Cmc
xjh(∑
jW:;jh(m)
j)
;Cmc
xjh)
: (20.47)
注意协方差矩阵 Cmc
xjh=(∑
jh(c)
jr(j)r(j)T+I) 1
是非对角的，且 W是与建模条件
均值的高斯 RBM相关联的权重矩阵。由于非对角的条件协方差结构，难以通过 对
1术语 “mcRBM’’ 根据字母 M-C-R-B-M 发音； “mc’’不是 “McDonald’s’’ 中的 “Mc’’的发音。
2这个版本的 Gaussian-Bernoulli RBM 能量函数 假定图像数据的每个像素具有零均值。考虑非零像素均值时，可
以简单地将像素偏移添加到模型中。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
580 第二十章 深度生成模型
比散度或持续性对比散度 来训练 mcRBM。CD和PCD需要从 x;h(m);h(c)的联合
分布中采样，这在标准 RBM中可以通过 Gibbs采样在条件分布上采样实现。但是，
在mcRBM 中，从 pmc(xjh(m);h(c))中抽样需要在学习的每个迭代计算 (Cmc) 1。
这对于更大的观察数据可能是不切实际的计算负担。 Ranzato and Hinton (2010)通
过使用 mcRBM 自由能上的哈密尔顿（混合） 蒙特卡罗 (Neal,1993)直接从边缘
p(x)采样，避免了直接从条件 pmc(xjh(m);h(c))抽样。
学生 t分布均值乘积 学生 t分布均值乘积 （mPoT）模型 (Ranzato et al. ,2010b )
以类似 mcRBM 扩展 cRBM的方式扩展 PoT模型 (Welling et al. ,2003a )。通过添
加类似高斯 RBM中隐藏单元 的非零高斯均值来实现。与 mcRBM 一样，观察值上
的PoT条件分布是多元高斯（具有非对角的协方差）分布 ;然而，不同于 mcRBM ，
隐藏变量的互补条件分布是由条件独立的 Gamma 分布给出。 Gamma 分布G(k; )
是关于正实数且均值为 k的概率分布。我们只需简单地了解 Gamma 分布就足以理
解mPoT模型的基本思想。
mPoT的能量函数 为：
EmPoT (x;h(m);h(c)) (20.48)
=Em(x;h(m)) +∑
j(
h(c)
j(
1 +1
2(r(j)Tx)2)
+ (1 j)logh(c)
j)
; (20.49)
其中 r(j)是与单元 h(c)
j相关联的协方差权重向量， Em(x;h(m))如式 (20.44 )所定义。
正如 mcRBM 一样， mPoT模型能量函数 指定一个多元 高斯分布 ，其中关于 x
的条件分布具有非对角的协方差。 mPoT模型中的学习（也像 mcRBM ）由于无法
从非对角高斯条件分布 pmPoT (xjh(m);h(c))采样而变得复杂。因此 Ranzato et al.
(2010b )也倡导通过哈密尔顿（混合） 蒙特卡罗 (Neal,1993)直接采样 p(x)。
尖峰和平板 RBM 尖峰和平板 RBM（spike and slab RBM ,ssRBM）(Courville
et al. ,2011b )提供对实值数据的协方差结构建模的另一种方法。与 mcRBM 相
比，ssRBM具有既不需要矩阵求逆也不需要哈密尔顿 蒙特卡罗 方法的优点。就
像mcRBM 和mPoT模型， ssRBM的二值隐藏单元 通过使用辅助实值变量来编码
跨像素的条件协方差。
尖峰和平板 RBM有两类隐藏单元 ：二值尖峰 (spike)单元 h和实值平板 (slab)
单元 s。条件于 隐藏单元 的可见单元均值由 (h⊙s)W⊤给出。换句话说，每一列 W:;iDRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.5实值数据上的玻尔兹曼机 581
定义当 hi= 1时可出现在输入中的分量。相应的尖峰变量 hi确定该分量是否存在。
如果存在的话，相应的平板变量 si确定该分量的强度。当尖峰变量激活时，相应的
平板变量将沿着 W:;i定义的轴的输入增加方差。这允许我们对输入的协方差建模。
幸运的是，使用 Gibbs采样的对比散度 和持续性对比散度 仍然适用。此处无需对任
何矩阵求逆。
形式上， ssRBM模型通过其 能量函数 定义：
Ess(x;s;h) = ∑
ix⊤W:;isihi+1
2x⊤(
+∑
iihi)
x (20.50)
+1
2∑
iis2
i ∑
iiisihi ∑
ibihi+∑
ii2
ihi; (20.51)
其中 bi是尖峰 hi的偏置，是观测值 x上的对角精度矩阵。参数 i>0是实值平
板变量 si的标量精度参数。参数 i是定义 x上的 h调制二次惩罚的非负对角矩
阵。每个 i是平板变量 si的均值参数。
利用能量函数 定义的联合分布，能相对容易地导出 ssRBM条件分布。例如，通
过边缘化平板变量 s，给定二值尖峰变量 h，关于观察量的条件分布由下式给出
pss(xjh) =1
P(h)1
Z∫
expf E(x;s;h)gds (20.52)
=N(
x;Css
xjh∑
iW:;iihi;Css
xjh)
(20.53)
其中 Css
xjh= (+∑
iihi ∑
i 1
ihiW:;iW⊤
:;i) 1。最后的等式只有在协方差矩阵
Css
xjh正定时成立。
由尖峰变量选通意味着 h⊙s上的真实边缘分布是稀疏的。这不同于 稀疏编码 ，
其中来自模型的样本在编码中 ‘‘几乎从不 ’’（在测度理论意义上）包含零，并且需
要MAP推断来强加稀疏性。
相比 mcRBM 和mPoT模型， ssRBM以明显不同的方式参数化观察量的条件
协方差。 mcRBM 和mPoT都通过(∑
jh(c)
jr(j)r(j)⊤+I) 1建模观察量的协方差
结构，使用 hj>0的隐藏单元 的激活来对方向 r(j)的条件协方差施加约束。相反，
ssRBM使用隐藏尖峰激活 hi= 1来指定观察结果的条件协方差，以沿着由相应权
重向量指定的方向捏合精度矩阵。 ssRBM条件协方差与一个不同模型给出的类似：
概率主成分分析的乘积（ PoPPCA ）(Williams and Agakov ,2002)。在过完备的设定
下，ssRBM参数化的稀疏激活仅允许在稀疏激活 hi的所选方向上有显著方差（高DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
582 第二十章 深度生成模型
于由 1给出的近似方差） 。在 mcRBM 或mPoT模型中， 过完备的表示意味着，
捕获观察空间中特定方向上的变化需要在该方向上的正交投影下去除潜在的所有约
束。这表明这些模型不太适合于 过完备设定。
尖峰和平板 RBM的主要缺点是参数的一些设置会对应于非正定的协方差矩阵。
这种协方差矩阵会在离均值更远的值上放置更大的未归一化概率，导致所有可能结
果上的积分发散。通常这个问题可以通过简单的启发式技巧来避免。理论上还没有
任何令人满意的解决方法。使用约束优化来显式地避免概率未定义的区域（不过分
保守是很难做到的） ，并且这还会阻止模型到达参数空间的高性能区域。
定性地， ssRBM的卷积变体能产生自然图像的优秀样本。图 16.1中展示了一些
样例。
ssRBM允许几个扩展，包括平板变量的高阶交互和平均池化 (Courville et al. ,
2014)使得模型能够在标注数据稀缺时为分类器学习到出色的特征。向 能量函
数添加一项能防止 配分函数 在稀疏编码 模型下变得不确定，如尖峰和平板 稀疏编
码(Goodfellow et al. ,2013g )，也称为 S3C。
20.6卷积玻尔兹曼机
如第九章所示，超高维度输入（如图像）会对机器学习模型的计算、内存和统
计要求造成很大的压力。通过使用小核的离散卷积来替换矩阵乘法是解决具有空间
平移不变性或时间结构的输入问题的标准方式。 Desjardins and Bengio (2008)表明
这种方法应用于 RBM时效果很好。
深度卷积网络通常需要池化操作，使得每个连续层的空间大小减小。前馈 卷积
网络通常使用池化函数，例如池化元素的最大值。目前尚不清楚如何将其推广到 基
于能量的模型 的设定中。我们可以在 n个二值检测器单元 d上引入二值池化单元 p，
强制 p= max idi，并且当违反约束时将 能量函数 设置为1。因为它需要评估 2n个
不同的能量设置来计算归一化常数，这种方式不能很好地扩展。对于小的 33池化
区域，每个池化单元需要评估 29= 512个能量函数 ！
Lee et al. (2009)针对这个问题，开发了一个称为 概率最大池化 (probabilistic
max pooling) 的解决方案（不要与 ‘‘随机池化 ’’混淆， ‘‘随机池化 ’’是用于隐含地构
建卷积前馈网络集成的技术） 。概率最大池化背后的策略是约束检测器单元，使得一
次最多只有一个可以处于活动状态。这意味着仅存在 n+ 1个总状态（ n个检测器DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.6卷积玻尔兹曼机 583
单元中某一个状态为开和一个对应于所有检测器单元关闭的附加状态） 。当且仅当检
测器单元中的一个开启时，池化单元打开。所有单元的状态关闭时，能量被分配为
零。我们可以认为这是在用包含 n+ 1个状态的单个变量来描述模型，或者等价地
具有 n+ 1个变量的模型，除了 n+ 1个联合分配的变量之外的能量赋为 1。
虽然高效的概率最大池化确实能强迫检测器单元互斥，这在某些情景下可能是
有用的正则化约束而在其他情景下是对模型容量有害的限制。它也不支持重叠池化
区域。从前馈 卷积网络 获得最佳性能通常需要重叠的池化区域，因此这种约束可能
大大降低了 卷积玻尔兹曼机 的性能。
Lee et al. (2009)证明概率最大池化可以用于构建卷积 深度玻尔兹曼机3。该模
型能够执行诸如填补输入缺失部分的操作。虽然这种模型在理论上有吸引力，让它
在实践中工作是具有挑战性的，作为分类器通常不如通过 监督训练的传统 卷积网络 。
许多卷积模型对于许多不同空间大小的输入同样有效。对于 玻尔兹曼机 ，由于
各种原因很难改变输入尺寸。 配分函数 随着输入大小的改变而改变。此外，许多 卷积
网络按与输入大小成比例地缩放池化区域来实现尺寸不变性，但缩放 玻尔兹曼机 池
化区域是不优雅的。传统的卷积神经网络可以使用固定数量的池化单元并且动态地
增加它们池化区域的大小，以此获得可变大小输入的固定尺寸的表示。对于 玻尔兹
曼机，大型池化区域的计算成本比朴素方法高很多。 Lee et al. (2009)的方法使得每
个检测器单元在相同的池化区域中互斥，解决了计算问题，但仍然不允许大小可变
的池化区域。例如，假设我们在学习边缘检测器时，检测器单元上具有 22的概率
最大池化。这强制约束在每个 22的区域中只能出现这些边中的一条。如果我们随
后在每个方向上将输入图像的大小增加 50%，则期望边缘的数量会相应地增加。相
反，如果我们在每个方向上将池化区域的大小增加 50%到33，则互斥性约束现
在指定这些边中的每一个在 33区域中仅可以出现一次。当我们以这种方式增长模
型的输入图像时，模型会生成密度较小的边。当然，这些问题只有在模型必须使用
可变数量的池化，以便产出固定大小的输出向量时才会出现。只要模型的输出是可
以与输入图像成比例缩放的特征图，使用概率最大池化的模型仍然可以接受可变大
小的输入图像。
图像边界处的像素也带来一些困难，由于 玻尔兹曼机 中的连接是对称的事实而
加剧。如果我们不隐式地补零输入，则将会导致比可见单元更少的 隐藏单元 ，并且
图像边界处的可见单元将不能被良好地建模，因为它们位于较少 隐藏单元 的接受场
3该论文将模型描述为 “深度信念网络 ’’，但因为它可以被描述为纯无向模型（具有易处理逐层 均匀场不动点更新） ，
所以它最适合 深度玻尔兹曼机 的定义。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
584 第二十章 深度生成模型
中。然而，如果我们隐式地补零输入，则边界处的 隐藏单元 将由较少的输入像素驱
动，并且可能在需要时无法激活。
20.7用于结构化或序列输出的玻尔兹曼机
在结构化输出场景中，我们希望训练可以从一些输入 x映射到一些输出 y的模
型， y的不同条目彼此相关，并且必须遵守一些约束。例如，在语音合成任务中， y
是波形，并且整个波形听起来必须像连贯的发音。
表示 y中的条目之间关系的自然方式是使用概率分布 p(yjx)。扩展到建模条
件分布的 玻尔兹曼机 可以支持这种概率模型。
使用玻尔兹曼机 条件建模的相同工具不仅可以用于结构化输出任务，还可以用
于序列建模。 在后一种情况下， 模型必须估计变量序列上的概率分布 p(x(1); : : : ; x())，
而不仅仅是将输入 x映射到输出 y。为完成这个任务，条件 玻尔兹曼机 可以表示
p(x()jx(1); : : : ; x( 1))形式的因子。
视频游戏和电影工业中一个重要序列建模任务是建模用于渲染 3-D人物骨架关
节角度的序列。这些序列通常通过记录角色移动的运动捕获系统收集。人物运动的概
率模型允许生成新的（之前没见过的）但真实的动画。为了解决这个序列建模任务，
Taylor et al. (2007)针对小的 m引入了条件 RBM建模 p(x(t)jx(t 1); : : : ; x(t m))。
该模型是 p(x(t))上的 RBM，其偏置参数是 x前面 m个值的线性函数。当我们条件
于 x(t 1)的不同值和更早的变量时，我们会得到一个关于 x的新 RBM。RBM关于
x的权重不会改变，但是条件于不同的过去值，我们可以改变 RBM中的不同 隐藏单
元处于活动状态的概率。通过激活和去激活 隐藏单元 的不同子集，我们可以对 x上
诱导的概率分布进行大的改变。条件 RBM的其他变体 (Mnih et al. ,2011)和使用
条件 RBM进行序列建模的其他变体是可能的 (Taylor and Hinton ,2009;Sutskever
et al. ,2009;Boulanger-Lewandowski et al. ,2012)。
另一个序列建模任务是对构成歌曲音符序列的分布进行建模。 Boulanger-
Lewandowski et al. (2012)引入了 RNN-RBM 序列模型并应用于这个任务。 RNN-
RBM由RNN（产生用于每个 时间步的RBM参数）组成，是帧序列 x(t)的生成模
型。与之前只有 RBM的偏置参数会在一个 时间步到下一个发生变化的方法不同，
RNN-RBM 使用 RNN来产生 RBM的所有参数（包括权重） 。为了训练模型，我们
需要能够通过 RNN反向传播 损失函数 的梯度。 损失函数 不直接应用于 RNN输出。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.8其他玻尔兹曼机 585
相反，它应用于 RBM。这意味着我们必须使用 对比散度 或相关算法关于 RBM参数
进行近似的微分。然后才可以使用通常的 通过时间反向传播 算法通过 RNN反向传
播该近似梯度。
20.8其他玻尔兹曼机
玻尔兹曼机 的许多其他变种是可能的。
玻尔兹曼机 可以用不同的训练 准则扩展。我们专注于训练为大致最大化生成标
准 logp(v)的玻尔兹曼机 。相反，旨在最大化 logp(yjv)来训练判别的 RBM也是
有可能的 (Larochelle and Bengio ,2008b )。当使用生成性和判别性标准的线性组合
时，该方法通常表现最好。不幸的是，至少使用现有的方法来看， RBM似乎并不
如MLP那样的监督学习器强大。
在实践中使用的大多数 玻尔兹曼机 在其能量函数 中仅具有二阶相互作用，意味
着它们的 能量函数 是许多项的和，并且每个单独项仅包括两个随机变量之间的乘积。
这种项的一个例子是 viWi;jhj。我们还可以训练高阶 玻尔兹曼机 (Sejnowski ,1987)
，其中能量函数 项涉及许多变量的乘积。 隐藏单元 和两个不同图像之间的三向交互
可以建模从一个视频帧到下一个帧的空间变换 (Memisevic and Hinton ,2007,2010)。
通过one-hot类别变量的乘法可以根据存在哪个类来改变可见单元和 隐藏单元 之间的
关系 (Nair and Hinton ,2009)。使用高阶交互的一个最近的示例是具有两组 隐藏单
元的玻尔兹曼机 ，一组同时与可见单元 v和类别标签 y交互，另一组仅与输入值 v
交互 (Luo et al. ,2011)。这可以被解释为鼓励一些 隐藏单元 学习使用与类相关的特
征来建模输入，而且还学习额外的 隐藏单元 （不需要根据样本类别，学习逼真 v样
本所需的繁琐细节） 。高阶交互的另一个用途是选通一些特征。 Sohn et al. (2013)介
绍了一个带有三阶交互的 玻尔兹曼机 ，以及与每个可见单元相关的二进制掩码变量。
当这些掩码变量设置为零时，它们消除可见单元对 隐藏单元 的影响。这允许将与分
类问题不相关的可见单元从估计类别的 推断路径中移除。
更一般地说， 玻尔兹曼机 框架是一个丰富的模型空间，允许比迄今为止已经探
索的更多的模型结构。开发新形式的 玻尔兹曼机 相比于开发新的神经网络层需要更
多细心和创造力，因为它通常很难找到一个能保持 玻尔兹曼机 所需的所有不同条件
分布的可解性的 能量函数 。尽管这需要努力，该领域仍对创新开放。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
586 第二十章 深度生成模型
20.9通过随机操作的反向传播
传统的神经网络对一些输入变量 x施加确定性变换。当开发 生成模型 时，我们
经常希望扩展 神经网络 以实现 x的随机变换。这样做的一个直接方法是使用额外输
入 z（从一些简单的概率分布采样得到，如均匀或 高斯分布 ）来增强神经网络。神经
网络在内部仍可以继续执行确定性计算，但是函数 f(x;z)对于不能访问 z的观察者
来说将是随机的。假设 f是连续可微的，我们可以像往常一样使用 反向传播 计算训
练所需的梯度。
作为示例，让我们考虑从均值 和方差 2的高斯分布 中采样 y的操作：
yN (; 2): (20.54)
因为 y的单个样本不是由函数产生的，而是由一个采样过程产生，它的输出会随我
们的每次查询变化，所以取 y相对于其分布的参数 和2的导数似乎是违反直觉
的。然而，我们可以将采样过程重写，对基本随机变量 zN (z; 0;1)进行转换以从
期望的分布获得样本：
y=+z: (20.55)
现在我们将其视为具有额外输入 z的确定性操作，可以通过采样操作来 反向传
播。至关重要的是，额外输入是一个随机变量，其分布不是任何我们想对其计算导
数的变量的函数。如果我们可以用相同的 z值再次重复采样操作，结果会告诉我们
或的微小变化将会如何改变输出。
能够通过该采样操作 反向传播 允许我们将其并入更大的图中。我们可以在采样
分布的输出之上构建图元素。例如，我们可以计算一些 损失函数 J(y)的导数。我们
还可以构建这样的图元素，其输出是采样操作的输入或参数。例如，我们可以通过
=f(x;)和=g(x;)构建更大的图。在这个增强图中，我们可以通过这些函数
的反向传播 导出∇J(y)。
在该高斯采样示例中使用的原理能更广泛地应用。我们可以将任何形为 p(y;)
或p(yjx;)的概率分布表示为 p(yj!)，其中!是同时包含参数 和输入 x的变
量(如果适用的话 )。给定从分布 p(yj!)采样的值 y（其中!可以是其他变量的函
数） ，我们可以将
yp(yj!) (20.56)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.9通过随机操作的反向传播 587
重写为
y=f(z;!); (20.57)
其中 z是随机性的来源。只要 f是几乎处处连续可微的，我们就可以使用传统
工具（例如应用于 f的反向传播 算法）计算 y相对于!的导数。至关重要的是，
!不能是 z的函数，且 z不能是!的函数。这种技术通常被称为 重参数化技巧
（reparametrization trick ） 、随机反向传播 (stochastic back-propagation) 或扰动分析
(perturbation analysis) 。
要求 f是连续可微的，当然需要 y是连续的。如果我们希望通过产生离散值
样本的采样过程进行 反向传播 ，则可以使用 强化学习 算法（如 REINFORCE 算法
(Williams ,1992)的变体）来估计 !上的梯度，这将在第 20.9.1节中讨论。
在神经网络应用中，我们通常选择从一些简单的分布中采样 z，如单位均匀分布
或单位高斯分布 ，并通过网络的确定性部分重塑其输入来实现更复杂的分布。
通过随机操作扩展梯度或优化的想法可追溯到二十世纪中叶 (Price ,1958;
Bonnet ,1964)，并且首先在 强化学习 (Williams ,1992)的情景下用于机器学习。
最近，它已被应用于变分近似 (Opper and Archambeau ,2009)和随机生成神经网
络(Bengio et al. ,2013b ;Kingma ,2013;Kingma and Welling ,2014b ,a;Rezende et al. ,
2014;Goodfellow et al. ,2014c )。许多网络，如 去噪自编码器 或使用 Dropout 的正则
化网络，也被自然地设计为将噪声作为输入，而不需要任何特殊的 重参数化 就能使
噪声独立于模型。
20.9.1 通过离散随机操作的反向传播
当模型发射离散变量 y时，重参数化技巧 不再适用。假设模型采用输入 x和参
数，两者都封装在向量 !中，并且将它们与随机噪声 z组合以产生 y：
y=f(z;!): (20.58)
因为 y是离散的， f必须是一个阶跃函数。阶跃函数的导数在任何点都是没用的。
在每个阶跃边界，导数是未定义的，但这是一个小问题。大问题是导数在阶跃边界
之间的区域几乎处处为零。因此，任何 代价函数 J(y)的导数无法给出如何更新模型
参数的任何信息。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
588 第二十章 深度生成模型
REINFORCE 算法（ REward Increment =nonnegative Factor Oﬀset Rein-
forcementCharacteristic Eligibility ）提供了定义一系列简单而强大解决方案的框
架(Williams ,1992)。其核心思想是，即使 J(f(z;!))是具有无用导数的阶跃函数，
期望代价 Ezp(z)J(f(z;!))通常是服从 梯度下降 的光滑函数。虽然当 y是高维（或
者是许多离散随机决策组合的结果）时，该期望通常是难解的，但我们可以使用 蒙
特卡罗平均进行无偏估计。梯度的随机估计可以与 SGD或其他基于随机梯度的优化
技术一起使用。
通过简单地微分期望成本，我们可以推导出 REINFORCE 最简单的版本：
Ez[J(y)] =∑
yJ(y)p(y); (20.59)
@E[J(y)]
@!=∑
yJ(y)@p(y)
@!(20.60)
=∑
yJ(y)p(y)@logp(y)
@!(20.61)
1
mm∑
y(i)p(y);i=1J(y(i))@logp(y(i))
@!: (20.62)
式(20.60 )依赖于 J不直接引用!的假设。放松这个假设来扩展该方法是简单的。
式(20.61 )利用对数的导数规则，@logp(y)
@!=1
p(y)@p(y)
@!。式 (20.62 )给出了该梯度的无
偏蒙特卡罗 估计。
在本节中我们写的 p(y)，可以等价地写成 p(yjx)。这是因为 p(y)由!参数化，
并且如果 x存在，!包含和 x两者。
简单 REINFORCE 估计的一个问题是其具有非常高的方差，需要采 y的许多
样本才能获得对梯度的良好估计，或者等价地，如果仅绘制一个样本， SGD将收
敛得非常缓慢并将需要较小的 学习率。通过使用 方差减小 （variance reduction ）方
法(Wilson ,1984;L’Ecuyer ,1994)，可以地减少该估计的方差。想法是修改估计量，
使其预期值保持不变，但方差减小。在 REINFORCE 的情况下提出的 方差减小 方
法，涉及计算用于偏移 J(y)的基线 (baseline) 。注意，不依赖于 y的任何偏移 b(w)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.9通过随机操作的反向传播 589
都不会改变估计梯度的期望，因为
Ep(y)[
@logp(y)
@!]
=∑
yp(y)@logp(y)
@!(20.63)
=∑
y@p(y)
@!(20.64)
=@
@!∑
yp(y) =@
@!1 = 0 ; (20.65)
这意味着
Ep(y)[
(J(y) b(!))@logp(y)
@!]
=Ep(y)[
J(y)@logp(y)
@!]
 b(!)Ep(y)[
@logp(y)
@!]
(20.66)
=Ep(y)[
J(y)@logp(y)
@!]
: (20.67)
此外，我们可以通过计算 (J(y) b(!))@logp(y)
@!关于 p(y)的方差，并关于 b(!)最小
化获得最优 b(!)。我们发现这个最佳基线 b(!)i对于向量!的每个元素 !i是不同
的：
b(!)i=Ep(y)[
J(y)@logp(y)2
@!i]
Ep(y)[
@logp(y)2
@!i]: (20.68)
相对于 !i的梯度估计则变为
(J(y) b(!)i)@logp(y)
@!i; (20.69)
其中 b(!)i估计上述 b(!)i。获得估计 b通常需要将额外输出添加到神经网络，并训
练新输出对!的每个元素估计 Ep(y)[J(y)@logp(y)2
@!i]和Ep(y)[@logp(y)2
@!i]。这些额外的输
出可以用 均方误差 目标训练， 对于给定的 !， 从p(y)采样 y时， 分别用 J(y)@logp(y)2
@!i
和@logp(y)2
@!i作目标。然后可以将这些估计代入式 (20.68 )就能恢复估计 b。Mnih and
Gregor (2014)倾向于使用通过目标 J(y)训练的单个共享输出（跨越 !的所有元素
i） ，并使用 b(!)Ep(y)[J(y)]作为基线。
在强化学习 背景下引入的 方差减小 方法 (Sutton et al. ,2000;Weaver and Tao ,
2001)，Dayan (1990)推广了二值奖励的前期工作。可以参考 Bengio et al. (2013b )、DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
590 第二十章 深度生成模型
Mnih and Gregor (2014)、Baet al. (2014)、Mnih et al. (2014)或Xuet al. (2015)中
在深度学习的背景下使用减少方差的 REINFORCE 算法的现代例子。除了使用与输
入相关的基线 b(!)，Mnih and Gregor (2014)发现可以在训练期间调整 (J(y) b(!))
的尺度（即除以训练期间的移动平均估计的标准差） ，即作为一种适应性 学习率，可
以抵消训练过程中该量大小发生的重要变化的影响。 Mnih and Gregor (2014)称之
为启发式 方差归一化 (variance normalization) 。
基于 REINFORCE 的估计器可以被理解为将 y的选择与 J(y)的对应值相关联
来估计梯度。如果在当前参数化下不太可能出现 y的良好值，则可能需要很长时间
来偶然获得它，并且获得所需信号的配置应当被加强。
20.10有向生成网络
如第十六章所讨论的， 有向图模型 构成了一类突出的 图模型。虽然有向图模型 在
更大的机器学习社群中非常流行，但在较小的深度学习社群中，大约直到 2013年它
们都掩盖在 无向模型 （如 RBM）的光彩之下。
在本节中，我们回顾一些传统上与深度学习社群相关的标准 有向图模型 。
我们已经描述过部分有向的模型—— 深度信念网络 。我们还描述过可以被认为
是浅度有向 生成模型 的稀疏编码 模型。尽管在样本生成和密度估计方面表现不佳，
在深度学习的背景下它们通常被用作特征学习器。我们接下来描述多种深度完全有
向的模型。
20.10.1 sigmoid 信念网络
sigmoid信念网络 (Neal,1990)是一种具有特定条件概率分布的 有向图模型 的简
单形式。一般来说，我们可以将 sigmoid信念网络 视为具有二值向量的状态 s，其中
状态的每个元素都受其祖先影响：
p(si) =(∑
j<iWj;isj+bi)
: (20.70)
sigmoid信念网络 最常见的结构是被分为许多层的结构，其中 原始采样 通过一系
列多个隐藏层进行，然后最终生成可见层。这种结构与 深度信念网络 非常相似，但
它们在采样过程开始时的单元彼此独立，而不是从 受限玻尔兹曼机 采样。这种结构DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 591
由于各种原因而令人感兴趣。一个原因是该结构是可见单元上概率分布的通用近似，
即在足够深的情况下，可以任意良好地近似二值变量的任何概率分布（即使各个层
的宽度受限于可见层的维度） (Sutskever and Hinton ,2008)。
虽然生成可见单元的样本在 sigmoid信念网络 中是非常高效的，但是其他大多
数操作不是很高效。给定可见单元，对 隐藏单元 的推断是难解的。因为变分下界涉
及对包含整个层的团求期望， 均匀场推断也是难以处理的。这个问题一直困难到足
以限制有向离散网络的普及。
在sigmoid信念网络 中执行推断的一种方法是构造专用于 sigmoid信念网络 的
不同下界 (Saul et al. ,1996)。这种方法只适用于非常小的网络。另一种方法是使用 学
成推断机制，如第 19.5节中描述的。 Helmholtz 机(Dayan et al. ,1995;Dayan and
Hinton ,1996)结合了一个 sigmoid信念网络 与一个预测 隐藏单元 上均匀场分布参数
的推断网络。 sigmoid信念网络 的现代方法 (Gregor et al. ,2014;Mnih and Gregor ,
2014)仍然使用这种 推断网络的方法。因为 潜变量的离散本质，这些技术仍然是困
难的。人们不能简单地通过 推断网络的输出 反向传播 ，而必须使用相对不可靠的机
制即通过离散采样过程进行 反向传播 （如第 20.9.1节所述） 。最近基于 重要采样 、重
加权的醒眠(Bornschein and Bengio ,2015)或双向 Helmholtz 机(Bornschein et al. ,
2015)的方法使得我们可以快速训练 sigmoid信念网络 ，并在基准任务上达到最好的
表现。
sigmoid信念网络 的一种特殊情况是没有 潜变量的情况。在这种情况下学习是高
效的，因为没有必要将 潜变量边缘化到似然之外。一系列称为 自回归网络 的模型将
这个完全可见的 信念网络 泛化到其他类型的变量（除二值变量）和其他结构（除对
数线性关系）的条件分布。 自回归网络 将在第 20.10.7节中描述。
20.10.2 可微生成器网络
许多生成模型 基于使用可微 生成器网络 （generator network ）的想法。这种模
型使用可微函数 g(z;(g))将潜变量 z的样本变换为样本 x或样本 x上的分布，可
微函数通常可以由神经网络表示。这类模型包括将 生成器网络 与推断网络配对的 变
分自编码器 、将生成器网络 与判别器网络配对的 生成式对抗网络 ，以及孤立地训练 生
成器网络 的技术。
生成器网络 本质上仅是用于生成样本的参数化计算过程，其中的体系结构提供
了从中采样的可能分布族以及选择这些族内分布的参数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
592 第二十章 深度生成模型
作为示例，从具有均值 和协方差 的正态分布绘制样本的标准过程是将来自
零均值和单位协方差的正态分布的样本 z馈送到非常简单的 生成器网络 中。这个 生
成器网络 只包含一个仿射层：
x=g(z) =+Lz; (20.71)
其中 L由的Cholesky 分解给出。
伪随机数发生器也可以使用简单分布的非线性变换。例如， 逆变换采样 (inverse
transform sampling)( Devroye ,2013)从U(0;1)中采一个标量 z，并且对标量 x应用
非线性变换。在这种情况下， g(z)由累积分布函数 F(x) =∫x
 1p(v)dv的反函数给
出。如果我们能够指定 p(x)，在 x上积分，并取所得函数的反函数，我们不用通过
机器学习就能从 p(x)进行采样。
为了从更复杂的分布（难以直接指定、难以积分或难以求所得积分的反函数）
中生成样本，我们使用 前馈网络 来表示非线性函数 g的参数族，并使用训练数据
来推断参数以选择所期望的函数。
我们可以认为 g提供了变量的非线性变化，将 z上的分布变换成 x上想要的分
布。
回顾式 (3.47)，对于可求反函数的、可微的、连续的 g，
pz(z) =px(g(z))det(@g
@z): (20.72)
这隐含地对 x施加概率分布：
px(x) =pz(g 1(x))
jdet(@g
@z)j: (20.73)
当然，取决于 g的选择，这个公式可能难以评估，因此我们经常需要使用间接学习
g的方法，而不是直接尝试最大化 logp(x)。
在某些情况下，我们使用 g来定义 x上的条件分布，而不是使用 g直接提供 x
的样本。例如，我们可以使用一个 生成器网络 ，其最后一层由 sigmoid输出组成，可
以提供 Bernoulli 分布的平均参数：
p(xi= 1jz) =g(z)i: (20.74)
在这种情况下，我们使用 g来定义 p(xjz)时，我们通过边缘化 z来对 x施加分布：
p(x) =Ezp(xjz): (20.75)DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 593
两种方法都定义了一个分布 pg(x)，并允许我们使用第 20.9节中的重参数化技
巧来训练 pg的各种评估 准则。
表示生成器网络 的两种不同方法（发出条件分布的参数相对直接发射样品）具
有互补的优缺点。当 生成器网络 在 x上定义条件分布时，它不但能生成连续数据，
也能生成离散数据。当 生成器网络 直接提供采样时，它只能产生连续的数据（我们
可以在前向传播中引入离散化，但这样做意味着模型不再能够使用 反向传播 进行训
练） 。直接采样的优点是，我们不再被迫使用条件分布（可以容易地写出来并由人类
设计者进行代数操作的形式） 。
基于可微 生成器网络 的方法是由分类可微前馈网络中 梯度下降 的成功应用而推
动的。在 监督学习 的背景中，基于梯度训练学习的深度前馈网络在给定足够的 隐藏
单元和足够的训练数据的情况下，在实践中似乎能保证成功。这个同样的方案能成
功转移到 生成式建模 上吗？
生成式建模 似乎比分类或回归更困难，因为学习过程需要优化难以处理的 准则。
在可微生成器网络 的情况中， 准则是难以处理的，因为数据不指定 生成器网络 的输
入 z和输出 x。在监督学习 的情况下，输入 x和输出 y同时给出，并且优化过程只
需学习如何产生指定的映射。在生成建模的情况下，学习过程需要确定如何以有用
的方式排布 z空间，以及额外的如何从 z映射到 x。
Dosovitskiy et al. (2015)研究了一个简化问题，其中 z和 x之间的对应关系已
经给出。具体来说，训练数据是计算机渲染的椅子图。 潜变量 z是渲染引擎的参数，
描述了椅子模型的选择、椅子的位置以及影响图像渲染的其他配置细节。使用这种
合成的生成数据， 卷积网络 能够学习将图像内容的描述 z映射到渲染图像的近似 x。
这表明当现代可微 生成器网络 具有足够的模型容量时，足以成为良好的 生成模型 ，
并且现代优化算法具有拟合它们的能力。困难在于当每个 x的 z的值不是固定的且
在每次训练前是未知时，如何训练 生成器网络 。
在接下来的章节中，我们讨论仅给出 x的训练样本，训练可微 生成器网络 的几
种方法。
20.10.3 变分自编码器
变分自编码器 （variational auto-encoder ,VAE）(Kingma ,2013;Rezende et al. ,
2014)是一个使用学好的近似 推断的有向模型 ，可以纯粹地使用基于梯度的方法进行DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
594 第二十章 深度生成模型
训练。
为了从模型生成样本， VAE首先从编码分布 pmodel (z)中采样 z。然后使样本通
过可微生成器网络 g(z)。最后，从分布 pmodel (x;g(z)) =pmodel (xjz)中采样 x。然
而在训练期间，近似 推断网络（或 编码器）q(zjx)用于获得 z，而 pmodel (xjz)则
被视为解码器网络。
变分自编码器 背后的关键思想是，它们可以通过最大化与数据点 x相关联的变
分下界L(q)来训练：
L(q) =Ezq(zjx)logpmodel (z;x) +H(q(zjx)) (20.76)
=Ezq(zjx)logpmodel (xjz) DKL(q(zjx)jjpmodel (z)) (20.77)
 logpmodel (x): (20.78)
在式 (20.76 )中，我们将第一项视为 潜变量的近似后验下可见和隐藏变量的联合对数
似然性（正如 EM一样，不同的是我们使用近似而不是精确后验） 。第二项则可视
为近似后验的熵。当 q被选择为 高斯分布 ，其中噪声被添加到预测平均值时，最大
化该熵项促使该噪声标准偏差的增加。更一般地，这个熵项鼓励变分后验将高概率
质量置于可能已经产生 x的许多 z值上，而不是坍缩到单个估计最可能值的点。在
式(20.77 )中，我们将第一项视为在其他 自编码器 中出现的重构对数似然。第二项试
图使近似后验分布 q(zjx)和模型先验 pmodel (z)彼此接近。
变分推断和学习的传统方法是通过优化算法 推断 q，通常是迭代不动点方程
（第 19.4节） 。 这些方法是缓慢的， 并且通常需要以闭解形式计算 Ezqlogpmodel (z;x)。
变分自编码器 背后的主要思想是训练产生 q参数的参数编码器（有时也称为 推断网
络或识别模型） 。只要 z是连续变量，我们就可以通过从 q(zjx) =q(z;f(x;))中
采样 z的样本反向传播 ，以获得相对于 的梯度。学习则仅包括相对于 编码器和解
码器的参数最大化L。L中的所有期望都可以通过 蒙特卡罗 采样来近似。
变分自编码器 方法是优雅的，理论上令人愉快的，并且易于实现。它也获得了出
色的结果，是 生成式建模 中的最先进方法之一。它的主要缺点是从在图像上训练的 变
分自编码器 中采样的样本往往有些模糊。这种现象的原因尚不清楚。一种可能性是
模糊性是最大似然的固有效应，因为我们需要最小化 DKL(pdatajjpmodel )。如图 3.6所
示，这意味着模型将为训练集中出现的点分配高的概率，但也可能为其他点分配高的
概率。还有其他原因可以导致模糊图像。模型选择将概率质量置于模糊图像而不是空
间的其他部分的部分原因是实际使用的 变分自编码器 通常在 pmodel (x;g(z))使用高
斯分布。最大化这种分布似然性的下界与训练具有 均方误差 的传统自编码器 类似，DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 595
这意味着它倾向于忽略由少量像素表示的特征或其中亮度变化微小的像素。如 Theis
et al. (2015)和Huszar (2015)指出的，该问题不是 VAE特有的，而是与优化对数
似然或 DKL(pdatajjpmodel )的生成模型 共享的。现代 VAE模型另一个麻烦的问题是，
它们倾向于仅使用 z维度中的小子集，就像 编码器不能够将具有足够局部方向的输
入空间变换到边缘分布与分解前匹配的空间。
VAE框架可以直接扩展到大范围的模型架构。相比 玻尔兹曼机 ，这是关键的优
势，因为 玻尔兹曼机 需要非常仔细地设计模型来保持易解性。 VAE可以与广泛的可
微算子族一起良好工作。一个特别复杂的 VAE是深度循环注意写者 (DRAW) 模型
(Gregor et al. ,2015)。DRAW使用一个循环编码器和循环解码器并结合 注意力机制 。
DRAW模型的生成过程包括顺序访问不同的小图像块并绘制这些点处的像素值。
我们还可以通过在 VAE框架内使用循环编码器和解码器来定义变分 RNN (Chung
et al. ,2015b )来扩展 VAE以生成序列。从传统 RNN生成样本仅在输出空间涉及
非确定性操作。而变分 RNN还具有由 VAE潜变量捕获的潜在更抽象层的随机变化
性。
VAE框架已不仅仅扩展到传统的变分下界， 还有 重要加权 自编码器 (importance-
weighted autoencoder)( Burda et al. ,2015)的目标：
Lk(x; q) =Ez(1);:::; z(k)q(zjx)[
log1
kk∑
i=1pmodel (x;z(i))
q(z(i)jx)]
: (20.79)
这个新的目标在 k= 1时等同于传统的下界 L。然而，它也可以被解释为基于提议
分布 q(zjx)中 z的重要采样 而形成的真实 logpmodel (x)估计。重要加权 自编码器 目
标也是 logpmodel (x)的下界，并且随着 k增加而变得更紧。
变分自编码器 与MP-DBM 和其他涉及通过近似 推断图的反向传播 方法有一些
有趣的联系 (Goodfellow et al. ,2013d ;Stoyanov et al. ,2011;Brakel et al. ,2013)。
这些以前的方法需要诸如 均匀场不动点方程的 推断过程来提供 计算图。变分自编码
器被定义为任意 计算图，这使得它能适用于更广泛的概率模型族，因为它不需要将
模型的选择限制到具有易处理的 均匀场不动点方程的那些模型。 变分自编码器 还具
有增加模型对数似然边界的优点，而 MP-DBM 和相关模型的 准则更具启发性，并
且除了使近似 推断的结果准确外很少有概率的解释。 变分自编码器 的一个缺点是它
仅针对一个问题学习 推断网络，即给定 x推断 z。较老的方法能够在给定任何其他
变量子集的情况下对任何变量子集执行近似 推断，因为均匀场不动点方程指定如何
在所有这些不同问题的 计算图之间共享参数。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
596 第二十章 深度生成模型
变分自编码器 的一个非常好的特性是，同时训练参数编码器与 生成器网络 的组
合迫使模型学习一个编码器可以捕获的可预测的坐标系。这使得它成为一个优秀
的流形学习 算法。图 20.6展示了由 变分自编码器 学到的低维流形的例子。图中所示
的情况之一，算法发现了存在于面部图像中两个独立的变化因素：旋转角和情绪表
达。
图20.6:由变分自编码器 学习的高维 流形在2维坐标系中的示例 (Kingma and Welling ,2014a )。
我们可以在纸上直接绘制两个可视化的维度，因此可以使用 2维潜在编码训练模型来了解模型的
工作原理（即使我们认为数据 流形的固有维度要高得多） 。图中所示的图像不是来自训练集的样本，
而是仅仅通过改变 2维‘‘编码”z，由模型 p(xjz)实际生成的图像 x（每个图像对应于 ‘‘编码”z
位于 2维均匀网格的不同选择） 。 (左)Frey人脸流形的2维映射。其中一个维度（水平）已发现
大致对应于面部的旋转，而另一个（垂直）对应于情绪表达。 (右)MNIST流形的2维映射。
20.10.4 生成式对抗网络
生成式对抗网络 （generative adversarial network ,GAN）(Goodfellow et al. ,
2014c )是基于可微 生成器网络 的另一种 生成式建模 方法。
生成式对抗网络 基于博弈论场景，其中 生成器网络 必须与对手竞争。 生成器网
络直接产生样本 x=g(z;(g))。其对手， 判别器网络 （discriminator network ） ，试
图区分从训练数据抽取的样本和从生成器抽取的样本。判别器发出由 d(x;(d))给出
的概率值，指示 x是真实训练样本而不是从模型抽取的伪造样本的概率。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 597
形式化表示 生成式对抗网络 中学习的最简单方式是零和游戏，其中函数
v((g);(d))确定判别器的收益。生成器接收  v((g);(d))作为它自己的收益。
在学习期间，每个玩家尝试最大化自己的收益，因此收敛在
g= arg min
gmax
dv(g; d): (20.80)
v的默认选择是
v((g);(d)) =Expdata logd(x) +Expmodel log(1 d(x)): (20.81)
这驱使判别器试图学习将样品正确地分类为真的或伪造的。同时，生成器试图欺骗
分类器以让其相信样本是真实的。在收敛时，生成器的样本与实际数据不可区分，并
且判别器处处都输出1
2。然后就可以丢弃判别器。
设计 GAN的主要动机是学习过程既不需要近似 推断也不需要 配分函数 梯度的
近似。当 max dv(g; d)在(g)中是凸的（例如，在 概率密度函数 的空间中直接执行
优化的情况）时，该过程保证收敛并且是渐近一致的。
不幸的是， 在实践中由神经网络表示的 g和d以及 max dv(g; d)不凸时， GAN中
的学习可能是困难的。 Goodfellow (2014)认为不收敛可能会引起 GAN的欠拟合问
题。一般来说，同时对两个玩家的成本梯度下降不能保证达到平衡。例如，考虑价
值函数 v(a; b) =ab，其中一个玩家控制 a并产生成本 ab，而另一玩家控制 b并接
收成本 ab。如果我们将每个玩家建模为无穷小的梯度步骤，每个玩家以另一个玩
家为代价降低自己的成本，则 a和b进入稳定的圆形轨迹，而不是到达原点处的平
衡点。注意，极小极大化游戏的平衡不是 v的局部最小值。相反，它们是同时最小
化的两个玩家成本的点。这意味着它们是 v的鞍点，相对于第一个玩家的参数是局
部最小值，而相对于第二个玩家的参数是局部最大值。两个玩家可以永远轮流增加
然后减少 v，而不是正好停在玩家没有能力降低其成本的鞍点。目前不知道这种不收
敛的问题会在多大程度上影响 GAN。
Goodfellow (2014)确定了另一种替代的形式化收益公式，其中博弈不再是零和，
每当判别器最优时，具有与最大似然学习相同的预期梯度。因为最大似然训练收敛，
这种 GAN博弈的重述在给定足够的样本时也应该收敛。不幸的是，这种替代的形
式化似乎并没有提高实践中的收敛，可能是由于判别器的次优性或围绕期望梯度的
高方差。
在真实实验中， GAN博弈的最佳表现形式既不是零和也不等价于最大似然，而
是Goodfellow et al. (2014c )引入的带有启发式动机的不同形式化。在这种最佳性能DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
598 第二十章 深度生成模型
的形式中，生成器旨在增加判别器发生错误的对数概率，而不是旨在降低判别器进
行正确预测的对数概率。这种重述仅仅是观察的结果，即使在判别器确信地拒绝所
有生成器样本的情况下，它也能导致生成器代价函数的导数相对于判别器的对数保
持很大。
稳定 GAN学习仍然是一个开放的问题。幸运的是，当仔细选择模型架构和
超参数时， GAN学习效果很好。 Radford et al. (2015)设计了一个深度卷积 GAN
（DCGAN ） ，在图像合成的任务上表现非常好，并表明其 潜在的表示空间能捕获到变
化的重要因素，如图 15.9所示。图 20.7展示了 DCGAN 生成器生成的图像示例。
图20.7:在LSUN数据集上训练后，由 GAN生成的图像。 (左)由DCGAN 模型生成的卧室图
像，经 Radford et al. (2015)许可转载。 (右)由LAPGAN 模型生成的教堂图像，经 Denton et al.
(2015)许可转载。
GAN学习问题也可以通过将生成过程分成许多级别的细节来简化。我们可以训
练有条件的 GAN (Mirza and Osindero ,2014)，并学习从分布 p(xjy)中采样，而不
是简单地从边缘分布 p(x)中采样。 Denton et al. (2015)表明一系列的条件 GAN可
以被训练为首先生成非常低分辨率的图像，然后增量地向图像添加细节。由于使用
拉普拉斯金字塔来生成包含不同细节水平的图像，这种技术被称为 LAPGAN 模型。
LAPGAN 生成器不仅能够欺骗判别器网络，而且能够欺骗人类观察者，实验主体将
高达 40％的网络输出识别为真实数据。请看图 20.7中LAPGAN 生成器生成的图像
示例。
GAN训练过程中一个不寻常的能力是它可以拟合向训练点分配零概率的概率
分布。生成器网络 学习跟踪其点在某种程度上类似于训练点的流形，而不是最大化
特定点的对数概率。有点矛盾的是，这意味着模型可以将负无穷大的对数似然分配DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 599
给测试集，同时仍然表示人类观察者判断为能捕获生成任务本质的流形。这不是明
显的优点或缺点，并且只要向 生成器网络 最后一层所有生成的值添加高斯噪声，就
可以保证 生成器网络 向所有点分配非零概率。以这种方式添加高斯噪声的 生成器网
络从相同分布的采样，即使用 生成器网络 参数化条件 高斯分布 的均值所获得的分布。
Dropout 似乎在判别器网络中很重要。特别地，在计算 生成器网络 的梯度时，单
元应当被随机地丢弃。使用权重除以二的确定性版本的判别器的梯度似乎不是那么
有效。同样，从不使用 Dropout 似乎会产生不良的结果。
虽然 GAN框架被设计为用于可微 生成器网络 ，但是类似的原理可以用于训练其
他类型的模型。例如， 自监督提升 ( self-supervised boosting) 可以用于训练 RBM生
成器以欺骗 逻辑回归 判别器 (Welling et al. ,2002)。
20.10.5 生成矩匹配网络
生成矩匹配网络 （generative moment matching network ）(Liet al. ,2015;Dzi-
ugaite et al. ,2015)是另一种基于可微 生成器网络 的生成模型 。与 VAE和GAN不
同，它们不需要将 生成器网络 与任何其他网络配对，如不需要与用于 VAE的推断网
络配对，也不需要与 GAN的判别器网络。
生成矩匹配网络 使用称为 矩匹配（moment matching ）的技术训练。 矩匹配背
后的基本思想是以如下的方式训练生成器——令模型生成的样本的许多统计量尽可
能与训练集中的样本相似。在此情景下， 矩（moment）是对随机变量不同幂的期
望。例如，第一 矩是均值，第二 矩是平方值的均值，以此类推。多维情况下，随机向
量的每个元素可以被升高到不同的幂，因此使得 矩可以是任意数量的形式
Ex∏
ixni
i; (20.82)
其中 n= [n1; n2; : : : ; n d]⊤是一个非负整数的向量。
在第一次检查时，这种方法似乎在计算上是不可行的。例如，如果我们想匹配
形式为 xixj的所有矩，那么我们需要最小化在 x的维度上是二次的多个值之间的
差。此外，甚至匹配所有第一和第二 矩将仅足以拟合多变量 高斯分布 ，其仅捕获值
之间的线性关系。我们使用神经网络的野心是捕获复杂的非线性关系，这将需要更
多的矩。GAN通过使用动态更新的判别器避免了穷举所有 矩的问题，该判别器自动
将其注意力集中在 生成器网络 最不匹配的统计量上。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
600 第二十章 深度生成模型
相反，我们可以通过最小化一个被称为 最大平均偏差 （maximum mean dis-
crepancy ,MMD）(Schölkopf and Smola ,2002;Gretton et al. ,2012)的代价函数 来
训练生成矩匹配网络 。该代价函数 通过向核函数定义的特征空间隐式映射，在无限
维空间中测量第一 矩的误差，使得对无限维向量的计算变得可行。当且仅当所比较
的两个分布相等时， MMD代价为零。
从可视化方面看，来自 生成矩匹配网络 的样本有点令人失望。幸运的是，它们
可以通过将 生成器网络 与自编码器 组合来改进。首先，训练 自编码器 以重构训练集。
接下来， 自编码器 的编码器用于将整个训练集转换到编码空间。然后训练 生成器网
络以生成编码样本，这些编码样本可以经解码器映射到视觉上令人满意的样本。
与GAN不同，代价函数 仅关于一批同时来自训练集和 生成器网络 的实例定义。
我们不可能将训练更新作为一个训练样本或仅来自 生成器网络 的一个样本的函数。
这是因为必须将 矩计算为许多样本的经验平均值。当批量大小太小时， MMD可能
低估采样分布的真实变化量。有限的批量大小都不足以大到完全消除这个问题，但
是更大的批量大小减少了低估的量。当批量大小太大时，训练过程就会慢得不可行，
因为计算单个小梯度步长必须一下子处理许多样本。
与GAN一样，即使 生成器网络 为训练点分配零概率，仍可以使用 MMD训练生
成器网络 。
20.10.6 卷积生成网络
当生成图像时，将卷积结构的引入 生成器网络 通常是有用的（见 Goodfellow
et al. (2014c )或Dosovitskiy et al. (2015)的例子） 。为此，我们使用卷积算子的 ‘‘转
置’’，如第 9.5节所述。这种方法通常能产生更逼真的图像，并且比不使用 参数共享 的
全连接层使用更少的参数。
用于识别任务的 卷积网络 具有从图像到网络顶部的某些概括层（通常是类标签）
的信息流。当该图像通过网络向上流动时，随着图像的表示变得对于有害变换保持
不变，信息也被丢弃。在 生成器网络 中，情况恰恰相反。要生成图像的表示通过网络
传播时必须添加丰富的详细信息，最后产生图像的最终表示，这个最终表示当然是
带有所有细节的精细图像本身（具有对象位置、姿势、纹理以及明暗） 。在卷积识别
网络中丢弃信息的主要机制是池化层。而 生成器网络 似乎需要添加信息。由于大多
数池化函数不可逆，我们不能将池化层求逆后放入 生成器网络 。更简单的操作是仅
仅增加表示的空间大小。似乎可接受的方法是使用 Dosovitskiy et al. (2015)引入的DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 601
‘‘去池化 ’’。该层对应于某些简化条件下 最大池化 的逆操作。首先， 最大池化 操作的
步幅被约束为等于池化区域的宽度。其次，每个池化区域内的最大输入被假定为左
上角的输入。最后，假设每个池化区域内所有非最大的输入为零。这些是非常强和
不现实的假设，但它们允许我们对 最大池化 算子求逆。逆去池化的操作分配一个零
张量，然后将每个值从输入的空间坐标 i复制到输出的空间坐标 ik。整数值 k定
义池化区域的大小。即使驱动去池化算子定义的假设是不现实的，后续层也能够学
习补偿其不寻常的输出，所以由整体模型生成的样本在视觉上令人满意。
20.10.7 自回归网络
自回归网络 是没有潜在随机变量的有向概率模型。这些模型中的条件概率分布
由神经网络表示（有时是极简单的神经网络，例如 逻辑回归 ） 。这些模型的图结构
是完全图。它们可以通过概率的链式法则分解观察变量上的联合概率，从而获得形
如P(xdjxd 1; : : : ; x 1)条件概率的乘积。这样的模型被称为 完全可见的贝叶斯网
络（fully-visible Bayes networks, FVBN ） ，并成功地以许多形式使用，首先是对每
个条件分布 逻辑回归 (Frey,1998)，然后是带有 隐藏单元 的神经网络 (Bengio and
Bengio ,2000b ;Larochelle and Murray ,2011)。在某些形式的 自回归网络 中，例如在
第20.10.10节中描述的 NADE (Larochelle and Murray ,2011)，我们可以引入 参数共
享的一种形式，它能带来统计优点（较少的唯一参数）和计算优势（较少计算量） 。
这是深度学习中反复出现的主题—— 特征重用 的另一个实例。
20.10.8 线性自回归网络
自回归网络 的最简单形式是没有 隐藏单元 、没有参数或特征共享的形式。每个
P(xijxi 1; : : : ; x 1)被参数化为 线性模型 （对于实值数据的 线性回归 ，对于二值数据
的逻辑回归 ，对于离散数据的 softmax回归） 。这个模型由 Frey (1998)引入，当有 d
个变量要建模时，该模型有 O(d2)个参数。如图 20.8所示。
如果变量是连续的， 线性自回归网络 只是表示多元 高斯分布 的另一种方式，只
能捕获观察变量之间线性的成对相互作用。
线性自回归网络 本质上是线性分类方法在 生成式建模 上的推广。因此，它们具
有与线性分类器相同的优缺点。像线性分类器一样，它们可以用凸 损失函数 训练，并
且有时允许闭解形式（如在高斯情况下） 。像线性分类器一样，模型本身不提供增加DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
602 第二十章 深度生成模型
x1x1x2x2x3x3x4x4P(x4|x1,x2,x3)P(x4|x1,x2,x3)P(x3|x1,x2)P(x3|x1,x2)P(x2|x1)P(x2|x1)P(x1)P(x1)x1x1x2x2x3x3x4x4
图20.8:完全可见的 信念网络 从前 i 1个变量预测第 i个变量。 (上)FVBN的有向图模型 。(下)
对数 FVBN相应的计算图，其中每个预测由线性预测器作出。
其容量的方法，因此必须使用其他技术（如输入的基扩展或核技巧）来提高容量。
20.10.9 神经自回归网络
神经自回归网络 (Bengio and Bengio ,2000a ,b)具有与逻辑 自回归网络 相同的从
左到右的 图模型（图 20.8） ，但在该 图模型结构内采用不同的条件分布参数。新的参
数化更强大，它可以根据需要随意增加容量，并允许近似任意联合分布。新的参数
化还可以引入深度学习中常见的参数共享和特征共享原理来改进 泛化能力。设计这
些模型的动机是避免传统表格 图模型引起的维数灾难 ，并与图 20.8共享相同的结构。
在表格离散概率模型中，每个条件分布由概率表表示，其中所涉及的变量的每个可
能配置都具有一个条目和一个参数。通过使用神经网络，可以获得两个优点：
1.通过具有 (i 1)k个输入和 k个输出的神经网络（如果变量是离散的并有 k
个值，使用 one-hot编码）参数化每个 P(xijxi 1; : : : ; x 1)，让我们不需要指数
量级参数（和样本）的情况下就能估计条件概率，然而仍然能够捕获随机变量
之间的高阶依赖性。
2.不需要对预测每个 xi使用不同的神经网络，如图 20.9所示的从左到右连接，允DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.10有向生成网络 603
许将所有神经网络合并成一个。等价地，它意味着为预测 xi所计算的 隐藏层特
征可以重新用于预测 xi+k(k > 0)。因此隐藏单元 被组织成第 i组中的所有单
元仅依赖于输入值 x1; : : : ; x i的特定的组。用于计算这些 隐藏单元 的参数被联
合优化以改进对序列中所有变量的预测。这是 重用原理 的一个实例，这是从循
环和卷积网络 架构到多任务和 迁移学习 的场景中反复出现的深度学习原理。
x1x1x2x2x3x3x4x4h1h1h2h2h3h3P(x4|x1,x2,x3)P(x4|x1,x2,x3)P(x3|x1,x2)P(x3|x1,x2)P(x2|x1)P(x2|x1)P(x1)P(x1)
图20.9:神经自回归网络 从前 i 1个变量预测第 i个变量 xi，但经参数化后，作为 x1; : : : ; x i函
数的特征（表示为 hi的隐藏单元 的组）可以在预测所有后续变量 xi+1; xi+2; : : : ; x d时重用。
如在第 6.2.2.1节中讨论的，使神经网络的输出预测 xi条件分布的 参数，每
个P(xijxi 1; : : : ; x 1)就可以表示一个条件分布。虽然原始 神经自回归网络 最初
是在纯粹离散多变量数据（带有 sigmoid 输出的 Bernoulli 变量或 softmax 输出
的Multinoulli 变量）的背景下评估，但我们可以自然地将这样的模型扩展到连续变
量或同时涉及离散和连续变量的联合分布。
20.10.10 NADE
神经自回归密度估计器 （neural auto-regressive density estimator ,NADE）是最
近非常成功的 神经自回归网络 的一种形式 (Larochelle and Murray ,2011)。与Bengio
and Bengio (2000b )的原始神经自回归网络 中的连接相同，但 NADE引入了附加
的参数共享 方案，如图 20.10所示。不同组 j的隐藏单元 的参数是共享的。
从第 i个输入 xi到第 j组隐藏单元 的第 k个元素 h(j)
k(ji)的权重 W′
j;k;i是DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
604 第二十章 深度生成模型
组内共享的：
W′
j;k;i=Wk;i: (20.83)
其余 j < i的权重为零。
x1x1x2x2x3x3x4x4h1h1h2h2h3h3P(x4|x1,x2,x3)P(x4|x1,x2,x3)P(x3|x1,x2)P(x3|x1,x2)P(x2|x1)P(x2|x1)P(x1)P(x1)
W:,1W:,1W:,1W:,2W:,2W:,3
图20.10:神经自回归密度估计器 （NADE）的示意图。 隐藏单元 被组织在组 h(j)中，使得只有输
入x1; : : : ; x i参与计算 h(i)和预测 P(xjjxj 1; : : : ; x 1)（对于 j > i） 。NADE使用特定的权重共
享模式区别于早期的 神经自回归网络 ：W′
j;k;i =Wk;i被共享于所有从 xi到任何 ji组中第 k个
单元的权重（在图中使用相同的线型表示复制权重的每个实例） 。注意向量 (W1;i; W2;i; : : : ; W n;i)
记为 W:;i。
Larochelle and Murray (2011)选择了这种共享方案，使得 NADE模型中的正
向传播与在 均匀场推断中执行的计算大致相似，以填充 RBM中缺失的输入。这个 均
匀场推断对应于运行具有共享权重的循环网络，并且该 推断的第一步与 NADE中的
相同。使用 NADE的唯一区别是，连接 隐藏单元 到输出的输出权重独立于连接输入
单元和隐藏单元 的权重进行参数化。在 RBM中，隐藏到输出的权重是输入到隐藏
权重的转置。 NADE架构可以扩展为不仅仅模拟 均匀场循环推断的一个时间步，而
是k步。这种方法称为 NADE -k(Raiko et al. ,2014)。
如前所述， 自回归网络 可以被扩展成处理连续数据。用于参数化连续密度的特别
强大和通用的方法是混合权重为 i（组 i的系数或先验概率） ，每组条件均值为 i
和每组条件方差为 2
i的高斯混合体。一个称为 RNADE 的模型 (Uria et al. ,2013)
使用这种参数化将 NADE扩展到实值。与其他混合密度网络一样，该分布的参数是
网络的输出，由 softmax 单元产生混合的权量概率以及参数化的方差，因此可使它DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.11从自编码器 采样 605
们为正的。由于条件均值 i和条件方差 2
i之间的相互作用， 随机梯度下降 在数值
上可能会表现不好。为了减少这种困难， Uria et al. (2013)在后向传播阶段使用伪梯
度代替平均值上的梯度。
另一个非常有趣的神经自回归架构的扩展摆脱了为观察到的变量选择任意顺序
的需要 (Murray and Larochelle ,2014)。在自回归网络 中，该想法是训练网络以能够
通过随机采样顺序来处理任何顺序，并将信息提供给指定哪些输入被观察的 隐藏单
元（在条件条的右侧） ，以及哪些是被预测并因此被认为是缺失的（在条件条的左
侧） 。这是不错的性质，因为它允许人们非常高效地使用训练好的 自回归网络 来执行
任何推断问题（即从给定任何变量的子集，从任何子集上的概率分布预测或采样） 。
最后，由于变量的许多顺序是可能的（对于 n个变量是 n!） ，并且变量的每个顺序 o
产生不同的 p(xjo)，我们可以组成许多 o值模型的集成：
pensemble (x) =1
kk∑
i=1p(xjo(i)): (20.84)
这个集成模型通常能更好地 泛化，并且为测试集分配比单个排序定义的单个模型更
高的概率。
在同一篇文章中，作者提出了深度版本的架构，但不幸的是，这立即使计算成
本像原始 神经自回归网络 一样高 (Bengio and Bengio ,2000b )。第一层和输出层仍然
可以在O(nh)的乘法 -加法操作中计算，如在常规 NADE中，其中 h是隐藏单元 的
数量（图 20.10和图 20.9中的组 hi的大小） ，而它在 Bengio and Bengio (2000b )中
是O(n2h)。然而，对于其他 隐藏层的计算量是O(n2h2)（假设在每个层存在 n组h
个隐藏单元 ，且在 l层的每个 ‘‘先前’’组参与预测 l+ 1层处的 ‘‘下一个 ’’组） 。如
在Murray and Larochelle (2014)中，使 l+ 1层上的第 i个组仅取决于第 i个组， l
层处的计算量将减少到 O(nh2)，但仍然比常规 NADE差h倍。
20.11从自编码器 采样
在第十四章中，我们看到许多种学习数据分布的 自编码器 。得分匹配 、去噪自
编码器和收缩自编码器 之间有着密切的联系。这些联系表明某些类型的 自编码器 以
某些方式学习数据分布。我们还没有讨论如何从这样的模型中采样。
某些类型的 自编码器 ，例如变分自编码器 ，明确地表示概率分布并且允许直接
的原始采样 。而大多数其他类型的 自编码器 则需要 MCMC采样。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
606 第二十章 深度生成模型
收缩自编码器 被设计为恢复数据流形切面的估计。这意味着使用注入噪声的
重复编码和解码将引起沿着流形表面的随机游走 (Rifai et al. ,2012;Mesnil et al. ,
2012)。这种流形扩散技术是 马尔可夫链 的一种。
更一般的 马尔可夫链 还可以从任何 去噪自编码器 中采样。
20.11.1 与任意去噪自编码器 相关的马尔可夫链
上述讨论留下了一个开放问题——注入什么噪声和从哪获得 马尔可夫链 （可以
根据自编码器 估计的分布生成样本） 。 Bengio et al. (2013d )展示了如何构建这种用
于广义去噪自编码器 (generalized denoising autoencoder) 的马尔可夫链 。广义去噪
自编码器 由去噪分布指定，给定损坏输入后，对干净输入的估计进行采样。
根据估计分布生成的 马尔可夫链 的每个步骤由以下子步骤组成，如图 20.11所
示：
1.从先前状态 x开始，注入损坏噪声，从 C(~xjx)中采样 ~x。
2.将~x编码为 h=f(~x)。
3.解码 h以获得 p(xj!=g(h)) =p(xj~x)的参数!=g(h)。
4.从p(xj!=g(h)) =p(xj~x)采样下一状态 x。
Bengio et al. (2014)表明，如果 自编码器 p(xj~x)形成对应真实条件分布的一致估
计量，则上述 马尔可夫链 的平稳分布形成数据生成分布 x的一致估计量（虽然是隐
式的） 。
20.11.2 夹合与条件采样
与玻尔兹曼机 类似，去噪自编码器 及其推广（例如下面描述的 GSN）可用于
从条件分布 p(xfjxo)中采样，只需夹合 观察单元 xf并在给定 xf和采好的 潜变
量（如果有的话）下仅重采样 自由单元 xo。例如， MP-DBM 可以被解释为 去噪自
编码器的一种形式，并且能够采样丢失的输入。 GSN随后将 MP-DBM 中的一些想
法推广以执行相同的操作 (Bengio et al. ,2014)。Alain et al. (2015)从Bengio et al.
(2014)的命题 1中发现了一个缺失条件，即转移算子（由从链的一个状态到下一个DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.11从自编码器 采样 607
xx˜x˜xhh!!ˆxˆxC(˜x|x)p(x|!)fg
图20.11:马尔可夫链 的每个步骤与训练好的 去噪自编码器 相关联，根据由去噪对数似然 准则隐式
训练的概率模型生成样本。每个步骤包括： (a)通过损坏过程 C向状态 x注入噪声产生 ~x，(b)用
函数 f对其编码，产生 h=f(~x)，(c)用函数 g解码结果，产生用于 重构分布的参数!，(d)给
定!，从重构分布 p(xj!=g(f(~x)))采样新状态。在典型的平方 重构误差 情况下， g(h) =^x，并
估计E[xj~x]，损坏包括添加高斯噪声，并且从 p(xj!)的采样包括第二次向 重构 ^x添加高斯噪声。
后者的噪声水平应对应于 重构的均方误差 ，而注入的噪声是控制混合速度以及估计器平滑经验分
布程度的超参数 (Vincent ,2011)。在这所示的例子中，只有 C和p条件是随机步骤（ f和g是
确定性计算） ，我们也可以在 自编码器 内部注入噪声，如 生成随机网络 (Bengio et al. ,2014)。
状态的随机映射定义）应该满足 细致平衡 （detailed balance ）的属性，表明无论转
移算子正向或反向运行， 马尔可夫链 都将保持平衡。
在图 20.12中展示了夹合一半像素（图像的右部分）并在另一半上运行 马尔可夫
链的实验。
20.11.3 回退训练过程
回退训练过程由 Bengio et al. (2013d )等人提出，作为一种加速 去噪自编码器 生
成训练收敛的方法。不像执行一步编码 -解码重建，该过程有代替的多个随机编码 -解
码步骤组成（如在生成 马尔可夫链 中） ，以训练样本初始化（正如在第 18.2节中描述
的对比散度 算法） ，并惩罚最后的概率重建（或沿途的所有重建） 。
训练 k个步骤与训练一个步骤是等价的（在实现相同稳态分布的意义上） ，但是
实际上可以更有效地去除来自数据的伪模式。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
608 第二十章 深度生成模型
图20.12:在每步仅重采样左半部分，夹合图像的右半部分并运行 马尔可夫链 的示意图。这些样本
来自重构 MNIST数字的 GSN（每个时间步使用回退过程） 。
20.12生成随机网络
生成随机网络 （generative stochastic network ,GSN）(Bengio et al. ,2014)是去
噪自编码器 的推广，除可见变量（通常表示为 x）之外，在生成 马尔可夫链 中还包
括潜变量 h。
GSN由两个条件概率分布参数化，指定 马尔可夫链 的一步：
1.p(x(k)jh(k))指示在给定当前 潜在状态下如何产生下一个可见变量。这种 ‘‘重
建分布 ’’也可以在 去噪自编码器 、RBM、DBN和DBM中找到。
2.p(h(k)jh(k 1);x(k 1))指示在给定先前的 潜在状态和可见变量下如何更新 潜
在状态变量。
去噪自编码器 和GSN不同于经典的概率模型（有向或无向） ，它们自己参数化
生成过程而不是通过可见和 潜变量的联合分布的数学形式。相反，后者 如果存在则
隐式地定义为生成 马尔可夫链 的稳态分布。存在稳态分布的条件是温和的，并且需
要与标准 MCMC方法相同的条件（见第 17.3节） 。这些条件是保证链混合的必要条DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.13其他生成方案 609
件，但它们可能被某些过渡分布的选择（例如，如果它们是确定性的）所违反。
我们可以想象 GSN不同的训练 准则。由 Bengio et al. (2014)提出和评估的
只对可见单元上对数概率的重建，如应用于 去噪自编码器 。通过将 x(0)= x夹
合到观察到的样本并且在一些后续 时间步处使生成 x的概率最大化，即最大化
logp(x(k)= xjh(k))，其中给定 x(0)= x后， h(k)从链中采样。为了估计相对于模
型其他部分的 logp(x(k)= xjh(k))的梯度， Bengio et al. (2014)使用了在第 20.9节
中介绍的 重参数化技巧 。
回退训练过程（在第 20.11.3节中描述）可以用来改善训练 GSN的收敛性 (Ben-
gioet al. ,2014)。
20.12.1 判别性 GSN
GSN的原始公式 (Bengio et al. ,2014)用于无监督学习 和对观察数据 x的p(x)
的隐式建模，但是我们可以修改框架来优化 p(yjx)。
例如， Zhou and Troyanskaya (2014)以如下方式推广 GSN，只反向传播 输出变
量上的重建对数概率，并保持输入变量固定。他们将这种方式成功应用于建模序列
（蛋白质二级结构） ，并在 马尔可夫链 的转换算子中引入（一维）卷积结构。重要的
是要记住，对于 马尔可夫链 的每一步，我们需要为每个层生成新序列，并且该序列
用于在下一 时间步计算其他层的值（例如下面一个和上面一个）的输入。
因此，马尔可夫链 确实不只是输出变量（与更高层的 隐藏层相关联） ，并且输入
序列仅用于条件化该链，其中 反向传播 使得它能够学习输入序列如何条件化由 马尔
可夫链隐含表示的输出分布。因此这是在结构化输出中使用 GSN的一个例子。
Zöhrer and Pernkopf (2014)引入了一个混合模型，通过简单地添加（使用不
同的权重）监督和非监督成本即 y和 x的重建对数概率，组合了监督目标（如上
面的工作）和无监督目标（如原始的 GSN） 。Larochelle and Bengio (2008b )以前
在RBM中就提出了这样的混合标准。他们展示了在这种方案下分类性能的提升。
20.13其他生成方案
目前为止我们已经描述的方法，使用 MCMC采样、原始采样 或两者的一些混
合来生成样本。虽然这些是 生成式建模 中最流行的方法，但它们绝不是唯一的方法。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
610 第二十章 深度生成模型
Sohl-Dickstein et al. (2015)开发了一种基于非平衡热力学学习 生成模型 的扩散
反演 (diﬀusion inversion) 训练方案。该方法基于我们希望从中采样的概率分布具有
结构的想法。这种结构会被递增地使概率分布具有更多熵的扩散过程逐渐破坏。为
了形成生成模型 ，我们可以反过来运行该过程，通过训练模型逐渐将结构恢复到非
结构化分布。通过迭代地应用使分布更接近目标分布的过程，我们可以逐渐接近该
目标分布。在涉及许多迭代以产生样本的意义上，这种方法类似于 MCMC方法。然
而，模型被定义为由链的最后一步产生的概率分布。在这个意义上，没有由迭代过程
诱导的近似。 Sohl-Dickstein et al. (2015)介绍的方法也非常接近于 去噪自编码器 的
生成解释（第 20.11.1节） 。与去噪自编码器 一样，扩散反演训练一个尝试概率地撤消
添加的噪声效果的转移算子。不同之处在于，扩散反演只需要消除扩散过程的一个
步骤，而不是一直返回到一个干净的数据点。这解决了 去噪自编码器 的普通重建对
数似然目标中存在的以下两难问题：小噪声的情况下学习者只能看到数据点附近的
配置，而在大噪声的情况下， 去噪自编码器 被要求做几乎不可能的工作（因为去噪
分布是高度复杂和 多峰值的） 。利用扩散反演目标，学习者可以更精确地学习数据点
周围的密度形状，以及去除可能在远离数据点处出现的假性模式。
样本生成的另一种方法是 近似贝叶斯计算 （approximate Bayesian computation ,
ABC）框架 (Rubin et al. ,1984)。在这种方法中，样本被拒绝或修改以使样本选定
函数的矩匹配期望分布的那些 矩。虽然这个想法与 矩匹配一样使用样本的 矩，但它
不同于矩匹配，因为它修改样本本身，而不是训练模型来自动发出具有正确 矩的样
本。Bachman and Precup (2015)展示了如何在深度学习的背景下使用 ABC中的想
法，即使用 ABC来塑造 GSN的MCMC轨迹。
我们期待更多其他等待发现的 生成式建模 方法。
20.14评估生成模型
研究生成模型 的研究者通常需要将一个 生成模型 与另一个 生成模型 比较，通常
是为了证明新发明的 生成模型 比之前存在的模型更能捕获一些分布。
这可能是一个困难且微妙的任务。通常，我们不能实际评估模型下数据的对数
概率，但仅可以评估一个近似。在这些情况下，重要的是思考和沟通清楚正在测量
什么。例如，假设我们可以评估模型 A对数似然的随机估计和模型 B对数似然的
确定性下界。如果模型 A得分高于模型 B，哪个更好？如果我们关心确定哪个模型DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.14评估生成模型 611
具有分布更好的内部表示，我们实际上不能说哪个更好，除非我们有一些方法来确
定模型 B的边界有多松。然而，如果我们关心在实践中该模型能用得多好，例如执
行异常检测，则基于特定于感兴趣的实际任务的准则，可以公平地说模型是更好的，
例如基于排名测试样例和排名标准，如 精度和召回率。
评估生成模型 的另一个微妙之处是，评估指标往往是自身困难的研究问题。可
能很难确定模型是否被公平比较。例如，假设我们使用 AIS来估计 logZ以便为我
们刚刚发明的新模型计算 log~p(x) logZ。AIS计算经济的实现可能无法找到模型
分布的几种模式并低估 Z，这将导致我们高估 logp(x)。因此可能难以判断高似然估
计是否是良好模型或不好的 AIS实现导致的结果。
机器学习的其他领域通常允许在数据预处理中有一些变化。例如，当比较 对象
识别算法的准确性时，通常可接受的是对每种算法略微不同地预处理输入图像（基
于每种算法具有何种输入要求） 。而因为预处理的变化，会导致 生成式建模 的不同，
甚至非常小和微妙的变化也是完全不可接受的。对输入数据的任何更改都会改变要
捕获的分布，并从根本上改变任务。例如，将输入乘以 0:1将人为地将概率增加 10
倍。
预处理的问题通常在基于 MNIST数据集上的 生成模型 产生， MNIST数据集是
非常受欢迎的 生成式建模 基准之一。 MNIST由灰度图像组成。一些模型将 MNIST
图像视为实向量空间中的点，而其他模型将其视为二值。还有一些将灰度值视为二
值样本的概率。我们必须将实值模型仅与其他实值模型比较，二值模型仅与其他二
值模型进行比较。否则，测量的似然性不在相同的空间。对于二值模型，对数似然可
以最多为零，而对于实值模型，它可以是任意高的，因为它是关于密度的测度。在
二值模型中，比较使用完全相同的二值化模型是重要的。例如，我们可以将 0:5设
为阈值后，将灰度像素二值化为 0或1，或者通过由灰度像素强度给出样本为 1的
概率来采一个随机样本。如果我们使用随机二值化，我们可能将整个数据集二值化
一次，或者我们可能为每个训练步骤采不同的随机样例，然后采多个样本进行评估。
这三个方案中的每一个都会产生极不相同的似然数，并且当比较不同的模型时，两
个模型使用相同的二值化方案来训练和评估是重要的。事实上，应用单个随机二值
化步骤的研究者共享包含随机二值化结果的文件，使得基于二值化步骤的不同输出
的结果没有差别。
因为从数据分布生成真实样本是 生成模型 的目标之一，所以实践者通常通过视
觉检查样本来评估 生成模型 。在最好的情况下，这不是由研究人员本身，而是由不
知道样品来源的实验受试者完成 (Denton et al. ,2015)。不幸的是，非常差的概率DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
612 第二十章 深度生成模型
模型可能会产生非常好的样本。验证模型是否仅复制一些训练示例的常见做法如
图16.1所示。该想法是根据在 x空间中的欧几里得距离，为一些生成的样本显示它
们在训练集中的最近邻。此测试旨在检测模型 过拟合训练集并仅再现训练实例的情
况。甚至可能同时 欠拟合和过拟合，但仍然能产生单独看起来好的样本。想象一下，
生成模型 用狗和猫的图像训练时，但只是简单地学习来重现狗的训练图像。这样的
模型明显 过拟合，因为它不能产生不在训练集中的图像，但是它也 欠拟合，因为它
不给猫的训练图像分配概率。然而，人类观察者将判断狗的每个个体图像都是高质
量的。在这个简单的例子中，对于能够检查许多样本的人类观察者来说，确定猫的
不存在是容易的。在更实际的设定中，在具有数万个模式的数据上训练后的 生成模
型可以忽略少数模式，并且人类观察者不能容易地检查或记住足够的图像以检测丢
失的变化。
由于样本的视觉质量不是可靠的标准，所以当计算可行时，我们通常还评估模
型分配给测试数据的对数似然。不幸的是，在某些情况下，似然性似乎不可能测量
我们真正关心的模型的任何属性。例如， MNIST的实值模型可以将任意低的方差
分配给从不改变的背景像素，获得任意高的似然。即使这不是一个非常有用的事情，
检测这些常量特征的模型和算法可以获得无限的奖励。实现接近负无穷代价的可能
性存在于任何实值的最大似然问题中，但是对于 MNIST的生成模型 问题尤为严重，
因为许多输出值是不需要预测的。这强烈地表明需要开发评估 生成模型 的其他方法。
Theis et al. (2015)回顾了评估 生成模型 所涉及的许多问题，包括上述的许多想
法。他们强调了 生成模型 有许多不同的用途，并且指标的选择必须与模型的预期用
途相匹配。例如，一些 生成模型 更好地为大多数真实的点分配高概率，而其他 生成
模型擅长于不将高概率分配给不真实的点。这些差异可能源于 生成模型 是设计为最
小化 DKL(pdatajjpmodel )还是 DKL(pmodeljjpdata)，如图 3.6所示。不幸的是，即使我
们将每个指标的使用限制在最适合的任务上，目前使用的所有指标仍存在严重的缺
陷。因此， 生成式建模 中最重要的研究课题之一不仅仅是如何提升 生成模型 ，事实
上还包括了设计新的技术来衡量我们的进步。
20.15结论
为了让模型理解表示在给定训练数据中的大千世界，训练具有 隐藏单元 的生成
模型是一种有力方法。通过学习模型 pmodel (x)和表示 pmodel (hjx)，生成模型 可以
解答 x输入变量之间关系的许多 推断问题，并且可以在层次的不同层对 h求期望来DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
20.15结论 613
提供表示 x的许多不同方式。 生成模型 承诺为 AI系统提供它们需要理解的、所有
不同直观概念的框架，让它们有能力在面对不确定性的情况下推理这些概念。我们
希望我们的读者能够找到增强这些方法的新途径，并继续探究学习和智能背后原理
的旅程。DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献
(-1). JMLR .617,648
(-1a). Icml’08. In ICML’08 . ACM. 648,673
(-1b). Icml’11. In ICML’11 .627,633
(-1c). Icml’13. In ICML’13 .634,659
(-1). International conference on learning representations 2014. In ICLR’2014 .659,674
(-1a). Nips’05. In NIPS 18 . MIT Press. 618
(-1b). Nips’13. In NIPS26 . NIPS Foundation. 628,634
Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis,
A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia,
Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Mané, D., Monga, R., Moore, S.,
Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker,
P., Vanhoucke, V., Vasudevan, V., Viégas, F., Vinyals, O., Warden, P., Wattenberg, M.,
Wicke, M., Yu, Y., and Zheng, X. (2015). TensorFlow: Large-scale machine learning on
heterogeneous systems. Software available from tensorﬂow.org. 24,182,379
Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. (1985). A learning algorithm for Boltzmann
machines. Cognitive Science ,9, 147–169. 485,558
Alain, G. and Bengio, Y. (2013). What regularized auto-encoders learn from the data generating
distribution. In ICLR’2013, arXiv:1211.4246 .432,438,444
Alain, G., Bengio, Y., Yao, L., Éric Thibodeau-Laufer, Yosinski, J., and Vincent, P. (2015).
GSNs: Generative stochastic networks. arXiv:1503.05571. 435,606
Anderson, E. (1935). The Irises of the Gaspé Peninsula. Bulletin of the American Iris Society ,
59, 2–5. 18
614DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 615
Ba, J., Mnih, V., and Kavukcuoglu, K. (2014). Multiple object recognition with visual attention.
arXiv:1412.7755 .590
Bachman, P. and Precup, D. (2015). Variational generative stochastic networks with collabo-
rative shaping. In Proceedings of the 32nd International Conference on Machine Learning,
ICML 2015, Lille, France, 6-11 July 2015 , pages 1964–1972. 610
Bacon, P.-L., Bengio, E., Pineau, J., and Precup, D. (2015). Conditional computation in neu-
ral networks using a decision-theoretic approach. In 2nd Multidisciplinary Conference on
Reinforcement Learning and Decision Making (RLDM 2015) .382
Bagnell, J. A. and Bradley, D. M. (2009). Diﬀerentiable sparse coding. In NIPS’2009 , pages
113–120. 424
Bahdanau, D., Cho, K., and Bengio, Y. (2015). Neural machine translation by jointly learning
to align and translate. In ICLR’2015, arXiv:1409.0473 .23,89,338,355,357,394,403,404
Bahl, L. R., Brown, P., de Souza, P. V., and Mercer, R. L. (1987). Speech recognition with
continuous-parameter hidden Markov models. Computer, Speech and Language ,2, 219–234.
389
Baldi, P. and Hornik, K. (1989). Neural networks and principal component analysis: Learning
from examples without local minima. Neural Networks ,2, 53–58. 244
Baldi, P., Brunak, S., Frasconi, P., Soda, G., and Pollastri, G. (1999). Exploiting the past and
the future in protein secondary structure prediction. Bioinformatics ,15(11), 937–946. 336
Baldi, P., Sadowski, P., and Whiteson, D. (2014). Searching for exotic particles in high-energy
physics with deep learning. Nature communications ,5.24
Ballard, D. H., Hinton, G. E., and Sejnowski, T. J. (1983). Parallel vision computation. Nature .
384
Barlow, H. B. (1989). Unsupervised learning. Neural Computation ,1, 295–311. 128
Barron, A. E. (1993). Universal approximation bounds for superpositions of a sigmoidal function.
IEEE Trans. on Information Theory ,39, 930–945. 171
Bartholomew, D. J. (1987). Latent variable models and factor analysis . Oxford University Press.
417
Basilevsky, A. (1994). Statistical Factor Analysis and Related Methods: Theory and Applications .
Wiley. 417DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
616 参考文献
Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I., Bergeron, A., Bouchard, N.,
Warde-Farley, D., and Bengio, Y. (2012a). Theano: new features and speed improvements.
Submited to the Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop,
http://www.iro.umontreal.ca/ lisa/publications2/index.php/publications/show/551. 23,73,
379
Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard,
N., and Bengio, Y. (2012b). Theano: new features and speed improvements. Deep Learning
and Unsupervised Feature Learning NIPS 2012 Workshop. 182,191
Basu, S. and Christensen, J. (2013). Teaching classiﬁcation boundaries to humans. In
AAAI’2013 .279
Baxter, J. (1995). Learning internal representations. In Proceedings of the 8th International
Conference on Computational Learning Theory (COLT’95) , pages 311–320, Santa Cruz, Cal-
ifornia. ACM Press. 210
Bayer, J. and Osendorfer, C. (2014). Learning stochastic recurrent networks. ArXiv e-prints .
227
Becker, S. and Hinton, G. (1992). A self-organizing neural network that discovers surfaces in
random-dot stereograms. Nature ,355, 161–163. 461
Behnke, S. (2001). Learning iterative image reconstruction in the neural abstraction pyramid.
Int. J. Computational Intelligence and Applications ,1(4), 427–438. 439
Beiu, V., Quintana, J. M., and Avedillo, M. J. (2003). VLSI implementations of threshold logic-a
comprehensive survey. Neural Networks, IEEE Transactions on ,14(5), 1217–1243. 383
Belkin, M. and Niyogi, P. (2002). Laplacian eigenmaps and spectral techniques for embedding
and clustering. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural
Information Processing Systems 14 (NIPS’01) , Cambridge, MA. MIT Press. 209
Belkin, M. and Niyogi, P. (2003a). Laplacian eigenmaps for dimensionality reduction and data
representation. Neural Computation ,15(6), 1373–1396. 442
Belkin, M. and Niyogi, P. (2003b). Using manifold structure for partially labeled classiﬁcation. In
S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing
Systems 15 (NIPS’02) , Cambridge, MA. MIT Press. 141
Bengio, E., Bacon, P.-L., Pineau, J., and Precup, D. (2015a). Conditional computation in neural
networks for faster models. arXiv:1511.06297. 382DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 617
Bengio, S. and Bengio, Y. (1996). An EM algorithm for asynchronous input/output hidden
Markov models. In L. Xu, editor, International Conference On Neural Information Processing ,
pages 328–334. 379
Bengio, S. and Bengio, Y. (2000a). Taking on the curse of dimensionality in joint distributions
using neural networks. IEEE Transactions on Neural Networks, special issue on Data Mining
and Knowledge Discovery ,11(3), 550–557. 602
Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. (2015b). Scheduled sampling for sequence
prediction with recurrent neural networks. Technical report, arXiv:1506.03099. 326
Bengio, Y. (2000). Gradient-based optimization of hyperparameters. Neural Computation ,
12(8), 1889–1900. 369
Bengio, Y. (2002). New distributed probabilistic language models. Technical Report 1215, Dept.
IRO, Université de Montréal. 396
Bengio, Y. (2009). Learning deep architectures for AI . Now Publishers. 173,530
Bengio, Y. (2015). Early inference in energy-based models approximates back-propagation.
Technical Report arXiv:1510.02777, Universite de Montreal. 559
Bengio, Y. and Bengio, S. (2000b). Modeling high-dimensional discrete data with multi-layer
neural networks. In NIPS 12 , pages 400–406. MIT Press. 601,602,603,605
Bengio, Y. and Delalleau, O. (2009). Justifying and generalizing contrastive divergence. Neural
Computation ,21(6), 1601–1621. 437,519
Bengio, Y. and Grandvalet, Y. (2004). No unbiased estimator of the variance of k-fold cross-
validation. In JML (1), pages 1089–1105. 107
Bengio, Y. and LeCun, Y. (2007a). Scaling learning algorithms towards AI. In Large Scale
Kernel Machines .17
Bengio, Y. and LeCun, Y. (2007b). Scaling learning algorithms towards AI. In L. Bottou,
O. Chapelle, D. DeCoste, and J. Weston, editors, Large Scale Kernel Machines . MIT Press.
17
Bengio, Y. and Monperrus, M. (2005). Non-local manifold tangent learning. In L. Saul, Y. Weiss,
and L. Bottou, editors, Advances in Neural Information Processing Systems 17 (NIPS’04) ,
pages 129–136. MIT Press. 138,443
Bengio, Y. and Sénécal, J.-S. (2003). Quick training of probabilistic neural nets by importance
sampling. In Proceedings of AISTATS 2003 .399DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
618 参考文献
Bengio, Y. and Sénécal, J.-S. (2008). Adaptive importance sampling to accelerate training of a
neural probabilistic language model. IEEE Trans. Neural Networks ,19(4), 713–722. 399
Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1991). Phonetically motivated acoustic
parameters for continuous speech recognition using artiﬁcial neural networks. In Proceedings
of EuroSpeech’91 .21,346,389
Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1992). Neural network-Gaussian mixture
hybrid for speech recognition or density estimation. In NIPS 4 , pages 175–182. Morgan
Kaufmann. 389
Bengio, Y., Frasconi, P., and Simard, P. (1993). The problem of learning long-term dependencies
in recurrent networks. In IEEE International Conference on Neural Networks , pages 1183–
1195, San Francisco. IEEE Press. (invited paper). 343
Bengio, Y., Simard, P., and Frasconi, P. (1994a). Learning long-term dependencies with gradient
descent is diﬃcult. IEEE Transactions on Neural Networks ,5(2), 157–166. 16,342,343,344
Bengio, Y., Simard, P., and Frasconi, P. (1994b). Learning long-term dependencies with gradient
descent is diﬃcult. IEEE Transactions on Neural Networks ,5(2), 157–166. 350
Bengio, Y., Latendresse, S., and Dugas, C. (1999). Gradient-based learning of hyper-parameters.
InLearning Conference .369
Bengio, Y., Ducharme, R., and Vincent, P. (2001a). A neural probabilistic language model.
In T. Leen, T. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing
Systems 13 (NIPS’00) , pages 933–938. MIT Press. 16
Bengio, Y., Ducharme, R., and Vincent, P. (2001b). A neural probabilistic language model. In
T. K. Leen, T. G. Dietterich, and V. Tresp, editors, NIPS’2000 , pages 932–938. MIT Press.
393,395,401,405,409
Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. (2003). A neural probabilistic language
model. JMLR ,3, 1137–1155. 395,401
Bengio, Y., Delalleau, O., and Le Roux, N. (2006a). The curse of highly variable functions for
local kernel machines. In NIP (1a), pages 107–114. 137
Bengio, Y., Larochelle, H., and Vincent, P. (2006b). Non-local manifold parzen windows. In
NIP (1a).138
Bengio, Y., Larochelle, H., and Vincent, P. (2006c). Non-local manifold Parzen windows. In
NIPS’2005 . MIT Press. 443DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 619
Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007a). Greedy layer-wise training of
deep networks. In NIPS’2006 .13,275
Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007b). Greedy layer-wise training
of deep networks. In B. Schölkopf, J. Platt, and T. Hoﬀman, editors, Advances in Neural
Information Processing Systems 19 (NIPS’06) , pages 153–160. MIT Press. 173
Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007c). Greedy layer-wise training of
deep networks. In Adv. Neural Inf. Proc. Sys. 19 , pages 153–160. 274
Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007d). Greedy layer-wise training
of deep networks. In NIPS 19 , pages 153–160. MIT Press. 275,450,451
Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In
ICML’09 . ACM. 278
Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013a). Better mixing via deep representa-
tions. In ICML’2013 .513
Bengio, Y., Léonard, N., and Courville, A. (2013b). Estimating or propagating gradients through
stochastic neurons for conditional computation. arXiv:1308.3432. 381,587,589
Bengio, Y., Léonard, N., and Courville, A. (2013c). Estimating or propagating gradients through
stochastic neurons for conditional computation. ArXiv e-prints ,abs/1308.3432 .381,382
Bengio, Y., Yao, L., Alain, G., and Vincent, P. (2013d). Generalized denoising auto-encoders as
generative models. In NIPS’2013 .432,606,607
Bengio, Y., Courville, A., and Vincent, P. (2013e). Representation learning: A review and
new perspectives. Pattern Analysis and Machine Intelligence, IEEE Transactions on ,35(8),
1798–1828. 472
Bengio, Y., Thibodeau-Laufer, E., Alain, G., and Yosinski, J. (2014). Deep generative stochastic
networks trainable by backprop. In ICML’2014 .606,607,608,609
Bennett, C. (1976). Eﬃcient estimation of free energy diﬀerences from Monte Carlo data. Journal
of Computational Physics ,22(2), 245–268. 535
Bennett, J. and Lanning, S. (2007). The Netﬂix prize. 407
Berglund, M. and Raiko, T. (2013). Stochastic gradient estimate variance in contrastive diver-
gence and persistent contrastive divergence. CoRR ,abs/1312.6002 .522
Bergstra, J. (2011). Incorporating Complex Cells into Neural Networks for Pattern Classiﬁcation .
Ph.D. thesis, Université de Montréal. 218DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
620 参考文献
Bergstra, J. and Bengio, Y. (2009). Slow, decorrelated features for pretraining complex cell-like
networks. In NIPS 22 , pages 99–107. MIT Press. 420
Bergstra, J. and Bengio, Y. (2011). Random search for hyper-parameter optimization. The
Learning Workshop , Fort Lauderdale, Florida. 368
Bergstra, J. and Bengio, Y. (2012). Random search for hyper-parameter optimization. J.
Machine Learning Res. ,13, 281–305. 368,369
Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J.,
Warde-Farley, D., and Bengio, Y. (2010a). Theano: a CPU and GPU math expression
compiler. In Proceedings of the Python for Scientiﬁc Computing Conference (SciPy) . Oral
Presentation. 23,73
Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J.,
Warde-Farley, D., and Bengio, Y. (2010b). Theano: a CPU and GPU math expression
compiler. In Proc. SciPy .182,191
Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J.,
Warde-Farley, D., and Bengio, Y. (2010c). Theano: a CPU and GPU math expression
compiler. In Proceedings of the Python for Scientiﬁc Computing Conference (SciPy) .379
Bergstra, J., Bardenet, R., Bengio, Y., and Kégl, B. (2011). Algorithms for hyper-parameter
optimization. In NIPS’2011 .370
Berkes, P. and Wiskott, L. (2005). Slow feature analysis yields a rich repertoire of complex cell
properties. Journal of Vision ,5(6), 579–602. 422
Bertsekas, D. P. and Tsitsiklis, J. (1996). Neuro-Dynamic Programming . Athena Scientiﬁc. 93
Besag, J. (1975). Statistical analysis of non-lattice data. The Statistician ,24(3), 179–195. 524
Bishop, C. M. (1994). Mixture density networks. 163
Bishop, C. M. (1995a). Regularization and complexity control in feed-forward networks. In
Proceedings International Conference on Artiﬁcial Neural Networks ICANN’95 , volume 1,
page 141–148. 207,214
Bishop, C. M. (1995b). Training with noise is equivalent to Tikhonov regularization. Neural
Computation ,7(1), 108–116. 207
Bishop, C. M. (2006). Pattern Recognition and Machine Learning . Springer. 87,126
Blum, A. L. and Rivest, R. L. (1992). Training a 3-node neural network is NP-complete. 249DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 621
Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. (1989). Learnability and the
Vapnik–Chervonenkis dimension. Journal of the ACM ,36(4), 929-- –865. 100
Bonnet, G. (1964). Transformations des signaux aléatoires à travers les systèmes non linéaires
sans mémoire. Annales des Télécommunications ,19(9–10), 203–220. 587
Bordes, A., Weston, J., Collobert, R., and Bengio, Y. (2011). Learning structured embeddings
of knowledge bases. In AAAI 2011 .410,411
Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2012). Joint learning of words and meaning
representations for open-text semantic parsing. AISTATS’2012 .342,410,411
Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2013a). A semantic matching energy
function for learning with multi-relational data. Machine Learning: Special Issue on Learning
Semantics .410
Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakhnenko, O. (2013b). Trans-
lating embeddings for modeling multi-relational data. In C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information Processing Sys-
tems 26 , pages 2787–2795. Curran Associates, Inc. 410
Bornschein, J. and Bengio, Y. (2015). Reweighted wake-sleep. In ICLR’2015, arXiv:1406.2751 .
591
Bornschein, J., Shabanian, S., Fischer, A., and Bengio, Y. (2015). Training bidirectional
Helmholtz machines. Technical report, arXiv:1506.03877. 591
Boser, B. E., Guyon, I. M., and Vapnik, V. N. (1992). A training algorithm for optimal margin
classiﬁers. In COLT ’92: Proceedings of the ﬁfth annual workshop on Computational learning
theory , pages 144–152, New York, NY, USA. ACM. 16,123
Bottou, L. (1998). Online algorithms and stochastic approximations. In D. Saad, editor, Online
Learning in Neural Networks . Cambridge University Press, Cambridge, UK. 252
Bottou, L. (2011). From machine learning to machine reasoning. Technical report,
arXiv.1102.1808. 340,341
Bottou, L. (2015). Multilayer neural networks. Deep Learning Summer School. 373
Bottou, L. and Bousquet, O. (2008a). The tradeoﬀs of large scale learning. In J. Platt, D. Koller,
Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20
(NIPS’07) , volume 20. MIT Press, Cambridge, MA. 240
Bottou, L. and Bousquet, O. (2008b). The tradeoﬀs of large scale learning. In NIPS’2008 .251DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
622 参考文献
Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2012). Modeling temporal depen-
dencies in high-dimensional sequences: Application to polyphonic music generation and tran-
scription. In ICML’12 .584
Boureau, Y., Ponce, J., and LeCun, Y. (2010). A theoretical analysis of feature pooling in vision
algorithms. In Proc. International Conference on Machine learning (ICML’10) .291
Boureau, Y., Le Roux, N., Bach, F., Ponce, J., and LeCun, Y. (2011). Ask the locals: multi-way
local pooling for image recognition. In Proc. International Conference on Computer Vision
(ICCV’11) . IEEE. 292
Bourlard, H. and Kamp, Y. (1988). Auto-association by multilayer perceptrons and singular
value decomposition. Biological Cybernetics ,59, 291–294. 428
Bourlard, H. and Wellekens, C. (1989). Speech pattern discrimination and multi-layered per-
ceptrons. Computer Speech and Language ,3, 1–19. 389
Boyd, S. and Vandenberghe, L. (2004). Convex Optimization . Cambridge University Press, New
York, NY, USA. 82
Brady, M. L., Raghavan, R., and Slawny, J. (1989). Back-propagation fails to separate where
perceptrons succeed. IEEE Transactions on Circuits and Systems ,36(5), 665–674. 242
Brakel, P., Stroobandt, D., and Schrauwen, B. (2013). Training energy-based models for time-
series imputation. Journal of Machine Learning Research ,14, 2771–2797. 575,595
Brand, M. (2003a). Charting a manifold. In S. Becker, S. Thrun, and K. Obermayer, editors,
Advances in Neural Information Processing Systems 15 (NIPS’02) , pages 961–968. MIT Press.
141
Brand, M. (2003b). Charting a manifold. In NIPS’2002 , pages 961–968. MIT Press. 442
Breiman, L. (1994). Bagging predictors. Machine Learning ,24(2), 123–140. 219
Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. (1984). Classiﬁcation and
Regression Trees . Wadsworth International Group, Belmont, CA. 125
Bridle, J. S. (1990). Alphanets: a recurrent ‘neural’ network architecture with a hidden Markov
model interpretation. Speech Communication ,9(1), 83–92. 160
Briggman, K., Denk, W., Seung, S., Helmstaedter, M. N., and Turaga, S. C. (2009). Maximin
aﬃnity learning of image segmentation. In NIPS’2009 , pages 1865–1873. 305DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 623
Brown, P. F., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., Jelinek, F., Laﬀerty, J. D., Mercer,
R. L., and Roossin, P. S. (1990). A statistical approach to machine translation. Computational
linguistics ,16(2), 79–85. 18
Brown, P. F., Pietra, V. J. D., DeSouza, P. V., Lai, J. C., and Mercer, R. L. (1992). Class-based
n-gram models of natural language. Computational Linguistics ,18, 467–479. 393
Bryson, A. and Ho, Y. (1969). Applied optimal control: optimization, estimation, and control .
Blaisdell Pub. Co. 194
Bryson, Jr., A. E. and Denham, W. F. (1961). A steepest-ascent method for solving optimum
programming problems. Technical Report BR-1303, Raytheon Company, Missle and Space
Division. 194
Buciluˇ a, C., Caruana, R., and Niculescu-Mizil, A. (2006). Model compression. In Proceedings of
the 12th ACM SIGKDD international conference on Knowledge discovery and data mining ,
pages 535–541. ACM. 380
Burda, Y., Grosse, R., and Salakhutdinov, R. (2015). Importance weighted autoencoders. arXiv
preprint arXiv:1509.00519 .595
Cai, M., Shi, Y., and Liu, J. (2013). Deep maxout neural networks for speech recognition. In
Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on , pages
291–296. IEEE. 167
Carreira-Perpiñan, M. A. and Hinton, G. E. (2005). On contrastive divergence learning. In
AISTATS’2005 , pages 33–40. 519
Caruana, R. (1993). Multitask connectionist learning. In Proceedings of the 1993 Connectionist
Models Summer School , pages 372–379. 209
Cauchy, A. (1847). Méthode générale pour la résolution de systèmes d’équations simultanées.
InCompte rendu des séances de l’académie des sciences , pages 536–538. 74,193
Cayton, L. (2005). Algorithms for manifold learning. Technical Report CS2008-0923, UCSD.
141
Chandola, V., Banerjee, A., and Kumar, V. (2009). Anomaly detection: A survey. ACM
computing surveys (CSUR) ,41(3), 15. 90
Chapelle, O., Weston, J., and Schölkopf, B. (2003). Cluster kernels for semi-supervised learning.
In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing
Systems 15 (NIPS’02) , pages 585–592, Cambridge, MA. MIT Press. 209DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
624 参考文献
Chapelle, O., Schölkopf, B., and Zien, A. (2006a). Semi-Supervised Learning . MIT Press,
Cambridge, MA. 209
Chapelle, O., Schölkopf, B., and Zien, A., editors (2006b). Semi-Supervised Learning . MIT
Press, Cambridge, MA. 461
Chellapilla, K., Puri, S., and Simard, P. (2006). High Performance Convolutional Neural Net-
works for Document Processing. In Guy Lorette, editor, Tenth International Workshop on
Frontiers in Handwriting Recognition , La Baule (France). Université de Rennes 1, Suvisoft.
http://www.suvisoft.com. 20,21,378
Chen, B., Ting, J.-A., Marlin, B. M., and de Freitas, N. (2010). Deep learning of invariant
spatio-temporal features from video. NIPS*2010 Deep Learning and Unsupervised Feature
Learning Workshop. 306
Chen, S. F. and Goodman, J. T. (1999). An empirical study of smoothing techniques for language
modeling. Computer, Speech and Language ,13(4), 359–393. 392,393
Chen, T., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., and Temam, O. (2014a). DianNao: A
small-footprint high-throughput accelerator for ubiquitous machine-learning. In Proceedings
of the 19th international conference on Architectural support for programming languages and
operating systems , pages 269–284. ACM. 383
Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang, C., and
Zhang, Z. (2015). MXNet: A ﬂexible and eﬃcient machine learning library for heterogeneous
distributed systems. arXiv preprint arXiv:1512.01274 .23
Chen, Y., Luo, T., Liu, S., Zhang, S., He, L., Wang, J., Li, L., Chen, T., Xu, Z., Sun, N., et al.
(2014b). DaDianNao: A machine-learning supercomputer. In Microarchitecture (MICRO),
2014 47th Annual IEEE/ACM International Symposium on , pages 609–622. IEEE. 383
Chilimbi, T., Suzue, Y., Apacible, J., and Kalyanaraman, K. (2014). Project Adam: Building
an eﬃcient and scalable deep learning training system. In 11th USENIX Symposium on
Operating Systems Design and Implementation (OSDI’14) .380
Cho, K., Raiko, T., and Ilin, A. (2010a). Parallel tempering is eﬃcient for learning restricted
Boltzmann machines. In Proceedings of the International Joint Conference on Neural Net-
works (IJCNN 2010) , Barcelona, Spain. 513
Cho, K., Raiko, T., and Ilin, A. (2010b). Parallel tempering is eﬃcient for learning restricted
Boltzmann machines. In IJCNN’2010 .523
Cho, K., Raiko, T., and Ilin, A. (2011). Enhanced gradient and adaptive learning rate for
training restricted Boltzmann machines. In ICML’2011 , pages 105–112. 574DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 625
Cho, K., Van Merriënboer, B., Gülçehre, Ç., Bahdanau, D., Bougares, F., Schwenk, H., and
Bengio, Y. (2014a). Learning phrase representations using RNN encoder–decoder for sta-
tistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP) , pages 1724–1734. Association for Computational
Linguistics. 337
Cho, K., van Merriënboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y. (2014b).
Learning phrase representations using RNN encoder-decoder for statistical machine trans-
lation. In Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP
2014) .402
Cho, K., Van Merriënboer, B., Bahdanau, D., and Bengio, Y. (2014c). On the properties of
neural machine translation: Encoder-decoder approaches. ArXiv e-prints ,abs/1409.1259 .
350
Choromanska, A., Henaﬀ, M., Mathieu, M., Arous, G. B., and LeCun, Y. (2014). The loss
surface of multilayer networks. 243,244
Chorowski, J., Bahdanau, D., Cho, K., and Bengio, Y. (2014). End-to-end continuous speech
recognition using attention-based recurrent NN: First results. arXiv:1412.1602. 391
Christianson, B. (1992). Automatic Hessians by reverse accumulation. IMA Journal of Numerical
Analysis ,12(2), 135–150. 193
Chrupala, G., Kadar, A., and Alishahi, A. (2015). Learning language through pictures. arXiv
1506.03694. 350
Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2014). Empirical evaluation of gated recurrent
neural networks on sequence modeling. NIPS’2014 Deep Learning workshop, arXiv 1412.3555.
350,391
Chung, J., Gülçehre, Ç., Cho, K., and Bengio, Y. (2015a). Gated feedback recurrent neural
networks. In ICML’15 .350
Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A., and Bengio, Y. (2015b). A recurrent
latent variable model for sequential data. In NIPS’2015 .595
Ciresan, D., Meier, U., Masci, J., and Schmidhuber, J. (2012). Multi-column deep neural network
for traﬃc sign classiﬁcation. Neural Networks ,32, 333–338. 22,173
Ciresan, D. C., Meier, U., Gambardella, L. M., and Schmidhuber, J. (2010). Deep big simple
neural nets for handwritten digit recognition. Neural Computation ,22, 1–14. 20,21,378DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
626 参考文献
Coates, A. and Ng, A. Y. (2011). The importance of encoding versus training with sparse coding
and vector quantization. In ICML’2011 .21,219,424
Coates, A., Lee, H., and Ng, A. Y. (2011). An analysis of single-layer networks in unsuper-
vised feature learning. In Proceedings of the Thirteenth International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS 2011) .309,386
Coates, A., Huval, B., Wang, T., Wu, D., Catanzaro, B., and Andrew, N. (2013). Deep learning
with COTS HPC systems. In S. Dasgupta and D. McAllester, editors, Proceedings of the 30th
International Conference on Machine Learning (ICML-13) , volume 28 (3), pages 1337–1345.
JMLR Workshop and Conference Proceedings. 20,21,309,380
Cohen, N., Sharir, O., and Shashua, A. (2015). On the expressive power of deep learning: A
tensor analysis. arXiv:1509.05009. 471
Collobert, R. (2004). Large Scale Machine Learning . Ph.D. thesis, Université de Paris VI, LIP6.
170
Collobert, R. (2011). Deep learning for eﬃcient discriminative parsing. In AISTATS’2011 .89,
405
Collobert, R. and Weston, J. (2008a). A uniﬁed architecture for natural language processing:
Deep neural networks with multitask learning. In ICML’2008 .400,405
Collobert, R. and Weston, J. (2008b). A uniﬁed architecture for natural language processing:
Deep neural networks with multitask learning. In ICML’2008 .454
Collobert, R., Bengio, S., and Bengio, Y. (2001). A parallel mixture of SVMs for very large
scale problems. Technical Report 12, IDIAP. 382
Collobert, R., Bengio, S., and Bengio, Y. (2002). Parallel mixture of SVMs for very large scale
problem. Neural Computation .382
Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. (2011a). Nat-
ural language processing (almost) from scratch. The Journal of Machine Learning Research ,
12, 2493–2537. 278,405,454,455
Collobert, R., Kavukcuoglu, K., and Farabet, C. (2011b). Torch7: A Matlab-like environment
for machine learning. In BigLearn, NIPS Workshop .23,182,379
Comon, P. (1994). Independent component analysis - a new concept? Signal Processing ,36,
287–314. 418DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 627
Cortes, C. and Vapnik, V. (1995). Support vector networks. Machine Learning ,20, 273–297.
16,123
Couprie, C., Farabet, C., Najman, L., and LeCun, Y. (2013). Indoor semantic segmentation using
depth information. In International Conference on Learning Representations (ICLR2013) .22,
173
Courbariaux, M., Bengio, Y., and David, J.-P. (2015). Low precision arithmetic for deep learning.
InArxiv:1412.7024, ICLR’2015 Workshop .383
Courville, A., Bergstra, J., and Bengio, Y. (2011a). Unsupervised models of images by spike-
and-slab RBMs. In ICML’2011 .476
Courville, A., Bergstra, J., and Bengio, Y. (2011b). Unsupervised models of images by spike-
and-slab RBMs. In ICM (1b).580
Courville, A., Desjardins, G., Bergstra, J., and Bengio, Y. (2014). The spike-and-slab RBM
and extensions to discrete and sparse data distributions. Pattern Analysis and Machine
Intelligence, IEEE Transactions on ,36(9), 1874–1887. 582
Cover, T. M. and Thomas, J. A. (2006). Elements of Information Theory, 2nd Edition . Wiley-
Interscience. 66
Cox, D. and Pinto, N. (2011). Beyond simple features: A large-scale feature search approach
to unconstrained face recognition. In Automatic Face & Gesture Recognition and Workshops
(FG 2011), 2011 IEEE International Conference on , pages 8–15. IEEE. 309
Cramér, H. (1946). Mathematical methods of statistics . Princeton University Press. 118,251
Crick, F. H. C. and Mitchison, G. (1983). The function of dream sleep. Nature ,304, 111–114.
517
Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics of
Control, Signals, and Systems ,2, 303–314. 171
Dahl, G. E., Ranzato, M., Mohamed, A., and Hinton, G. E. (2010). Phone recognition with the
mean-covariance restricted Boltzmann machine. In Advances in Neural Information Process-
ing Systems (NIPS) .22
Dahl, G. E., Yu, D., Deng, L., and Acero, A. (2012). Context-dependent pre-trained deep neural
networks for large vocabulary speech recognition. IEEE Transactions on Audio, Speech, and
Language Processing ,20(1), 33–42. 390DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
628 参考文献
Dahl, G. E., Sainath, T. N., and Hinton, G. E. (2013). Improving deep neural networks for
LVCSR using rectiﬁed linear units and dropout. In ICASSP’2013 .390
Dahl, G. E., Jaitly, N., and Salakhutdinov, R. (2014). Multi-task neural networks for QSAR
predictions. arXiv:1406.1231. 24
Dauphin, Y. and Bengio, Y. (2013). Stochastic ratio matching of RBMs for sparse high-
dimensional inputs. In NIP (1b).527
Dauphin, Y., Glorot, X., and Bengio, Y. (2011). Large-scale learning of embeddings with
reconstruction sampling. In ICML’2011 .400
Dauphin, Y., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., and Bengio, Y. (2014). Identifying
and attacking the saddle point problem in high-dimensional non-convex optimization. In
NIPS’2014 .243,244
Davis, A., Rubinstein, M., Wadhwa, N., Mysore, G., Durand, F., and Freeman, W. T. (2014).
The visual microphone: Passive recovery of sound from video. ACM Transactions on Graphics
(Proc. SIGGRAPH) ,33(4), 79:1–79:10. 384
Dayan, P. (1990). Reinforcement comparison. In Connectionist Models: Proceedings of the 1990
Connectionist Summer School , San Mateo, CA. 589
Dayan, P. and Hinton, G. E. (1996). Varieties of Helmholtz machine. Neural Networks ,9(8),
1385–1403. 591
Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. (1995). The Helmholtz machine. Neural
computation ,7(5), 889–904. 591
Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Le, Q., Mao, M., Ranzato, M., Senior,
A., Tucker, P., Yang, K., and Ng, A. Y. (2012). Large scale distributed deep networks. In
NIPS’2012 .23,380
Dean, T. and Kanazawa, K. (1989). A model for reasoning about persistence and causation.
Computational Intelligence ,5(3), 142–150. 565
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., and Harshman, R. (1990). In-
dexing by latent semantic analysis. Journal of the American Society for Information Science ,
41(6), 391–407. 405,409
Delalleau, O. and Bengio, Y. (2011). Shallow vs. deep sum-product networks. In NIPS .17,471
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). ImageNet: A Large-Scale
Hierarchical Image Database. In CVPR09 .18DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 629
Deng, J., Berg, A. C., Li, K., and Fei-Fei, L. (2010a). What does classifying more than 10,000
image categories tell us? In Proceedings of the 11th European Conference on Computer Vision:
Part V , ECCV’10, pages 71–84, Berlin, Heidelberg. Springer-Verlag. 18
Deng, L. and Yu, D. (2014). Deep learning – methods and applications. Foundations and Trends
in Signal Processing .390
Deng, L., Seltzer, M., Yu, D., Acero, A., Mohamed, A., and Hinton, G. (2010b). Binary coding
of speech spectrograms using a deep auto-encoder. In Interspeech 2010 , Makuhari, Chiba,
Japan. 22
Denil, M., Bazzani, L., Larochelle, H., and de Freitas, N. (2012). Learning where to attend with
deep architectures for image tracking. Neural Computation ,24(8), 2151–2184. 312
Denton, E., Chintala, S., Szlam, A., and Fergus, R. (2015). Deep generative image models using
a Laplacian pyramid of adversarial networks. NIPS .598,611
Desjardins, G. and Bengio, Y. (2008). Empirical evaluation of convolutional RBMs for vision.
Technical Report 1327, Département d’Informatique et de Recherche Opérationnelle, Univer-
sité de Montréal. 582
Desjardins, G., Courville, A., Bengio, Y., Vincent, P., and Delalleau, O. (2010a). Tempered
Markov chain Monte Carlo for training of restricted Boltzmann machine. In AISTATS , pages
145–152. 513
Desjardins, G., Courville, A. C., Bengio, Y., Vincent, P., and Delalleau, O. (2010b). Tempered
Markov chain Monte Carlo for training of restricted Boltzmann machines. In International
Conference on Artiﬁcial Intelligence and Statistics , pages 145–152. 523
Desjardins, G., Courville, A., and Bengio, Y. (2011). On tracking the partition function. In
NIPS’2011 .536
Devlin, J., Zbib, R., Huang, Z., Lamar, T., Schwartz, R., and Makhoul, J. (2014). Fast and
robust neural network joint models for statistical machine translation. In Proc. ACL’2014 .
402
Devroye, L. (2013). Non-Uniform Random Variate Generation . SpringerLink : Bücher. Springer
New York. 592
DiCarlo, J. J. (2013). Mechanisms underlying visual object recognition: Humans vs. neurons
vs. machines. NIPS Tutorial. 24,311
Dinh, L., Krueger, D., and Bengio, Y. (2014). NICE: Non-linear independent components
estimation. arXiv:1410.8516. 420DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
630 参考文献
Donahue, J., Hendricks, L. A., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K.,
and Darrell, T. (2014). Long-term recurrent convolutional networks for visual recognition and
description. arXiv:1411.4389. 90
Donoho, D. L. and Grimes, C. (2003). Hessian eigenmaps: new locally linear embedding tech-
niques for high-dimensional data. Technical Report 2003-08, Dept. Statistics, Stanford Uni-
versity. 141,442
Dosovitskiy, A., Springenberg, J. T., and Brox, T. (2015). Learning to generate chairs with
convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition , pages 1538–1546. 593,600
Doya, K. (1993). Bifurcations of recurrent neural networks in gradient descent learning. IEEE
Transactions on Neural Networks ,1, 75–80. 342,344
Dreyfus, S. E. (1962). The numerical solution of variational problems. Journal of Mathematical
Analysis and Applications ,5(1), 30–45. 194
Dreyfus, S. E. (1973). The computational solution of optimal control problems with time lag.
IEEE Transactions on Automatic Control ,18(4) , 383–385. 194
Drucker, H. and LeCun, Y. (1992). Improving generalisation performance using double back-
propagation. IEEE Transactions on Neural Networks ,3(6), 991–997. 232
Duchi, J., Hazan, E., and Singer, Y. (2011). Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine Learning Research .260
Dudik, M., Langford, J., and Li, L. (2011). Doubly robust policy evaluation and learning. In
Proceedings of the 28th International Conference on Machine learning , ICML ’11. 409
Dugas, C., Bengio, Y., Belisle, F., Nadeau, C., and Garcia, R. (2001a). Incorporating second-
order functional knowledge for better option pricing. In NIPS 13 . MIT Press. 61
Dugas, C., Bengio, Y., Bélisle, F., and Nadeau, C. (2001b). Incorporating second-order func-
tional knowledge for better option pricing. In T. Leen, T. Dietterich, and V. Tresp, editors,
Advances in Neural Information Processing Systems 13 (NIPS’00) , pages 472–478. MIT Press.
169
Dziugaite, G. K., Roy, D. M., and Ghahramani, Z. (2015). Training generative neural networks
via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906 .599
El Hihi, S. and Bengio, Y. (1996). Hierarchical recurrent neural networks for long-term depen-
dencies. In NIPS 8 . MIT Press. 339,347DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 631
Elkahky, A. M., Song, Y., and He, X. (2015). A multi-view deep learning approach for cross
domain user modeling in recommendation systems. In Proceedings of the 24th International
Conference on World Wide Web , pages 278–288. 407
Elman, J. L. (1993). Learning and development in neural networks: The importance of starting
small. Cognition ,48, 781–799. 278
Erhan, D., Manzagol, P.-A., Bengio, Y., Bengio, S., and Vincent, P. (2009). The diﬃculty of
training deep architectures and the eﬀect of unsupervised pre-training. In AISTATS’2009 ,
pages 153–160. 173
Erhan, D., Bengio, Y., Courville, A., Manzagol, P., Vincent, P., and Bengio, S. (2010). Why
does unsupervised pre-training help deep learning? J. Machine Learning Res. 451,453,454,
455
Fahlman, S. E., Hinton, G. E., and Sejnowski, T. J. (1983). Massively parallel architectures for
AI: NETL, thistle, and Boltzmann machines. In Proceedings of the National Conference on
Artiﬁcial Intelligence AAAI-83 .485,558
Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Dollár, P., Gao, J., He, X., Mitchell,
M., Platt, J. C., Zitnick, C. L., and Zweig, G. (2015). From captions to visual concepts and
back. arXiv:1411.4952. 90
Farabet, C., LeCun, Y., Kavukcuoglu, K., Culurciello, E., Martini, B., Akselrod, P., and Talay,
S. (2011). Large-scale FPGA-based convolutional networks. In R. Bekkerman, M. Bilenko,
and J. Langford, editors, Scaling up Machine Learning: Parallel and Distributed Approaches .
Cambridge University Press. 446
Farabet, C., Couprie, C., Najman, L., and LeCun, Y. (2013). Learning hierarchical features
for scene labeling. IEEE Transactions on Pattern Analysis and Machine Intelligence ,35(8),
1915–1929. 22,173,305
Fei-Fei, L., Fergus, R., and Perona, P. (2006). One-shot learning of object categories. IEEE
Transactions on Pattern Analysis and Machine Intelligence ,28(4), 594–611. 458
Finn, C., Tan, X. Y., Duan, Y., Darrell, T., Levine, S., and Abbeel, P. (2015). Learning
visual feature spaces for robotic manipulation with deep spatial autoencoders. arXiv preprint
arXiv:1509.06113 .23
Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Annals of
Eugenics ,7, 179–188. 18,92DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
632 参考文献
Földiák, P. (1989). Adaptive network for optimal linear feature extraction. In International
Joint Conference on Neural Networks (IJCNN) , volume 1, pages 401–405, Washington 1989.
IEEE, New York. 420
Franzius, M., Sprekeler, H., and Wiskott, L. (2007). Slowness and sparseness lead to place,
head-direction, and spatial-view cells. 422
Franzius, M., Wilbert, N., and Wiskott, L. (2008). Invariant object recognition with slow feature
analysis. In Proceedings of the 18th international conference on Artiﬁcial Neural Networks,
Part I , ICANN ’08, pages 961–970, Berlin, Heidelberg. Springer-Verlag. 422
Frasconi, P., Gori, M., and Sperduti, A. (1997). On the eﬃcient classiﬁcation of data structures
by neural networks. In Proc. Int. Joint Conf. on Artiﬁcial Intelligence .340,341
Frasconi, P., Gori, M., and Sperduti, A. (1998). A general framework for adaptive processing of
data structures. IEEE Transactions on Neural Networks ,9(5), 768–786. 340,341
Freund, Y. and Schapire, R. E. (1996a). Experiments with a new boosting algorithm. In Machine
Learning: Proceedings of Thirteenth International Conference , pages 148–156, USA. ACM.
221
Freund, Y. and Schapire, R. E. (1996b). Game theory, on-line prediction and boosting. In
Proceedings of the Ninth Annual Conference on Computational Learning Theory , pages 325–
332. 221
Frey, B. J. (1998). Graphical models for machine learning and digital communication . MIT
Press. 601
Frey, B. J., Hinton, G. E., and Dayan, P. (1996). Does the wake-sleep algorithm learn good
density estimators? In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in
Neural Information Processing Systems 8 (NIPS’95) , pages 661–670. MIT Press, Cambridge,
MA. 556
Frobenius, G. (1908). Über matrizen aus positiven elementen, s. B. Preuss. Akad. Wiss. Berlin,
Germany. 507
Fukushima, K. (1975). Cognitron: A self-organizing multilayered neural network. Biological
Cybernetics ,20, 121–136. 14,194,450
Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism
of pattern recognition unaﬀected by shift in position. Biological Cybernetics ,36, 193–202.
14,20,21,194,312DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 633
Gal, Y. and Ghahramani, Z. (2015). Bayesian convolutional neural networks with Bernoulli
approximate variational inference. arXiv preprint arXiv:1506.02158 .226
Gallinari, P., LeCun, Y., Thiria, S., and Fogelman-Soulie, F. (1987). Memoires associatives
distribuees. In Proceedings of COGNITIVA 87 , Paris, La Villette. 439
Garcia-Duran, A., Bordes, A., Usunier, N., and Grandvalet, Y. (2015). Combining two
and three-way embeddings models for link prediction in knowledge bases. arXiv preprint
arXiv:1506.00999 .411
Garofolo, J. S., Lamel, L. F., Fisher, W. M., Fiscus, J. G., and Pallett, D. S. (1993). Darpa timit
acoustic-phonetic continous speech corpus cd-rom. nist speech disc 1-1.1. NASA STI/Recon
Technical Report N ,93, 27403. 389
Garson, J. (1900). The metric system of identiﬁcation of criminals, as used in Great Britain
and Ireland. The Journal of the Anthropological Institute of Great Britain and Ireland , (2),
177–227. 18
Gers, F. A., Schmidhuber, J., and Cummins, F. (2000). Learning to forget: Continual prediction
with LSTM. Neural computation ,12(10), 2451–2471. 348,351
Ghahramani, Z. and Hinton, G. E. (1996). The EM algorithm for mixtures of factor analyzers.
Technical Report CRG-TR-96-1, Dpt. of Comp. Sci., Univ. of Toronto. 416
Gillick, D., Brunk, C., Vinyals, O., and Subramanya, A. (2015). Multilingual language processing
from bytes. arXiv preprint arXiv:1512.00103 .405
Girshick, R., Donahue, J., Darrell, T., and Malik, J. (2015). Region-based convolutional networks
for accurate object detection and segmentation. 362
Giudice, M. D., Manera, V., and Keysers, C. (2009). Programmed to learn? The ontogeny of
mirror neurons. Dev. Sci. ,12(2), 350-- –363. 559
Glorot, X., Bordes, A., and Bengio, Y. (2011a). Deep sparse rectiﬁer neural networks. In
AISTATS’2011 .15,150,169,195,257
Glorot, X., Bordes, A., and Bengio, Y. (2011b). Domain adaptation for large-scale sentiment
classiﬁcation: A deep learning approach. In ICML’2011 .432
Glorot, X., Bordes, A., and Bengio, Y. (2011c). Domain adaptation for large-scale sentiment
classiﬁcation: A deep learning approach. In ICM (1b), pages 97–110. 456
Goldberger, J., Roweis, S., Hinton, G. E., and Salakhutdinov, R. (2005). Neighbourhood compo-
nents analysis. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information
Processing Systems 17 (NIPS’04) . MIT Press. 101DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
634 参考文献
Gong, S., McKenna, S., and Psarrou, A. (2000). Dynamic Vision: From Images to Face Recog-
nition . Imperial College Press. 142,442
Goodfellow, I., Le, Q., Saxe, A., and Ng, A. (2009). Measuring invariances in deep networks.
In Y. Bengio, D. Schuurmans, C. Williams, J. Laﬀerty, and A. Culotta, editors, Advances in
Neural Information Processing Systems 22 (NIPS’09) , pages 646–654. 218
Goodfellow, I., Koenig, N., Muja, M., Pantofaru, C., Sorokin, A., and Takayama, L. (2010).
Help me help you: Interfaces for personal robots. In Proc. of Human Robot Interaction
(HRI) , Osaka, Japan. ACM Press, ACM Press. 88
Goodfellow, I., Mirza, M., Xiao, D., Courville, A., and Bengio, Y. (2014a). An empirical
investigation of catastrophic forgetting in gradient-based neural networks. In ICLR’14 .167
Goodfellow, I. J. (2010). Technical report: Multidimensional, downsampled convolution for
autoencoders. Technical report, Université de Montréal. 301
Goodfellow, I. J. (2014). On distinguishability criteria for estimating generative models. In
International Conference on Learning Representations, Workshops Track .530,597
Goodfellow, I. J., Courville, A., and Bengio, Y. (2011). Spike-and-slab sparse coding for unsu-
pervised feature discovery. In NIPS Workshop on Challenges in Learning Hierarchical Models .
453,457
Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013a). Maxout
networks. In ICML’2013 .167
Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013b). Maxout
networks. In ICM (1c), pages 1319–1327. 226,291,311
Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013c). Maxout
networks. Technical Report arXiv:1302.4389, Université de Montréal. 386
Goodfellow, I. J., Mirza, M., Courville, A., and Bengio, Y. (2013d). Multi-prediction deep
Boltzmann machines. In NIP (1b).89,525,571,573,574,575,576,595
Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R.,
Bergstra, J., Bastien, F., and Bengio, Y. (2013e). Pylearn2: a machine learning research
library. arXiv preprint arXiv:1308.4214 .23,379
Goodfellow, I. J., Courville, A., and Bengio, Y. (2013f). Scaling up spike-and-slab models for
unsupervised feature learning. IEEE T. PAMI , pages 1902–1914. 424,425,554DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 635
Goodfellow, I. J., Courville, A., and Bengio, Y. (2013g). Scaling up spike-and-slab models
for unsupervised feature learning. IEEE Transactions on Pattern Analysis and Machine
Intelligence ,35(8), 1902–1914. 582
Goodfellow, I. J., Shlens, J., and Szegedy, C. (2014b). Explaining and harnessing adversarial
examples. CoRR ,abs/1412.6572 .229,230,232,472,473
Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville,
A., and Bengio, Y. (2014c). Generative adversarial networks. In NIPS’2014 .463,587,596,
597,600
Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., and Shet, V. (2014d). Multi-digit number
recognition from Street View imagery using deep convolutional neural networks. In Interna-
tional Conference on Learning Representations .22,89,173,174,333,358,381
Goodfellow, I. J., Vinyals, O., and Saxe, A. M. (2015). Qualitatively characterizing neural
network optimization problems. In International Conference on Learning Representations .
243,244,245,247
Goodman, J. (2001). Classes for fast maximum entropy training. In International Conference
on Acoustics, Speech and Signal Processing (ICASSP) , Utah. 396
Gori, M. and Tesi, A. (1992). On the problem of local minima in backpropagation. IEEE
Transactions on Pattern Analysis and Machine Intelligence ,PAMI-14 (1), 76–86. 242
Gosset, W. S. (1908). The probable error of a mean. Biometrika ,6(1), 1–25. Originally published
under the pseudonym “Student” . 18
Gouws, S., Bengio, Y., and Corrado, G. (2014). BilBOWA: Fast bilingual distributed represen-
tations without word alignments. Technical report, arXiv:1410.2455. 405,458
Graf, H. P. and Jackel, L. D. (1989). Analog electronic neural network circuits. Circuits and
Devices Magazine, IEEE ,5(4), 44–49. 383
Graves, A. (2011). Practical variational inference for neural networks. In NIPS’2011 .207
Graves, A. (2012). Supervised Sequence Labelling with Recurrent Neural Networks . Studies in
Computational Intelligence. Springer. 319,335,350,391
Graves, A. (2013). Generating sequences with recurrent neural networks. Technical report,
arXiv:1308.0850. 164,339,350,353,357
Graves, A. and Jaitly, N. (2014). Towards end-to-end speech recognition with recurrent neural
networks. In ICML’2014 .348DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
636 参考文献
Graves, A. and Schmidhuber, J. (2005). Framewise phoneme classiﬁcation with bidirectional
LSTM and other neural network architectures. Neural Networks ,18(5), 602–610. 336
Graves, A. and Schmidhuber, J. (2009). Oﬄine handwriting recognition with multidimensional
recurrent neural networks. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors,
NIPS’2008 , pages 545–552. 336,348
Graves, A., Fernández, S., Gomez, F., and Schmidhuber, J. (2006). Connectionist tempo-
ral classiﬁcation: Labelling unsegmented sequence data with recurrent neural networks. In
ICML’2006 , pages 369–376, Pittsburgh, USA. 391
Graves, A., Liwicki, M., Bunke, H., Schmidhuber, J., and Fernández, S. (2008). Unconstrained
on-line handwriting recognition with recurrent neural networks. In J. Platt, D. Koller,
Y. Singer, and S. Roweis, editors, NIPS’2007 , pages 577–584. 336
Graves, A., Mohamed, A., and Hinton, G. (2013). Speech recognition with deep recurrent neural
networks. In ICASSP’2013 , pages 6645–6649. 336,348,391
Graves, A., Wayne, G., and Danihelka, I. (2014). Neural Turing machines. arXiv:1410.5401. 23,
355
Grefenstette, E., Hermann, K. M., Suleyman, M., and Blunsom, P. (2015). Learning to transduce
with unbounded memory. In NIPS’2015 .355
Greﬀ, K., Srivastava, R. K., Koutník, J., Steunebrink, B. R., and Schmidhuber, J. (2015).
LSTM: a search space odyssey. arXiv preprint arXiv:1503.04069 .351
Gregor, K. and LeCun, Y. (2010a). Emergence of complex-like cells in a temporal product
network with local receptive ﬁelds. Technical report, arXiv:1006.0448. 299
Gregor, K. and LeCun, Y. (2010b). Learning fast approximations of sparse coding. In L. Bottou
and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on
Machine Learning (ICML-10) . ACM. 557
Gregor, K., Danihelka, I., Mnih, A., Blundell, C., and Wierstra, D. (2014). Deep autoregressive
networks. In International Conference on Machine Learning (ICML’2014) .591
Gregor, K., Danihelka, I., Graves, A., and Wierstra, D. (2015). DRAW: A recurrent neural
network for image generation. arXiv preprint arXiv:1502.04623 .595
Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B., and Smola, A. (2012). A kernel
two-sample test. The Journal of Machine Learning Research ,13(1), 723–773. 600DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 637
Guillaume Desjardins, Karen Simonyan, R. P. K. K. (2015). Natural neural networks. Technical
report, arXiv:1507.00210. 272
Gulcehre, C. and Bengio, Y. (2013). Knowledge matters: Importance of prior information for
optimization. Technical Report arXiv:1301.4083, Universite de Montreal. 22
Guo, H. and Gelfand, S. B. (1992). Classiﬁcation trees with neural network feature extraction.
Neural Networks, IEEE Transactions on ,3(6), 923–933. 382
Gupta, S., Agrawal, A., Gopalakrishnan, K., and Narayanan, P. (2015). Deep learning with
limited numerical precision. CoRR ,abs/1502.02551 .383
Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estimation prin-
ciple for unnormalized statistical models. In Proceedings of The Thirteenth International
Conference on Artiﬁcial Intelligence and Statistics (AISTATS’10) .528
Hadsell, R., Sermanet, P., Ben, J., Erkan, A., Han, J., Muller, U., and LeCun, Y. (2007). Online
learning for oﬀroad robots: Spatial label propagation to learn long-range traversability. In
Proceedings of Robotics: Science and Systems , Atlanta, GA, USA. 385
Hajnal, A., Maass, W., Pudlak, P., Szegedy, M., and Turan, G. (1993). Threshold circuits of
bounded depth. J. Comput. System. Sci. ,46, 129–154. 172
Håstad, J. (1986). Almost optimal lower bounds for small depth circuits. In Proceedings of
the 18th annual ACM Symposium on Theory of Computing , pages 6–20, Berkeley, California.
ACM Press. 172
Håstad, J. and Goldmann, M. (1991). On the power of small-depth threshold circuits. Compu-
tational Complexity ,1, 113–129. 172
Hastie, T., Tibshirani, R., and Friedman, J. (2001). The elements of statistical learning: data
mining, inference and prediction . Springer Series in Statistics. Springer Verlag. 126
He, K., Zhang, X., Ren, S., and Sun, J. (2015). Delving deep into rectiﬁers: Surpassing human-
level performance on ImageNet classiﬁcation. arXiv preprint arXiv:1502.01852 .23,167
Hebb, D. O. (1949). The Organization of Behavior . Wiley, New York. 13,15,559
Henaﬀ, M., Jarrett, K., Kavukcuoglu, K., and LeCun, Y. (2011). Unsupervised learning of
sparse features for scalable audio classiﬁcation. In ISMIR’11 .446
Henderson, J. (2003). Inducing history representations for broad coverage statistical parsing. In
HLT-NAACL , pages 103–110. 405DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
638 参考文献
Henderson, J. (2004). Discriminative training of a neural network statistical parser. In Pro-
ceedings of the 42nd Annual Meeting on Association for Computational Linguistics , page 95.
405
Henniges, M., Puertas, G., Bornschein, J., Eggert, J., and Lücke, J. (2010). Binary sparse
coding. In Latent Variable Analysis and Signal Separation , pages 450–457. Springer. 545
Herault, J. and Ans, B. (1984). Circuits neuronaux à synapses modiﬁables: Décodage de mes-
sages composites par apprentissage non supervisé. Comptes Rendus de l ’Académie des Sci-
ences ,299(III-13) , 525--–528. 418
Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen,
P., Sainath, T., and Kingsbury, B. (2012a). Deep neural networks for acoustic modeling in
speech recognition. IEEE Signal Processing Magazine ,29(6), 82–97. 22,89,390
Hinton, G., Vinyals, O., and Dean, J. (2015). Distilling the knowledge in a neural network.
arXiv preprint arXiv:1503.02531 .380
Hinton, G. E. (1989). Connectionist learning procedures. Artiﬁcial Intelligence ,40, 185–234.
420
Hinton, G. E. (1990). Mapping part-whole hierarchies into connectionist networks. Artiﬁcial
Intelligence ,46(1), 47–75. 355
Hinton, G. E. (1999). Products of experts. In Proceedings of the Ninth International Conference
on Artiﬁcial Neural Networks (ICANN) , volume 1, pages 1–6, Edinburgh, Scotland. IEE. 485
Hinton, G. E. (2000). Training products of experts by minimizing contrastive divergence. Tech-
nical Report GCNU TR 2000-004, Gatsby Unit, University College London. 518,577
Hinton, G. E. (2006). To recognize shapes, ﬁrst learn to generate images. Technical Report
UTML TR 2006-003, University of Toronto. 450
Hinton, G. E. (2007a). How to do backpropagation in a brain. Invited talk at the NIPS’2007
Deep Learning Workshop. 559
Hinton, G. E. (2007b). Learning multiple layers of representation. Trends in cognitive sciences ,
11(10), 428–434. 563
Hinton, G. E. (2010). A practical guide to training restricted Boltzmann machines. Technical
Report UTML TR 2010-003, Comp. Sc., University of Toronto. 518
Hinton, G. E. (2012). Tutorial on deep learning. IPAM Graduate Summer School: Deep
Learning, Feature Learning. 261DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 639
Hinton, G. E. and Ghahramani, Z. (1997). Generative models for discovering sparse distributed
representations. Philosophical Transactions of the Royal Society of London .128
Hinton, G. E. and McClelland, J. L. (1988). Learning representations by recirculation. In
NIPS’1987 , pages 358–366. 428
Hinton, G. E. and Roweis, S. (2003). Stochastic neighbor embedding. In NIPS’2002 .442
Hinton, G. E. and Salakhutdinov, R. (2006). Reducing the dimensionality of data with neural
networks. Science ,313(5786), 504–507. 434,447,450,451,453
Hinton, G. E. and Sejnowski, T. J. (1986). Learning and relearning in Boltzmann machines.
In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing , volume 1,
chapter 7, pages 282–317. MIT Press, Cambridge. 485,558
Hinton, G. E. and Sejnowski, T. J. (1999). Unsupervised learning: foundations of neural com-
putation . MIT press. 461
Hinton, G. E. and Shallice, T. (1991). Lesioning an attractor network: investigations of acquired
dyslexia. Psychological review ,98(1), 74. 12
Hinton, G. E. and Zemel, R. S. (1994). Autoencoders, minimum description length, and
Helmholtz free energy. In NIPS’1993 .428
Hinton, G. E., Sejnowski, T. J., and Ackley, D. H. (1984a). Boltzmann machines: Constraint
satisfaction networks that learn. Technical Report TR-CMU-CS-84-119, Carnegie-Mellon
University, Dept. of Computer Science. 485
Hinton, G. E., Sejnowski, T. J., and Ackley, D. H. (1984b). Boltzmann machines: Constraint
satisfaction networks that learn. Technical Report TR-CMU-CS-84-119, Carnegie-Mellon
University, Dept. of Computer Science. 558
Hinton, G. E., McClelland, J., and Rumelhart, D. (1986). Distributed representations. In D. E.
Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing: Explorations in the
Microstructure of Cognition , volume 1, pages 77–109. MIT Press, Cambridge. 16,194,448
Hinton, G. E., Revow, M., and Dayan, P. (1995a). Recognizing handwritten digits using mixtures
of linear models. In G. Tesauro, D. Touretzky, and T. Leen, editors, Advances in Neural
Information Processing Systems 7 (NIPS’94) , pages 1015–1022. MIT Press, Cambridge, MA.
416
Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995b). The wake-sleep algorithm for
unsupervised neural networks. Science ,268, 1558–1161. 430,556DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
640 参考文献
Hinton, G. E., Dayan, P., and Revow, M. (1997). Modelling the manifolds of images of hand-
written digits. IEEE Transactions on Neural Networks ,8, 65–74. 425
Hinton, G. E., Welling, M., Teh, Y. W., and Osindero, S. (2001). A new view of ICA. In
Proceedings of 3rd International Conference on Independent Component Analysis and Blind
Signal Separation (ICA’01) , pages 746–751, San Diego, CA. 418
Hinton, G. E., Osindero, S., and Teh, Y. (2006a). A fast learning algorithm for deep belief nets.
Neural Computation ,18, 1527–1554. 13,17,21,505,563,564
Hinton, G. E., Osindero, S., and Teh, Y.-W. (2006b). A fast learning algorithm for deep belief
nets. Neural Computation ,18, 1527–1554. 125,450,451
Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2012b).
Improving neural networks by preventing co-adaptation of feature detectors. Technical report,
arXiv:1207.0580. 204,225
Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2012c).
Improving neural networks by preventing co-adaptation of feature detectors. Technical report,
arXiv:1207.0580. 228
Hinton, G. E., Vinyals, O., and Dean, J. (2014). Dark knowledge. Invited talk at the BayLearn
Bay Area Machine Learning Symposium. 380
Hochreiter, S. (1991a). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis,
T.U. München. 342,343
Hochreiter, S. (1991b). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis,
Institut für Informatik, Lehrstuhl Prof. Brauer, Technische Universität München. 16
Hochreiter, S. and Schmidhuber, J. (1995). Simplifying neural nets by discovering ﬂat minima.
InAdvances in Neural Information Processing Systems 7 , pages 529–536. MIT Press. 208
Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Computation ,
9(8), 1735–1780. 16,348,350
Hochreiter, S., Bengio, Y., and Frasconi, P. (2001). Gradient ﬂow in recurrent nets: the diﬃculty
of learning long-term dependencies. In J. Kolen and S. Kremer, editors, Field Guide to
Dynamical Recurrent Networks . IEEE Press. 350
Holi, J. L. and Hwang, J.-N. (1993). Finite precision error analysis of neural network hardware
implementations. Computers, IEEE Transactions on ,42(3), 281–290. 383DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 641
Holt, J. L. and Baker, T. E. (1991). Back propagation simulations using limited precision
calculations. In Neural Networks, 1991., IJCNN-91-Seattle International Joint Conference
on, volume 2, pages 121–126. IEEE. 383
Hornik, K., Stinchcombe, M., and White, H. (1989). Multilayer feedforward networks are uni-
versal approximators. Neural Networks ,2, 359–366. 171
Hornik, K., Stinchcombe, M., and White, H. (1990). Universal approximation of an unknown
mapping and its derivatives using multilayer feedforward networks. Neural networks ,3(5),
551–560. 171
Hsu, F.-H. (2002). Behind Deep Blue: Building the Computer That Defeated the World Chess
Champion . Princeton University Press, Princeton, NJ, USA. 2
Huang, F. and Ogata, Y. (2002). Generalized pseudo-likelihood estimates for Markov random
ﬁelds on lattice. Annals of the Institute of Statistical Mathematics ,54(1), 1–18. 524
Huang, P.-S., He, X., Gao, J., Deng, L., Acero, A., and Heck, L. (2013). Learning deep struc-
tured semantic models for web search using clickthrough data. In Proceedings of the 22nd
ACM international conference on Conference on information & knowledge management , pages
2333–2338. ACM. 407
Hubel, D. and Wiesel, T. (1968). Receptive ﬁelds and functional architecture of monkey striate
cortex. Journal of Physiology (London) ,195, 215–243. 310
Hubel, D. H. and Wiesel, T. N. (1959). Receptive ﬁelds of single neurons in the cat’s striate
cortex. Journal of Physiology ,148, 574–591. 310
Hubel, D. H. and Wiesel, T. N. (1962). Receptive ﬁelds, binocular interaction, and functional
architecture in the cat’s visual cortex. Journal of Physiology (London) ,160, 106–154. 310
Huszar, F. (2015). How (not) to train your generative model: schedule sampling, likelihood,
adversary? arXiv:1511.05101 .595
Hutter, F., Hoos, H., and Leyton-Brown, K. (2011). Sequential model-based optimization for
general algorithm conﬁguration. In LION-5 . Extended version as UBC Tech report TR-2010-
10.370
Hyotyniemi, H. (1996). Turing machines are recurrent neural networks. In STeP’96 , pages
13–24. 324
Hyvärinen, A. (1999). Survey on independent component analysis. Neural Computing Surveys ,
2, 94–128. 418DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
642 参考文献
Hyvärinen, A. (2005a). Estimation of non-normalized statistical models using score matching.
Journal of Machine Learning Research ,6, 695–709. 436
Hyvärinen, A. (2005b). Estimation of non-normalized statistical models using score matching.
J. Machine Learning Res. ,6.525
Hyvärinen, A. (2007a). Connections between score matching, contrastive divergence, and pseu-
dolikelihood for continuous-valued variables. IEEE Transactions on Neural Networks ,18,
1529–1531. 526
Hyvärinen, A. (2007b). Some extensions of score matching. Computational Statistics and Data
Analysis ,51, 2499–2512. 526
Hyvärinen, A. and Pajunen, P. (1999). Nonlinear independent component analysis: Existence
and uniqueness results. Neural Networks ,12(3), 429–439. 419
Hyvärinen, A., Karhunen, J., and Oja, E. (2001). Independent Component Analysis . Wiley-
Interscience. 418
Hyvärinen, A., Hurri, J., and Hoyer, P. O. (2009). Natural Image Statistics: A probabilistic
approach to early computational vision . Springer-Verlag. 315
Iba, Y. (2001). Extended ensemble Monte Carlo. International Journal of Modern Physics ,
C12, 623–656. 513
Inayoshi, H. and Kurita, T. (2005). Improved generalization by adding both auto-association and
hidden-layer noise to neural-network-based-classiﬁers. IEEE Workshop on Machine Learning
for Signal Processing , pages 141 ––146. 439
Ioﬀe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by
reducing internal covariate shift. 88,270,272
Jacobs, R. A. (1988). Increased rates of convergence through learning rate adaptation. Neural
networks ,1(4), 295–307. 260
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive mixtures of
local experts. Neural Computation ,3, 79–87. 163,382
Jaeger, H. (2003). Adaptive nonlinear system identiﬁcation with echo state networks. In Ad-
vances in Neural Information Processing Systems 15 .344
Jaeger, H. (2007a). Discovering multiscale dynamical features with hierarchical echo state net-
works. Technical report, Jacobs University. 339DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 643
Jaeger, H. (2007b). Echo state network. Scholarpedia ,2(9), 2330. 344
Jaeger, H. (2012). Long short-term memory in echo state networks: Details of a simulation
study. Technical report, Technical report, Jacobs University Bremen. 345
Jaeger, H. and Haas, H. (2004). Harnessing nonlinearity: Predicting chaotic systems and saving
energy in wireless communication. Science ,304(5667), 78–80. 21,344
Jaeger, H., Lukosevicius, M., Popovici, D., and Siewert, U. (2007). Optimization and applica-
tions of echo state networks with leaky- integrator neurons. Neural Networks ,20(3), 335–352.
347
Jain, V., Murray, J. F., Roth, F., Turaga, S., Zhigulin, V., Briggman, K. L., Helmstaedter,
M. N., Denk, W., and Seung, H. S. (2007). Supervised learning of image restoration with
convolutional networks. In Computer Vision, 2007. ICCV 2007. IEEE 11th International
Conference on , pages 1–8. IEEE. 305
Jaitly, N. and Hinton, G. (2011). Learning a better representation of speech soundwaves using
restricted Boltzmann machines. In Acoustics, Speech and Signal Processing (ICASSP), 2011
IEEE International Conference on , pages 5884–5887. IEEE. 389
Jaitly, N. and Hinton, G. E. (2013). Vocal tract length perturbation (VTLP) improves speech
recognition. In ICML’2013 .206
Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009a). What is the best multi-stage
architecture for object recognition? In Proc. International Conference on Computer Vision
(ICCV’09) , pages 2146–2153. IEEE. 15,166
Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009b). What is the best multi-stage
architecture for object recognition? In ICCV’09 .20,21,150,195,309,446
Jarzynski, C. (1997). Nonequilibrium equality for free energy diﬀerences. Phys. Rev. Lett. ,78,
2690–2693. 532,535
Jaynes, E. T. (2003). Probability Theory: The Logic of Science . Cambridge University Press. 47
Jean, S., Cho, K., Memisevic, R., and Bengio, Y. (2014). On using very large target vocabulary
for neural machine translation. arXiv:1412.2007. 402
Jelinek, F. and Mercer, R. L. (1980). Interpolated estimation of Markov source parameters from
sparse data. In E. S. Gelsema and L. N. Kanal, editors, Pattern Recognition in Practice .
North-Holland, Amsterdam. 392DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
644 参考文献
Jia, Y. (2013). Caﬀe: An open source convolutional architecture for fast feature embedding.
http://caffe.berkeleyvision.org/ .23,182
Jia, Y., Huang, C., and Darrell, T. (2012). Beyond spatial pyramids: Receptive ﬁeld learning
for pooled image features. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE
Conference on , pages 3370–3377. IEEE. 292
Jim, K.-C., Giles, C. L., and Horne, B. G. (1996). An analysis of noise in recurrent neural
networks: convergence and generalization. IEEE Transactions on Neural Networks ,7(6),
1424–1438. 207
Jordan, M. I. (1998). Learning in Graphical Models . Kluwer, Dordrecht, Netherlands. 16
Joulin, A. and Mikolov, T. (2015). Inferring algorithmic patterns with stack-augmented recurrent
nets. arXiv preprint arXiv:1503.01007 .355
Jozefowicz, R., Zaremba, W., and Sutskever, I. (2015). An empirical evaluation of recurrent
network architectures. In ICML’2015 .259,350,351
Judd, J. S. (1989). Neural Network Design and the Complexity of Learning . MIT press. 249
Jutten, C. and Herault, J. (1991). Blind separation of sources, part I: an adaptive algorithm
based on neuromimetic architecture. Signal Processing ,24, 1–10. 418
Kahou, S. E., Pal, C., Bouthillier, X., Froumenty, P., Gülçehre, c., Memisevic, R., Vincent,
P., Courville, A., Bengio, Y., Ferrari, R. C., Mirza, M., Jean, S., Carrier, P. L., Dauphin,
Y., Boulanger-Lewandowski, N., Aggarwal, A., Zumer, J., Lamblin, P., Raymond, J.-P.,
Desjardins, G., Pascanu, R., Warde-Farley, D., Torabi, A., Sharma, A., Bengio, E., Côté,
M., Konda, K. R., and Wu, Z. (2013). Combining modality speciﬁc deep neural networks for
emotion recognition in video. In Proceedings of the 15th ACM on International Conference
on Multimodal Interaction .173
Kalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. In
EMNLP’2013 .402
Kalchbrenner, N., Danihelka, I., and Graves, A. (2015). Grid long short-term memory. arXiv
preprint arXiv:1507.01526 .337
Kamyshanska, H. and Memisevic, R. (2015). The potential energy of an autoencoder. IEEE
Transactions on Pattern Analysis and Machine Intelligence .438
Karpathy, A. and Li, F.-F. (2015). Deep visual-semantic alignments for generating image de-
scriptions. In CVPR’2015 . arXiv:1412.2306. 90DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 645
Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., and Fei-Fei, L. (2014). Large-
scale video classiﬁcation with convolutional neural networks. In CVPR .18
Karush, W. (1939). Minima of Functions of Several Variables with Inequalities as Side Con-
straints . Master’s thesis, Dept. of Mathematics, Univ. of Chicago. 85
Katz, S. M. (1987). Estimation of probabilities from sparse data for the language model compo-
nent of a speech recognizer. IEEE Transactions on Acoustics, Speech, and Signal Processing ,
ASSP-35 (3), 400–401. 392
Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2008). Fast inference in sparse coding algo-
rithms with applications to object recognition. Technical report, Computational and Biolog-
ical Learning Lab, Courant Institute, NYU. Tech Report CBLL-TR-2008-12-01. 446
Kavukcuoglu, K., Ranzato, M.-A., Fergus, R., and LeCun, Y. (2009). Learning invariant features
through topographic ﬁlter maps. In CVPR’2009 .446
Kavukcuoglu, K., Sermanet, P., Boureau, Y.-L., Gregor, K., Mathieu, M., and LeCun, Y. (2010).
Learning convolutional feature hierarchies for visual recognition. In NIPS’2010 .309,446
Kelley, H. J. (1960). Gradient theory of optimal ﬂight paths. ARS Journal ,30(10), 947–954.
194
Khan, F., Zhu, X., and Mutlu, B. (2011). How do humans teach: On curriculum learning and
teaching dimension. In Advances in Neural Information Processing Systems 24 (NIPS’11) ,
pages 1449–1457. 279
Kim, S. K., McAfee, L. C., McMahon, P. L., and Olukotun, K. (2009). A highly scalable
restricted Boltzmann machine FPGA implementation. In Field Programmable Logic and
Applications, 2009. FPL 2009. International Conference on , pages 367–372. IEEE. 383
Kindermann, R. (1980). Markov Random Fields and Their Applications (Contemporary Math-
ematics ; V. 1) . American Mathematical Society. 481
Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 .261
Kingma, D. and LeCun, Y. (2010a). Regularized estimation of image statistics by score matching.
InNIPS’2010 .437
Kingma, D. and LeCun, Y. (2010b). Regularized estimation of image statistics by score match-
ing. In J. Laﬀerty, C. K. I. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta, editors,
Advances in Neural Information Processing Systems 23 , pages 1126–1134. 527DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
646 参考文献
Kingma, D., Rezende, D., Mohamed, S., and Welling, M. (2014). Semi-supervised learning with
deep generative models. In NIPS’2014 .362
Kingma, D. P. (2013). Fast gradient-based inference with continuous latent variable models in
auxiliary form. Technical report, arxiv:1306.0733. 587,593
Kingma, D. P. and Welling, M. (2014a). Auto-encoding variational bayes. In Proceedings of the
International Conference on Learning Representations (ICLR) .557,587,596
Kingma, D. P. and Welling, M. (2014b). Eﬃcient gradient-based inference through transforma-
tions between bayes nets and neural nets. Technical report, arxiv:1402.0480. 587
Kirkpatrick, S., Jr., C. D. G., , and Vecchi, M. P. (1983). Optimization by simulated annealing.
Science ,220, 671–680. 278
Kiros, R., Salakhutdinov, R., and Zemel, R. (2014a). Multimodal neural language models. In
ICML’2014 .90
Kiros, R., Salakhutdinov, R., and Zemel, R. (2014b). Unifying visual-semantic embeddings with
multimodal neural language models. arXiv: 1411.2539 [cs.LG] .90,348
Klementiev, A., Titov, I., and Bhattarai, B. (2012). Inducing crosslingual distributed represen-
tations of words. In Proceedings of COLING 2012 .405,458
Knowles-Barley, S., Jones, T. R., Morgan, J., Lee, D., Kasthuri, N., Lichtman, J. W., and
Pﬁster, H. (2014). Deep learning for the connectome. GPU Technology Conference .24
Koller, D. and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques .
MIT Press. 495,505,550
Konig, Y., Bourlard, H., and Morgan, N. (1996). REMAP: Recursive estimation and maxi-
mization of a posteriori probabilities – application to transition-based connectionist speech
recognition. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural In-
formation Processing Systems 8 (NIPS’95) . MIT Press, Cambridge, MA. 389
Koren, Y. (2009). The BellKor solution to the Netﬂix grand prize. 221,407
Kotzias, D., Denil, M., de Freitas, N., and Smyth, P. (2015). From group to individual labels
using deep features. In ACM SIGKDD .93
Koutnik, J., Greﬀ, K., Gomez, F., and Schmidhuber, J. (2014). A clockwork RNN. In
ICML’2014 .347
Kočiský, T., Hermann, K. M., and Blunsom, P. (2014). Learning Bilingual Word Representations
by Marginalizing Alignments. In Proceedings of ACL .403DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 647
Krause, O., Fischer, A., Glasmachers, T., and Igel, C. (2013). Approximation properties of
DBNs with binary hidden units and real-valued visible units. In ICML’2013 .471
Krizhevsky, A. (2010). Convolutional deep belief networks on CIFAR-10. Technical report, Uni-
versity of Toronto. Unpublished Manuscript: http://www.cs.utoronto.ca/ kriz/conv-cifar10-
aug2010.pdf. 379
Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images.
Technical report, University of Toronto. 18,476
Krizhevsky, A. and Hinton, G. E. (2011). Using very deep autoencoders for content-based image
retrieval. In ESANN .447
Krizhevsky, A., Sutskever, I., and Hinton, G. (2012a). ImageNet classiﬁcation with deep convo-
lutional neural networks. In NIPS’2012 .20,21,88,173,316
Krizhevsky, A., Sutskever, I., and Hinton, G. (2012b). ImageNet classiﬁcation with deep
convolutional neural networks. In Advances in Neural Information Processing Systems 25
(NIPS’2012) .22,385,388
Krueger, K. A. and Dayan, P. (2009). Flexible shaping: how learning in small steps helps.
Cognition ,110, 380–394. 278
Kuhn, H. W. and Tucker, A. W. (1951). Nonlinear programming. In Proceedings of the Second
Berkeley Symposium on Mathematical Statistics and Probability , pages 481–492, Berkeley,
Calif. University of California Press. 85
Kumar, A., Irsoy, O., Ondruska, P., Iyyer, M., Bradbury, J., Gulrajani, I., and Socher, R.
(2015a). Ask me anything: Dynamic memory networks for natural language processing.
Technical report, arXiv:1506.07285. 355
Kumar, A., Irsoy, O., Su, J., Bradbury, J., English, R., Pierce, B., Ondruska, P., Iyyer, M.,
Gulrajani, I., and Socher, R. (2015b). Ask me anything: Dynamic memory networks for
natural language processing. arXiv:1506.07285 .411
Kumar, M. P., Packer, B., and Koller, D. (2010). Self-paced learning for latent variable models.
In J. Laﬀerty, C. K. I. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta, editors, Advances
in Neural Information Processing Systems 23 , pages 1189–1197. 278
Lang, K. J. and Hinton, G. E. (1988). The development of the time-delay neural network
architecture for speech recognition. Technical Report CMU-CS-88-152, Carnegie-Mellon Uni-
versity. 312,318,346DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
648 参考文献
Lang, K. J., Waibel, A. H., and Hinton, G. E. (1990). A time-delay neural network architecture
for isolated word recognition. Neural networks ,3(1), 23–43. 318
Langford, J. and Zhang, T. (2008). The epoch-greedy algorithm for contextual multi-armed
bandits. In NIPS’2008 , pages 1096-- –1103. 408
Lappalainen, H., Giannakopoulos, X., Honkela, A., and Karhunen, J. (2000). Nonlinear inde-
pendent component analysis using ensemble learning: Experiments and discussion. In Proc.
ICA. Citeseer. 419
Larochelle, H. and Bengio, Y. (2008a). Classiﬁcation using discriminative restricted Boltzmann
machines. In ICM (1a), pages 536–543. 218,452
Larochelle, H. and Bengio, Y. (2008b). Classiﬁcation using discriminative restricted Boltzmann
machines. In ICML’2008 .585,609
Larochelle, H. and Hinton, G. E. (2010). Learning to combine foveal glimpses with a third-
order Boltzmann machine. In Advances in Neural Information Processing Systems 23 , pages
1243–1251. 312
Larochelle, H. and Murray, I. (2011). The Neural Autoregressive Distribution Estimator. In
AISTATS’2011 .601,603,604
Larochelle, H., Erhan, D., and Bengio, Y. (2008). Zero-data learning of new tasks. In AAAI
Conference on Artiﬁcial Intelligence .209,458
Larochelle, H., Bengio, Y., Louradour, J., and Lamblin, P. (2009). Exploring strategies for
training deep neural networks. In JML (1), pages 1–40. 454
Lasserre, J. A., Bishop, C. M., and Minka, T. P. (2006). Principled hybrids of generative
and discriminative models. In Proceedings of the Computer Vision and Pattern Recognition
Conference (CVPR’06) , pages 87–94, Washington, DC, USA. IEEE Computer Society. 209,
217
Le, Q., Ngiam, J., Chen, Z., hao Chia, D. J., Koh, P. W., and Ng, A. (2010). Tiled convolutional
neural networks. In J. Laﬀerty, C. K. I. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta,
editors, Advances in Neural Information Processing Systems 23 (NIPS’10) , pages 1279–1287.
299
Le, Q., Ranzato, M., Monga, R., Devin, M., Corrado, G., Chen, K., Dean, J., and Ng, A. (2012).
Building high-level features using large scale unsupervised learning. In ICML’2012 .20,21DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 649
Le Roux, N. and Bengio, Y. (2007). Representational power of restricted Boltzmann machines
and deep belief networks. Technical Report 1294, Département d’Informatique et de Recherche
Opérationnelle, Université de Montréal. 471
Le Roux, N. and Bengio, Y. (2008). Representational power of restricted Boltzmann machines
and deep belief networks. Neural Computation ,20(6), 1631–1649. 559
Le Roux, N., Bengio, Y., and Fitzgibbon, A. (2011). Improving ﬁrst and second-order methods
by modeling uncertainty. In Optimization for Machine Learning . MIT Press. Eds. S. Sra, S.
Nowozin and S.J. Wright. 269
LeCun, Y. (1985). Une procédure d’apprentissage pour Réseau à seuil assymétrique. In Cogni-
tiva 85: A la Frontière de l’Intelligence Artiﬁcielle, des Sciences de la Connaissance et des
Neurosciences , pages 599–604, Paris 1985. CESTA, Paris. 194
LeCun, Y. (1986). Learning processes in an asymmetric threshold network. In E. Bienenstock,
F. Fogelman-Soulié, and G. Weisbuch, editors, Disordered Systems and Biological Organiza-
tion, pages 233–240. Springer-Verlag, Berlin, Les Houches 1985. 297
LeCun, Y. (1987). Modèles connexionistes de l’apprentissage . Ph.D. thesis, Université de Paris
VI.16,428,439
LeCun, Y. (1989). Generalization and network design strategies. Technical Report CRG-TR-
89-4, University of Toronto. 280,297
LeCun, Y. and Cortes, C. (1998). The mnist database of handwritten digits. 264
LeCun, Y., Jackel, L. D., Boser, B., Denker, J. S., Graf, H. P., Guyon, I., Henderson, D.,
Howard, R. E., and Hubbard, W. (1989). Handwritten digit recognition: Applications of
neural network chips and automatic learning. IEEE Communications Magazine ,27(11), 41–
46.313
LeCun, Y., Bottou, L., Orr, G. B., and Müller, K. (1998a). Eﬃcient backprop. In Neural
Networks, Tricks of the Trade .364
LeCun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (1998b). Gradient based learning applied to
document recognition. Proc. IEEE .14,16,18,21
LeCun, Y., Bottou, L., Bengio, Y., and Haﬀner, P. (2001). Gradient-based learning applied
to document recognition. In S. Haykin and B. Kosko, editors, Intelligent Signal Processing ,
pages 306–351. IEEE Press. 316,389,391DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
650 参考文献
LeCun, Y., Kavukcuoglu, K., and Farabet, C. (2010). Convolutional networks and applications in
vision. In Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium
on, pages 253–256. IEEE. 316
L’Ecuyer, P. (1994). Eﬃciency improvement and variance reduction. In Proceedings of the 1994
Winter Simulation Conference , pages 122-- –132. 588
Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., and Tu, Z. (2014). Deeply-supervised nets. arXiv
preprint arXiv:1409.5185 .277
Lee, H., Battle, A., Raina, R., and Ng, A. (2007). Eﬃcient sparse coding algorithms. In
B. Schölkopf, J. Platt, and T. Hoﬀman, editors, Advances in Neural Information Processing
Systems 19 (NIPS’06) , pages 801–808. MIT Press. 543
Lee, H., Ekanadham, C., and Ng, A. (2008). Sparse deep belief net model for visual area V2.
InNIPS’07 .218
Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. (2009). Convolutional deep belief net-
works for scalable unsupervised learning of hierarchical representations. In L. Bottou and
M. Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine
Learning (ICML’09) . ACM, Montreal, Canada. 309,582,583
Lee, Y. J. and Grauman, K. (2011). Learning the easy things ﬁrst: self-paced visual category
discovery. In CVPR’2011 .278
Leibniz, G. W. (1676). Memoir using the chain rule. (Cited in TMME 7:2&3 p 321-332, 2010).
193
Lenat, D. B. and Guha, R. V. (1989). Building large knowledge-based systems; representation
and inference in the Cyc project . Addison-Wesley Longman Publishing Co., Inc. 2
Leshno, M., Lin, V. Y., Pinkus, A., and Schocken, S. (1993). Multilayer feedforward networks
with a nonpolynomial activation function can approximate any function. Neural Networks ,
6, 861--–867. 171,172
Levenberg, K. (1944). A method for the solution of certain non-linear problems in least squares.
Quarterly Journal of Applied Mathematics ,II(2), 164–168. 265
L’Hôpital, G. F. A. (1696). Analyse des inﬁniment petits, pour l’intelligence des lignes courbes .
Paris: L’Imprimerie Royale. 193
Li, Y., Swersky, K., and Zemel, R. S. (2015). Generative moment matching networks. CoRR ,
abs/1502.02761 .599DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 651
Lin, T., Horne, B. G., Tino, P., and Giles, C. L. (1996). Learning long-term dependencies is not
as diﬃcult with NARX recurrent neural networks. IEEE Transactions on Neural Networks ,
7(6), 1329–1338. 346
Lin, Y., Liu, Z., Sun, M., Liu, Y., and Zhu, X. (2015). Learning entity and relation embeddings
for knowledge graph completion. In Proc. AAAI’15 .411
Linde, N. (1992). The machine that changed the world, episode 3. Documentary miniseries. 2
Lindsey, C. and Lindblad, T. (1994). Review of hardware neural networks: a user ’s perspective.
InProc. Third Workshop on Neural Networks: From Biology to High Energy Physics , pages
195--–202, Isola d’Elba, Italy. 383
Linnainmaa, S. (1976). Taylor expansion of the accumulated rounding error. BIT Numerical
Mathematics ,16(2), 146–160. 194
LISA (2008). Deep learning tutorials: Restricted Boltzmann machines. Technical report, LISA
Lab, Université de Montréal. 500
Long, P. M. and Servedio, R. A. (2010). Restricted Boltzmann machines are hard to approxi-
mately evaluate or simulate. In Proceedings of the 27th International Conference on Machine
Learning (ICML’10) .560
Lotter, W., Kreiman, G., and Cox, D. (2015). Unsupervised learning of visual structure using
predictive generative networks. arXiv preprint arXiv:1511.06380 .463,464
Lovelace, A. (1842). Notes upon L. F. Menabrea’s “Sketch of the Analytical Engine invented by
Charles Babbage” . 1
Lu, L., Zhang, X., Cho, K., and Renals, S. (2015). A study of the recurrent neural network
encoder-decoder for large vocabulary speech recognition. In Proc. Interspeech .391
Lu, T., Pál, D., and Pál, M. (2010). Contextual multi-armed bandits. In International Confer-
ence on Artiﬁcial Intelligence and Statistics , pages 485–492. 408
Luenberger, D. G. (1984). Linear and Nonlinear Programming . Addison Wesley. 269
Lukoševičius, M. and Jaeger, H. (2009). Reservoir computing approaches to recurrent neural
network training. Computer Science Review ,3(3), 127–149. 344
Luo, H., Shen, R., Niu, C., and Ullrich, C. (2011). Learning class-relevant features and class-
irrelevant features via a hybrid third-order RBM. In International Conference on Artiﬁcial
Intelligence and Statistics , pages 470–478. 585DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
652 参考文献
Luo, H., Carrier, P. L., Courville, A., and Bengio, Y. (2013). Texture modeling with convolu-
tional spike-and-slab RBMs and deep extensions. In AISTATS’2013 .90
Lyu, S. (2009). Interpretation and generalization of score matching. In Proceedings of the
Twenty-ﬁfth Conference in Uncertainty in Artiﬁcial Intelligence (UAI’09) .526
Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E., and Svetnik, V. (2015). Deep neural nets as
a method for quantitative structure –activity relationships. J. Chemical information and
modeling .451
Maas, A. L., Hannun, A. Y., and Ng, A. Y. (2013). Rectiﬁer nonlinearities improve neural
network acoustic models. In ICML Workshop on Deep Learning for Audio, Speech, and
Language Processing .166
Maass, W. (1992). Bounds for the computational power and learning complexity of analog
neural nets (extended abstract). In Proc. of the 25th ACM Symp. Theory of Computing ,
pages 335–344. 172
Maass, W., Schnitger, G., and Sontag, E. D. (1994). A comparison of the computational power
of sigmoid and Boolean threshold circuits. Theoretical Advances in Neural Computation and
Learning , pages 127–151. 172
Maass, W., Natschlaeger, T., and Markram, H. (2002). Real-time computing without stable
states: A new framework for neural computation based on perturbations. Neural Computa-
tion,14(11), 2531–2560. 344
MacKay, D. (2003). Information Theory, Inference and Learning Algorithms . Cambridge Uni-
versity Press. 66
Maclaurin, D., Duvenaud, D., and Adams, R. P. (2015). Gradient-based hyperparameter opti-
mization through reversible learning. arXiv preprint arXiv:1502.03492 .369
Mao, J., Xu, W., Yang, Y., Wang, J., and Yuille, A. (2014). Deep captioning with multimodal
recurrent neural networks (m-rnn). arXiv: 1412.6632 [cs.CV] .90
Marcotte, P. and Savard, G. (1992). Novel approaches to the discrimination problem. Zeitschrift
für Operations Research (Theory) ,36, 517–545. 236
Marlin, B. and de Freitas, N. (2011). Asymptotic eﬃciency of deterministic estimators for
discrete energy-based models: Ratio matching and pseudolikelihood. In UAI’2011 .525,527
Marlin, B., Swersky, K., Chen, B., and de Freitas, N. (2010). Inductive principles for restricted
Boltzmann machine learning. In AISTATS’2010 , pages 509–516. 521,526DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 653
Marquardt, D. W. (1963). An algorithm for least-squares estimation of non-linear parameters.
Journal of the Society of Industrial and Applied Mathematics ,11(2), 431–441. 265
Marr, D. and Poggio, T. (1976). Cooperative computation of stereo disparity. Science ,194.312
Martens, J. (2010). Deep learning via Hessian-free optimization. In ICML’2010 , pages 735–742.
258
Martens, J. and Medabalimi, V. (2014). On the expressive eﬃciency of sum product networks.
arXiv:1411.7717 .471
Martens, J. and Sutskever, I. (2011). Learning recurrent neural networks with Hessian-free
optimization. In Proc. ICML’2011 . ACM. 351,352
Mase, S. (1995). Consistency of the maximum pseudo-likelihood estimator of continuous state
space Gibbsian processes. The Annals of Applied Probability ,5(3), pp. 603–612. 524
McClelland, J., Rumelhart, D., and Hinton, G. (1995). The appeal of parallel distributed
processing. In Computation & intelligence , pages 305–341. American Association for Artiﬁcial
Intelligence. 15
McCulloch, W. S. and Pitts, W. (1943). A logical calculus of ideas immanent in nervous activity.
Bulletin of Mathematical Biophysics ,5, 115–133. 13
Mead, C. and Ismail, M. (2012). Analog VLSI implementation of neural systems , volume 80.
Springer Science & Business Media. 383
Melchior, J., Fischer, A., and Wiskott, L. (2013). How to center binary deep Boltzmann ma-
chines. arXiv preprint arXiv:1311.1354 .574
Memisevic, R. and Hinton, G. E. (2007). Unsupervised learning of image transformations. In
Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR’07) .585
Memisevic, R. and Hinton, G. E. (2010). Learning to represent spatial transformations with
factored higher-order Boltzmann machines. Neural Computation ,22(6), 1473–1492. 585
Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller,
X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., and Bergstra, J. (2011).
Unsupervised and transfer learning challenge: a deep learning approach. In JMLR W&CP:
Proc. Unsupervised and Transfer Learning , volume 7. 173,453,457
Mesnil, G., Rifai, S., Dauphin, Y., Bengio, Y., and Vincent, P. (2012). Surﬁng on the manifold.
Learning Workshop, Snowbird. 606DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
654 参考文献
Miikkulainen, R. and Dyer, M. G. (1991). Natural language processing with modular PDP
networks and distributed lexicon. Cognitive Science ,15, 343–399. 405
Mikolov, T. (2012). Statistical Language Models based on Neural Networks . Ph.D. thesis, Brno
University of Technology. 352
Mikolov, T., Deoras, A., Kombrink, S., Burget, L., and Cernocky, J. (2011a). Empirical eval-
uation and combination of advanced language modeling techniques. In Proc. 12th annual
conference of the international speech communication association (INTERSPEECH 2011) .
401
Mikolov, T., Deoras, A., Povey, D., Burget, L., and Cernocky, J. (2011b). Strategies for training
large scale neural network language models. In Proc. ASRU’2011 .278,401
Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a). Eﬃcient estimation of word represen-
tations in vector space. In International Conference on Learning Representations: Workshops
Track .455
Mikolov, T., Le, Q. V., and Sutskever, I. (2013b). Exploiting similarities among languages for
machine translation. Technical report, arXiv:1309.4168. 458
Minka, T. (2005). Divergence measures and message passing. Microsoft Research Cambridge
UK Tech Rep MSRTR2005173 ,72(TR-2005-173). 532
Minsky, M. L. and Papert, S. A. (1969). Perceptrons . MIT Press, Cambridge. 14
Mirza, M. and Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint
arXiv:1411.1784 .598
Mishkin, D. and Matas, J. (2015). All you need is a good init. arXiv preprint arXiv:1511.06422 .
258
Misra, J. and Saha, I. (2010). Artiﬁcial neural networks in hardware: A survey of two decades
of progress. Neurocomputing ,74(1), 239–255. 383
Mitchell, T. M. (1997). Machine Learning . McGraw-Hill, New York. 87
Miyato, T., Maeda, S., Koyama, M., Nakae, K., and Ishii, S. (2015). Distributional smoothing
with virtual adversarial training. In ICLR . Preprint: arXiv:1507.00677. 230
Mnih, A. and Gregor, K. (2014). Neural variational inference and learning in belief networks.
InICML’2014 .589,590,591DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 655
Mnih, A. and Hinton, G. E. (2009). A scalable hierarchical distributed language model. In
D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information
Processing Systems 21 (NIPS’08) , pages 1081–1088. 396
Mnih, A. and Kavukcuoglu, K. (2013). Learning word embeddings eﬃciently with noise-
contrastive estimation. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Wein-
berger, editors, Advances in Neural Information Processing Systems 26 , pages 2265–2273.
Curran Associates, Inc. 93,400,529
Mnih, A. and Teh, Y. W. (2012). A fast and simple algorithm for training neural probabilistic
language models. In ICML’2012 , pages 1751–1758. 400
Mnih, V. and Hinton, G. (2010). Learning to detect roads in high-resolution aerial images. In
Proceedings of the 11th European Conference on Computer Vision (ECCV) .90
Mnih, V., Larochelle, H., and Hinton, G. (2011). Conditional restricted Boltzmann machines for
structure output prediction. In Proc. Conf. on Uncertainty in Artiﬁcial Intelligence (UAI) .
584
Mnih, V., Heess, N., Graves, A., and Kavukcuoglu, K. (2014). Recurrent models of visual
attention. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger,
editors, NIPS’2014 , pages 2204–2212. 590
Mnih, V., Kavukcuoglo, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves,
A., Riedmiller, M., Fidgeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A.,
Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., and Hassabis, D. (2015).
Human-level control through deep reinforcement learning. Nature ,518, 529–533. 23
Mobahi, H. and Fisher, III, J. W. (2015). A theoretical analysis of optimization by Gaussian
continuation. In AAAI’2015 .278
Mobahi, H., Collobert, R., and Weston, J. (2009). Deep learning from temporal coherence in
video. In L. Bottou and M. Littman, editors, Proceedings of the 26th International Conference
on Machine Learning , pages 737–744, Montreal. Omnipress. 420
Mohamed, A., Dahl, G., and Hinton, G. (2009). Deep belief networks for phone recognition.
390
Mohamed, A., Sainath, T. N., Dahl, G., Ramabhadran, B., Hinton, G. E., and Picheny, M. A.
(2011). Deep belief networks using discriminative features for phone recognition. In Acoustics,
Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on , pages 5060–
5063. IEEE. 390DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
656 参考文献
Mohamed, A., Dahl, G., and Hinton, G. (2012a). Acoustic modeling using deep belief networks.
IEEE Trans. on Audio, Speech and Language Processing ,20(1), 14–22. 390
Mohamed, A., Hinton, G., and Penn, G. (2012b). Understanding how deep belief networks
perform acoustic modelling. In Acoustics, Speech and Signal Processing (ICASSP), 2012
IEEE International Conference on , pages 4273–4276. IEEE. 390
Moller, M. (1993). Eﬃcient Training of Feed-Forward Neural Networks . Ph.D. thesis, Aarhus
University, Aarhus, Denmark. 269
Montavon, G. and Muller, K.-R. (2012). Deep Boltzmann machines and the centering
trick. In G. Montavon, G. Orr, and K.-R. Müller, editors, Neural Networks: Tricks of
the Trade , volume 7700 of Lecture Notes in Computer Science , pages 621–637. Preprint:
http://arxiv.org/abs/1203.3783. 574
Montúfar, G. and Ay, N. (2011). Reﬁnements of universal approximation results for deep belief
networks and restricted Boltzmann machines. Neural Computation ,23(5), 1306–1319. 471
Montufar, G. F., Pascanu, R., Cho, K., and Bengio, Y. (2014). On the number of linear regions
of deep neural networks. In NIPS’2014 .17,172,471
Mor-Yosef, S., Samueloﬀ, A., Modan, B., Navot, D., and Schenker, J. G. (1990). Ranking the
risk factors for cesarean: logistic regression analysis of a nationwide study. Obstet Gynecol ,
75(6), 944–7. 2
Morin, F. and Bengio, Y. (2005). Hierarchical probabilistic neural network language model. In
AISTATS’2005 .396,398
Mozer, M. C. (1992). The induction of multiscale temporal structure. In J. M. S. Hanson
and R. Lippmann, editors, Advances in Neural Information Processing Systems 4 (NIPS’91) ,
pages 275–282, San Mateo, CA. Morgan Kaufmann. 347
Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective . MIT Press, Cambridge,
MA, USA. 56,87,126
Murray, B. U. I. and Larochelle, H. (2014). A deep and tractable density estimator. In
ICML’2014 .164,605
Nair, V. and Hinton, G. (2010a). Rectiﬁed linear units improve restricted Boltzmann machines.
InICML’2010 .150,169
Nair, V. and Hinton, G. E. (2009). 3d object recognition with deep belief nets. In Y. Bengio,
D. Schuurmans, J. D. Laﬀerty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural
Information Processing Systems 22 , pages 1339–1347. Curran Associates, Inc. 585DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 657
Nair, V. and Hinton, G. E. (2010b). Rectiﬁed linear units improve restricted Boltzmann ma-
chines. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International
Conference on Machine Learning (ICML-10) , pages 807–814. ACM. 14
Narayanan, H. and Mitter, S. (2010). Sample complexity of testing the manifold hypothesis. In
J. Laﬀerty, C. K. I. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta, editors, Advances
in Neural Information Processing Systems 23 , pages 1786–1794. 141
Naumann, U. (2008). Optimal Jacobian accumulation is NP-complete. Mathematical Program-
ming ,112(2), 427–441. 191
Navigli, R. and Velardi, P. (2005). Structural semantic interconnections: a knowledge-based
approach to word sense disambiguation. IEEE Trans. Pattern Analysis and Machine Intelli-
gence ,27(7), 1075-- –1086. 411
Neal, R. and Hinton, G. (1999). A view of the EM algorithm that justiﬁes incremental, sparse,
and other variants. In M. I. Jordan, editor, Learning in Graphical Models . MIT Press, Cam-
bridge, MA. 540
Neal, R. M. (1990). Learning stochastic feedforward networks. Technical report. 590
Neal, R. M. (1993). Probabilistic inference using Markov chain Monte-Carlo methods. Technical
Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto. 580
Neal, R. M. (1994). Sampling from multimodal distributions using tempered transitions. Tech-
nical Report 9421, Dept. of Statistics, University of Toronto. 513
Neal, R. M. (1996). Bayesian Learning for Neural Networks . Lecture Notes in Statistics.
Springer. 227
Neal, R. M. (2001). Annealed importance sampling. Statistics and Computing ,11(2), 125–139.
532,534,535
Neal, R. M. (2005). Estimating ratios of normalizing constants using linked importance sampling.
535,536
Nesterov, Y. (1983). A method of solving a convex programming problem with convergence rate
O(1/k2).Soviet Mathematics Doklady ,27, 372–376. 255
Nesterov, Y. (2004). Introductory lectures on convex optimization : a basic course . Applied
optimization. Kluwer Academic Publ., Boston, Dordrecht, London. 255
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A. Y. (2011). Reading digits in
natural images with unsupervised feature learning. Deep Learning and Unsupervised Feature
Learning Workshop, NIPS. 18DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
658 参考文献
Ney, H. and Kneser, R. (1993). Improved clustering techniques for class-based statistical lan-
guage modelling. In European Conference on Speech Communication and Technology (Eu-
rospeech) , pages 973–976, Berlin. 393
Ng, A. (2015). Advice for applying machine learning.
https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf .358
Niesler, T. R., Whittaker, E. W. D., and Woodland, P. C. (1998). Comparison of part-of-
speech and automatically derived category-based language models for speech recognition. In
International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pages 177–
180. 393
Ning, F., Delhomme, D., LeCun, Y., Piano, F., Bottou, L., and Barbano, P. E. (2005). To-
ward automatic phenotyping of developing embryos from videos. Image Processing, IEEE
Transactions on ,14(9), 1360–1371. 305
Nocedal, J. and Wright, S. (2006). Numerical Optimization . Springer. 82,85
Norouzi, M. and Fleet, D. J. (2011). Minimal loss hashing for compact binary codes. In
ICML’2011 .447
Nowlan, S. J. (1990). Competing experts: An experimental investigation of associative mixture
models. Technical Report CRG-TR-90-5, University of Toronto. 382
Nowlan, S. J. and Hinton, G. E. (1992). Adaptive soft weight tying using Gaussian mixtures.
In J. M. S. Hanson and R. Lippmann, editors, Advances in Neural Information Processing
Systems 4 (NIPS’91) , pages 993–1000, San Mateo, CA. Morgan Kaufmann. 122
Olshausen, B. and Field, D. J. (2005). How close are we to understanding V1? Neural Compu-
tation ,17, 1665–1699. 14
Olshausen, B. A. and Field, D. J. (1996). Emergence of simple-cell receptive ﬁeld properties by
learning a sparse code for natural images. Nature ,381, 607–609. 128,218,315,422
Olshausen, B. A., Anderson, C. H., and Van Essen, D. C. (1993). A neurobiological model of
visual attention and invariant pattern recognition based on dynamic routing of information.
J. Neurosci. ,13(11), 4700–4719. 382
Opper, M. and Archambeau, C. (2009). The variational Gaussian approximation revisited.
Neural computation ,21(3), 786–792. 587
Oquab, M., Bottou, L., Laptev, I., and Sivic, J. (2014). Learning and transferring mid-level
image representations using convolutional neural networks. In Computer Vision and Pattern
Recognition (CVPR), 2014 IEEE Conference on , pages 1717–1724. IEEE. 455DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 659
Osindero, S. and Hinton, G. E. (2008). Modeling image patches with a directed hierarchy of
Markov random ﬁelds. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances
in Neural Information Processing Systems 20 (NIPS’07) , pages 1121–1128, Cambridge, MA.
MIT Press. 538
Ovid and Martin, C. (2004). Metamorphoses . W.W. Norton. 1
Paccanaro, A. and Hinton, G. E. (2000). Extracting distributed representations of concepts
and relations from positive and negative propositions. In International Joint Conference on
Neural Networks (IJCNN) , Como, Italy. IEEE, New York. 410,411
Paine, T. L., Khorrami, P., Han, W., and Huang, T. S. (2014). An analysis of unsupervised
pre-training in light of recent advances. arXiv preprint arXiv:1412.6597 .453
Palatucci, M., Pomerleau, D., Hinton, G. E., and Mitchell, T. M. (2009). Zero-shot learning with
semantic output codes. In Y. Bengio, D. Schuurmans, J. D. Laﬀerty, C. K. I. Williams, and
A. Culotta, editors, Advances in Neural Information Processing Systems 22 , pages 1410–1418.
Curran Associates, Inc. 458
Parker, D. B. (1985). Learning-logic. Technical Report TR-47, Center for Comp. Research in
Economics and Management Sci., MIT. 194
Pascanu, R., Mikolov, T., and Bengio, Y. (2013a). On the diﬃculty of training recurrent neural
networks. In ICML’2013 .246,342,347,352,353,354
Pascanu, R., Mikolov, T., and Bengio, Y. (2013b). On the diﬃculty of training recurrent neural
networks. In ICM (1c).344
Pascanu, R., Gulcehre, C., Cho, K., and Bengio, Y. (2014a). How to construct deep recurrent
neural networks. In ICLR .17,227,339,340,348,391
Pascanu, R., Montufar, G., and Bengio, Y. (2014b). On the number of inference regions of deep
feed forward networks with piece-wise linear activations. In ICL(1).468
Pati, Y., Rezaiifar, R., and Krishnaprasad, P. (1993). Orthogonal matching pursuit: Recursive
function approximation with applications to wavelet decomposition. In Proceedings of the 27
th Annual Asilomar Conference on Signals, Systems, and Computers , pages 40–44. 219
Pearl, J. (1985). Bayesian networks: A model of self-activated memory for evidential reasoning.
InProceedings of the 7th Conference of the Cognitive Science Society, University of California,
Irvine , pages 329–334. 479
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference .
Morgan Kaufmann. 48DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
660 参考文献
Perron, O. (1907). Zur theorie der matrices. Mathematische Annalen ,64(2), 248–263. 507
Petersen, K. B. and Pedersen, M. S. (2006). The matrix cookbook. Version 20051003. 27
Peterson, G. B. (2004). A day of great illumination: B. F. Skinner’s discovery of shaping.
Journal of the Experimental Analysis of Behavior ,82(3), 317–328. 278
Pham, D.-T., Garat, P., and Jutten, C. (1992). Separation of a mixture of independent sources
through a maximum likelihood approach. In EUSIPCO , pages 771–774. 418
Pham, P.-H., Jelaca, D., Farabet, C., Martini, B., LeCun, Y., and Culurciello, E. (2012). Neu-
Flow: dataﬂow vision processing system-on-a-chip. In Circuits and Systems (MWSCAS),
2012 IEEE 55th International Midwest Symposium on , pages 1044–1047. IEEE. 383
Pinheiro, P. H. O. and Collobert, R. (2014). Recurrent convolutional neural networks for scene
labeling. In ICML’2014 .305
Pinheiro, P. H. O. and Collobert, R. (2015). From image-level to pixel-level labeling with
convolutional networks. In Conference on Computer Vision and Pattern Recognition (CVPR) .
305
Pinto, N., Cox, D. D., and DiCarlo, J. J. (2008). Why is real-world visual object recognition
hard? PLoS Comput Biol ,4.387
Pinto, N., Stone, Z., Zickler, T., and Cox, D. (2011). Scaling up biologically-inspired computer
vision: A case study in unconstrained face recognition on facebook. In Computer Vision
and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference
on, pages 35–42. IEEE. 309
Pollack, J. B. (1990). Recursive distributed representations. Artiﬁcial Intelligence ,46(1), 77–
105. 340
Polyak, B. and Juditsky, A. (1992). Acceleration of stochastic approximation by averaging.
SIAM J. Control and Optimization ,30(4) , 838–855. 273
Polyak, B. T. (1964). Some methods of speeding up the convergence of iteration methods. USSR
Computational Mathematics and Mathematical Physics ,4(5), 1–17. 252
Poole, B., Sohl-Dickstein, J., and Ganguli, S. (2014). Analyzing noise in autoencoders and deep
networks. CoRR ,abs/1406.1831 .206
Poon, H. and Domingos, P. (2011). Sum-product networks for deep learning. In Learning
Workshop , Fort Lauderdale, FL. 471DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 661
Presley, R. K. and Haggard, R. L. (1994). A ﬁxed point implementation of the backpropaga-
tion learning algorithm. In Southeastcon’94. Creative Technology Transfer-A Global Aﬀair.,
Proceedings of the 1994 IEEE , pages 136–138. IEEE. 383
Price, R. (1958). A useful theorem for nonlinear devices having Gaussian inputs. IEEE Trans-
actions on Information Theory ,4(2), 69–72. 587
Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., and Fried, I. (2005). Invariant visual
representation by single neurons in the human brain. Nature ,435(7045), 1102–1107. 311
Radford, A., Metz, L., and Chintala, S. (2015). Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 .469,470,
598
Raiko, T., Yao, L., Cho, K., and Bengio, Y. (2014). Iterative neural autoregressive distribution
estimator (NADE-k). Technical report, arXiv:1406.1485. 575,604
Raina, R., Madhavan, A., and Ng, A. Y. (2009a). Large-scale deep unsupervised learning using
graphics processors. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-sixth
International Conference on Machine Learning (ICML’09) , pages 873–880, New York, NY,
USA. ACM. 21
Raina, R., Madhavan, A., and Ng, A. Y. (2009b). Large-scale deep unsupervised learning using
graphics processors. In ICML’2009 .378
Ramsey, F. P. (1926). Truth and probability. In R. B. Braithwaite, editor, The Foundations
of Mathematics and other Logical Essays , chapter 7, pages 156–198. McMaster University
Archive for the History of Economic Thought. 49
Ranzato, M. and Hinton, G. H. (2010). Modeling pixel means and covariances using factorized
third-order Boltzmann machines. In CVPR’2010 , pages 2551–2558. 580
Ranzato, M., Poultney, C., Chopra, S., and LeCun, Y. (2007a). Eﬃcient learning of sparse
representations with an energy-based model. In NIPS’2006 .13,432,450,451
Ranzato, M., Poultney, C., Chopra, S., and LeCun, Y. (2007b). Eﬃcient learning of sparse
representations with an energy-based model. In B. Schölkopf, J. Platt, and T. Hoﬀman,
editors, Advances in Neural Information Processing Systems 19 (NIPS’06) , pages 1137–1144.
MIT Press. 17
Ranzato, M., Huang, F., Boureau, Y., and LeCun, Y. (2007c). Unsupervised learning of invariant
feature hierarchies with applications to object recognition. In CVPR’07 .309DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
662 参考文献
Ranzato, M., Boureau, Y., and LeCun, Y. (2008). Sparse feature learning for deep belief net-
works. In NIPS’2007 .432
Ranzato, M., Krizhevsky, A., and Hinton, G. E. (2010a). Factored 3-way restricted Boltzmann
machines for modeling natural images. In Proceedings of AISTATS 2010 .578,579
Ranzato, M., Mnih, V., and Hinton, G. (2010b). Generating more realistic images using gated
MRFs. In NIPS’2010 .580
Rao, C. (1945). Information and the accuracy attainable in the estimation of statistical param-
eters. Bulletin of the Calcutta Mathematical Society ,37, 81–89. 118,251
Rasmus, A., Valpola, H., Honkala, M., Berglund, M., and Raiko, T. (2015). Semi-supervised
learning with ladder network. arXiv preprint arXiv:1507.02672 .362,452
Recht, B., Re, C., Wright, S., and Niu, F. (2011). Hogwild: A lock-free approach to parallelizing
stochastic gradient descent. In NIPS’2011 .379
Reichert, D. P., Seriès, P., and Storkey, A. J. (2011). Neuronal adaptation for sampling-based
probabilistic inference in perceptual bistability. In Advances in Neural Information Processing
Systems , pages 2357–2365. 568
Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approx-
imate inference in deep generative models. In ICML’2014 . Preprint: arXiv:1401.4082. 557,
587,593
Rifai, S., Vincent, P., Muller, X., Glorot, X., and Bengio, Y. (2011a). Contractive auto-encoders:
Explicit invariance during feature extraction. In ICML’2011 .444,445,446
Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., and Glorot, X. (2011b).
Higher order contractive auto-encoder. In ECML PKDD .444,445
Rifai, S., Dauphin, Y., Vincent, P., Bengio, Y., and Muller, X. (2011c). The manifold tangent
classiﬁer. In NIPS’2011 .232,445
Rifai, S., Dauphin, Y., Vincent, P., Bengio, Y., and Muller, X. (2011d). The manifold tangent
classiﬁer. In NIPS’2011 . Student paper award. 232
Rifai, S., Bengio, Y., Dauphin, Y., and Vincent, P. (2012). A generative process for sampling
contractive auto-encoders. In ICML’2012 .606
Ringach, D. and Shapley, R. (2004). Reverse correlation in neurophysiology. Cognitive Science ,
28(2), 147–166. 313DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 663
Roberts, S. and Everson, R. (2001). Independent component analysis: principles and practice .
Cambridge University Press. 419
Robinson, A. J. and Fallside, F. (1991). A recurrent error propagation network speech recognition
system. Computer Speech and Language ,5(3), 259–274. 21,389
Rockafellar, R. T. (1997). Convex analysis. princeton landmarks in mathematics. 82
Romero, A., Ballas, N., Ebrahimi Kahou, S., Chassang, A., Gatta, C., and Bengio, Y. (2015).
Fitnets: Hints for thin deep nets. In ICLR’2015, arXiv:1412.6550 .276
Rosen, J. B. (1960). The gradient projection method for nonlinear programming. part i. linear
constraints. Journal of the Society for Industrial and Applied Mathematics ,8(1), pp. 181–217.
83
Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and
organization in the brain. Psychological Review ,65, 386–408. 13,21
Rosenblatt, F. (1962). Principles of Neurodynamics . Spartan, New York. 21
Rosenblatt, M. (1956). Remarks on some nonparametric estimates of a density function. The
Annals of Mathematical Statistics ,27(3), 832–837. 13
Roweis, S. and Saul, L. K. (2000). Nonlinear dimensionality reduction by locally linear embed-
ding. Science ,290(5500). 141,442
Roweis, S., Saul, L., and Hinton, G. (2002). Global coordination of local linear models. In T. Di-
etterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing
Systems 14 (NIPS’01) , Cambridge, MA. MIT Press. 416
Rubin, D. B. et al. (1984). Bayesianly justiﬁable and relevant frequency calculations for the
applied statistician. The Annals of Statistics ,12(4), 1151–1172. 610
Rumelhart, D., Hinton, G., and Williams, R. (1986a). Learning representations by back-
propagating errors. Nature ,323, 533–536. 13,194,405,409
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986b). Learning internal representations
by error propagation. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed
Processing , volume 1, chapter 8, pages 318–362. MIT Press, Cambridge. 18,21,194
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986c). Learning representations by
back-propagating errors. Nature ,323, 533–536. 16,175,318
Rumelhart, D. E., McClelland, J. L., and the PDP Research Group (1986d). Parallel Distributed
Processing: Explorations in the Microstructure of Cognition . MIT Press, Cambridge. 15,22DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
664 参考文献
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A.,
Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. (2014a). ImageNet Large Scale Visual
Recognition Challenge. 18
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A.,
Khosla, A., Bernstein, M., et al. (2014b). Imagenet large scale visual recognition challenge.
arXiv preprint arXiv:1409.0575 .23
Russel, S. J. and Norvig, P. (2003). Artiﬁcial Intelligence: a Modern Approach . Prentice Hall.
77
Rust, N., Schwartz, O., Movshon, J. A., and Simoncelli, E. (2005). Spatiotemporal elements of
macaque V1 receptive ﬁelds. Neuron ,46(6), 945–956. 312
Sainath, T., Mohamed, A., Kingsbury, B., and Ramabhadran, B. (2013). Deep convolutional
neural networks for LVCSR. In ICASSP 2013 .390
Salakhutdinov, R. (2010). Learning in Markov random ﬁelds using tempered transitions. In
Y. Bengio, D. Schuurmans, C. Williams, J. Laﬀerty, and A. Culotta, editors, Advances in
Neural Information Processing Systems 22 (NIPS’09) .513
Salakhutdinov, R. and Hinton, G. (2009a). Deep Boltzmann machines. In Proceedings of the
International Conference on Artiﬁcial Intelligence and Statistics , volume 5, pages 448–455.
20,21,565,568,571,573
Salakhutdinov, R. and Hinton, G. (2009b). Semantic hashing. In International Journal of
Approximate Reasoning .447
Salakhutdinov, R. and Hinton, G. E. (2007a). Learning a nonlinear embedding by preserving
class neighbourhood structure. In Proceedings of AISTATS-2007 .449
Salakhutdinov, R. and Hinton, G. E. (2007b). Semantic hashing. In SIGIR’2007 .447
Salakhutdinov, R. and Hinton, G. E. (2008). Using deep belief nets to learn covariance kernels
for Gaussian processes. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances
in Neural Information Processing Systems 20 (NIPS’07) , pages 1249–1256, Cambridge, MA.
MIT Press. 209
Salakhutdinov, R. and Hinton, G. E. (2009c). Deep Boltzmann machines. In AISTATS’2009 ,
pages 448–455. 451
Salakhutdinov, R. and Larochelle, H. (2010). Eﬃcient learning of deep Boltzmann machines. In
Proceedings of the Thirteenth International Conference on Artiﬁcial Intelligence and Statistics
(AISTATS 2010), JMLR W&CP , volume 9, pages 693–700. 556DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 665
Salakhutdinov, R. and Mnih, A. (2008). Probabilistic matrix factorization. In NIPS’2008 .407
Salakhutdinov, R. and Murray, I. (2008). On the quantitative analysis of deep belief networks.
In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, Proceedings of the Twenty-ﬁfth
International Conference on Machine Learning (ICML’08) , volume 25, pages 872–879. ACM.
535,565
Salakhutdinov, R., Mnih, A., and Hinton, G. (2007). Restricted Boltzmann machines for col-
laborative ﬁltering. In ICML .407
Sanger, T. D. (1994). Neural network learning control of robot manipulators using gradually
increasing task diﬃculty. IEEE Transactions on Robotics and Automation ,10(3).278
Saul, L. K. and Jordan, M. I. (1996). Exploiting tractable substructures in intractable networks.
In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Pro-
cessing Systems 8 (NIPS’95) . MIT Press, Cambridge, MA. 543
Saul, L. K., Jaakkola, T., and Jordan, M. I. (1996). Mean ﬁeld theory for sigmoid belief networks.
Journal of Artiﬁcial Intelligence Research ,4, 61–76. 21,591
Savich, A. W., Moussa, M., and Areibi, S. (2007). The impact of arithmetic representation on
implementing mlp-bp on fpgas: A study. Neural Networks, IEEE Transactions on ,18(1),
240–252. 383
Saxe, A. M., Koh, P. W., Chen, Z., Bhand, M., Suresh, B., and Ng, A. (2011). On random
weights and unsupervised feature learning. In Proc. ICML’2011 . ACM. 309
Saxe, A. M., McClelland, J. L., and Ganguli, S. (2013). Exact solutions to the nonlinear
dynamics of learning in deep linear neural networks. In ICLR .243,244,257
Schaul, T., Antonoglou, I., and Silver, D. (2014). Unit tests for stochastic optimization. In
International Conference on Learning Representations .262
Schmidhuber, J. (1996). Sequential neural text compression. IEEE Transactions on Neural
Networks ,7(1), 142–146. 339,405
Schmidhuber, J. (2012). Self-delimiting neural networks. arXiv preprint arXiv:1210.0118 .332
Schölkopf, B. and Smola, A. J. (2002). Learning with kernels: Support vector machines, regu-
larization, optimization, and beyond . MIT press. 600
Schölkopf, B., Burges, C. J. C., and Smola, A. J. (1998a). Advances in kernel methods: support
vector learning . MIT Press, Cambridge, MA. 141DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
666 参考文献
Schölkopf, B., Smola, A., and Müller, K.-R. (1998b). Nonlinear component analysis as a kernel
eigenvalue problem. Neural Computation ,10, 1299–1319. 442
Schölkopf, B., Burges, C. J. C., and Smola, A. J. (1999). Advances in Kernel Methods — Support
Vector Learning . MIT Press, Cambridge, MA. 16
Schölkopf, B., Mika, S., Burges, C., Knirsch, P., Müller, K.-R., Rätsch, G., and Smola, A.
(1999). Input space versus feature space in kernel-based methods. IEEE Trans. Neural
Networks ,10(5), 1000–1017. 124
Schölkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., and Mooij, J. (2012). On causal
and anticausal learning. In ICML’2012 , pages 1255–1262. 464
Schuster, M. (1999). On supervised learning from sequential data with applications for speech
recognition. 164
Schuster, M. and Paliwal, K. (1997). Bidirectional recurrent neural networks. IEEE Transactions
on Signal Processing ,45(11), 2673–2681. 335
Schwenk, H. (2007). Continuous space language models. Computer speech and language ,21,
492–518. 395
Schwenk, H. (2010). Continuous space language models for statistical machine translation. The
Prague Bulletin of Mathematical Linguistics ,93, 137–146. 401
Schwenk, H. (2014). Cleaned subset of WMT ’14 dataset. 18
Schwenk, H. and Bengio, Y. (1998). Training methods for adaptive boosting of neural networks
for character recognition. In NIPS 10 . MIT Press. 221
Schwenk, H. and Gauvain, J.-L. (2002). Connectionist language modeling for large vocabulary
continuous speech recognition. In International Conference on Acoustics, Speech and Signal
Processing (ICASSP) , pages 765–768, Orlando, Florida. 395
Schwenk, H., Costa-jussà, M. R., and Fonollosa, J. A. R. (2006). Continuous space language
models for the IWSLT 2006 task. In International Workshop on Spoken Language Translation ,
pages 166–173. 401
Seide, F., Li, G., and Yu, D. (2011). Conversational speech transcription using context-
dependent deep neural networks. In Interspeech 2011 , pages 437–440. 22
Sejnowski, T. (1987). Higher-order Boltzmann machines. In AIP Conference Proceedings 151
on Neural Networks for Computing , pages 398–403. American Institute of Physics Inc. 585DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 667
Series, P., Reichert, D. P., and Storkey, A. J. (2010). Hallucinations in Charles Bonnet syn-
drome induced by homeostasis: a deep Boltzmann machine model. In Advances in Neural
Information Processing Systems , pages 2020–2028. 568
Sermanet, P., Chintala, S., and LeCun, Y. (2012). Convolutional neural networks applied to
house numbers digit classiﬁcation. In International Conference on Pattern Recognition (ICPR
2012) .387
Sermanet, P., Kavukcuoglu, K., Chintala, S., and LeCun, Y. (2013). Pedestrian detection with
unsupervised multi-stage feature learning. In Proc. International Conference on Computer
Vision and Pattern Recognition (CVPR’13) . IEEE. 22,173
Shilov, G. (1977). Linear Algebra . Dover Books on Mathematics Series. Dover Publications. 27
Siegelmann, H. (1995). Computation beyond the Turing limit. Science ,268(5210), 545–548.
323
Siegelmann, H. and Sontag, E. (1991). Turing computability with neural nets. Applied Mathe-
matics Letters ,4(6), 77–80. 323
Siegelmann, H. T. and Sontag, E. D. (1995). On the computational power of neural nets. Journal
of Computer and Systems Sciences ,50(1), 132–150. 323,324,344
Sietsma, J. and Dow, R. (1991). Creating artiﬁcial neural networks that generalize. Neural
Networks ,4(1), 67–79. 206
Simard, D., Steinkraus, P. Y., and Platt, J. C. (2003). Best practices for convolutional neural
networks. In ICDAR’2003 .316
Simard, P. and Graf, H. P. (1994). Backpropagation without multiplication. In Advances in
Neural Information Processing Systems , pages 232–239. 383
Simard, P., Victorri, B., LeCun, Y., and Denker, J. (1992). Tangent prop - A formalism for
specifying selected invariances in an adaptive network. In NIPS’1991 .231,232,300
Simard, P. Y., LeCun, Y., and Denker, J. (1993). Eﬃcient pattern recognition using a new
transformation distance. In NIPS’92 .231
Simard, P. Y., LeCun, Y. A., Denker, J. S., and Victorri, B. (1998). Transformation invariance in
pattern recognition — tangent distance and tangent propagation. Lecture Notes in Computer
Science ,1524 .231
Simons, D. J. and Levin, D. T. (1998). Failure to detect changes to people during a real-world
interaction. Psychonomic Bulletin & Review ,5(4), 644–649. 462DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
668 参考文献
Simonyan, K. and Zisserman, A. (2015). Very deep convolutional networks for large-scale image
recognition. In ICLR .274
Sjöberg, J. and Ljung, L. (1995). Overtraining, regularization and searching for a minimum,
with application to neural networks. International Journal of Control ,62(6), 1391–1407. 214
Skinner, B. F. (1958). Reinforcement today. American Psychologist ,13, 94–99. 278
Smolensky, P. (1986). Information processing in dynamical systems: Foundations of harmony
theory. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing ,
volume 1, chapter 6, pages 194–281. MIT Press, Cambridge. 485,498,560
Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical Bayesian optimization of machine
learning algorithms. In NIPS’2012 .370
Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., and Manning, C. D. (2011a). Dynamic
pooling and unfolding recursive autoencoders for paraphrase detection. In NIPS’2011 .340,
341
Socher, R., Manning, C., and Ng, A. Y. (2011b). Parsing natural scenes and natural language
with recursive neural networks. In Proceedings of the Twenty-Eighth International Conference
on Machine Learning (ICML’2011) .340
Socher, R., Pennington, J., Huang, E. H., Ng, A. Y., and Manning, C. D. (2011c). Semi-
supervised recursive autoencoders for predicting sentiment distributions. In EMNLP’2011 .
340,341
Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., and Potts, C.
(2013a). Recursive deep models for semantic compositionality over a sentiment treebank. In
EMNLP’2013 .340,341
Socher, R., Ganjoo, M., Manning, C. D., and Ng, A. Y. (2013b). Zero-shot learning through
cross-modal transfer. In 27th Annual Conference on Neural Information Processing Systems
(NIPS 2013) .458
Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsuper-
vised learning using nonequilibrium thermodynamics. 609,610
Sohn, K., Zhou, G., and Lee, H. (2013). Learning and selecting features jointly with point-wise
gated Boltzmann machines. In ICML’2013 .585
Solomonoﬀ, R. J. (1989). A system for incremental learning based on algorithmic probability.
278DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 669
Sontag, E. D. (1998). VC dimension of neural networks. NATO ASI Series F Computer and
Systems Sciences ,168, 69–96. 466,469
Sontag, E. D. and Sussman, H. J. (1989). Backpropagation can give rise to spurious local minima
even for networks without hidden layers. Complex Systems ,3, 91–106. 242
Sparkes, B. (1996). The Red and the Black: Studies in Greek Pottery . Routledge. 1
Spitkovsky, V. I., Alshawi, H., and Jurafsky, D. (2010). From baby steps to leapfrog: how “less
is more” in unsupervised dependency parsing. In HLT’10 .278
Squire, W. and Trapp, G. (1998). Using complex variables to estimate derivatives of real func-
tions. SIAM Rev. ,40(1), 110-- –112. 372
Srebro, N. and Shraibman, A. (2005). Rank, trace-norm and max-norm. In Proceedings of the
18th Annual Conference on Learning Theory , pages 545–560. Springer-Verlag. 205
Srivastava, N. (2013). Improving Neural Networks With Dropout . Master’s thesis, U. Toronto.
455
Srivastava, N. and Salakhutdinov, R. (2012). Multimodal learning with deep Boltzmann ma-
chines. In NIPS’2012 .459
Srivastava, N., Salakhutdinov, R. R., and Hinton, G. E. (2013). Modeling documents with deep
Boltzmann machines. arXiv preprint arXiv:1309.6865 .565
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout:
A simple way to prevent neural networks from overﬁtting. Journal of Machine Learning
Research ,15, 1929–1958. 221,226,227,228,573
Srivastava, R. K., Greﬀ, K., and Schmidhuber, J. (2015). Highway networks. arXiv:1505.00387 .
277
Steinkrau, D., Simard, P. Y., and Buck, I. (2005). Using GPUs for machine learning algorithms.
2013 12th International Conference on Document Analysis and Recognition ,0, 1115–1119.
378
Stoyanov, V., Ropson, A., and Eisner, J. (2011). Empirical risk minimization of graphical model
parameters given approximate inference, decoding, and model structure. In Proceedings of
the 14th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) , vol-
ume 15 of JMLR Workshop and Conference Proceedings , pages 725–733, Fort Lauderdale.
Supplementary material (4 pages) also available. 575,595DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
670 参考文献
Sukhbaatar, S., Szlam, A., Weston, J., and Fergus, R. (2015). Weakly supervised memory
networks. arXiv preprint arXiv:1503.08895 .355
Supancic, J. and Ramanan, D. (2013). Self-paced learning for long-term tracking. In
CVPR’2013 .279
Sussillo, D. (2014). Random walks: Training very deep nonlinear feed-forward networks with
smart initialization. CoRR ,abs/1412.6558 .247,258,259,343
Sutskever, I. (2012). Training Recurrent Neural Networks . Ph.D. thesis, Department of computer
science, University of Toronto. 346,352
Sutskever, I. and Hinton, G. E. (2008). Deep narrow sigmoid belief networks are universal
approximators. Neural Computation ,20(11), 2629–2636. 591
Sutskever, I. and Tieleman, T. (2010). On the Convergence Properties of Contrastive Divergence.
InAISTATS’2010 .520
Sutskever, I., Hinton, G., and Taylor, G. (2009). The recurrent temporal restricted Boltzmann
machine. In NIPS’2008 .584
Sutskever, I., Martens, J., and Hinton, G. E. (2011). Generating text with recurrent neural
networks. In ICML’2011 , pages 1017–1024. 405
Sutskever, I., Martens, J., Dahl, G., and Hinton, G. (2013). On the importance of initialization
and momentum in deep learning. In ICML .255,346,352
Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural
networks. In NIPS’2014, arXiv:1409.3215 .23,89,337,348,350,402
Sutton, R. and Barto, A. (1998). Reinforcement Learning: An Introduction . MIT Press. 93
Sutton, R. S., Mcallester, D., Singh, S., and Mansour, Y. (2000). Policy gradient methods for
reinforcement learning with function approximation. In NIPS’1999 , pages 1057-- –1063. MIT
Press. 589
Swersky, K., Ranzato, M., Buchman, D., Marlin, B., and de Freitas, N. (2011). On autoencoders
and score matching for energy based models. In ICML’2011 . ACM. 437
Swersky, K., Snoek, J., and Adams, R. P. (2014). Freeze-thaw Bayesian optimization. arXiv
preprint arXiv:1406.3896 .370
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Van-
houcke, V., and Rabinovich, A. (2014a). Going deeper with convolutions. Technical report,
arXiv:1409.4842. 20,21,173,221,230,232,277,294DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 671
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., and Fergus, R.
(2014b). Intriguing properties of neural networks. ICLR ,abs/1312.6199 .229
Szegedy, C., Vanhoucke, V., Ioﬀe, S., Shlens, J., and Wojna, Z. (2015). Rethinking the Inception
Architecture for Computer Vision. ArXiv e-prints .208,274
Taigman, Y., Yang, M., Ranzato, M., and Wolf, L. (2014). DeepFace: Closing the gap to
human-level performance in face veriﬁcation. In CVPR’2014 .88
Tandy, D. W. (1997). Works and Days: A Translation and Commentary for the Social Sciences .
University of California Press. 1
Tang, Y. and Eliasmith, C. (2010). Deep networks for robust visual recognition. In Proceedings
of the 27th International Conference on Machine Learning, June 21-24, 2010, Haifa, Israel .
206
Tang, Y., Salakhutdinov, R., and Hinton, G. (2012). Deep mixtures of factor analysers. arXiv
preprint arXiv:1206.4635 .416
Taylor, G. and Hinton, G. (2009). Factored conditional restricted Boltzmann machines for
modeling motion style. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-
sixth International Conference on Machine Learning (ICML’09) , pages 1025–1032, Montreal,
Quebec, Canada. ACM. 584
Taylor, G., Hinton, G. E., and Roweis, S. (2007). Modeling human motion using binary latent
variables. In B. Schölkopf, J. Platt, and T. Hoﬀman, editors, Advances in Neural Information
Processing Systems 19 (NIPS’06) , pages 1345–1352. MIT Press, Cambridge, MA. 584
Teh, Y., Welling, M., Osindero, S., and Hinton, G. E. (2003). Energy-based models for sparse
overcomplete representations. Journal of Machine Learning Research ,4, 1235–1260. 418
Tenenbaum, J., de Silva, V., and Langford, J. C. (2000). A global geometric framework for
nonlinear dimensionality reduction. Science ,290(5500), 2319–2323. 141,442,455
Theis, L., van den Oord, A., and Bethge, M. (2015). A note on the evaluation of generative
models. arXiv:1511.01844. 595,612
Thompson, J., Jain, A., LeCun, Y., and Bregler, C. (2014). Joint training of a convolutional
network and a graphical model for human pose estimation. In NIPS’2014 .305
Thrun, S. (1995). Learning to play the game of chess. In NIPS’1994 .231
Tibshirani, R. J. (1995). Regression shrinkage and selection via the lasso. Journal of the Royal
Statistical Society B ,58, 267–288. 203DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
672 参考文献
Tieleman, T. (2008). Training restricted Boltzmann machines using approximations to the
likelihood gradient. In ICML’2008 , pages 1064–1071. 520
Tieleman, T. and Hinton, G. (2009). Using fast weights to improve persistent contrastive diver-
gence. In ICML’2009 .523
Tipping, M. E. and Bishop, C. M. (1999). Mixtures of probabilistic principal component anal-
ysers. Neural Computation ,11(2), 443–482. 418
Torralba, A., Fergus, R., and Weiss, Y. (2008). Small codes and large databases for recognition.
InProceedings of the Computer Vision and Pattern Recognition Conference (CVPR’08) , pages
1–8. 447
Touretzky, D. S. and Minton, G. E. (1985). Symbols among the neurons: Details of a con-
nectionist inference architecture. In Proceedings of the 9th International Joint Conference on
Artiﬁcial Intelligence - Volume 1 , IJCAI’85, pages 238–243, San Francisco, CA, USA. Morgan
Kaufmann Publishers Inc. 15
Tu, K. and Honavar, V. (2011). On the utility of curricula in unsupervised learning of proba-
bilistic grammars. In IJCAI’2011 .278
Turaga, S. C., Murray, J. F., Jain, V., Roth, F., Helmstaedter, M., Briggman, K., Denk, W.,
and Seung, H. S. (2010). Convolutional networks can learn to generate aﬃnity graphs for
image segmentation. Neural Computation ,22, 511–538. 305
Turian, J., Ratinov, L., and Bengio, Y. (2010). Word representations: A simple and general
method for semi-supervised learning. In Proc. ACL’2010 , pages 384–394. 454
Töscher, A., Jahrer, M., and Bell, R. M. (2009). The BigChaos solution to the Netﬂix grand
prize. 407
Uria, B., Murray, I., and Larochelle, H. (2013). Rnade: The real-valued neural autoregressive
density-estimator. In NIPS’2013 .604,605
van den Oörd, A., Dieleman, S., and Schrauwen, B. (2013). Deep content-based music recom-
mendation. In NIPS’2013 .407
van der Maaten, L. and Hinton, G. E. (2008). Visualizing data using t-SNE. J. Machine Learning
Res.,9.405,442
Vanhoucke, V., Senior, A., and Mao, M. Z. (2011). Improving the speed of neural networks on
CPUs. In Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop .377,383DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 673
Vapnik, V. N. (1982). Estimation of Dependences Based on Empirical Data . Springer-Verlag,
Berlin. 100
Vapnik, V. N. (1995). The Nature of Statistical Learning Theory . Springer, New York. 100
Vapnik, V. N. and Chervonenkis, A. Y. (1971). On the uniform convergence of relative frequen-
cies of events to their probabilities. Theory of Probability and Its Applications ,16, 264–280.
100
Vincent, P. (2011). A connection between score matching and denoising autoencoders. Neural
Computation ,23(7).437,438,439,607
Vincent, P. and Bengio, Y. (2003). Manifold Parzen windows. In NIPS’2002 . MIT Press. 443
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008a). Extracting and composing
robust features with denoising autoencoders. In ICM (1a), pages 1096–1103. 206
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008b). Extracting and composing
robust features with denoising autoencoders. In ICML 2008 .439
Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., and Manzagol, P.-A. (2010). Stacked denois-
ing autoencoders: Learning useful representations in a deep network with a local denoising
criterion. J. Machine Learning Res. ,11.439
Vincent, P., de Brébisson, A., and Bouthillier, X. (2015). Eﬃcient exact gradient update for
training deep networks with very large sparse targets. In C. Cortes, N. D. Lawrence, D. D. Lee,
M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems
28, pages 1108–1116. Curran Associates, Inc. 395
Vinyals, O., Kaiser, L., Koo, T., Petrov, S., Sutskever, I., and Hinton, G. (2014a). Grammar as
a foreign language. arXiv preprint arXiv:1412.7449 .348
Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2014b). Show and tell: a neural image
caption generator. arXiv 1411.4555. 348
Vinyals, O., Fortunato, M., and Jaitly, N. (2015a). Pointer networks. arXiv preprint
arXiv:1506.03134 .355
Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2015b). Show and tell: a neural image
caption generator. In CVPR’2015 . arXiv:1411.4555. 90
Viola, P. and Jones, M. (2001). Robust real-time object detection. In International Journal of
Computer Vision .381DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
674 参考文献
Visin, F., Kastner, K., Cho, K., Matteucci, M., Courville, A., and Bengio, Y. (2015). ReNet:
A recurrent neural network based alternative to convolutional networks. arXiv preprint
arXiv:1505.00393 .337
Von Melchner, L., Pallas, S. L., and Sur, M. (2000). Visual behaviour mediated by retinal
projections directed to the auditory pathway. Nature ,404(6780), 871–876. 14
Wager, S., Wang, S., and Liang, P. (2013). Dropout training as adaptive regularization. In
Advances in Neural Information Processing Systems 26 , pages 351–359. 227
Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K., and Lang, K. (1989). Phoneme recogni-
tion using time-delay neural networks. IEEE Transactions on Acoustics, Speech, and Signal
Processing ,37, 328–339. 318,385,389
Wan, L., Zeiler, M., Zhang, S., LeCun, Y., and Fergus, R. (2013). Regularization of neural
networks using dropconnect. In ICML’2013 .228
Wang, S. and Manning, C. (2013). Fast dropout training. In ICML’2013 .227
Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014a). Knowledge graph and text jointly embed-
ding. In Proc. EMNLP’2014 .410
Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014b). Knowledge graph embedding by translating
on hyperplanes. In Proc. AAAI’2014 .411
Warde-Farley, D., Goodfellow, I. J., Courville, A., and Bengio, Y. (2014). An empirical analysis
of dropout in piecewise linear networks. In ICL(1).224,227,228
Wawrzynek, J., Asanovic, K., Kingsbury, B., Johnson, D., Beck, J., and Morgan, N. (1996).
Spert-II: A vector microprocessor system. Computer ,29(3), 79–86. 383
Weaver, L. and Tao, N. (2001). The optimal reward baseline for gradient-based reinforcement
learning. In Proc. UAI’2001 , pages 538–545. 589
Weinberger, K. Q. and Saul, L. K. (2004a). Unsupervised learning of image manifolds by
semideﬁnite programming. In Proceedings of the Computer Vision and Pattern Recognition
Conference (CVPR’04) , volume 2, pages 988–995, Washington D.C. 141
Weinberger, K. Q. and Saul, L. K. (2004b). Unsupervised learning of image manifolds by
semideﬁnite programming. In CVPR’2004 , pages 988–995. 442
Weiss, Y., Torralba, A., and Fergus, R. (2008). Spectral hashing. In NIPS , pages 1753–1760.
447DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 675
Welling, M., Zemel, R. S., and Hinton, G. E. (2002). Self supervised boosting. In Advances in
Neural Information Processing Systems , pages 665–672. 599
Welling, M., Hinton, G. E., and Osindero, S. (2003a). Learning sparse topographic representa-
tions with products of Student-t distributions. In NIPS’2002 .580
Welling, M., Zemel, R., and Hinton, G. E. (2003b). Self-supervised boosting. In S. Becker,
S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems
15 (NIPS’02) , pages 665–672. MIT Press. 530
Welling, M., Rosen-Zvi, M., and Hinton, G. E. (2005). Exponential family harmoniums with an
application to information retrieval. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances
in Neural Information Processing Systems 17 (NIPS’04) , volume 17, Cambridge, MA. MIT
Press. 577
Werbos, P. J. (1981). Applications of advances in nonlinear sensitivity analysis. In Proceedings
of the 10th IFIP Conference, 31.8 - 4.9, NYC , pages 762–770. 194
Weston, J., Bengio, S., and Usunier, N. (2010). Large scale image annotation: learning to rank
with joint word-image embeddings. Machine Learning ,81(1), 21–35. 342
Weston, J., Chopra, S., and Bordes, A. (2014). Memory networks. arXiv preprint
arXiv:1410.3916 .355,411
Widrow, B. and Hoﬀ, M. E. (1960). Adaptive switching circuits. In 1960 IRE WESCON
Convention Record , volume 4, pages 96–104. IRE, New York. 13,18,20,21
Wikipedia (2015). List of animals by number of neurons — Wikipedia, the free encyclopedia.
[Online; accessed 4-March-2015]. 20,21
Williams, C. K. I. and Agakov, F. V. (2002). Products of Gaussians and Probabilistic Minor
Component Analysis. Neural Computation ,14(5) , 1169–1182. 581
Williams, C. K. I. and Rasmussen, C. E. (1996). Gaussian processes for regression. In D. Touret-
zky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems
8 (NIPS’95) , pages 514–520. MIT Press, Cambridge, MA. 124
Williams, R. J. (1992). Simple statistical gradient-following algorithms connectionist reinforce-
ment learning. Machine Learning ,8, 229–256. 587,588
Williams, R. J. and Zipser, D. (1989). A learning algorithm for continually running fully recur-
rent neural networks. Neural Computation ,1, 270–280. 192DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
676 参考文献
Wilson, D. R. and Martinez, T. R. (2003). The general ineﬃciency of batch training for gradient
descent learning. Neural Networks ,16(10), 1429–1451. 238
Wilson, J. R. (1984). Variance reduction techniques for digital simulation. American Journal of
Mathematical and Management Sciences ,4(3), 277-- –312. 588
Wiskott, L. and Sejnowski, T. J. (2002). Slow feature analysis: Unsupervised learning of invari-
ances. Neural Computation ,14(4), 715–770. 420,421
Wolpert, D. and MacReady, W. (1997). No free lunch theorems for optimization. IEEE Trans-
actions on Evolutionary Computation ,1, 67–82. 249
Wu, R., Yan, S., Shan, Y., Dang, Q., and Sun, G. (2015). Deep image: Scaling up image
recognition. arXiv:1501.02876. 380
Wu, Z. (1997). Global continuation for distance geometry problems. SIAM Journal of Opti-
mization ,7, 814–836. 278
Xiong, H. Y., Barash, Y., and Frey, B. J. (2011). Bayesian prediction of tissue-regulated splicing
using RNA sequence and cellular context. Bioinformatics ,27(18), 2554–2562. 227
Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R. S., and Bengio,
Y. (2015). Show, attend and tell: Neural image caption generation with visual attention. In
ICML’2015, arXiv:1502.03044 .90,348,590
Yildiz, I. B., Jaeger, H., and Kiebel, S. J. (2012). Re-visiting the echo state property. Neural
networks ,35, 1–9. 345
Yosinski, J., Clune, J., Bengio, Y., and Lipson, H. (2014). How transferable are features in deep
neural networks? In NIPS 27 , pages 3320–3328. Curran Associates, Inc. 276,455
Younes, L. (1998). On the convergence of Markovian stochastic algorithms with rapidly decreas-
ing ergodicity rates. In Stochastics and Stochastics Models , pages 177–228. 520
Yu, D., Wang, S., and Deng, L. (2010). Sequential labeling using deep-structured conditional
random ﬁelds. IEEE Journal of Selected Topics in Signal Processing .275
Zaremba, W. and Sutskever, I. (2014). Learning to execute. arXiv 1410.4615. 279
Zaremba, W. and Sutskever, I. (2015). Reinforcement learning neural Turing machines.
arXiv:1505.00521 .357
Zaslavsky, T. (1975). Facing Up to Arrangements: Face-Count Formulas for Partitions of Space
by Hyperplanes . Number no. 154 in Memoirs of the American Mathematical Society. American
Mathematical Society. 468DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
参考文献 677
Zeiler, M. D. and Fergus, R. (2014). Visualizing and understanding convolutional networks. In
ECCV’14 .5
Zeiler, M. D., Ranzato, M., Monga, R., Mao, M., Yang, K., Le, Q., Nguyen, P., Senior, A.,
Vanhoucke, V., Dean, J., and Hinton, G. E. (2013). On rectiﬁed linear units for speech
processing. In ICASSP 2013 .390
Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. (2015). Object detectors emerge
in deep scene CNNs. ICLR’2015, arXiv:1412.6856. 469
Zhou, J. and Troyanskaya, O. G. (2014). Deep supervised and convolutional generative stochastic
network for protein secondary structure prediction. In ICML’2014 .609
Zhou, Y. and Chellappa, R. (1988). Computation of optical ﬂow using a neural network. In
Neural Networks, 1988., IEEE International Conference on , pages 71–78. IEEE. 289
Zöhrer, M. and Pernkopf, F. (2014). General stochastic networks for classiﬁcation. In NIPS’2014 .
609DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语
绝对值整流 absolute value rectiﬁcation 166,167,172
准确率 accuracy 91,359,371–374
声学 acoustic 391
激活函数 activation function 147,244,256,257,259,270–272,276,277
AdaGrad AdaGrad 260,261
对抗 adversarial 463
对抗样本 adversarial example 229,230
对抗训练 adversarial training 229,230,232,473
几乎处处 almost everywhere 64
几乎必然 almost sure 114
几乎必然收敛 almost sure convergence 114
选择性剪接数据集 alternative splicing dataset 455
原始采样 Ancestral Sampling 493,494,506,512,556,564,568,590,605,609
退火重要采样 annealed importance sampling 532–536,565,570,611
专用集成电路 application-speciﬁc integrated circuit 383
近似贝叶斯计算 approximate Bayesian computation 610
近似推断 approximate inference 489,496,498,538–541,555–557
架构 architecture 170
人工智能 artiﬁcial intelligence 1–4,6–10,16,17,21,47,49,136,138,141,278,361,376,384,
410,415,443,461,470,471,475,613
人工神经网络 artiﬁcial neural network 12,13,20,21,376
渐近无偏 asymptotically unbiased 109
678DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 679
异步随机梯度下降 Asynchoronous Stochastic Gradient Descent 379
异步 asynchronous 239
注意力机制 attention mechanism 312,338,357,381,382,403,404,595
属性 attribute 410
自编码器 autoencoder xv,4,20,21,168,232,233,244,259,292,300–302,321,372,419,424,
425,427–441,444–447,449,451,452,463,473,513,520,527,550,557,594,595,600,
605–607
自动微分 automatic diﬀerentiation 191
自动语音识别 Automatic Speech Recognition 389,390
自回归网络 auto-regressive network 591,601,602,604,605
反向传播 back propagate 424
反向传播 back propagation 147,175,405,428,529,559,574–576,584–587,591,593–595,609
回退 back-oﬀ 477
反向传播 backprop 153,175,181,182,185,187,188,383,384
通过时间反向传播 back-propagation through time 325–327,585
反向传播 backward propagation 256–258,270,325,327,328,344–346,353,354,357
词袋 bag of words 400
Bagging bootstrap aggregating 219–222,224,228
bandit bandit 408
批量 batch vii,236–238,250–252,255,260,272
批标准化 batch normalization 229,270–272,361,454,455
贝叶斯误差 Bayes error 102,103,359
贝叶斯规则 Bayes’ rule 63,64,119,462,464,534
贝叶斯推断 Bayesian inference 87,121,122,449
贝叶斯网络 Bayesian network 479,482,495,565
贝叶斯概率 Bayesian probability 49
贝叶斯统计 Bayesian statistics 118
基准 bechmark 106,359
信念网络 belief network 21,479,591,602
Bernoulli 分布 Bernoulli distribution 56,61,157–159,368,434,547,569,572,592DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
680 术语
基准 baseline 361,362,374
BFGS BFGS 269
偏置 bias in aﬃne function 96,198,201,242,256,259,325,333,349–353,370,395,407,545,
546,558,563,564,566,570,571,574,578,579,581,584
偏差 bias in statistics 196,197,264,399
有偏 biased 239,247
有偏重要采样 biased importance sampling 399,504
偏差 biass 114
二元语法 bigram 392,399
二元关系 binary relation 409
二值稀疏编码 binary sparse coding 545–550
比特 bit66
块坐标下降 block coordinate descent 273
块吉布斯采样 block Gibbs Sampling 499,509,562
玻尔兹曼分布 Boltzmann distribution 484
玻尔兹曼机 Boltzmann Machine 247,259,292,484,485,499,512,519,558–560,566,570,574,
575,577,578,583–585,595,606
Boosting Boosting 221,228
桥式采样 bridge sampling 532,535,536
广播 broadcasting 29
磨合 Burning-in 508,517–519,521,522,570,572
变分法 calculus of variations 155,543,544,550,553,554
容量 capacity 98,99,101,104,106,114,214,221,236,358,363–366,380,381,393,400,401,
429,430,432,433,435,439,440,469,522,527
级联 cascade 381,383
灾难遗忘 catastrophic forgetting 167
范畴分布 categorical distribution 56,368
因果因子 causal factor 465,469,471,472
因果模型 causal modeling 53
中心差分 centered diﬀerence 372DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 681
中心极限定理 central limit theorem 58,503
链式法则 chain rule 53,76,524
混沌 chaos 257
弦chord 491,492
弦图 chordal graph 492
梯度截断 clip gradient 164
截断梯度 clipping the gradient 352
团clique 481–485,490–493,495,496,538,542,564
团势能 clique potential 481,483,484
闭式解 closed form solution 205,419,421
级联 coalesced 378,382
编码 code 428–430,432–434,444,446,447
协同过滤 collaborative ﬁltering 406,407
列column 28
列空间 column space 33
共因 common cause 488
完全图 complete graph 490
复杂细胞 complex cell 311
计算图 computational graph 176,246,319–321,327–329,340,354,497,575,595,602
计算机视觉 Computer Vision 217,362,376,383–385,388,420,469
概念漂移 concept drift 456,457
条件计算 conditional computation 381
条件概率 conditional probability 52,53,64,69,523
条件独立的 conditionally independent 53,417,480,486,487,491
共轭 conjugate 267
共轭方向 conjugate directions 266
共轭梯度 conjugate gradient 266–269
联结主义 connectionism 12,13,15,16,19,376,558
一致性 consistency 114
约束优化 constrained optimization 82,83,85,219,484DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
682 术语
特定环境下的独立 context-speciﬁc independences 487
contextual bandit contextual bandit 408,409
延拓法 continuation method 277,278
收缩 contractive 345,444–446
收缩自编码器 contractive autoencoder 433,437,439,441,444,445,605,606
对比散度 contrastive divergence 247,437,518–522,526,528,563,564,570,573,574,579–581,
585,607
凸优化 Convex optimization 82,240–242,260,273
卷积 convolution 280,281,449,498
卷积玻尔兹曼机 Convolutional Boltzmann Machine 292
卷积玻尔兹曼机 convolutional Boltzmann machine 583
卷积网络 convolutional net 471
卷积网络 convolutional network 20,21,144,174,241,245,280,281,284,286,287,289,292–296,
298,300,301,303,305–313,316–318,336,337,359,361,362,374,378,390,394,401,402,
407,455,468,469,582,583,593,600,603
卷积神经网络 convolutional neural network 145,217,228,280,283,284,289,294,305
坐标上升 coordinate ascent 540,542,571
坐标下降 coordinate descent 273
共父 coparent 538,546
相关系数 correlation 55
代价 cost 119,134,242–245,247,251,256,359,360,364,369,454,505
代价函数 cost function 26,74,76,78,87,104,115,116,132–134,152,200,202,203,207,208,
213,214,230,234–236,241–248,250,251,254,268,270,271,273,274,277,278,352,359,
364,374,412,420,422,432,436,437,452,464,505,523,574,587,600
协方差 covariance 55,60,201,219,426
协方差矩阵 covariance matrix 55,58,60,417,426
协方差 RBM covariance RBM 579,580
覆盖 coverage 360,374
准则 criterion 74,209,250,253,255,261–264,266,268,321,326,344,400,434,436–438,445,
446,574,585,593,595,607,609
临界点 critical point 74–77,79–82,241–244,248,249,265,452,550,552DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 683
临界温度 critical temperatures 513
互相关函数 cross-correlation 282
交叉熵 cross-entropy 68,116,153–156,188,189,191,194,329,332,395,396
累积函数 cumulative function 503
课程学习 curriculum learning 278,279,326
维数灾难 curse of dimensionality 135,136,138,393,394,467,472,602
曲率 curvature 78–81,99,200,241,252,265
控制论 cybernetics 12,13
衰减 damping 550
数据生成分布 data generating distribution 97,235,239,240,250
数据生成过程 data generating process 97,448
数据并行 data parallelism 379
数据点 data point 92
数据集 dataset 87,92–95,97,98,101,104,106,107,113–115,118,119,125,128,131,133,134,
141
数据集增强 dataset augmentation 385,388
决策树 decision tree 125,127,381–383,465
解码器 decoder 4,337,338,401–403,416,419,420,422–426,428–430,433–435,438–440,446,
468,594
分解 decompose 38
深度信念网络 deep belief network 17,21,309,451,471,519,535,537,561,563–565,567,568,
571,583,590,608
深度玻尔兹曼机 Deep Boltzmann Machine xiv,20,21,451,512,519,522,525,526,537,538,
550,556,561,563,565–576,583,608
深度回路 deep circuit 471
深度前馈网络 deep feedforward network 145,147,390,416,427
深度生成模型 deep generative model 451
深度学习 deep learning 1,4,5,7,10–15,17,18,22–24,26,73,74,76,79,82,87–89,92,93,
100,105,125,128,132,133,135–138,141,144,196,197,209–211,229,234,236,238,
247,250,255,260,261,265,268,269,274,344,357,361,363,370,373,376,378,380,
382–385,389–391,406,407,409,411,414,415,443,447,455,457,461,465,471,473–475,
483,495–498,500,505,506,509,515,517,520,525,537,538,541,542,554DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
684 术语
深度模型 deep model 93,234,235,240,242,244,256,262,276,451,521,525
深度网络 deep network 144,210,257,271,277,470
信任度 degree of belief 49
去噪 denoising 90,92,432,436,437,439,444,475,527
去噪自编码器 denoising autoencoder xv,206,432,433,435–439,441,444,453,456,587,605–
610
去噪得分匹配 denoising score matching 437,527
依赖 dependency 473,475,487,491,495
深度 depth 145
导数 derivative 74,76,77,81,86
描述 description 70
设计矩阵 design matrix 93–95,129
细致平衡 detailed balance 607
探测级 detector stage 289
确定性 deterministic 237
对角矩阵 diagonal matrix 36
微分熵 diﬀerential entropy 67,551
微分方程 diﬀerential equation 254
降维 dimensionality reduction 405,428,447
Dirac delta 函数 Dirac delta function 59
Dirac分布 dirac distribution 59,60,527,541,542,552,553
有向 directed 69
有向图模型 directed graphical model 330,333,417,461,479–481,490,493,494,590,602
有向模型 Directed Model 480,481,484,487,489–491,494,506,537,556,564,565,593
方向导数 directional derivative 76,77
判别RBM discriminative RBM 452
判别器网络 discriminator network 596
分布式表示 distributed representation 16,138,227,393–395,403,405–407,409–411,443,448,
458,465–470,472,497,498
深度神经网络 DNN 246,260,261,264,270,272,380,383,390,449–452,470,565
领域自适应 domain adaption 456DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 685
点积 dot product 30,35,123,124
双反向传播 double backprop 232,473
双重分块循环矩阵 doubly block circulant matrix 283,306
降采样 downsampling 292,297
Dropout Dropout 207,221–229,251,256,361,363,365,366,380,382,390,454,455,573,575,
587,599
Dropout Boosting Dropout Boosting 227,228
d-分离 d-separation 487,489
动态规划 dynamic programming 187
动态结构 dynamic structure 381,382
提前终止 early stopping 211–216,236,257,361,453,454
回声状态网络 echo state network 21,344–347
有效容量 eﬀective capacity 100
特征分解 eigendecomposition 37–39
特征值 eigenvalue 37
特征向量 eigenvector 37
基本单位向量 elementary basis vectors 484
元素对应乘积 element-wise product 30
嵌入 embedding 441,442
经验分布 empirical distribution 59,60,235,237,527
经验频率 empirical frequency 59
经验风险 empirical risk 235
经验风险最小化 empirical risk minimization 235,236
编码器 encoder 4,337,338,401–403,420,423–426,428–431,433–439,441,442,444,446,450,
557,594,595
端到端的 end-to-end 358,361,362,373,391,495
能量函数 energy function 484,485,498,499,510,517,558–560,565,566,574,577–582,585
基于能量的模型 Energy-based model 484–486,498,505,506,509,510,512,513,558,560,565,
582
集成 ensemble 196,219–222,224–226,228,380,401,449DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
686 术语
集成学习 ensemble learning 419
轮epoch 241,373
轮数 epochs 212
等式约束 equality constraint 83,84
均衡分布 Equilibrium Distribution 507,508
等变 equivariance 285
等变表示 equivariant representations 284
误差条 error bar 103
误差函数 error function 74
误差度量 error metric 358,359
错误率 error rate 91,359,360,365
估计量 estimator 108–115,196,455,467,519,522
欧几里得范数 Euclidean norm 34
欧拉-拉格朗日方程 Euler-Lagrange Equation 551
证据下界 evidence lower bound 538,539,542,543,547,564
样本 example 13,23,88,90–95,97,99,100,102,106,107,109,110,112–119,123–125,128,
129,131–133,135–138,141,209
额外误差 excess error 251,255
期望 expectation 54,56
期望最大化 expectation maximization 418,540–543,594
E步expectation step 540
期望值 expected value 54
经验 experience, E 87,88,92,94,95
专家网络 expert network 382
相消解释 explaining away 537,549,564
相消解释作用 explaining away eﬀect 488
解释因子 explanatory factort 462,470,472,473
梯度爆炸 exploding gradient 247
开发 exploitation 408,409
探索 exploration 408,409DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 687
指数分布 exponential distribution 58
因子 factor 481–483,485,492,493,558,584
因子分析 factor analysis 417,419,425
因子图 factor graph 492,493
因子 factorial 416,424,425,500,543,550,561,562,567,568
分解 factorization 69,70
分解的 factorized 473
变差因素 factors of variation 4,6,173,469,471,472
快速Dropout fast dropout 227
快速持续性对比散度 fast persistent contrastive divergence 523
可行 feasible 83,84,86
特征 feature 88,92–96,98,99,104,123–125,128–131
特征提取器 feature extractor 421,424,452,468,542
特征映射 feature map 281,388
特征选择 feature selection 203
反馈 feedback 145
前向 feedforward 145
前馈分类器 feedforward classiﬁer 463
前馈网络 feedforward network 145–150,156,168,169,171,173,193–195,244,246,247,258,
275,318,320,329,333,336,343,346,360,361,428,431,433,434,436,448,449,463,
464,471,473,592
前馈神经网络 feedforward neural network 145–148,151,153,165,171,175,245,433
现场可编程门阵列 ﬁeld programmable gated array 383
精调 ﬁne-tune 450,451,454,519
精调 ﬁne-tuning 274,275,424,564
有限差分 ﬁnite diﬀerence 372
第一层 ﬁrst layer 145
不动点方程 ﬁxed point equation 544,548,549,553,555,556,568,571
定点运算 ﬁxed-point arithmetic 377
翻转 ﬂip282DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
688 术语
浮点运算 ﬂoat-point arithmetic 377
遗忘门 forget gate 349–351
前向模式累加 forward mode accumulation 192
前向传播 forward propagation 175,182,183,256–258,284,300,301,308,324,325,337,345,
348
傅立叶变换 Fourier transform 307,308
中央凹 fovea 312
自由能 free energy 486
频率派概率 frequentist probability 49
频率派统计 frequentist statistics 118
Frobenius 范数 Frobenius norm 35,41,44,45
F分数 F-score 360
全full296
泛函 functional 155,550–554
泛函导数 functional derivative 550–553
Gabor函数 Gabor function 313–316
Gamma 分布 Gamma distribution 580
门控 gated 348–351,354
门控循环网络 gated recurrent net 361
门控循环单元 gated recurrent unit 348,350,361
门控RNN gated RNN 348,350
选通器 gater 382
高斯分布 Gaussian distribution xx,57,58,60,68,154,156,162,164,294,417,425,553,554,
577,579,580,586,587,594,599,601
高斯核 Gaussian kernel 124,465
高斯混合模型 Gaussian Mixture Model 60,61,389,390,495
高斯混合体 Gaussian mixtures 465
高斯输出分布 Gaussian output distribution 155
高斯RBM Gaussian RBM 578–580
Gaussian-Bernoulli RBM Gaussian-Bernoulli RBM xiv,577–579DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 689
通用GPU general purpose GPU 378
泛化 generalization 97,99,136,137,146–149,151,171,174,194,196,197,256,276,363,380,
385,388,424,456–458,464,467,468,471
泛化误差 generalization error 97,100–102,114,235,238–240,249,251,256,258,260,361,
363–366,424
泛化 generalize 256,456–458,467–469,472,591,602,605
广义函数 generalized function 59
广义Lagrange 函数 generalized Lagrange function 83,84,203
广义Lagrangian generalized Lagrangian 83,85
广义伪似然 generalized pseudolikelihood 524,525,575
广义伪似然估计 generalized pseudolikelihood estimator 524
广义得分匹配 generalized score matching 526,527
生成式对抗框架 generative adversarial framework 464
生成式对抗网络 generative adversarial network 463,464,512,530,591,596–600
生成模型 generative model 384,416,418,419,421,424,425,427,430–432,439,452,463,464,
469,470,497,512,514,530,536,556–558,563–565,584,586,590,591,593,595,599,
610–613
生成式建模 generative modeling 593,594,596,601,609–612
生成矩匹配网络 generative moment matching network 599,600
生成随机网络 generative stochastic network xv,430,606–610
生成器网络 generator network 591–594,596,598–600
吉布斯分布 Gibbs distribution 483
Gibbs采样 Gibbs Sampling 494,498–500,509–512,514,521,526,564,567,569,572,575,580,
581
吉布斯步数 Gibbs steps 518,520,522,572
全局对比度归一化 Global contrast normalization 386–388
全局极小值 global minima 244,245
全局最小点 global minimum 75,76,82,85,242,243,248,278
梯度 gradient 76–78,82,83,85,86,198–200,202,204,213,214,322,325–329,342,343,345,
346,348,351–357,437,438
梯度上升 gradient ascent 547DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
690 术语
梯度截断 gradient clipping 245,247,257,353,354
梯度下降 gradient descent 74,75,77–83,85,123,132–134,204,205,214,221,236,237,241,
244–246,248,250–254,257,258,265,271–273,353,364,370,379,380,404,420,428,436,
446,452,469,510,540,544,548,576,588,593
图模型 graphical model 69,330–333,395,474,475,478,480,486,487,490,493–498,500,537,
542,543,549,550,553,558,560,561,565,566,590,602
图形处理器 Graphics Processing Unit 238,377–379,382,383
贪心 greedy 450,451
贪心算法 greedy algorithm 274,450
贪心逐层预训练 greedy layer-wise pretraining 309,571,574,575
贪心逐层训练 greedy layer-wise training 571
贪心逐层无监督预训练 greedy layer-wise unsupervised pretraining 449–451
贪心监督预训练 greedy supervised pretraining 274,275
贪心无监督预训练 greedy unsupervised pretraining 451,573
网格搜索 grid search 367–369
Hadamard 乘积 Hadamard product xix,30
汉明距离 Hamming distance 527
硬专家混合体 hard mixture of experts 382
硬双曲正切函数 hard tanh 170
簧风琴 harmonium 498,560
哈里斯链 Harris Chain 508
Helmholtz 机Helmholtz machine 430,591
Hessian Hessian xix,78–82,199,200,202,203,214,238,241,243,245,247,252,265–267,269,
270,278,351,452,453,574
异方差 heteroscedastic 162
隐藏层 hidden layer 5,13,146–148,150,165,170–172,184,188,190,195,223,270,271,274–
277,300,323,428,433,439,445,447,448,470,471,526,537,560–570,572,579,590,
603,605,609
隐马尔可夫模型 Hidden Markov Model 389–391DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 691
隐藏单元 hidden unit vi,5,15,16,20,21,148,154,156,165,166,168–172,175,190,194,
205–207,210,214,217,219,221–223,225,228,229,242,256,259,272,294,299,320,
322–326,328,331,333,334,338,344,347–349,351,362,364–367,373,381,382,386,404,
420,433,436,444,445,465,468–471,491,495,498,499,509,516,519,521,526,538,
540,542,545,546,549,559–561,564–570,574,577–581,583–585,591,593,601,603–605,
612
隐藏变量 hidden variable 525,537
爬山 hill climbing 77
超参数 hyperparameter 252,253,258,260–263,358,362–370,374,454
超参数优化 hyperparameter optimization 367
假设空间 hypothesis space 98
同分布的 identically distributed 97
可辨认的 identiﬁable 242
单位矩阵 identity matrix xvii,31
独立同分布假设 i.i.d. assumption 97
病态 ill conditioning 241
不道德 immorality 490,491
重要采样 Importance Sampling 399,400,503–505,531–535,591,595
相互独立的 independent 53,97
独立成分分析 independent component analysis 417–421
独立同分布 independent identically distributed 502,530
独立子空间分析 independent subspace analysis 420
索引 index of matrix 27,28
指示函数 indicator function 58
不等式约束 inequality constraint 83–85
推断 inference xiv,2,207,224,226–228,392,393,414,430,431,496,541,558,559,564,
566–570,572–576,581,585,591–595,597,599,604,605,612
无限 inﬁnite 455
信息检索 information retrieval 447
内积 inner product 123
输入 input 281,452DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
692 术语
输入分布 input distribution 452,453,456
干预查询 intervention query 53
不变 invariant 290
求逆 invert 578
Isomap Isomap 455
各向同性 isotropic 58,61
Jacobian Jacobian xix,77,78,176,178,180,183,185,186,232,277,328,342,344,345,372,
420,444,445
Jacobian 矩阵 Jacobian matrix 65,178,191,192
联合概率分布 joint probability distribution 50,52,53,69,558–560,565
Karush–Kuhn–Tucker Karush–Kuhn–Tucker 83–85,203,205
核函数 kernel function 123,281
核机器 kernel machine 124,125,146,209,344,465,563
核方法 kernel method 124
核技巧 kernel trick 123,124,133,146
KL散度 KL divergence 116,218,538,544
知识库 knowledge base 2,410,411
知识图谱 knowledge graph 411
Krylov 方法 Krylov method 193
KL散度 Kullback-Leibler (KL) divergence xx,67,68
标签 label 92,94,124,136,452,458,469,471
标注 labeled 362,363,374,449,453,455,457,458,460,461
拉格朗日乘子 Lagrange multiplier 551,552
语言模型 language model 354,391–393,401,402,405,409,505
Laplace 分布 Laplace distribution 58
大学习步骤 large learning step 543
潜在 latent 163,417,418,425,430,450,462,495,521,559,560,596,598,601,608
潜层 latent layer 560DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 693
潜变量 latent variable xiii,60,163,242,395,416–418,428,430–432,434,451,461,465,471,
485,486,495–498,500,511,513,516,520,526,537,538,540,541,543,544,547,553,
559–561,563–566,575,591,593–595,606,608
大数定理 Law of large number 502
逐层的 layer-wise 450
L-BFGS L-BFGS 269,270
渗漏整流线性单元 Leaky ReLU 166,167,361
渗漏单元 leaky unit 346–348
学成 learned 449,453,457,458,464,466,469,472,473,556,557,591
学习近似推断 learned approximate inference 446
学习器 learner 106,138,239,456,458,462,468,471,472
学习率 learning rate 77,79,133,234,238,241,250,251,253,255,260–263,265,267,270,361,
362,364–367,371,522,523,572,588,590
勒贝格可积 Lebesgue-integrable 516
左特征向量 left eigenvector 37
左奇异向量 left singular vector 40
莱布尼兹法则 Leibniz’s rule 516
似然 likelihood 49
线搜索 line search 77,83,268
线性自回归网络 linear auto-regressive network 601
线性分类器 linear classiﬁer 236,427,448,452,457,466,469
线性组合 linear combination 33
线性相关 linear dependence 33
线性因子模型 linear factor model 416,417,419,420,422,424,425,427,500,542,578
线性模型 linear model 14,197,202,203,205,214,227,230,559,601
线性回归 linear regression 87,94,96–98,100,101,104,108,117–119,121–123,133,134,197,
199–202,204,205,218,227,259,344,427,543,601
线性阀值单元 linear threshold units 468,469
线性无关 linearly independent 33
链接预测 link prediction 411
链接重要采样 linked importance sampling 536DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
694 术语
Lipschitz Lipschitz 82
Lipschitz 常数 Lipschitz constant 82
Lipschitz 连续 Lipschitz continuous 82
流体状态机 liquid state machine 344
局部条件概率分布 local conditional probability distribution 479
局部不变性先验 local constancy prior 136
局部对比度归一化 local contrast normalization 387,388
局部下降 local descent 249
局部核 local kernel 137,465
局部极大值 local maxima 127,244
局部极大点 local maximum 74,75,79,80,243,548
局部极小值 local minima 242–244,248,278,452
局部极小点 local minimum 74–76,79,80,82,212,213,236,242,243,248,254,452
对数尺度 logarithmic scale 367,368
逻辑回归 logistic regression 2,6,123,146,153,155,177,197,205,230,309,361,366,396,529,
559,599,601
logistic sigmoid logistic sigmoid vi,61,62,122,157,159,168,171
分对数 logit 63,158
对数线性模型 log-linear model 485
长短期记忆 long short-term memory ix,16,22,259,277,348–352,354,355,357,361,391
长期依赖 long-term dependency 246,340,342–344,346,347,350,354
环loop 491,492
环状信念传播 loopy belief propagation 497,498
损失 loss91,116,132,527,575
损失函数 loss function 74,107,134,218,235,236,244,247,248,252,277,324–326,354,364,
395,400,421,429,430,432,434,446,584,586,601
机器学习 machine learning 2,3,7,10,12–18,20,24,26,72,86–95,97–100,102,104,105,108,
112,113,118,119,123,126,132,134,135,138,139,141,196,203,205–207,219–221,231,
233–236,239,240,250,251,259,278,318,352,358–363,370,371,373,376,377,379–381,
400,406,407,409,410,428,439,442,448,452,457,472,473,475,485,489,495,497,
501,505,517,518,541,550,551,556DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 695
机器学习模型 machine learning model 451
机器翻译 machine translation 361,458
主对角线 main diagonal 29
流形 manifold 139,141,142,232,425,426,437–445,472,473,495,510,512,596
流形假设 manifold hypothesis 140
流形学习 manifold learning 139,433,441–443,596
边缘概率分布 marginal probability distribution 52
马尔可夫链 Markov Chain xv,505–513,517–523,526,533,565,568,570,572,606–609
马尔可夫链蒙特卡罗 Markov Chain Monte Carlo 414,503,505,506,508,510,512,517–519,
523,527,533,562,568,574,605,608–610
马尔可夫网络 Markov network 481,485,495,499
马尔可夫随机场 Markov random ﬁeld 481,485
掩码 mask 221–224,227,228
矩阵 matrix 28
矩阵逆 matrix inversion 31,32
矩阵乘积 matrix product 29
最大范数 max norm 35
池pool 290,292,293
最大池化 max pooling 289–292,300,468,601
极大值 maxima 243,244
M步maximization step 540,541
最大后验 Maximum A Posteriori v,121,122,203,391,431,541–543,557,581
最大似然 maximum likelihood 419,423,515,544,545
最大似然估计 maximum likelihood estimation 115–119,121,122,134,237,392,519,524,528,
542,544
最大平均偏差 maximum mean discrepancy 600
maxout maxout 212,242,258,277,291,316,361
maxout 单元 maxout unit 167,172,316,364
平均绝对误差 mean absolute error 156
均值和协方差 RBM mean and covariance RBM 579–582
学生 t分布均值乘积 mean product of Student t-distribution 579–582DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
696 术语
均方误差 mean squared error 95,96,103,104,113,116–118,120,129,148,154–156,158,194,
344,421,429,434,436,463,464,589,594,607
均值-协方差 RBM mean-covariance restricted Boltzmann machine 485
均匀场 meanﬁeld 21,567–569,571–573,575,576,583,591,595,604
均值场 mean-ﬁeld 543–550,553,556,557
测度论 measure theory 64
零测度 measure zero 64
记忆网络 memory network 355,357,411
信息传输 message passing 550
小批量 minibatch vii,132,183,188,190,220–222,236–240,247,250–253,255,258,260–264,
269,271,319,352,353,373,379,382,428,435,452,501,508,518,520,522,540,572,576
小批量随机 minibatch stochastic 238
极小值 minima 244,248
极小点 minimum 249,250,552
混合 Mixing 510–514,520–523
混合时间 Mixing Time 508,509
混合密度网络 mixture density network 163
混合分布 mixture distribution 59
专家混合体 mixture of experts 382,465
模态 modality 459
峰值 mode xiii,510–514,519,521–523,550
模型 model 451
模型平均 model averaging 219–221
模型压缩 model compression 380
模型可辨识性 model identiﬁability 242
模型并行 model parallelism 379
矩moment 599,600,610
矩匹配 moment matching 599,610
动量 momentum 252–255,260,262,263,276,361
蒙特卡罗 Monte Carlo 226,399,501–503,505,514,517,523,531,556,580,588,594
Moore-Penrose 伪逆 Moore-Penrose pseudoinverse xix,41,99,105DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 697
道德化 moralization 490,491
道德图 moralized graph 490,491
多层感知机 multilayer perceptron 5,20,21,145,187–189,194,274,275,297,339,340,402,439,
470,559,564,565,567,568,573,574,585
多峰值 multimodal 532,549,610
多模态学习 multimodal learning 459
多项式分布 multinomial distribution 56
Multinoulli 分布 multinoulli distribution 56,59,60,73,159,163
多预测深度玻尔兹曼机 multi-prediction deep Boltzmann machine 574–576,595,606
多任务学习 multitask learning 209,210,456,457
多维正态分布 multivariate normal distribution 58,417,511
朴素贝叶斯 naive Bayes 2
奈特 nats 66
自然语言处理 Natural Language Processing 245,362,376,391,394,395,405,406,409,454
最近邻 nearest neighbor 137,449,465–467
最近邻图 nearest neighbor graph 442
最近邻回归 nearest neighbor regression 101,125
负定 negative deﬁnite 38
负部函数 negative part function 63
负相 negative phase 516–519,521–523,525,526,556,560,570,571
半负定 negative semideﬁnite 38
Nesterov 动量 Nesterov momentum 255
网络 network 145
神经自回归密度估计器 neural auto-regressive density estimator xiv,601,603–605
神经自回归网络 neural auto-regressive network 602–605
神经语言模型 Neural Language Model 393,395,396,398,400,401,405,410
神经机器翻译 Neural Machine Translation 394
神经网络 neural network 12–17,19–23,196–198,204–206,214,217,220,221,223,224,228–231,
233,234,240–249,256,257,260,261,265,266,268,269,272–274,276–279,318,340,348,
355,357,376–378,383,386,389–391,394,395,400,401,404,405,407,410,428,443,446,
451–454,465,469,505,555,586DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
698 术语
神经网络图灵机 neural Turing machine 355,356
牛顿法 Newton’s method 81,82,85,241,242,244,249,265–267,269,273
n-gram n-gram 392,393,395,396,400–402,466,477
没有免费午餐定理 no free lunch theorem 102,105,471
噪声 noise 101,140,238,247,252,278,361,362,452,527–530
噪声分布 noise distribution 528–530
噪声对比估计 noise-contrastive estimation 528–530
非凸 nonconvex 240,242–245,261,265,274,278
非分布式 nondistributed 466–468
非分布式表示 nondistributed representation 465–467
非线性共轭梯度 nonlinear conjugate gradients 268,269
非线性独立成分估计 nonlinear independent components estimation 419,420
非参数 non-parametric 100,393,441–443
范数 norm 34
正态分布 normal distribution 57,58,61,503,552
正规方程 normal equation 96,98,99,133,148
归一化的 normalized 51
标准初始化 normalized initialization 257
数值 numeric value 182
数值优化 numerical optimization 234,241,245
对象识别 object recognition 245,361,363,384,388,389,422,424,458,611
目标 objective 454
目标函数 objective function 74,77,84,196–201,203,204,212,213,216,220,235–237,240,
245–247,249,251,252,264–266,268,273,277,278,352,358,367,373,449,469,524,526,
563,571
奥卡姆剃刀 Occam’s razor 100
one-hot one-hot 125,131,161,193,393,394,453,454,458,465,467,585,602
一次学习 one-shot learning 458
在线 online 237
在线学习 online learning 239DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 699
操作 operation 176
最佳容量 optimal capacity 101,103,114
原点 origin 33
正交 orthogonal 36
正交矩阵 orthogonal matrix 37
标准正交 orthonormal 36,39
输出 output 452
输出层 output layer 145
过完备 overcomplete 430,433,581,582
过估计 overestimation 505
过拟合 overﬁtting 98,99,105,114,196,197,214,236,240,251,257,358,362,364,365,371,
374,380,449,453,454,477,612
过拟合机制 overﬁtting regime 101
上溢 overﬂow 72,73,534
并行分布式处理 Parallel Distributed Processing 194
并行回火 parallel tempering 513,523,536
参数 parameter 94
参数服务器 parameter server 380
参数共享 parameter sharing 217,223,224,228,284,285,287,299,312,318,319,321,322,331,
332,401,600,601,603
有参情况 parametric case 118
参数化整流线性单元 parametric ReLU 167,361
偏导数 partial derivative 76,77,444,550
配分函数 Partition Function 414,483,485,501,505,514,515,517,518,523,524,526–528,
530–536,556,558–560,563,564,570,577,582,583,597
性能度量 performance measures 87,88,91,95,360,361
性能度量 performance metrics 358,359,361,369,371,373,374
置换不变性 permutation invariant 295
持续性对比散度 persistent contrastive divergence 520,522,563,571,574,580,581
音素 phoneme 389–391,456DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
700 术语
语音 phonetic 391
分段 piecewise 361
点估计 point estimator 108
策略 policy 408,409
策略梯度 policy gradient 382
池化 pooling 206,228,280,286,289–294,298,305,308,309,311,312,385,420
池化函数 pooling function 289
病态条件 poor conditioning 74,81,238,241,245,247,249,252,453
正定 positive deﬁnite 38
正部函数 positive part function 63
正相 positive phase 516–519,522,523,556,559,570
半正定 positive semideﬁnite 38
后验概率 posterior probability 60
幂方法 power method 247
PR曲线 PR curve 360
精度 precision 57,360,372,611
精度矩阵 precision matrix 58
预测稀疏分解 predictive sparse decomposition 446
预训练 pretraining 274–277,390,424,450–455,497,520,526
初级视觉皮层 primary visual cortex 310
主成分分析 principal components analysis xi,42–44,128–130,134,209,234,301,387,417–419,
421,423,425–427,429,440,445,447
先验概率 prior probability 60
先验概率分布 prior probability distribution 118,294
概率PCA probabilistic PCA 417–419,425,537,538
概率密度函数 probability density function 51,52,57–59,64,502,550–552,597
概率分布 probability distribution 47,50–56,58–61,65–67,69,70,359,471,515,528,530
概率质量函数 probability mass function 50,51,90,559,570
专家之积 product of expert 485
乘法法则 product rule 53DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 701
成比例 proportional 70
提议分布 proposal distribution 399,531,533–535
伪似然 pseudolikelihood 523–529,570
象限对 quadrature pair 315
量子力学 quantum mechanics 48
径向基函数 radial basis function 124,146,169,470
随机搜索 random search 368–370
随机变量 random variable 49–56,58–60,64,65,67,69,70,471,524,529,533
值域 range 33
比率匹配 ratio matching 526,527,563
召回率 recall 360,381,611
接受域 receptive ﬁeld 286,294
再循环 recirculation 428
推荐系统 recommender system 406–408
重构 reconstruction 428,429,435–438,440,441,444–446,607,608
重构误差 reconstruction error 418,421,425,426,430,432,436,437,439,444,445,447,453,
513,607
整流线性 rectiﬁed linear 151,167,229,242,272,289
整流线性变换 rectiﬁed linear transformation 152
整流线性单元 rectiﬁed linear unit 14,15,150,151,165–172,177,194,195,232,277,361,374,
390,432,454
整流网络 rectiﬁer network 172,173,195
循环 recurrence 449
循环卷积网络 recurrent convolutional network 306
循环网络 recurrent network 145,245–247,306,318–323,325,329,332,337,340,342–346,348,
349,352,353,356,411,416,439,473,549,575,576
循环神经网络 recurrent neural network ix,21,22,144,145,207,227,246,305,317–324,327,
329–340,342–344,347,348,351,354,357,391,402,549,584,585,595
回归 regression 103
正则化 regularization 104,105,118,122,196–205,207,208,211–219,221,226–235,257,354,
358,361,363–365,386–388,420,430,431,433,437,439,445,452,454,471DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
702 术语
正则化 regularize 238,364,420,454,455,513,527,574,583,587
正则化项 regularizer 104,122,126,134,361,451,453,454,466
强化学习 reinforcement learning 23,93,231,382,408,409,457,556,587,589
关系 relation 409–411
关系型数据库 relational database 410
重参数化 reparametrization 574,587
重参数化技巧 reparametrization trick 587,593,609
表示 representation 2–7,16,209,218,219,296,356,366,393,394,402,403,410,429,430,432,
439–441,447
表示学习 representation learning 4,402,416,418,447–449,451,456,457,460–462,465,471–
473,500,513
表示容量 representational capacity 100
储层计算 reservoir computing 344
受限玻尔兹曼机 Restricted Boltzmann Machine 227,300,390,407,436,437,447,449,471,489,
498–500,509,513,514,516,518–522,532,535–537,560–567,570,571,573,574,577,578,
580,582,584,585,590,599,604,608,609
反向相关 reverse correlation 313
反向模式累加 reverse mode accumulation 191
岭回归 ridge regression 198
右特征向量 right eigenvector 37
右奇异向量 right singular vector 40
风险 risk235
行row28
扫视 saccade 312
鞍点 saddle point 75,76,79,80,82,243–245,247,248,265,266
无鞍牛顿法 saddle-free Newton method 244
相同 same 296,297
样本均值 sample mean 110
样本方差 sample variance 110,111
饱和 saturate 61
标量 scalar 27DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 703
得分 score 436–439,525,526
得分匹配 score matching 436,437,444,525–529,605
二阶导数 second derivative 77–80
二阶导数测试 second derivative test 80
第二层 second layer 145
二阶方法 second-order method 244
自对比估计 self-contrastive estimation 530
自信息 self-information 66
语义哈希 semantic hashing 447
半受限波尔兹曼机 semi-restricted Boltzmann Machine 538
半监督 semi-supervised 362,414
半监督学习 semi-supervised learning 208,209,230,449,451,453,461,462,472
可分离的 separable 308,448,452
分离的 separate 472
分离 separation 486,487,494
情景 setting 457,458,468,470
浅度回路 shadow circuit 471
香农熵 Shannon entropy xx,66,67
香农 shannons 66
塑造 shaping 278,559,610
短列表 shortlist 395,396
sigmoid sigmoid 157–161,168,194,277,361,424,510
sigmoid 信念网络 sigmoid Belief Network 590,591
简单细胞 simple cell 310
奇异的 singular 34
奇异值 singular value 39,40
奇异值分解 singular value decomposition 39–41,130,407
奇异向量 singular vector 39
跳跃连接 skip connection 339,340,346,347
慢特征分析 slow feature analysis 420–422,473DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
704 术语
慢性原则 slowness principle 420–422
平滑 smoothing 393
平滑先验 smoothness prior 136
softmax softmax 448
softmax 函数 softmax function 72,73,208,225,226,324,327,371,374,382
softmax 单元 softmax unit 374
softplus softplus 169
softplus 函数 softplus function 61–63,158,169
生成子空间 span 33
稀疏 sparse 202,203,217–219,226,430–433,439
稀疏激活 sparse activation 195
稀疏编码 sparse coding 273,422–425,431,439,446,450,489,491,495,500,526,537,542,543,
550,557,581,582,590
稀疏连接 sparse connectivity 284–286
稀疏初始化 sparse initialization 258
稀疏交互 sparse interactions 284
稀疏权重 sparse weights 284
谱半径 spectral radius 344–346
语音识别 Speech Recognition 361,376,380,389–391,456
sphering sphering 387
尖峰和平板 spike and slab 316,424,425
尖峰和平板 RBM spike and slab RBM 579–582
虚假模态 spurious modes 519,521
方阵 square 34
标准差 standard deviation 54,112,237,271,272,385–388
标准差 standard error 57,111,112,237
标准正态分布 standard normal distribution 57
声明 statement 47,48
平稳的 stationary 332
平稳分布 Stationary Distribution 507–509,511DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 705
驻点 stationary point 74,84
统计效率 statistic eﬃciency 118
统计学习理论 statistical learning theory 97
统计量 statistics 108
最陡下降 steepest descent 246
随机 stochastic 237,238
随机课程 stochastic curriculum 279
随机梯度上升 Stochastic Gradient Ascent 540
随机梯度下降 stochastic gradient descent 14,87,132,133,204,205,215,227,237–241,245,
250–253,255,257,269,276,343,352,353,355,361,379,436,505,517,573,574,588,605
随机矩阵 Stochastic Matrix 507
随机最大似然 stochastic maximum likelihood 520–523,525,527,528,563,564,567,570–573,
575
流stream 239
步幅 stride 286,290,292,293,296,297,300,301,305
结构学习 structure learning 495,497
结构化概率模型 structured probabilistic model 47,69,70,471,474,476,478–481,494,497,558
结构化变分推断 structured variational inference 543
亚原子 subatomic 48
子采样 subsample 501
求和法则 sum rule 52
和-积网络 sum-product network 471
监督 supervised 92,209,210,217,230,235,309,310,316,378,424,439,448–452,454,556,583
监督学习 supervised learning xxi,87,92–94,101,107,116,122,123,125,126,134,140,144,
209,231,235,341,361,396,406,408,409,414,431,448,449,451,452,454–457,461,
462,471,528,593
监督学习算法 supervised learning algorithm 92
监督模型 supervised model 452
监督预训练 supervised pretraining 455
支持向量 support vector 124,465
代理损失函数 surrogate loss function 236,247DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
706 术语
符号 symbol 181
符号表示 symbolic representation 181,465,467
对称 symmetric 36
切面距离 tangent distance 231
切平面 tangent plane 439,442,445
正切传播 tangent prop 231–233
目标 target 92–95,101,102,105,108,116,122,128,134,135,137,138,141
泰勒 taylor 79,81,202,214,241
导师驱动过程 teacher forcing 326,327
温度 temperature 513
回火转移 tempered transition 513
回火 tempering 513
张量 tensor 28
测试误差 test error 97,98,101,103,240,362,364,365,370,371,374,451,453,454
测试集 test set 91,95,97,98,106,107,112,234,236,251,276,362,363,365,371,374,453
碰撞情况 the collider case 488
绑定的权重 tied weights 284
Tikhonov 正则 Tikhonov regularization 198
平铺卷积 tiled convolution 299,300,302,304
时延神经网络 time delay neural network 313,318,390
时间步 time step 167,246,247,264,318–334,338–340,342,345,347–349,351–353,356,391,
403,404,422,576,584,604,608,609
Toeplitz 矩阵 Toeplitz matrix 283
标记 token 391,392,410
容差 tolerance 85,548
地质ICA topographic ICA 420
训练误差 training error 97,98,100–103,235,240,363–365,371,374,453
训练集 training set 97,98,234–240,242,248,250,251,253,255,259,261–264,266,268,273,
276,279,359,361–363,365,366,371,372,374,461,463,467
转录 transcribe 89,91,94DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 707
转录系统 transcription system 358,360,371,373,374
迁移学习 transfer learning 453,455–460,603
转移 transition 321
转置 transpose 29
三角不等式 triangle inequality 34
三角形化 triangulate 492
三角形化图 triangulated graph 492
三元语法 trigram 392
无偏 unbiased 109,239,240,250,502–504,527
无偏样本方差 unbiased sample variance 111
欠完备 undercomplete 429,430
欠定的 underdetermined 551
欠估计 underestimation 505
欠拟合 underﬁtting 98,99,105,114,196–198,240,294,358,364,365,371,372,374,597,612
欠拟合机制 underﬁtting regime 101
下溢 underﬂow 72,73
潜在 underlying 235,236,461–465,469–473
潜在成因 underlying cause 460,462,472
无向 undirected 69
无向模型 undirected Model 481–487,489–492,494,499,501,509,514–517,537,556,563,564,
590
展开图 unfolded graph 321,322,325,391
展开 unfolding 319–321,339,391
均匀分布 uniform distribution 51,52,55,67,164,455
一元语法 unigram 392,399
单峰值 unimodal 513,555
单元 unit 146
单位范数 unit norm 36,43
单位向量 unit vector 36
万能近似定理 universal approximation theorem 171,433DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
708 术语
万能近似器 universal approximator 60,470,471,559
万能函数近似器 universal function approximator 151
未标注 unlabeled 449,453,454,458,460,462,471
未归一化概率函数 unnormalized probability function 482,483,485,492
非共享卷积 unshared convolution 298
无监督 unsupervised 20,21,92,209,217,227,362,390,414,422,424,439,446,448–452,454,
457,458,461,462
无监督学习 unsupervised learning 87,92–94,107,128,134,206,209,210,233,235,362,390,
414,431,442,449–454,456,457,461–463,528,609
无监督学习算法 unsupervised learning algorithm 92
无监督预训练 unsupervised pretraining 449,451–456
有效 valid 283,296,297
验证集 validation set 106,236,241,258,367–369,454
梯度消失与爆炸问题 vanishing and exploding gradient problem 246,247,258
梯度消失 vanishing gradient 247
Vapnik-Chervonenkis 维度 Vapnik-Chervonenkis dimension 100,466,469
变量消去 variable elimination 546
方差 variance 54,56,57,111,196–198,201,205,219
方差减小 variance reduction 588,589
变分自编码器 variational auto-encoder 195,430,505,557,591,593–596,599,605
变分导数 variational derivative 550
变分自由能 variational free energy 538
变分推断 variational inference 496,498,525
去噪 denoise 128,385
向量 vector 27
虚拟对抗样本 virtual adversarial example 230
虚拟对抗训练 virtual adversarial training 451
可见层 visible layer 5
V-结构 V-structure 488,538
醒眠 wake sleep 556,564,591DRAFT仅供学习使用，不得用于商业目的。 https://github.com/exacity/deeplearningbook-chinese
术语 709
warp warp 379,382
支持向量机 support vector machine 123–125,153,309,366,521
无向图模型 undirected graphical model 515,530
权重 weight 94
权重衰减 weight decay 104–106,198–201,204,205,208,212,214,216,217,226,227,242,257,
273,363–366,431,453,523,543
权重比例推断规则 weight scaling inference rule 225–228
权重空间对称性 weight space symmetry 242
条件概率分布 conditional probability distribution 533
白化 whitening 387
宽度 width 146
赢者通吃 winner-take-all 161
正切传播 tangent propagation 473
流形正切分类器 manifold tangent classiﬁer 473
词嵌入 word embedding 362,394,403,405,407,453,458
词义消歧 word-sense disambiguation 411
零数据学习 zero-data learning 458,460
零次学习 zero-shot learning 458–460